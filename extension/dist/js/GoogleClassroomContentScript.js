/*! For license information please see GoogleClassroomContentScript.js.LICENSE.txt */
(()=>{var t={377:(t,e,n)=>{var s=n(832),r=n(652),a=n(801),i=n(30),o=n(91),l=n(49),u=n(971);u.alea=s,u.xor128=r,u.xorwow=a,u.xorshift7=i,u.xor4096=o,u.tychei=l,t.exports=u},832:function(t,e,n){var s;!function(t,r,a){function i(t){var e,n=this,s=(e=4022871197,function(t){t=t.toString();for(var n=0;n<t.length;n++){var s=.02519603282416938*(e+=t.charCodeAt(n));s-=e=s>>>0,e=(s*=e)>>>0,e+=4294967296*(s-=e)}return 2.3283064365386963e-10*(e>>>0)});n.next=function(){var t=2091639*n.s0+2.3283064365386963e-10*n.c;return n.s0=n.s1,n.s1=n.s2,n.s2=t-(n.c=0|t)},n.c=1,n.s0=s(" "),n.s1=s(" "),n.s2=s(" "),n.s0-=s(t),n.s0<0&&(n.s0+=1),n.s1-=s(t),n.s1<0&&(n.s1+=1),n.s2-=s(t),n.s2<0&&(n.s2+=1),s=null}function o(t,e){return e.c=t.c,e.s0=t.s0,e.s1=t.s1,e.s2=t.s2,e}function l(t,e){var n=new i(t),s=e&&e.state,r=n.next;return r.int32=function(){return 4294967296*n.next()|0},r.double=function(){return r()+11102230246251565e-32*(2097152*r()|0)},r.quick=r,s&&("object"==typeof s&&o(s,n),r.state=function(){return o(n,{})}),r}r&&r.exports?r.exports=l:n.amdD&&n.amdO?void 0===(s=function(){return l}.call(e,n,e,r))||(r.exports=s):this.alea=l}(0,t=n.nmd(t),n.amdD)},49:function(t,e,n){var s;!function(t,r,a){function i(t){var e=this,n="";e.next=function(){var t=e.b,n=e.c,s=e.d,r=e.a;return t=t<<25^t>>>7^n,n=n-s|0,s=s<<24^s>>>8^r,r=r-t|0,e.b=t=t<<20^t>>>12^n,e.c=n=n-s|0,e.d=s<<16^n>>>16^r,e.a=r-t|0},e.a=0,e.b=0,e.c=-1640531527,e.d=1367130551,t===Math.floor(t)?(e.a=t/4294967296|0,e.b=0|t):n+=t;for(var s=0;s<n.length+20;s++)e.b^=0|n.charCodeAt(s),e.next()}function o(t,e){return e.a=t.a,e.b=t.b,e.c=t.c,e.d=t.d,e}function l(t,e){var n=new i(t),s=e&&e.state,r=function(){return(n.next()>>>0)/4294967296};return r.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},r.int32=n.next,r.quick=r,s&&("object"==typeof s&&o(s,n),r.state=function(){return o(n,{})}),r}r&&r.exports?r.exports=l:n.amdD&&n.amdO?void 0===(s=function(){return l}.call(e,n,e,r))||(r.exports=s):this.tychei=l}(0,t=n.nmd(t),n.amdD)},652:function(t,e,n){var s;!function(t,r,a){function i(t){var e=this,n="";e.x=0,e.y=0,e.z=0,e.w=0,e.next=function(){var t=e.x^e.x<<11;return e.x=e.y,e.y=e.z,e.z=e.w,e.w^=e.w>>>19^t^t>>>8},t===(0|t)?e.x=t:n+=t;for(var s=0;s<n.length+64;s++)e.x^=0|n.charCodeAt(s),e.next()}function o(t,e){return e.x=t.x,e.y=t.y,e.z=t.z,e.w=t.w,e}function l(t,e){var n=new i(t),s=e&&e.state,r=function(){return(n.next()>>>0)/4294967296};return r.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},r.int32=n.next,r.quick=r,s&&("object"==typeof s&&o(s,n),r.state=function(){return o(n,{})}),r}r&&r.exports?r.exports=l:n.amdD&&n.amdO?void 0===(s=function(){return l}.call(e,n,e,r))||(r.exports=s):this.xor128=l}(0,t=n.nmd(t),n.amdD)},91:function(t,e,n){var s;!function(t,r,a){function i(t){var e=this;e.next=function(){var t,n,s=e.w,r=e.X,a=e.i;return e.w=s=s+1640531527|0,n=r[a+34&127],t=r[a=a+1&127],n^=n<<13,t^=t<<17,n^=n>>>15,t^=t>>>12,n=r[a]=n^t,e.i=a,n+(s^s>>>16)|0},function(t,e){var n,s,r,a,i,o=[],l=128;for(e===(0|e)?(s=e,e=null):(e+="\0",s=0,l=Math.max(l,e.length)),r=0,a=-32;a<l;++a)e&&(s^=e.charCodeAt((a+32)%e.length)),0===a&&(i=s),s^=s<<10,s^=s>>>15,s^=s<<4,s^=s>>>13,a>=0&&(i=i+1640531527|0,r=0==(n=o[127&a]^=s+i)?r+1:0);for(r>=128&&(o[127&(e&&e.length||0)]=-1),r=127,a=512;a>0;--a)s=o[r+34&127],n=o[r=r+1&127],s^=s<<13,n^=n<<17,s^=s>>>15,n^=n>>>12,o[r]=s^n;t.w=i,t.X=o,t.i=r}(e,t)}function o(t,e){return e.i=t.i,e.w=t.w,e.X=t.X.slice(),e}function l(t,e){null==t&&(t=+new Date);var n=new i(t),s=e&&e.state,r=function(){return(n.next()>>>0)/4294967296};return r.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},r.int32=n.next,r.quick=r,s&&(s.X&&o(s,n),r.state=function(){return o(n,{})}),r}r&&r.exports?r.exports=l:n.amdD&&n.amdO?void 0===(s=function(){return l}.call(e,n,e,r))||(r.exports=s):this.xor4096=l}(0,t=n.nmd(t),n.amdD)},30:function(t,e,n){var s;!function(t,r,a){function i(t){var e=this;e.next=function(){var t,n,s=e.x,r=e.i;return t=s[r],n=(t^=t>>>7)^t<<24,n^=(t=s[r+1&7])^t>>>10,n^=(t=s[r+3&7])^t>>>3,n^=(t=s[r+4&7])^t<<7,t=s[r+7&7],n^=(t^=t<<13)^t<<9,s[r]=n,e.i=r+1&7,n},function(t,e){var n,s=[];if(e===(0|e))s[0]=e;else for(e=""+e,n=0;n<e.length;++n)s[7&n]=s[7&n]<<15^e.charCodeAt(n)+s[n+1&7]<<13;for(;s.length<8;)s.push(0);for(n=0;n<8&&0===s[n];++n);for(8==n?s[7]=-1:s[n],t.x=s,t.i=0,n=256;n>0;--n)t.next()}(e,t)}function o(t,e){return e.x=t.x.slice(),e.i=t.i,e}function l(t,e){null==t&&(t=+new Date);var n=new i(t),s=e&&e.state,r=function(){return(n.next()>>>0)/4294967296};return r.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},r.int32=n.next,r.quick=r,s&&(s.x&&o(s,n),r.state=function(){return o(n,{})}),r}r&&r.exports?r.exports=l:n.amdD&&n.amdO?void 0===(s=function(){return l}.call(e,n,e,r))||(r.exports=s):this.xorshift7=l}(0,t=n.nmd(t),n.amdD)},801:function(t,e,n){var s;!function(t,r,a){function i(t){var e=this,n="";e.next=function(){var t=e.x^e.x>>>2;return e.x=e.y,e.y=e.z,e.z=e.w,e.w=e.v,(e.d=e.d+362437|0)+(e.v=e.v^e.v<<4^t^t<<1)|0},e.x=0,e.y=0,e.z=0,e.w=0,e.v=0,t===(0|t)?e.x=t:n+=t;for(var s=0;s<n.length+64;s++)e.x^=0|n.charCodeAt(s),s==n.length&&(e.d=e.x<<10^e.x>>>4),e.next()}function o(t,e){return e.x=t.x,e.y=t.y,e.z=t.z,e.w=t.w,e.v=t.v,e.d=t.d,e}function l(t,e){var n=new i(t),s=e&&e.state,r=function(){return(n.next()>>>0)/4294967296};return r.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},r.int32=n.next,r.quick=r,s&&("object"==typeof s&&o(s,n),r.state=function(){return o(n,{})}),r}r&&r.exports?r.exports=l:n.amdD&&n.amdO?void 0===(s=function(){return l}.call(e,n,e,r))||(r.exports=s):this.xorwow=l}(0,t=n.nmd(t),n.amdD)},971:(t,e,n)=>{var s;!function(r,a){var i,o=this,l=256,u=a.pow(l,6),c=a.pow(2,52),h=2*c,p=255;function d(t,e,n){var s=[],p=y(g((e=1==e?{entropy:!0}:e||{}).entropy?[t,b(r)]:null==t?function(){try{var t;return i&&(t=i.randomBytes)?t=t(l):(t=new Uint8Array(l),(o.crypto||o.msCrypto).getRandomValues(t)),b(t)}catch(t){var e=o.navigator,n=e&&e.plugins;return[+new Date,o,n,o.screen,b(r)]}}():t,3),s),d=new f(s),x=function(){for(var t=d.g(6),e=u,n=0;t<c;)t=(t+n)*l,e*=l,n=d.g(1);for(;t>=h;)t/=2,e/=2,n>>>=1;return(t+n)/e};return x.int32=function(){return 0|d.g(4)},x.quick=function(){return d.g(4)/4294967296},x.double=x,y(b(d.S),r),(e.pass||n||function(t,e,n,s){return s&&(s.S&&m(s,d),t.state=function(){return m(d,{})}),n?(a.random=t,e):t})(x,p,"global"in e?e.global:this==a,e.state)}function f(t){var e,n=t.length,s=this,r=0,a=s.i=s.j=0,i=s.S=[];for(n||(t=[n++]);r<l;)i[r]=r++;for(r=0;r<l;r++)i[r]=i[a=p&a+t[r%n]+(e=i[r])],i[a]=e;(s.g=function(t){for(var e,n=0,r=s.i,a=s.j,i=s.S;t--;)e=i[r=p&r+1],n=n*l+i[p&(i[r]=i[a=p&a+e])+(i[a]=e)];return s.i=r,s.j=a,n})(l)}function m(t,e){return e.i=t.i,e.j=t.j,e.S=t.S.slice(),e}function g(t,e){var n,s=[],r=typeof t;if(e&&"object"==r)for(n in t)try{s.push(g(t[n],e-1))}catch(t){}return s.length?s:"string"==r?t:t+"\0"}function y(t,e){for(var n,s=t+"",r=0;r<s.length;)e[p&r]=p&(n^=19*e[p&r])+s.charCodeAt(r++);return b(e)}function b(t){return String.fromCharCode.apply(0,t)}if(a.seedrandom=d,y(a.random(),r),t.exports){t.exports=d;try{i=n(906)}catch(t){}}else void 0===(s=function(){return d}.call(e,n,e,t))||(t.exports=s)}([],Math)},906:()=>{},993:()=>{},352:()=>{},589:()=>{},758:()=>{}},e={};function n(s){if(e[s])return e[s].exports;var r=e[s]={id:s,loaded:!1,exports:{}};return t[s].call(r.exports,r,r.exports,n),r.loaded=!0,r.exports}n.amdD=function(){throw new Error("define cannot be used indirect")},n.amdO={},n.d=(t,e)=>{for(var s in e)n.o(e,s)&&!n.o(t,s)&&Object.defineProperty(t,s,{enumerable:!0,get:e[s]})},n.g=function(){if("object"==typeof globalThis)return globalThis;try{return this||new Function("return this")()}catch(t){if("object"==typeof window)return window}}(),n.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),n.r=t=>{"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(t,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(t,"__esModule",{value:!0})},n.nmd=t=>(t.paths=[],t.children||(t.children=[]),t),(()=>{"use strict";var t={};n.r(t),n.d(t,{assertParamsValid:()=>wr,computeFlatOffset:()=>Fr,computeOutShape:()=>kr,getNormalizedAxes:()=>Sr,isSliceContinous:()=>Dr,maskToAxes:()=>vr,parseSliceParams:()=>_r,startForAxis:()=>Ar,startIndicesWithElidedDims:()=>Tr,stopForAxis:()=>Rr,stopIndicesWithElidedDims:()=>$r,stridesForAxis:()=>Er,stridesWithElidedDims:()=>Nr});var e={};n.r(e),n.d(e,{collectGatherOpShapeInfo:()=>oi,computeOutShape:()=>ii,segOpComputeOptimalWindowSize:()=>ai});var s={};n.r(s),n.d(s,{ERF_A1:()=>Pl,ERF_A2:()=>Wl,ERF_A3:()=>Vl,ERF_A4:()=>Ul,ERF_A5:()=>Gl,ERF_P:()=>Bl,PARALLELIZE_THRESHOLD:()=>si,SELU_SCALE:()=>zl,SELU_SCALEALPHA:()=>Ll,applyActivation:()=>So,assertAndGetBroadcastShape:()=>Xa,assertAxesAreInnerMostDims:()=>ea,assertParamsConsistent:()=>Ra,assignToTypedArray:()=>Zl,axesAreInnerMostDims:()=>Jr,calculateShapes:()=>Ml,castTensor:()=>eu,combineLocations:()=>Zr,complexWithEvenIndex:()=>Xl,complexWithOddIndex:()=>Yl,computeConv2DInfo:()=>da,computeConv3DInfo:()=>fa,computeDefaultPad:()=>ma,computeDilation2DInfo:()=>ca,computeOptimalWindowSize:()=>ri,computeOutAndReduceShapes:()=>Qr,computeOutShape:()=>Da,computePool2DInfo:()=>ha,computePool3DInfo:()=>pa,convertConv2DDataFormat:()=>ka,eitherStridesOrDilationsAreOne:()=>va,expandShapeToKeepDim:()=>ta,exponent:()=>tu,exponents:()=>Ql,getAxesPermutation:()=>na,getBroadcastDims:()=>qa,getComplexWithIndex:()=>Jl,getFusedBiasGradient:()=>Co,getFusedDyActivation:()=>Io,getImageCenter:()=>Tl,getInnerMostAxes:()=>ra,getPermuted:()=>El,getReductionAxes:()=>Ka,getReshaped:()=>$l,getReshapedPermuted:()=>Al,getSliceBeginCoords:()=>Rl,getSliceSize:()=>Dl,getUndoAxesPermutation:()=>sa,linspaceImpl:()=>su,log:()=>jl,mergeRealAndImagArrays:()=>ql,prepareAndValidate:()=>Fl,prepareSplitSize:()=>so,reshapeTensor:()=>nu,segment_util:()=>e,shouldFuse:()=>To,slice_util:()=>t,splitRealAndImagArrays:()=>Kl,tupleValuesAreOne:()=>wa,upcastType:()=>as,validateInput:()=>Ol,validateUpdateShape:()=>_l,warn:()=>Hl});var r={};n.r(r),n.d(r,{json:()=>up});var a={};n.r(a),n.d(a,{json:()=>cp});var i={};n.r(i),n.d(i,{json:()=>hp});var o={};n.r(o),n.d(o,{json:()=>pp});var l={};n.r(l),n.d(l,{json:()=>dp});var u={};n.r(u),n.d(u,{json:()=>fp});var c={};n.r(c),n.d(c,{json:()=>mp});var h={};n.r(h),n.d(h,{json:()=>gp});var p={};n.r(p),n.d(p,{json:()=>yp});var d={};n.r(d),n.d(d,{json:()=>bp});var f={};n.r(f),n.d(f,{json:()=>xp});var m={};n.r(m),n.d(m,{json:()=>wp});var g={};n.r(g),n.d(g,{json:()=>vp});var y={};n.r(y),n.d(y,{json:()=>kp});var b={};n.r(b),n.d(b,{json:()=>Np});var x={};n.r(x),n.d(x,{json:()=>Ip});var w={};n.r(w),n.d(w,{json:()=>Cp});var v={};n.r(v),n.d(v,{addImpl:()=>Vx,ceilImpl:()=>yw,expImpl:()=>ev,expm1Impl:()=>rv,floorImpl:()=>Iv,logImpl:()=>Mv,maxImpl:()=>Uv,multiplyImpl:()=>ov,notEqualImpl:()=>tk,rsqrtImpl:()=>uk,simpleAbsImpl:()=>Jx,sliceImpl:()=>hv,squaredDifferenceImpl:()=>Fk,subImpl:()=>fv,transposeImpl:()=>Gv,uniqueImpl:()=>Wk});var k={};n.r(k),n.d(k,{CQI:()=>Gr});let N={player:null,video:null,stream:null,ctx:null,canvas:null,model:null};class I{constructor(t,e){this.backend=t,this.dataMover=e,this.data=new WeakMap,this.dataIdsCount=0}get(t){return this.data.has(t)||this.dataMover.moveData(this.backend,t),this.data.get(t)}set(t,e){this.dataIdsCount++,this.data.set(t,e)}has(t){return this.data.has(t)}delete(t){return this.dataIdsCount--,this.data.delete(t)}numDataIds(){return this.dataIdsCount}}class C{time(t){return S("time")}read(t){return S("read")}readSync(t){return S("readSync")}numDataIds(){return S("numDataIds")}disposeData(t){return S("disposeData")}write(t,e,n){return S("write")}move(t,e,n,s){return S("move")}memory(){return S("memory")}floatPrecision(){return S("floatPrecision")}epsilon(){return 32===this.floatPrecision()?1e-7:1e-4}batchMatMul(t,e,n,s){return S("batchMatMul")}fusedBatchMatMul({a:t,b:e,transposeA:n,transposeB:s,bias:r,activation:a,preluActivationWeights:i}){return S("fusedBatchMatMul")}slice(t,e,n){return S("slice")}stridedSlice(t,e,n,s){return S("stridedSlice")}unstack(t,e){return S("unstack")}reverse(t,e){return S("reverse")}concat(t,e){return S("concat")}neg(t){return S("neg")}add(t,e){return S("add")}addN(t){return S("addN")}subtract(t,e){return S("subtract")}multiply(t,e){return S("multiply")}realDivide(t,e){return S("realDivide")}floorDiv(t,e){return S("floorDiv")}sum(t,e){return S("sum")}prod(t,e){return S("prod")}unsortedSegmentSum(t,e,n){return S("unsortedSegmentSum")}argMin(t,e){return S("argMin")}argMax(t,e){return S("argMax")}equal(t,e){return S("equal")}notEqual(t,e){return S("notEqual")}less(t,e){return S("less")}lessEqual(t,e){return S("lessEqual")}greater(t,e){return S("greater")}greaterEqual(t,e){return S("greaterEqual")}logicalNot(t){return S("logicalNot")}logicalAnd(t,e){return S("logicalAnd")}logicalOr(t,e){return S("logicalOr")}where(t){return S("where")}select(t,e,n){return S("select")}topk(t,e,n){return S("topk")}min(t,e){return S("min")}minimum(t,e){return S("minimum")}mod(t,e){return S("mod")}max(t,e){return S("max")}maximum(t,e){return S("maximum")}all(t,e){return S("all")}any(t,e){return S("any")}squaredDifference(t,e){return S("squaredDifference")}ceil(t){return S("ceil")}floor(t){return S("floor")}round(t){return S("round")}sign(t){return S("sign")}isNaN(t){return S("isNaN")}isInf(t){return S("isInf")}isFinite(t){return S("isFinite")}pow(t,e){return S("pow")}exp(t){return S("exp")}expm1(t){return S("expm1")}softmax(t,e){return S("softmax")}log(t){return S("log")}log1p(t){return S("log1p")}sqrt(t){return S("sqrt")}rsqrt(t){return S("rsqrt")}square(t){return S("square")}reciprocal(t){return S("reciprocal")}relu(t){return S("relu")}relu6(t){return S("relu6")}prelu(t,e){return S("prelu")}elu(t){return S("elu")}eluDer(t,e){return S("eluDer")}selu(t){return S("selu")}int(t){return S("int")}clip(t,e,n){return S("clip")}abs(t){return S("abs")}complexAbs(t){return S("complexAbs")}sigmoid(t){return S("sigmoid")}softplus(t){return S("softplus")}sin(t){return S("sin")}cos(t){return S("cos")}tan(t){return S("tan")}asin(t){return S("asin")}acos(t){return S("acos")}atan(t){return S("atan")}atan2(t,e){return S("atan2")}sinh(t){return S("sinh")}cosh(t){return S("cosh")}tanh(t){return S("tanh")}asinh(t){return S("asinh")}acosh(t){return S("acosh")}atanh(t){return S("atanh")}erf(t){return S("erf")}step(t,e){return S("step")}fusedConv2d({input:t,filter:e,convInfo:n,bias:s,activation:r,preluActivationWeights:a}){return S("fusedConv2d")}conv2d(t,e,n){return S("conv2d")}conv2dDerInput(t,e,n){return S("conv2dDerInput")}conv2dDerFilter(t,e,n){return S("conv2dDerFilter")}fusedDepthwiseConv2D({input:t,filter:e,convInfo:n,bias:s,activation:r,preluActivationWeights:a}){return S("fusedDepthwiseConv2D")}depthwiseConv2D(t,e,n){return S("depthwiseConv2D")}depthwiseConv2DDerInput(t,e,n){return S("depthwiseConv2DDerInput")}depthwiseConv2DDerFilter(t,e,n){return S("depthwiseConv2DDerFilter")}conv3d(t,e,n){return S("conv3d")}conv3dDerInput(t,e,n){return S("conv3dDerInput")}conv3dDerFilter(t,e,n){return S("conv3dDerFilter")}maxPool(t,e){return S("maxPool")}maxPoolBackprop(t,e,n,s){return S("maxPoolBackprop")}avgPool(t,e){return S("avgPool")}avgPoolBackprop(t,e,n){return S("avgPoolBackprop")}avgPool3d(t,e){return S("avgPool3d")}avgPool3dBackprop(t,e,n){return S("avgPool3dBackprop")}maxPool3d(t,e){return S("maxPool3d")}maxPool3dBackprop(t,e,n,s){return S("maxPool3dBackprop")}reshape(t,e){return S("reshape")}cast(t,e){return S("cast")}tile(t,e){return S("tile")}pad(t,e,n){return S("pad")}transpose(t,e){return S("transpose")}gather(t,e,n){return S("gather")}gatherND(t,e){return S("gatherND")}scatterND(t,e,n){return S("scatterND")}batchToSpaceND(t,e,n){return S("batchToSpaceND")}spaceToBatchND(t,e,n){return S("spaceToBatchND")}resizeBilinear(t,e,n,s){return S("resizeBilinear")}resizeBilinearBackprop(t,e,n){return S("resizeBilinearBackprop")}resizeNearestNeighbor(t,e,n,s){return S("resizeNearestNeighbor")}resizeNearestNeighborBackprop(t,e,n){return S("resizeNearestNeighborBackprop")}batchNorm(t,e,n,s,r,a){return S("batchNorm")}localResponseNormalization4D(t,e,n,s,r){return S("localResponseNormalization4D")}LRNGrad(t,e,n,s,r,a,i){return S("LRNGrad")}multinomial(t,e,n,s){return S("multinomial")}oneHot(t,e,n,s){return S("oneHot")}cumsum(t,e,n,s){return S("cumsum")}nonMaxSuppression(t,e,n,s,r){return S("nonMaxSuppression")}fft(t){return S("fft")}ifft(t){return S("ifft")}complex(t,e){return S("complex")}real(t){return S("real")}imag(t){return S("imag")}cropAndResize(t,e,n,s,r,a){return S("cropAndResize")}depthToSpace(t,e,n){return S("depthToSpace")}split(t,e,n){return S("split")}sparseToDense(t,e,n,s){return S("sparseToDense")}diag(t){return S("diag")}fill(t,e,n){return S("fill")}onesLike(t){return S("onesLike")}zerosLike(t){return S("zerosLike")}linspace(t,e,n){return S("linspace")}dispose(){return S("dispose")}}function S(t){throw new Error(`'${t}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`)}function T(t){let e=t.length,n=0,s=0;for(;e>0;)s=Math.random()*e|0,e--,n=t[e],t[e]=t[s],t[s]=n}function $(t,e,n){return Math.max(t,Math.min(e,n))}function E(t){return t%2==0?t:t+1}function A(t,e){if(!t)throw new Error("string"==typeof e?e:e())}function R(t,e,n=""){A(O(t,e),(()=>n+` Shapes ${t} and ${e} must match`))}function D(t){A(null!=t,(()=>"The input to the tensor constructor must be a non-null value."))}function F(t,e=[],n=!1){if(null==e&&(e=[]),Array.isArray(t)||j(t)&&!n)for(let s=0;s<t.length;++s)F(t[s],e,n);else e.push(t);return e}function _(t){if(0===t.length)return 1;let e=t[0];for(let n=1;n<t.length;n++)e*=t[n];return e}function O(t,e){if(t===e)return!0;if(null==t||null==e)return!1;if(t.length!==e.length)return!1;for(let n=0;n<t.length;n++)if(t[n]!==e[n])return!1;return!0}function M(t){return t%1==0}function L(t){const e=Math.ceil(Math.sqrt(t));return[e,Math.ceil(t/e)]}function z(t,e){return e<=t.length?t:t+" ".repeat(e-t.length)}function B(t,e=(t=>0),n){return new Promise(((s,r)=>{let a=0;const i=()=>{if(t())return void s();a++;const o=e(a);null!=n&&a>=n?r():setTimeout(i,o)};i()}))}function P(t,e){let n=1,s=-1;for(let e=0;e<t.length;++e)if(t[e]>=0)n*=t[e];else if(-1===t[e]){if(-1!==s)throw Error(`Shapes can only have 1 implicit size. Found -1 at dim ${s} and dim ${e}`);s=e}else if(t[e]<0)throw Error(`Shapes can not be < 0. Found ${t[e]} at dim ${e}`);if(-1===s){if(e>0&&e!==n)throw Error(`Size(${e}) must match the product of shape ${t}`);return t}if(0===n)throw Error(`Cannot infer the missing size in [${t}] when there are 0 elements`);if(e%n!=0)throw Error(`The implicit shape can't be a fractional number. Got ${e} / ${n}`);const r=t.slice();return r[s]=e/n,r}function W(t,e){const n=e.length;return A((t=null==t?e.map(((t,e)=>e)):[].concat(t)).every((t=>t>=-n&&t<n)),(()=>`All values in axis param must be in range [-${n}, ${n}) but got axis `+t)),A(t.every((t=>M(t))),(()=>"All values in axis param must be integers but got axis "+t)),t.map((t=>t<0?n+t:t))}function V(t,e){const n=[],s=[],r=null!=e&&Array.isArray(e)&&0===e.length,a=null==e||r?null:W(e,t).sort();let i=0;for(let e=0;e<t.length;++e){if(null!=a){if(a[i]===e&&1!==t[e])throw new Error(`Can't squeeze axis ${e} since its dim '${t[e]}' is not 1`);(null==a[i]||a[i]>e)&&1===t[e]&&(n.push(t[e]),s.push(e)),a[i]<=e&&i++}1!==t[e]&&(n.push(t[e]),s.push(e))}return{newShape:n,keptDims:s}}function U(t,e){let n=null;if(null==t||"float32"===t)n=new Float32Array(e);else if("int32"===t)n=new Int32Array(e);else{if("bool"!==t)throw new Error("Unknown data type "+t);n=new Uint8Array(e)}return n}function G(t,e){let n=null;if(null==t||"float32"===t)n=new Float32Array(e);else if("int32"===t)n=new Int32Array(e);else if("bool"===t)n=new Uint8Array(e);else{if("string"!==t)throw new Error("Unknown data type "+t);n=new Array(e)}return n}function H(t,e){return!("complex64"===e||"float32"===e&&"complex64"!==t||"int32"===e&&"float32"!==t&&"complex64"!==t||"bool"===e&&"bool"===t)}function j(t){return t instanceof Float32Array||t instanceof Int32Array||t instanceof Uint8Array}function q(t){if("float32"===t||"int32"===t)return 4;if("complex64"===t)return 8;if("bool"===t)return 1;throw new Error("Unknown dtype "+t)}function K(t){return"string"==typeof t||t instanceof String}function X(t){return"number"==typeof t}function Y(t){return Array.isArray(t)?Y(t[0]):t instanceof Float32Array?"float32":t instanceof Int32Array||t instanceof Uint8Array?"int32":X(t)?"float32":K(t)?"string":"boolean"==typeof t?"bool":"float32"}function J(t){return!!(t&&t.constructor&&t.call&&t.apply)}function Z(t,e){for(let n=e;n<t;++n)if(t%n==0)return n;return t}function Q(t){const e=t.length;if(e<2)return[];const n=new Array(e-1);n[e-2]=t[e-1];for(let s=e-3;s>=0;--s)n[s]=n[s+1]*t[s+1];return n}function tt(t,e,n){const s=new Array;if(1===e.length){const r=e[0];for(let e=0;e<r;e++)s[e]=n[t+e]}else{const r=e[0],a=e.slice(1),i=a.reduce(((t,e)=>t*e));for(let e=0;e<r;e++)s[e]=tt(t+e*i,a,n)}return s}function et(t,e){if(0===t.length)return e[0];const n=t.reduce(((t,e)=>t*e));if(0===n)return[];if(n!==e.length)throw new Error(`[${t}] does not match the input size ${e.length}.`);return tt(0,t,e)}function nt(t,e){const n=st(t,e);for(let t=0;t<n.length;t++)n[t]=1;return n}function st(t,e){if(null==e||"float32"===e||"complex64"===e)return new Float32Array(t);if("int32"===e)return new Int32Array(t);if("bool"===e)return new Uint8Array(t);throw new Error("Unknown data type "+e)}function rt(t,e){const n=t.reduce(((t,e)=>t*e),1);if(null==e||"float32"===e)return et(t,new Float32Array(n));if("int32"===e)return et(t,new Int32Array(n));if("bool"===e)return et(t,new Uint8Array(n));throw new Error("Unknown data type "+e)}function at(t){t.forEach((e=>{A(Number.isInteger(e)&&e>=0,(()=>`Tensor must have a shape comprised of positive integers but got shape [${t}].`))}))}function it(t,e,n){if(0===e)return 0;if(1===e)return t[0];let s=t[t.length-1];for(let e=0;e<t.length-1;++e)s+=n[e]*t[e];return s}function ot(t,e,n){if(0===e)return[];if(1===e)return[t];const s=new Array(e);for(let e=0;e<s.length-1;++e)s[e]=Math.floor(t/n[e]),t-=s[e]*n[e];return s[s.length-1]=t,s}function lt(t){return t&&t.then&&"function"==typeof t.then}class ut{constructor(t){this.global=t,this.flags={},this.flagRegistry={},this.urlFlags={},this.populateURLFlags()}setPlatform(t,e){null!=this.platform&&console.warn(`Platform ${this.platformName} has already been set. Overwriting the platform with ${e}.`),this.platformName=t,this.platform=e}registerFlag(t,e,n){if(this.flagRegistry[t]={evaluationFn:e,setHook:n},null!=this.urlFlags[t]){const e=this.urlFlags[t];console.warn(`Setting feature override from URL ${t}: ${e}.`),this.set(t,e)}}async getAsync(t){return t in this.flags||(this.flags[t]=await this.evaluateFlag(t)),this.flags[t]}get(t){if(t in this.flags)return this.flags[t];const e=this.evaluateFlag(t);if(lt(e))throw new Error(`Flag ${t} cannot be synchronously evaluated. Please use getAsync() instead.`);return this.flags[t]=e,this.flags[t]}getNumber(t){return this.get(t)}getBool(t){return this.get(t)}getFlags(){return this.flags}get features(){return this.flags}set(t,e){if(null==this.flagRegistry[t])throw new Error(`Cannot set flag ${t} as it has not been registered.`);this.flags[t]=e,null!=this.flagRegistry[t].setHook&&this.flagRegistry[t].setHook(e)}evaluateFlag(t){if(null==this.flagRegistry[t])throw new Error(`Cannot evaluate flag '${t}': no evaluation function found.`);return this.flagRegistry[t].evaluationFn()}setFlags(t){this.flags=Object.assign({},t)}reset(){this.flags={},this.urlFlags={},this.populateURLFlags()}populateURLFlags(){if(void 0===this.global||void 0===this.global.location||void 0===this.global.location.search)return;const t=function(t){const e={};return t.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g,((t,...n)=>(function(t,e,n){t[decodeURIComponent(e)]=decodeURIComponent(n||"")}(e,n[0],n[1]),n.join("=")))),e}(this.global.location.search);"tfjsflags"in t&&t.tfjsflags.split(",").forEach((t=>{const[e,n]=t.split(":");this.urlFlags[e]=function(t,e){if("true"===(e=e.toLowerCase())||"false"===e)return"true"===e;if(""+ +e===e)return+e;throw new Error(`Could not parse value flag value ${e} for flag ${t}.`)}(e,n)}))}}function ct(){return pt}let ht,pt=null;function dt(){if(null==ht){let t;if("undefined"!=typeof window)t=window;else if(void 0!==n.g)t=n.g;else if("undefined"!=typeof process)t=process;else{if("undefined"==typeof self)throw new Error("Could not find a global object");t=self}ht=t}return ht}function ft(t,e){const n=function(){const t=dt();return null==t._tfGlobals&&(t._tfGlobals=new Map),t._tfGlobals}();if(n.has(t))return n.get(t);{const s=e();return n.set(t,s),n.get(t)}}const mt="Abs",gt="Acos",yt="Acosh",bt="Add",xt="AddN",wt="ArgMax",vt="ArgMin",kt="Asin",Nt="Asinh",It="Atan",Ct="Atanh",St="Atan2",Tt="AvgPool",$t="AvgPoolBackprop",Et="AvgPool3D",At="BatchMatMul",Rt="BatchToSpaceND",Dt="BroadcastTo",Ft="Cast",_t="Ceil",Ot="ClipByValue",Mt="Complex",Lt="Concat",zt="Conv2D",Bt="Conv2DBackpropFilter",Pt="Conv2DBackpropInput",Wt="Conv3D",Vt="Conv3DBackpropFilterV2",Ut="Conv3DBackpropInputV2",Gt="Cos",Ht="Cosh",jt="Cumsum",qt="DepthwiseConv2dNative",Kt="DepthwiseConv2dNativeBackpropFilter",Xt="DepthwiseConv2dNativeBackpropInput",Yt="Dilation2D",Jt="Dilation2DBackpropInput",Zt="Dilation2DBackpropFilter",Qt="Div",te="Elu",ee="Erf",ne="Exp",se="Expm1",re="FFT",ae="Fill",ie="FlipLeftRight",oe="Floor",le="FloorDiv",ue="FusedBatchNorm",ce="GatherV2",he="GreaterEqual",pe="Identity",de="IFFT",fe="Imag",me="IsFinite",ge="IsInf",ye="IsNan",be="Log",xe="Log1p",we="LogicalNot",ve="LogSoftmax",ke="Max",Ne="Maximum",Ie="MaxPool",Ce="MaxPoolBackprop",Se="MaxPool3D",Te="MaxPoolWithArgmax",$e="Mean",Ee="Minimum",Ae="MirrorPad",Re="Multiply",De="Negate",Fe="NotEqual",_e="NonMaxSuppressionV3",Oe="NonMaxSuppressionV4",Me="NonMaxSuppressionV5",Le="OnesLike",ze="OneHot",Be="PadV2",Pe="Prelu",We="Real",Ve="Reciprocal",Ue="Relu",Ge="Reshape",He="ResizeNearestNeighbor",je="ResizeBilinear",qe="Relu6",Ke="Reverse",Xe="Round",Ye="Rsqrt",Je="SelectV2",Ze="Selu",Qe="Slice",tn="Sin",en="Sinh",nn="Sign",sn="Sigmoid",rn="Softplus",an="Sqrt",on="SpaceToBatchND",ln="SplitV",un="Softmax",cn="SquaredDifference",hn="Square",pn="Sub",dn="Tan",fn="Tanh",mn="Tile",gn="Transpose",yn="Unique",bn="Unpack",xn="UnsortedSegmentSum",wn="ZerosLike",vn="Step",kn="FromPixels",Nn="RotateWithOffset",In="_FusedMatMul",Cn="FusedConv2D",Sn="FusedDepthwiseConv2D",Tn=ft("kernelRegistry",(()=>new Map)),$n=ft("gradRegistry",(()=>new Map));function En(t,e){const n=_n(t,e);return Tn.get(n)}function An(t){return $n.get(t)}function Rn(t){const e=Tn.entries(),n=[];for(;;){const{done:s,value:r}=e.next();if(s)break;const[a,i]=r,[o]=a.split("_");o===t&&n.push(i)}return n}function Dn(t){const{kernelName:e,backendName:n}=t,s=_n(e,n);Tn.has(s)&&console.warn(`The kernel '${e}' for backend '${n}' is already registered`),Tn.set(s,t)}function Fn(t){const{kernelName:e}=t;$n.has(e)&&ct().getBool("DEBUG")&&console.warn(`Overriding the gradient for '${e}'`),$n.set(e,t)}function _n(t,e){return`${e}_${t}`}class On{constructor(t,e){this.backendTimer=t,this.logger=e,null==e&&(this.logger=new Ln)}profileKernel(t,e,n){let s;const r=this.backendTimer.time((()=>{s=n()}));for(let e=0;e<s.length;e++){const n=s[e];n.data().then((e=>{Mn(e,n.dtype,t)}))}return{kernelName:t,outputs:s,inputs:e,timeMs:r.then((t=>t.kernelMs)),extraInfo:r.then((t=>null!=t.getExtraProfileInfo?t.getExtraProfileInfo():""))}}logKernelProfile(t){const{kernelName:e,outputs:n,timeMs:s,inputs:r,extraInfo:a}=t;n.forEach((t=>{Promise.all([t.data(),s,a]).then((n=>{this.logger.logKernelProfile(e,t,n[0],n[1],r,n[2])}))}))}}function Mn(t,e,n){if("float32"!==e)return!1;for(let e=0;e<t.length;e++){const s=t[e];if(isNaN(s)||!isFinite(s))return console.warn(`Found ${s} in the result of '${n}'`),!0}return!1}class Ln{logKernelProfile(t,e,n,s,r,a){const i="number"==typeof s?z(s+"ms",9):s.error,o=z(t,25),l=e.rank,u=e.size,c=z(e.shape.toString(),14);let h="";for(const t in r){const n=r[t];if(null!=n){const s=n.shape||e.shape,r=s.length;h+=`${t}: ${r}D ${r>0?s:""} `}}console.log(`%c${o}\t%c${i}\t%c${l}D ${c}\t%c${u}\t%c${h}\t%c${a}`,"font-weight:bold","color:red","color:blue","color: orange","color: green","color: steelblue")}}function zn(t,e,n,s){const r=Q(e),a=function(t,e,n,s){const r=_(e),a=s[s.length-1],i=new Array(a).fill(0),o=e.length,l="complex64"===n?Vn(t):t;if(o>1)for(let t=0;t<r/a;t++){const e=t*a;for(let t=0;t<a;t++)i[t]=Math.max(i[t],Bn(l[e+t],0,n).length)}return i}(t,e,n,r),i=e.length,o=Wn(t,e,n,r,a),l=["Tensor"];return s&&(l.push("  dtype: "+n),l.push("  rank: "+i),l.push(`  shape: [${e}]`),l.push("  values:")),l.push(o.map((t=>"    "+t)).join("\n")),l.join("\n")}function Bn(t,e,n){let s;return s=Array.isArray(t)?parseFloat(t[0].toFixed(7))+" + "+parseFloat(t[1].toFixed(7))+"j":K(t)?`'${t}'`:"bool"===n?Pn(t):parseFloat(t.toFixed(7)).toString(),z(s,e)}function Pn(t){return 0===t?"false":"true"}function Wn(t,e,n,s,r,a=!0){const i="complex64"===n?2:1,o=e[0],l=e.length;if(0===l)return"complex64"===n?[Bn(Vn(t)[0],0,n)]:"bool"===n?[Pn(t[0])]:[t[0].toString()];if(1===l){if(o>20){const e=3*i;let s=Array.from(t.slice(0,e)),a=Array.from(t.slice((o-3)*i,o*i));return"complex64"===n&&(s=Vn(s),a=Vn(a)),["["+s.map(((t,e)=>Bn(t,r[e],n))).join(", ")+", ..., "+a.map(((t,e)=>Bn(t,r[o-3+e],n))).join(", ")+"]"]}return["["+("complex64"===n?Vn(t):Array.from(t)).map(((t,e)=>Bn(t,r[e],n))).join(", ")+"]"]}const u=e.slice(1),c=s.slice(1),h=s[0]*i,p=[];if(o>20){for(let e=0;e<3;e++){const s=e*h,a=s+h;p.push(...Wn(t.slice(s,a),u,n,c,r,!1))}p.push("...");for(let e=o-3;e<o;e++){const s=e*h,a=s+h;p.push(...Wn(t.slice(s,a),u,n,c,r,e===o-1))}}else for(let e=0;e<o;e++){const s=e*h,a=s+h;p.push(...Wn(t.slice(s,a),u,n,c,r,e===o-1))}const d=2===l?",":"";p[0]="["+p[0]+d;for(let t=1;t<p.length-1;t++)p[t]=" "+p[t]+d;let f=",\n";for(let t=2;t<l;t++)f+="\n";return p[p.length-1]=" "+p[p.length-1]+"]"+(a?"":f),p}function Vn(t){const e=[];for(let n=0;n<t.length;n+=2)e.push([t[n],t[n+1]]);return e}function Un(t,e){if("string"===e)throw new Error("Cannot convert a string[] to a TypedArray");if(Array.isArray(t)&&(t=F(t)),ct().getBool("DEBUG")&&function(t,e){for(let n=0;n<t.length;n++){const s=t[n];if(isNaN(s)||!isFinite(s))throw Error(`A tensor of type ${e} being uploaded contains ${s}.`)}}(t,e),function(t,e){return t instanceof Float32Array&&"float32"===e||t instanceof Int32Array&&"int32"===e||t instanceof Uint8Array&&"bool"===e}(t,e))return t;if(null==e||"float32"===e||"complex64"===e)return new Float32Array(t);if("int32"===e)return new Int32Array(t);if("bool"===e){const e=new Uint8Array(t.length);for(let n=0;n<e.length;++n)0!==Math.round(t[n])&&(e[n]=1);return e}throw new Error("Unknown data type "+e)}function Gn(){return ct().platform.now()}function Hn(t,e="utf-8"){return e=e||"utf-8",ct().platform.encode(t,e)}function jn(t,e="utf-8"){return e=e||"utf-8",ct().platform.decode(t,e)}class qn{constructor(t,e,n){if(this.dtype=e,this.shape=t.slice(),this.size=_(t),null!=n){const t=n.length;A(t===this.size,(()=>`Length of values '${t}' does not match the size inferred by the shape '${this.size}'.`))}if("complex64"===e)throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");this.values=n||G(e,this.size),this.strides=Q(t)}set(t,...e){0===e.length&&(e=[0]),A(e.length===this.rank,(()=>`The number of provided coordinates (${e.length}) must match the rank (${this.rank})`));const n=this.locToIndex(e);this.values[n]=t}get(...t){0===t.length&&(t=[0]);let e=0;for(const n of t){if(n<0||n>=this.shape[e]){const e=`Requested out of range element at ${t}.   Buffer shape=`+this.shape;throw new Error(e)}e++}let n=t[t.length-1];for(let e=0;e<t.length-1;++e)n+=this.strides[e]*t[e];return this.values[n]}locToIndex(t){if(0===this.rank)return 0;if(1===this.rank)return t[0];let e=t[t.length-1];for(let n=0;n<t.length-1;++n)e+=this.strides[n]*t[n];return e}indexToLoc(t){if(0===this.rank)return[];if(1===this.rank)return[t];const e=new Array(this.shape.length);for(let n=0;n<e.length-1;++n)e[n]=Math.floor(t/this.strides[n]),t-=e[n]*this.strides[n];return e[e.length-1]=t,e}get rank(){return this.shape.length}toTensor(){return Kn().makeTensor(this.values,this.shape,this.dtype)}}let Kn=null,Xn=null,Yn=null;class Jn{constructor(t,e,n,s){this.kept=!1,this.isDisposedInternal=!1,this.shape=t.slice(),this.dtype=e||"float32",this.size=_(t),this.strides=Q(t),this.dataId=n,this.id=s,this.rankType=this.rank<5?this.rank.toString():"higher"}get rank(){return this.shape.length}async buffer(){const t=await this.data();return Xn.buffer(this.shape,this.dtype,t)}bufferSync(){return Xn.buffer(this.shape,this.dtype,this.dataSync())}async array(){const t=await this.data();return et(this.shape,t)}arraySync(){return et(this.shape,this.dataSync())}async data(){this.throwIfDisposed();const t=Kn().read(this.dataId);if("string"===this.dtype){const e=await t;try{return e.map((t=>jn(t)))}catch(t){throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")}}return t}dataSync(){this.throwIfDisposed();const t=Kn().readSync(this.dataId);if("string"===this.dtype)try{return t.map((t=>jn(t)))}catch(t){throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")}return t}async bytes(){this.throwIfDisposed();const t=await Kn().read(this.dataId);return"string"===this.dtype?t:new Uint8Array(t.buffer)}dispose(){this.isDisposed||(Kn().disposeTensor(this),this.isDisposedInternal=!0)}get isDisposed(){return this.isDisposedInternal}throwIfDisposed(){if(this.isDisposed)throw new Error("Tensor is disposed.")}print(t=!1){return Xn.print(this,t)}clone(){return this.throwIfDisposed(),Xn.clone(this)}toString(t=!1){return zn(this.dataSync(),this.shape,this.dtype,t)}cast(t){return this.throwIfDisposed(),Xn.cast(this,t)}variable(t=!0,e,n){return this.throwIfDisposed(),Kn().makeVariable(this,t,e,n)}}Object.defineProperty(Jn,Symbol.hasInstance,{value:t=>!!t&&null!=t.data&&null!=t.dataSync&&null!=t.throwIfDisposed});class Zn extends Jn{constructor(t,e,n,s){super(t.shape,t.dtype,t.dataId,s),this.trainable=e,this.name=n}assign(t){if(t.dtype!==this.dtype)throw new Error(`dtype of the new value (${t.dtype}) and previous value (${this.dtype}) must match`);if(!O(t.shape,this.shape))throw new Error(`shape of the new value (${t.shape}) and previous value (${this.shape}) must match`);Kn().disposeTensor(this),this.dataId=t.dataId,Kn().incRef(this,null)}dispose(){Kn().disposeVariable(this),this.isDisposedInternal=!0}}var Qn,ts,es,ns,ss;Object.defineProperty(Zn,Symbol.hasInstance,{value:t=>t instanceof Jn&&null!=t.assign&&t.assign instanceof Function}),function(t){t.R0="R0",t.R1="R1",t.R2="R2",t.R3="R3",t.R4="R4",t.R5="R5",t.R6="R6"}(Qn||(Qn={})),function(t){t.float32="float32",t.int32="int32",t.bool="int32",t.complex64="complex64"}(ts||(ts={})),function(t){t.float32="float32",t.int32="int32",t.bool="bool",t.complex64="complex64"}(es||(es={})),function(t){t.float32="float32",t.int32="float32",t.bool="float32",t.complex64="complex64"}(ns||(ns={})),function(t){t.float32="complex64",t.int32="complex64",t.bool="complex64",t.complex64="complex64"}(ss||(ss={}));const rs={float32:ns,int32:ts,bool:es,complex64:ss};function as(t,e){if("string"===t||"string"===e){if("string"===t&&"string"===e)return"string";throw new Error(`Can not upcast ${t} with ${e}`)}return rs[t][e]}function is(t){return as(t,"int32")}function os(t,e){if(t.dtype===e.dtype)return[t,e];const n=as(t.dtype,e.dtype);return[t.cast(n),e.cast(n)]}function ls(t,e){return e.some((e=>e.id===t.id))}function us(t){const e=[];return cs(t,e,new Set),e}function cs(t,e,n){if(null==t)return;if(t instanceof Jn)return void e.push(t);if(s=t,!Array.isArray(s)&&"object"!=typeof s)return;var s;const r=t;for(const t in r){const s=r[t];n.has(s)||(n.add(s),cs(s,e,n))}}class hs{constructor(){this.registeredVariables={},this.nextTapeNodeId=0,this.numBytes=0,this.numTensors=0,this.numStringTensors=0,this.numDataBuffers=0,this.gradientDepth=0,this.kernelDepth=0,this.scopeStack=[],this.numDataMovesStack=[],this.nextScopeId=0,this.tensorInfo=new WeakMap,this.profiling=!1,this.activeProfile={newBytes:0,newTensors:0,peakBytes:0,kernels:[],result:null}}dispose(){for(const t in this.registeredVariables)this.registeredVariables[t].dispose()}}class ps{constructor(t){this.ENV=t,this.registry={},this.registryFactory={},this.pendingBackendInitId=0,this.state=new hs}async ready(){if(null!=this.pendingBackendInit)return this.pendingBackendInit.then((()=>{}));if(null!=this.backendInstance)return;const t=this.getSortedBackends();for(let e=0;e<t.length;e++){const n=t[e];if(await this.initializeBackend(n).success)return void await this.setBackend(n)}throw new Error("Could not initialize any backends, all backend initializations failed.")}get backend(){if(null!=this.pendingBackendInit)throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);if(null==this.backendInstance){const{name:t,asyncInit:e}=this.initializeBackendsAndReturnBest();if(e)throw new Error(`The highest priority backend '${t}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);this.setBackend(t)}return this.backendInstance}backendNames(){return Object.keys(this.registryFactory)}findBackend(t){if(!(t in this.registry)){if(!(t in this.registryFactory))return null;{const{asyncInit:e}=this.initializeBackend(t);if(e)return null}}return this.registry[t]}findBackendFactory(t){return t in this.registryFactory?this.registryFactory[t].factory:null}registerBackend(t,e,n=1){return t in this.registryFactory?(console.warn(t+" backend was already registered. Reusing existing backend factory."),!1):(this.registryFactory[t]={factory:e,priority:n},!0)}async setBackend(t){if(null==this.registryFactory[t])throw new Error(`Backend name '${t}' not found in registry`);if(this.backendName=t,null==this.registry[t]){this.backendInstance=null;const{success:e,asyncInit:n}=this.initializeBackend(t);if(!(n?await e:e))return!1}return this.backendInstance=this.registry[t],this.setupRegisteredKernels(),this.profiler=new On(this.backendInstance),!0}setupRegisteredKernels(){Rn(this.backendName).forEach((t=>{null!=t.setupFunc&&t.setupFunc(this.backendInstance)}))}disposeRegisteredKernels(t){Rn(t).forEach((e=>{null!=e.disposeFunc&&e.disposeFunc(this.registry[t])}))}initializeBackend(t){const e=this.registryFactory[t];if(null==e)throw new Error(`Cannot initialize backend ${t}, no registration found.`);try{const n=e.factory();if(!n||n instanceof C||"function"!=typeof n.then)return this.registry[t]=n,{success:!0,asyncInit:!1};{const e=++this.pendingBackendInitId,s=n.then((n=>!(e<this.pendingBackendInitId||(this.registry[t]=n,this.pendingBackendInit=null,0)))).catch((n=>(e<this.pendingBackendInitId||(this.pendingBackendInit=null,console.warn(`Initialization of backend ${t} failed`),console.warn(n.stack||n.message)),!1)));return this.pendingBackendInit=s,{success:s,asyncInit:!0}}}catch(e){return console.warn(`Initialization of backend ${t} failed`),console.warn(e.stack||e.message),{success:!1,asyncInit:!1}}}removeBackend(t){if(!(t in this.registryFactory))throw new Error(t+" backend not found in registry");this.backendName===t&&null!=this.pendingBackendInit&&this.pendingBackendInitId++,t in this.registry&&(this.disposeRegisteredKernels(t),this.registry[t].dispose(),delete this.registry[t]),delete this.registryFactory[t],this.backendName===t&&(this.pendingBackendInit=null,this.backendName=null,this.backendInstance=null)}getSortedBackends(){if(0===Object.keys(this.registryFactory).length)throw new Error("No backend found in registry.");return Object.keys(this.registryFactory).sort(((t,e)=>this.registryFactory[e].priority-this.registryFactory[t].priority))}initializeBackendsAndReturnBest(){const t=this.getSortedBackends();for(let e=0;e<t.length;e++){const n=t[e],{success:s,asyncInit:r}=this.initializeBackend(n);if(r||s)return{name:n,asyncInit:r}}throw new Error("Could not initialize any backends, all backend initializations failed.")}moveData(t,e){const n=this.state.tensorInfo.get(e),s=n.backend,r=this.readSync(e);s.disposeData(e),n.backend=t,t.move(e,r,n.shape,n.dtype),this.shouldCheckForMemLeaks()&&this.state.numDataMovesStack[this.state.numDataMovesStack.length-1]++}tidy(t,e){let n,s=null;if(null==e){if("function"!=typeof t)throw new Error("Please provide a function to tidy()");e=t}else{if("string"!=typeof t&&!(t instanceof String))throw new Error("When calling with two arguments, the first argument to tidy() must be a string");if("function"!=typeof e)throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");s=t}return this.scopedRun((()=>this.startScope(s)),(()=>this.endScope(n)),(()=>(n=e(),n instanceof Promise&&console.error("Cannot return a Promise inside of tidy."),n)))}scopedRun(t,e,n){t();try{const t=n();return e(),t}catch(t){throw e(),t}}nextTensorId(){return ps.nextTensorId++}nextVariableId(){return ps.nextVariableId++}clone(t){const e=this.makeTensorFromDataId(t.dataId,t.shape,t.dtype),n={x:t};return this.addTapeNode(this.state.activeScope.name,n,[e],(t=>({x:()=>{const e="float32",n={x:t},s={dtype:e};return fs.runKernelFunc((n=>n.cast(t,e)),n,null,Ft,s)}})),[],{}),e}runKernel(t,e,n,s,r){return this.runKernelFunc(null,e,null,t,n,s,r)}shouldCheckForMemLeaks(){return this.ENV.getBool("IS_TEST")}checkKernelForMemLeak(t,e,n){const s=this.backend.numDataIds();let r=0;n.forEach((t=>{r+="complex64"===t.dtype?3:1}));const a=this.state.numDataMovesStack[this.state.numDataMovesStack.length-1],i=s-e-r-a;if(i>0)throw new Error(`Backend '${this.backendName}' has an internal memory leak (${i} data ids) after running '${t}'`)}runKernelFunc(t,e,n,s,r,a,i){let o,l=[];const u=this.isTapeOn();null==s&&(s=null!=this.state.activeScope?this.state.activeScope.name:"");const c=this.state.numBytes,h=this.state.numTensors;let p;this.shouldCheckForMemLeaks()&&this.state.numDataMovesStack.push(0);const d=En(s,this.backendName);let f,m;if(null!=d)p=()=>{const t=this.backend.numDataIds();f=d.kernelFunc({inputs:e,attrs:r,backend:this.backend});const n=Array.isArray(f)?f:[f];this.shouldCheckForMemLeaks()&&this.checkKernelForMemLeak(s,t,n);const o=n.map((({dataId:t,shape:e,dtype:n})=>this.makeTensorFromDataId(t,e,n)));if(u){let t=this.getTensorsForGradient(s,e,o);if(null==t){null==i&&(i=[]);const e=o.filter(((t,e)=>i[e]));t=(a||[]).slice().concat(e)}l=this.saveTensorsForBackwardMode(t)}return o};else{const e=t=>{u&&(l=t.map((t=>this.keep(this.clone(t)))))};p=()=>{const n=this.backend.numDataIds();f=this.tidy((()=>t(this.backend,e)));const r=Array.isArray(f)?f:[f];return this.shouldCheckForMemLeaks()&&this.checkKernelForMemLeak(s,n,r),r}}return this.scopedRun((()=>this.state.kernelDepth++),(()=>this.state.kernelDepth--),(()=>{this.ENV.getBool("DEBUG")||this.state.profiling?(m=this.profiler.profileKernel(s,e,(()=>p())),this.ENV.getBool("DEBUG")&&this.profiler.logKernelProfile(m),o=m.outputs):o=p()})),u&&this.addTapeNode(s,e,o,n,l,r),this.state.profiling&&this.state.activeProfile.kernels.push({name:s,bytesAdded:this.state.numBytes-c,totalBytesSnapshot:this.state.numBytes,tensorsAdded:this.state.numTensors-h,totalTensorsSnapshot:this.state.numTensors,inputShapes:Object.keys(e).map((t=>null!=e[t]?e[t].shape:null)),outputShapes:o.map((t=>t.shape)),kernelTimeMs:m.timeMs,extraInfo:m.extraInfo}),Array.isArray(f)?o:o[0]}saveTensorsForBackwardMode(t){return t.map((t=>this.keep(this.clone(t))))}getTensorsForGradient(t,e,n){const s=An(t);if(null!=s){const t=s.inputsToSave||[],r=s.outputsToSave||[];let a;s.saveAllInputs?(A(Array.isArray(e),(()=>"saveAllInputs is true, expected inputs to be an array.")),a=Object.keys(e).map((t=>e[t]))):a=t.map((t=>e[t]));const i=n.filter(((t,e)=>r[e]));return a.concat(i)}return null}makeTensor(t,e,n,s){if(null==t)throw new Error("Values passed to engine.makeTensor() are null");n=n||"float32",s=s||this.backend;let r=t;"string"===n&&K(t[0])&&(r=t.map((t=>Hn(t))));const a=s.write(r,e,n),i=new Jn(e,n,a,this.nextTensorId());if(this.incRef(i,s),"string"===n){const t=this.state.tensorInfo.get(a),e=function(t){if(null==t)return 0;let e=0;return t.forEach((t=>e+=t.length)),e}(r);this.state.numBytes+=e-t.bytes,t.bytes=e}return i}makeTensorFromDataId(t,e,n,s){const r=new Jn(e,n=n||"float32",t,this.nextTensorId());return this.incRef(r,s),r}makeVariable(t,e=!0,n,s){n=n||this.nextVariableId().toString(),null!=s&&s!==t.dtype&&(t=t.cast(s));const r=new Zn(t,e,n,this.nextTensorId());if(null!=this.state.registeredVariables[r.name])throw new Error(`Variable with name ${r.name} was already registered`);return this.state.registeredVariables[r.name]=r,this.incRef(r,this.backend),r}incRef(t,e){const n=this.state.tensorInfo.has(t.dataId)?this.state.tensorInfo.get(t.dataId).refCount:0;if(this.state.numTensors++,"string"===t.dtype&&this.state.numStringTensors++,0===n){this.state.numDataBuffers++;let n=0;"complex64"!==t.dtype&&"string"!==t.dtype&&(n=t.size*q(t.dtype)),this.state.tensorInfo.set(t.dataId,{backend:e||this.backend,dtype:t.dtype,shape:t.shape,bytes:n,refCount:0}),this.state.numBytes+=n}this.state.tensorInfo.get(t.dataId).refCount++,t instanceof Zn||this.track(t)}disposeTensor(t){if(!this.state.tensorInfo.has(t.dataId))return;this.state.numTensors--,"string"===t.dtype&&this.state.numStringTensors--;const e=this.state.tensorInfo.get(t.dataId);e.refCount<=1?("complex64"!==t.dtype&&(this.state.numBytes-=e.bytes),this.state.numDataBuffers--,e.backend.disposeData(t.dataId),this.state.tensorInfo.delete(t.dataId)):this.state.tensorInfo.get(t.dataId).refCount--}disposeVariables(){for(const t in this.state.registeredVariables){const e=this.state.registeredVariables[t];this.disposeVariable(e)}}disposeVariable(t){this.disposeTensor(t),null!=this.state.registeredVariables[t.name]&&delete this.state.registeredVariables[t.name]}memory(){const t=this.backend.memory();return t.numTensors=this.state.numTensors,t.numDataBuffers=this.state.numDataBuffers,t.numBytes=this.state.numBytes,this.state.numStringTensors>0&&(t.unreliable=!0,null==t.reasons&&(t.reasons=[]),t.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)")),t}async profile(t){this.state.profiling=!0;const e=this.state.numBytes,n=this.state.numTensors;this.state.activeProfile.kernels=[],this.state.activeProfile.result=await t(),this.state.profiling=!1,this.state.activeProfile.peakBytes=Math.max(...this.state.activeProfile.kernels.map((t=>t.totalBytesSnapshot))),this.state.activeProfile.newBytes=this.state.numBytes-e,this.state.activeProfile.newTensors=this.state.numTensors-n;for(const t of this.state.activeProfile.kernels)t.kernelTimeMs=await t.kernelTimeMs,t.extraInfo=await t.extraInfo;return this.state.activeProfile}isTapeOn(){return this.state.gradientDepth>0&&0===this.state.kernelDepth}addTapeNode(t,e,n,s,r,a){const i={id:this.state.nextTapeNodeId++,kernelName:t,inputs:e,outputs:n,saved:r},o=An(t);null!=o&&(s=o.gradFunc),null!=s&&(i.gradient=t=>(t=t.map(((t,e)=>{if(null==t){const t=n[e],s=st(t.size,t.dtype);return this.makeTensor(s,t.shape,t.dtype)}return t})),s(t.length>1?t:t[0],r,a))),this.state.activeTape.push(i)}keep(t){return t.kept=!0,t}startTape(){0===this.state.gradientDepth&&(this.state.activeTape=[]),this.state.gradientDepth++}endTape(){this.state.gradientDepth--}startScope(t){const e={track:[],name:"unnamed scope",id:this.state.nextScopeId++};t&&(e.name=t),this.state.scopeStack.push(e),this.state.activeScope=e}endScope(t){const e=us(t),n=new Set(e.map((t=>t.id)));for(let t=0;t<this.state.activeScope.track.length;t++){const e=this.state.activeScope.track[t];e.kept||n.has(e.id)||e.dispose()}const s=this.state.scopeStack.pop();this.state.activeScope=0===this.state.scopeStack.length?null:this.state.scopeStack[this.state.scopeStack.length-1],e.forEach((t=>{t.kept||t.scopeId!==s.id||this.track(t)}))}gradients(t,e,n,s=!1){if(A(e.length>0,(()=>"gradients() received an empty list of xs.")),null!=n&&"float32"!==n.dtype)throw new Error(`dy must have 'float32' dtype, but has '${n.dtype}'`);const r=this.scopedRun((()=>this.startTape()),(()=>this.endTape()),(()=>this.tidy("forward",t)));A(r instanceof Jn,(()=>"The result y returned by f() must be a tensor."));const a=function(t,e,n){const s={},r={};for(let t=0;t<e.length;t++)s[e[t].id]=!0;for(let n=0;n<t.length;n++){const a=t[n],i=a.inputs;for(const t in i){const n=i[t];let o=!1;for(let t=0;t<e.length;t++)if(s[n.id]){a.outputs.forEach((t=>s[t.id]=!0)),o=!0,r[a.id]=!0;break}if(o)break}}const a={};a[n.id]=!0;const i={};for(let e=t.length-1;e>=0;e--){const n=t[e],s=n.inputs;for(let t=0;t<n.outputs.length;t++)if(a[n.outputs[t].id]){for(const t in s)a[s[t].id]=!0,i[n.id]=!0;break}}const o=[];for(let e=0;e<t.length;e++){const n=t[e];if(r[n.id]&&i[n.id]){const t={};for(const e in n.inputs){const r=n.inputs[e];s[r.id]&&(t[e]=r)}const e=Object.assign({},n);e.inputs=t,e.outputs=n.outputs,o.push(e)}}return o}(this.state.activeTape,e,r);if(!s&&0===a.length&&e.length>0)throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");return this.tidy("backward",(()=>{const t={};t[r.id]=null==n?function(t){const e=nt(_(t),"float32");return fs.makeTensor(e,t,"float32")}(r.shape):n,function(t,e,n,s){for(let r=e.length-1;r>=0;r--){const a=e[r],i=[];if(a.outputs.forEach((e=>{const n=t[e.id];null!=n?i.push(n):i.push(null)})),null==a.gradient)throw new Error(`Cannot compute gradient: gradient function not found for ${a.kernelName}.`);const o=a.gradient(i);for(const e in a.inputs){if(!(e in o))throw new Error(`Cannot backprop through input ${e}. Available gradients found: ${Object.keys(o)}.`);const r=n((()=>o[e]()));if("float32"!==r.dtype)throw new Error(`Error in gradient for op ${a.kernelName}. The gradient of input ${e} must have 'float32' dtype, but has '${r.dtype}'`);const i=a.inputs[e];if(!O(r.shape,i.shape))throw new Error(`Error in gradient for op ${a.kernelName}. The gradient of input '${e}' has shape '${r.shape}', which does not match the shape of the input '${i.shape}'`);if(null==t[i.id])t[i.id]=r;else{const e=t[i.id];t[i.id]=s(e,r),e.dispose()}}}}(t,a,(t=>this.tidy(t)),ms);const s=e.map((e=>t[e.id]));return 0===this.state.gradientDepth&&(this.state.activeTape.forEach((t=>{for(const e of t.saved)e.dispose()})),this.state.activeTape=null),{value:r,grads:s}}))}customGrad(t){return A(J(t),(()=>"The f passed in customGrad(f) must be a function.")),(...e)=>{let n;A(e.every((t=>t instanceof Jn)),(()=>"The args passed in customGrad(f)(x1, x2,...) must all be tensors"));const s={};return e.forEach(((t,e)=>{s[e]=t})),this.runKernelFunc(((s,r)=>(n=t(...e,r),A(n.value instanceof Jn,(()=>"The function f passed in customGrad(f) must return an object where `obj.value` is a tensor")),A(J(n.gradFunc),(()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.")),n.value)),s,((t,s)=>{const r=n.gradFunc(t,s),a=Array.isArray(r)?r:[r];A(a.length===e.length,(()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).")),A(a.every((t=>t instanceof Jn)),(()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors."));const i={};return a.forEach(((t,e)=>{i[e]=()=>t})),i}))}}readSync(t){return this.state.tensorInfo.get(t).backend.readSync(t)}read(t){return this.state.tensorInfo.get(t).backend.read(t)}async time(t){const e=Gn(),n=await this.backend.time(t);return n.wallMs=Gn()-e,n}track(t){return null!=this.state.activeScope&&(t.scopeId=this.state.activeScope.id,this.state.activeScope.track.push(t)),t}get registeredVariables(){return this.state.registeredVariables}reset(){this.pendingBackendInitId++,this.state.dispose(),this.ENV.reset(),this.state=new hs;for(const t in this.registry)this.disposeRegisteredKernels(t),this.registry[t].dispose(),delete this.registry[t];this.backendName=null,this.backendInstance=null,this.pendingBackendInit=null}}function ds(){const t=dt();if(null==t._tfengine){const e=new ut(t);t._tfengine=new ps(e)}var e;return e=t._tfengine.ENV,pt=e,Kn=()=>t._tfengine,t._tfengine}ps.nextTensorId=0,ps.nextVariableId=0;const fs=ds();function ms(t,e){const n={a:t,b:e};return fs.runKernelFunc(((n,s)=>{const r=n.add(t,e);return s([t,e]),r}),n,null,bt)}function gs(){return"undefined"!=typeof window&&null!=window.document||"undefined"!=typeof WorkerGlobalScope}const ys=ct();function bs(t,e){let n=t;if(j(t))return"string"===e?[]:[t.length];if(!Array.isArray(t))return[];const s=[];for(;Array.isArray(n)||j(n)&&"string"!==e;)s.push(n.length),n=n[0];return Array.isArray(t)&&ct().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")&&xs(t,s,[]),s}function xs(t,e,n){if(n=n||[],!Array.isArray(t)&&!j(t))return void A(0===e.length,(()=>`Element arr[${n.join("][")}] is a primitive, but should be an array/TypedArray of ${e[0]} elements`));A(e.length>0,(()=>`Element arr[${n.join("][")}] should be a primitive, but is an array of ${t.length} elements`)),A(t.length===e[0],(()=>`Element arr[${n.join("][")}] should have ${e[0]} elements, but has ${t.length} elements`));const s=e.slice(1);for(let e=0;e<t.length;++e)xs(t[e],s,n.concat(e))}function ws(t,e,n,s){if(null!=t&&("numeric"!==t&&t!==e||"numeric"===t&&"string"===e))throw new Error(`Argument '${n}' passed to '${s}' must be ${t} tensor, but got ${e} tensor`)}function vs(t,e,n,s="numeric"){if(t instanceof Jn)return ws(s,t.dtype,e,n),t;let r=Y(t);if("string"!==r&&["bool","int32","float32"].indexOf(s)>=0&&(r=s),ws(s,r,e,n),null==t||!j(t)&&!Array.isArray(t)&&"number"!=typeof t&&"boolean"!=typeof t&&"string"!=typeof t){const s=null==t?"null":t.constructor.name;throw new Error(`Argument '${e}' passed to '${n}' must be a Tensor or TensorLike, but got '${s}'`)}const a=bs(t,r);j(t)||Array.isArray(t)||(t=[t]);const i="string"!==r?Un(t,r):F(t,[],!0);return fs.makeTensor(i,a,r)}function ks(t,e,n,s="numeric"){if(!Array.isArray(t))throw new Error(`Argument ${e} passed to ${n} must be a \`Tensor[]\` or \`TensorLike[]\``);return t.map(((t,s)=>vs(t,`${e}[${s}]`,n)),s)}function Ns(t){const e=Object.keys(t);if(1!==e.length)throw new Error("Please provide an object with a single key (operation name) mapping to a function. Got an object with "+e.length+" keys.");let n=e[0];const s=t[n];n.endsWith("_")&&(n=n.substring(0,n.length-1)),n+="__op";const r=(...t)=>{fs.startScope(n);try{const e=s(...t);return lt(e)&&console.error("Cannot return a Promise inside of tidy."),fs.endScope(e),e}catch(t){throw fs.endScope(null),t}};return Object.defineProperty(r,"name",{value:n,configurable:!0}),r}ys.registerFlag("DEBUG",(()=>!1),(t=>{t&&console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.")})),ys.registerFlag("IS_BROWSER",(()=>gs())),ys.registerFlag("IS_NODE",(()=>"undefined"!=typeof process&&void 0!==process.versions&&void 0!==process.versions.node)),ys.registerFlag("IS_CHROME",(()=>"undefined"!=typeof navigator&&null!=navigator&&null!=navigator.userAgent&&/Chrome/.test(navigator.userAgent)&&/Google Inc/.test(navigator.vendor))),ys.registerFlag("PROD",(()=>!1)),ys.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY",(()=>ys.getBool("DEBUG"))),ys.registerFlag("DEPRECATION_WARNINGS_ENABLED",(()=>!0)),ys.registerFlag("IS_TEST",(()=>!1));const Is=Ns({complex_:function(t,e){const n=vs(t,"real","complex"),s=vs(e,"imag","complex");R(n.shape,s.shape,`real and imag shapes, ${n.shape} and ${s.shape}, must match in call to tf.complex().`);const r={real:n,imag:s};return fs.runKernelFunc((t=>t.complex(n,s)),r,null,Mt)}});function Cs(t,e,n,s){if(null==s&&(s=Y(t)),"complex64"===s)throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");if(!j(t)&&!Array.isArray(t)&&"number"!=typeof t&&"boolean"!=typeof t&&"string"!=typeof t)throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");if(null!=e){at(e);const t=_(e),s=_(n);A(t===s,(()=>`Based on the provided shape, [${e}], the tensor should have ${t} values but has ${s}`));for(let t=0;t<n.length;++t){const s=n[t],r=t!==n.length-1||s!==_(e.slice(t));A(n[t]===e[t]||!r,(()=>`Error creating a new Tensor. Inferred shape (${n}) does not match the provided shape (${e}). `))}}return j(t)||Array.isArray(t)||(t=[t]),e=e||n,t="string"!==s?Un(t,s):F(t,[],!0),fs.makeTensor(t,e,s)}function Ss(t,e,n){return Cs(t,e,bs(t,n),n)}const Ts={float32:4,float16:2,int32:4,uint16:2,uint8:1,bool:1,complex64:8};async function $s(t,e){const n=[],s=[],r=Array.isArray(t)?t.map((t=>t.name)):Object.keys(t);for(let a=0;a<r.length;++a){const i=r[a],o=Array.isArray(t)?t[a].tensor:t[i];if("float32"!==o.dtype&&"int32"!==o.dtype&&"bool"!==o.dtype&&"string"!==o.dtype&&"complex64"!==o.dtype)throw new Error(`Unsupported dtype in weight '${i}': ${o.dtype}`);const l={name:i,shape:o.shape,dtype:o.dtype};if("string"===o.dtype){const t=new Promise((async t=>{const e=await o.bytes(),n=e.reduce(((t,e)=>t+e.length),0)+4*e.length,s=new Uint8Array(n);let r=0;for(let t=0;t<e.length;t++){const n=e[t],a=new Uint8Array(new Uint32Array([n.length]).buffer);s.set(a,r),r+=4,s.set(n,r),r+=n.length}t(s)}));s.push(t)}else s.push(o.data());null!=e&&(l.group=e),n.push(l)}return{data:Es(await Promise.all(s)),specs:n}}function Es(t){if(null===t)throw new Error("Invalid input value: "+JSON.stringify(t));let e=0;const n=[];t.forEach((t=>{if(e+=t.byteLength,n.push(t.byteLength===t.buffer.byteLength?t:new t.constructor(t)),!(t instanceof Float32Array||t instanceof Int32Array||t instanceof Uint8Array))throw new Error("Unsupported TypedArray subtype: "+t.constructor.name)}));const s=new Uint8Array(e);let r=0;return n.forEach((t=>{s.set(new Uint8Array(t.buffer),r),r+=t.byteLength})),s.buffer}const As="undefined"!=typeof Buffer&&("undefined"==typeof Blob||"undefined"==typeof atob||"undefined"==typeof btoa);function Rs(t){return As?Buffer.byteLength(t):new Blob([t]).size}function Ds(t){if(1===t.length)return t[0];let e=0;t.forEach((t=>{e+=t.byteLength}));const n=new Uint8Array(e);let s=0;return t.forEach((t=>{n.set(new Uint8Array(t),s),s+=t.byteLength})),n.buffer}function Fs(t){if(t.modelTopology instanceof ArrayBuffer)throw new Error("Expected JSON model topology, received ArrayBuffer.");return{dateSaved:new Date,modelTopologyType:"JSON",modelTopologyBytes:null==t.modelTopology?0:Rs(JSON.stringify(t.modelTopology)),weightSpecsBytes:null==t.weightSpecs?0:Rs(JSON.stringify(t.weightSpecs)),weightDataBytes:null==t.weightData?0:t.weightData.byteLength}}function _s(){const t=function(){const t=t=>{let e=t<<13,n=0;for(;0==(8388608&e);)n-=8388608,e<<=1;return e&=-8388609,n+=947912704,e|n},e=new Uint32Array(2048);e[0]=0;for(let n=1;n<1024;n++)e[n]=t(n);for(let t=1024;t<2048;t++)e[t]=939524096+(t-1024<<13);return e}(),e=function(){const t=new Uint32Array(64);t[0]=0,t[31]=1199570944,t[32]=2147483648,t[63]=3347054592;for(let e=1;e<31;e++)t[e]=e<<23;for(let e=33;e<63;e++)t[e]=2147483648+(e-32<<23);return t}(),n=function(){const t=new Uint32Array(64);for(let e=0;e<64;e++)t[e]=1024;return t[0]=t[32]=0,t}();return s=>{const r=new ArrayBuffer(4*s.length),a=new Uint32Array(r);for(let r=0;r<s.length;r++){const i=s[r],o=t[n[i>>10]+(1023&i)]+e[i>>10];a[r]=o}return new Float32Array(r)}}class Os{constructor(){this.saveRouters=[],this.loadRouters=[]}static getInstance(){return null==Os.instance&&(Os.instance=new Os),Os.instance}static registerSaveRouter(t){Os.getInstance().saveRouters.push(t)}static registerLoadRouter(t){Os.getInstance().loadRouters.push(t)}static getSaveHandlers(t){return Os.getHandlers(t,"save")}static getLoadHandlers(t,e){return Os.getHandlers(t,"load",e)}static getHandlers(t,e,n){const s=[];return("load"===e?Os.getInstance().loadRouters:Os.getInstance().saveRouters).forEach((e=>{const r=e(t,n);null!==r&&s.push(r)})),s}}const Ms=t=>Os.getSaveHandlers(t),Ls="tensorflowjs",zs="models_store",Bs="model_info_store";function Ps(){if(!ct().getBool("IS_BROWSER"))throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");const t="undefined"==typeof window?self:window,e=t.indexedDB||t.mozIndexedDB||t.webkitIndexedDB||t.msIndexedDB||t.shimIndexedDB;if(null==e)throw new Error("The current browser does not appear to support IndexedDB.");return e}function Ws(t){const e=t.result;e.createObjectStore(zs,{keyPath:"modelPath"}),e.createObjectStore(Bs,{keyPath:"modelPath"})}class Vs{constructor(t){if(this.indexedDB=Ps(),null==t||!t)throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");this.modelPath=t}async save(t){if(t.modelTopology instanceof ArrayBuffer)throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");return this.databaseAction(this.modelPath,t)}async load(){return this.databaseAction(this.modelPath)}databaseAction(t,e){return new Promise(((t,n)=>{const s=this.indexedDB.open(Ls,1);s.onupgradeneeded=()=>Ws(s),s.onsuccess=()=>{const r=s.result;if(null==e){const e=r.transaction(zs,"readonly"),s=e.objectStore(zs).get(this.modelPath);s.onsuccess=()=>{if(null==s.result)return r.close(),n(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));t(s.result.modelArtifacts)},s.onerror=t=>(r.close(),n(s.error)),e.oncomplete=()=>r.close()}else{const s=Fs(e),a=r.transaction(Bs,"readwrite");let i=a.objectStore(Bs);const o=i.put({modelPath:this.modelPath,modelArtifactsInfo:s});let l;o.onsuccess=()=>{l=r.transaction(zs,"readwrite");const o=l.objectStore(zs).put({modelPath:this.modelPath,modelArtifacts:e,modelArtifactsInfo:s});o.onsuccess=()=>t({modelArtifactsInfo:s}),o.onerror=t=>{i=a.objectStore(Bs);const e=i.delete(this.modelPath);e.onsuccess=()=>(r.close(),n(o.error)),e.onerror=t=>(r.close(),n(o.error))}},o.onerror=t=>(r.close(),n(o.error)),a.oncomplete=()=>{null==l?r.close():l.oncomplete=()=>r.close()}}},s.onerror=t=>n(s.error)}))}}Vs.URL_SCHEME="indexeddb://";const Us=t=>{return ct().getBool("IS_BROWSER")&&!Array.isArray(t)&&t.startsWith(Vs.URL_SCHEME)?(e=t.slice(Vs.URL_SCHEME.length),new Vs(e)):null;var e};Os.registerSaveRouter(Us),Os.registerLoadRouter(Us);class Gs{constructor(){this.indexedDB=Ps()}async listModels(){return new Promise(((t,e)=>{const n=this.indexedDB.open(Ls,1);n.onupgradeneeded=()=>Ws(n),n.onsuccess=()=>{const s=n.result,r=s.transaction(Bs,"readonly"),a=r.objectStore(Bs).getAll();a.onsuccess=()=>{const e={};for(const t of a.result)e[t.modelPath]=t.modelArtifactsInfo;t(e)},a.onerror=t=>(s.close(),e(a.error)),r.oncomplete=()=>s.close()},n.onerror=t=>e(n.error)}))}async removeModel(t){var e;return t=(e=t).startsWith(Vs.URL_SCHEME)?e.slice(Vs.URL_SCHEME.length):e,new Promise(((e,n)=>{const s=this.indexedDB.open(Ls,1);s.onupgradeneeded=()=>Ws(s),s.onsuccess=()=>{const r=s.result,a=r.transaction(Bs,"readwrite"),i=a.objectStore(Bs),o=i.get(t);let l;o.onsuccess=()=>{if(null==o.result)return r.close(),n(new Error(`Cannot find model with path '${t}' in IndexedDB.`));{const s=i.delete(t),a=()=>{l=r.transaction(zs,"readwrite");const s=l.objectStore(zs).delete(t);s.onsuccess=()=>e(o.result.modelArtifactsInfo),s.onerror=t=>n(o.error)};s.onsuccess=a,s.onerror=t=>(a(),r.close(),n(o.error))}},o.onerror=t=>(r.close(),n(o.error)),a.oncomplete=()=>{null==l?r.close():l.oncomplete=()=>r.close()}},s.onerror=t=>n(s.error)}))}}const Hs="/",js="tensorflowjs_models",qs="info",Ks="model_topology",Xs="weight_specs",Ys="weight_data",Js="model_metadata";function Zs(t){return{info:[js,t,qs].join(Hs),topology:[js,t,Ks].join(Hs),weightSpecs:[js,t,Xs].join(Hs),weightData:[js,t,Ys].join(Hs),modelMetadata:[js,t,Js].join(Hs)}}function Qs(t){const e=t.split(Hs);if(e.length<3)throw new Error("Invalid key format: "+t);return e.slice(1,e.length-1).join(Hs)}class tr{constructor(t){if(!ct().getBool("IS_BROWSER")||"undefined"==typeof window||void 0===window.localStorage)throw new Error("The current environment does not support local storage.");if(this.LS=window.localStorage,null==t||!t)throw new Error("For local storage, modelPath must not be null, undefined or empty.");this.modelPath=t,this.keys=Zs(this.modelPath)}async save(t){if(t.modelTopology instanceof ArrayBuffer)throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");{const e=JSON.stringify(t.modelTopology),n=JSON.stringify(t.weightSpecs),s=Fs(t);try{return this.LS.setItem(this.keys.info,JSON.stringify(s)),this.LS.setItem(this.keys.topology,e),this.LS.setItem(this.keys.weightSpecs,n),this.LS.setItem(this.keys.weightData,function(t){if(As)return Buffer.from(t).toString("base64");const e=new Uint8Array(t);let n="";for(let t=0,s=e.length;t<s;t++)n+=String.fromCharCode(e[t]);return btoa(n)}(t.weightData)),this.LS.setItem(this.keys.modelMetadata,JSON.stringify({format:t.format,generatedBy:t.generatedBy,convertedBy:t.convertedBy,userDefinedMetadata:t.userDefinedMetadata})),{modelArtifactsInfo:s}}catch(t){throw this.LS.removeItem(this.keys.info),this.LS.removeItem(this.keys.topology),this.LS.removeItem(this.keys.weightSpecs),this.LS.removeItem(this.keys.weightData),this.LS.removeItem(this.keys.modelMetadata),new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${s.modelTopologyBytes}, weightSpecsBytes=${s.weightSpecsBytes}, weightDataBytes=${s.weightDataBytes}.`)}}}async load(){const t=JSON.parse(this.LS.getItem(this.keys.info));if(null==t)throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);if("JSON"!==t.modelTopologyType)throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");const e={},n=JSON.parse(this.LS.getItem(this.keys.topology));if(null==n)throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);e.modelTopology=n;const s=JSON.parse(this.LS.getItem(this.keys.weightSpecs));if(null==s)throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);e.weightSpecs=s;const r=this.LS.getItem(this.keys.modelMetadata);if(null!=r){const t=JSON.parse(r);e.format=t.format,e.generatedBy=t.generatedBy,e.convertedBy=t.convertedBy,e.userDefinedMetadata=t.userDefinedMetadata}const a=this.LS.getItem(this.keys.weightData);if(null==a)throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);return e.weightData=function(t){if(As){const e=Buffer.from(t,"base64");return e.buffer.slice(e.byteOffset,e.byteOffset+e.byteLength)}const e=atob(t),n=new Uint8Array(e.length);for(let t=0;t<e.length;++t)n.set([e.charCodeAt(t)],t);return n.buffer}(a),e}}tr.URL_SCHEME="localstorage://";const er=t=>{return ct().getBool("IS_BROWSER")&&!Array.isArray(t)&&t.startsWith(tr.URL_SCHEME)?(e=t.slice(tr.URL_SCHEME.length),new tr(e)):null;var e};Os.registerSaveRouter(er),Os.registerLoadRouter(er);class nr{constructor(){A(ct().getBool("IS_BROWSER"),(()=>"Current environment is not a web browser")),A("undefined"==typeof window||void 0!==window.localStorage,(()=>"Current browser does not appear to support localStorage")),this.LS=window.localStorage}async listModels(){const t={},e=js+Hs,n=Hs+qs;for(let s=0;s<this.LS.length;++s){const r=this.LS.key(s);r.startsWith(e)&&r.endsWith(n)&&(t[Qs(r)]=JSON.parse(this.LS.getItem(r)))}return t}async removeModel(t){var e;const n=Zs(t=(e=t).startsWith(tr.URL_SCHEME)?e.slice(tr.URL_SCHEME.length):e);if(null==this.LS.getItem(n.info))throw new Error(`Cannot find model at path '${t}'`);const s=JSON.parse(this.LS.getItem(n.info));return this.LS.removeItem(n.info),this.LS.removeItem(n.topology),this.LS.removeItem(n.weightSpecs),this.LS.removeItem(n.weightData),s}}class sr{constructor(){this.managers={}}static getInstance(){return null==sr.instance&&(sr.instance=new sr),sr.instance}static registerManager(t,e){A(null!=t,(()=>"scheme must not be undefined or null.")),t.endsWith("://")&&(t=t.slice(0,t.indexOf("://"))),A(t.length>0,(()=>"scheme must not be an empty string."));const n=sr.getInstance();A(null==n.managers[t],(()=>`A model store manager is already registered for scheme '${t}'.`)),n.managers[t]=e}static getManager(t){const e=this.getInstance().managers[t];if(null==e)throw new Error(`Cannot find model manager for scheme '${t}'`);return e}static getSchemes(){return Object.keys(this.getInstance().managers)}}class rr{fetch(t,e){return fetch(t,e)}now(){return performance.now()}encode(t,e){if("utf-8"!==e&&"utf8"!==e)throw new Error("Browser's encoder only supports utf-8, but got "+e);return null==this.textEncoder&&(this.textEncoder=new TextEncoder),this.textEncoder.encode(t)}decode(t,e){return new TextDecoder(e).decode(t)}}if(ct().get("IS_BROWSER")){ct().setPlatform("browser",new rr);try{sr.registerManager(tr.URL_SCHEME,new nr)}catch(t){}try{sr.registerManager(Vs.URL_SCHEME,new Gs)}catch(t){}}let ar;function ir(t,e="float32",n){return e=e||"float32",at(t),new qn(t,e,n)}ct().get("IS_NODE")&&ct().setPlatform("node",new class{constructor(){this.util=n(758),this.textEncoder=new this.util.TextEncoder}fetch(t,e){return null!=ct().global.fetch?ct().global.fetch(t,e):(null==ar&&(ar=n(352)),ar(t,e))}now(){const t=process.hrtime();return 1e3*t[0]+t[1]/1e6}encode(t,e){if("utf-8"!==e&&"utf8"!==e)throw new Error("Node built-in encoder only supports utf-8, but got "+e);return this.textEncoder.encode(t)}decode(t,e){return 0===t.length?"":new this.util.TextDecoder(e).decode(t)}});const or=Ns({cast_:function(t,e){const n=vs(t,"x","cast");if(!function(t){return"bool"===t||"complex64"===t||"float32"===t||"int32"===t||"string"===t}(e))throw new Error("Failed to cast to unknown dtype "+e);if("string"===e&&"string"!==n.dtype||"string"!==e&&"string"===n.dtype)throw new Error("Only strings can be casted to strings");const s={x:n},r={dtype:e};return fs.runKernelFunc((t=>t.cast(n,e)),s,null,Ft,r)}}),lr=Ns({clone_:function(t){const e=vs(t,"x","clone",null),n={x:e};return fs.runKernelFunc((()=>fs.makeTensorFromDataId(e.dataId,e.shape,e.dtype)),n,null,pe)}});function ur(t){return new Promise((t=>setTimeout(t))).then(t)}ds(),Xn={buffer:ir,cast:or,clone:lr,print:function(t,e=!1){console.log(t.toString(e))}};class cr{constructor(t){if(!ct().getBool("IS_BROWSER"))throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");t.startsWith(cr.URL_SCHEME)&&(t=t.slice(cr.URL_SCHEME.length)),null!=t&&0!==t.length||(t="model"),this.modelTopologyFileName=t+".json",this.weightDataFileName=t+".weights.bin"}async save(t){if("undefined"==typeof document)throw new Error("Browser downloads are not supported in this environment since `document` is not present");const e=window.URL.createObjectURL(new Blob([t.weightData],{type:"application/octet-stream"}));if(t.modelTopology instanceof ArrayBuffer)throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");{const n=[{paths:["./"+this.weightDataFileName],weights:t.weightSpecs}],s={modelTopology:t.modelTopology,format:t.format,generatedBy:t.generatedBy,convertedBy:t.convertedBy,weightsManifest:n},r=window.URL.createObjectURL(new Blob([JSON.stringify(s)],{type:"application/json"})),a=null==this.jsonAnchor?document.createElement("a"):this.jsonAnchor;if(a.download=this.modelTopologyFileName,a.href=r,await ur((()=>a.dispatchEvent(new MouseEvent("click")))),null!=t.weightData){const t=null==this.weightDataAnchor?document.createElement("a"):this.weightDataAnchor;t.download=this.weightDataFileName,t.href=e,await ur((()=>t.dispatchEvent(new MouseEvent("click"))))}return{modelArtifactsInfo:Fs(t)}}}}function hr(t,e,n,s){!function(t){A(null!=t&&Array.isArray(t)&&t.length>0,(()=>"promises must be a none empty array"))}(t),function(t,e){A(t>=0&&t<=1,(()=>"Progress fraction must be in range [0, 1], but got startFraction "+t)),A(e>=0&&e<=1,(()=>"Progress fraction must be in range [0, 1], but got endFraction "+e)),A(e>=t,(()=>`startFraction must be no more than endFraction, but got startFraction ${t} and endFraction `+e))}(n=null==n?0:n,s=null==s?1:s);let r=0;return Promise.all(t.map((a=>(a.then((a=>{const i=n+ ++r/t.length*(s-n);return e(i),a})),a))))}async function pr(t,e){null==e&&(e={});const n=null==e.fetchFunc?ct().platform.fetch:e.fetchFunc,s=t.map((t=>n(t,e.requestInit,{isBinary:!0}))),r=(null==e.onProgress?await Promise.all(s):await hr(s,e.onProgress,0,.5)).map((t=>t.arrayBuffer()));return null==e.onProgress?await Promise.all(r):await hr(r,e.onProgress,.5,1)}cr.URL_SCHEME="downloads://",Os.registerSaveRouter((t=>ct().getBool("IS_BROWSER")&&!Array.isArray(t)&&t.startsWith(cr.URL_SCHEME)?function(t="model"){return new cr(t)}(t.slice(cr.URL_SCHEME.length)):null));class dr{constructor(t,e){if(this.DEFAULT_METHOD="POST",null==e&&(e={}),this.weightPathPrefix=e.weightPathPrefix,this.onProgress=e.onProgress,this.weightUrlConverter=e.weightUrlConverter,null!=e.fetchFunc?(A("function"==typeof e.fetchFunc,(()=>"Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)")),this.fetch=e.fetchFunc):this.fetch=ct().platform.fetch,A(null!=t&&t.length>0,(()=>"URL path for http must not be null, undefined or empty.")),Array.isArray(t)&&A(2===t.length,(()=>`URL paths for http must have a length of 2, (actual length is ${t.length}).`)),this.path=t,null!=e.requestInit&&null!=e.requestInit.body)throw new Error("requestInit is expected to have no pre-existing body, but has one.");this.requestInit=e.requestInit||{}}async save(t){if(t.modelTopology instanceof ArrayBuffer)throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");const e=Object.assign({method:this.DEFAULT_METHOD},this.requestInit);e.body=new FormData;const n=[{paths:["./model.weights.bin"],weights:t.weightSpecs}],s={modelTopology:t.modelTopology,format:t.format,generatedBy:t.generatedBy,convertedBy:t.convertedBy,userDefinedMetadata:t.userDefinedMetadata,weightsManifest:n};e.body.append("model.json",new Blob([JSON.stringify(s)],{type:"application/json"}),"model.json"),null!=t.weightData&&e.body.append("model.weights.bin",new Blob([t.weightData],{type:"application/octet-stream"}),"model.weights.bin");const r=await this.fetch(this.path,e);if(r.ok)return{modelArtifactsInfo:Fs(t),responses:[r]};throw new Error("BrowserHTTPRequest.save() failed due to HTTP response status "+r.status+".")}async load(){const t=await this.fetch(this.path,this.requestInit);if(!t.ok)throw new Error(`Request to ${this.path} failed with status code `+t.status+". Please verify this URL points to the model JSON of the model to load.");let e;try{e=await t.json()}catch(t){let e=`Failed to parse model JSON of response from ${this.path}.`;throw this.path.endsWith(".pb")?e+=" Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.":e+=" Please make sure the server is serving valid JSON for this request.",new Error(e)}const n=e.modelTopology,s=e.weightsManifest,r=e.generatedBy,a=e.convertedBy,i=e.format,o=e.userDefinedMetadata;if(null==n&&null==s)throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);let l,u;if(null!=s){const t=await this.loadWeights(s);[l,u]=t}const c={modelTopology:n,weightSpecs:l,weightData:u,userDefinedMetadata:o,generatedBy:r,convertedBy:a,format:i},h=e.modelInitializer;return h&&(c.modelInitializer=h),c}async loadWeights(t){const e=Array.isArray(this.path)?this.path[1]:this.path,[n,s]=function(t){const e=t.lastIndexOf("/"),n=t.lastIndexOf("?");return[t.substring(0,e)+"/",n>e?t.substring(n):""]}(e),r=this.weightPathPrefix||n,a=[];for(const e of t)a.push(...e.weights);const i=[],o=[];for(const e of t)for(const t of e.paths)null!=this.weightUrlConverter?o.push(this.weightUrlConverter(t)):i.push(r+t+s);return this.weightUrlConverter&&i.push(...await Promise.all(o)),[a,Ds(await pr(i,{requestInit:this.requestInit,fetchFunc:this.fetch,onProgress:this.onProgress}))]}}function fr(t){return null!=t.match(dr.URL_SCHEME_REGEX)}dr.URL_SCHEME_REGEX=/^https?:\/\//;const mr=(t,e)=>{if("undefined"==typeof fetch&&(null==e||null==e.fetchFunc))return null;{let n=!0;if(n=Array.isArray(t)?t.every((t=>fr(t))):fr(t),n)return gr(t,e)}return null};function gr(t,e){return new dr(t,e)}function yr(t,e){return gr(t,e)}let br;Os.registerSaveRouter(mr),Os.registerLoadRouter(mr);const xr=Ns({fromPixels_:function(t,e=3){if(e>4)throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");if(null==t)throw new Error("pixels passed to tf.browser.fromPixels() can not be null");let n=!1,s=!1,r=!1,a=!1,i=!1;if(t.data instanceof Uint8Array)n=!0;else if("undefined"!=typeof ImageData&&t instanceof ImageData)s=!0;else if("undefined"!=typeof HTMLVideoElement&&t instanceof HTMLVideoElement)r=!0;else if("undefined"!=typeof HTMLImageElement&&t instanceof HTMLImageElement)a=!0;else{if(null==t.getContext)throw new Error("pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, but was "+t.constructor.name);i=!0}if(r){const e=2;if(r&&t.readyState<e)throw new Error("The video element has not loaded data yet. Please wait for `loadeddata` event on the <video> element.")}if(null!=En(kn,fs.backendName)){const n={pixels:t},s={numChannels:e};return fs.runKernel(kn,n,s)}const[o,l]=r?[t.videoWidth,t.videoHeight]:[t.width,t.height];let u,c;if(i?u=t.getContext("2d").getImageData(0,0,o,l).data:s||n?u=t.data:(a||r)&&(null==br&&(br=document.createElement("canvas").getContext("2d")),br.canvas.width=o,br.canvas.height=l,br.drawImage(t,0,0,o,l),u=br.getImageData(0,0,o,l).data),4===e)c=new Int32Array(u);else{const t=o*l;c=new Int32Array(t*e);for(let n=0;n<t;n++)for(let t=0;t<e;++t)c[n*e+t]=u[4*n+t]}return function(t,e,n){if(D(t),null!=e&&3!==e.length)throw new Error("tensor3d() requires shape to have three numbers");const s=bs(t,n);if(3!==s.length&&1!==s.length)throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");if(1===s.length&&null==e)throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");return Cs(t,e,s,n)}(c,[l,o,e],"int32")}});function wr(t,e,n){const s=t.shape.length;A(s===e.length,(()=>`Error in slice${s}D: Length of begin ${e} must match the rank of the array (${s}).`)),A(s===n.length,(()=>`Error in slice${s}D: Length of size ${n} must match the rank of the array (${s}).`));for(let r=0;r<s;++r)A(e[r]+n[r]<=t.shape[r],(()=>`Error in slice${s}D: begin[${r}] + size[${r}] (${e[r]+n[r]}) would overflow input.shape[${r}] (${t.shape[r]})`))}function vr(t){const e=[];let n=0;for(;t>0;)1&t&&e.push(n),t/=2,n++;return e}function kr(t,e,n){const s=[];for(let r=0;r<t.length;r++)s[r]=Math.ceil((e[r]-t[r])/n[r]);return s}function Nr(t,e,n,s){const r=[...t];for(let t=r.length;t<s.length;t++)r.push(1);for(let t=0;t<n;t++)0===t?r[e]=1:(r.splice(e,0,1),r.pop());return r}function Ir(t,e,n){return n<=t?n:n-(e-1)}function Cr(t,e){const n=[];for(let s=0;s<t;s++)n.push(e+s);return n}function Sr(t,e,n,s,r,a,i,o,l){const u=t.length;let c=new Array(u),h=new Array(u),p=new Array(u);if(e.length&&n>0){const l=e[0],u=n+1;c=Tr(i,l,u,s,t),h=$r(o,l,u,r,t),p=Nr(a,l,u,t)}else for(let e=0;e<u;e++)c[e]=Ar(i,s,a,t,e,l),h[e]=Rr(o,r,a,t,e,l),p[e]=Er(a,e,l);return{begin:c,end:h,strides:p}}function Tr(t,e,n,s,r){const a=[...r],i=Cr(n,e);for(let r=0;r<a.length;r++)if(i.indexOf(r)>-1)a[r]=0;else{const i=Ir(e,n,r);let o=s[i];t&1<<i&&(o=0),a[r]=o}return a}function $r(t,e,n,s,r){const a=[...r],i=Cr(n,e);for(let r=0;r<a.length;r++)if(i.indexOf(r)>-1)a[r]=Number.MAX_SAFE_INTEGER;else{const i=Ir(e,n,r);let o=s[i];t&1<<i&&(o=Number.MAX_SAFE_INTEGER),a[r]=o}for(let t=0;t<a.length;t++){const e=r[t];a[t]<0&&(a[t]+=e),a[t]=$(0,a[t],r[t])}return a}function Er(t,e,n){let s=t[e];return(n&1<<e||null==s)&&(s=1),s}function Ar(t,e,n,s,r,a){let i=e[r];const o=n[r]||1;(t&1<<r||a&1<<r||null==i)&&(i=o>0?Number.MIN_SAFE_INTEGER:Number.MAX_SAFE_INTEGER);const l=s[r];return i<0&&(i+=l),i=$(0,i,l-1),i}function Rr(t,e,n,s,r,a){let i=e[r];const o=n[r]||1;(t&1<<r||a&1<<r||null==i)&&(i=o>0?Number.MAX_SAFE_INTEGER:Number.MIN_SAFE_INTEGER);const l=s[r];return i<0&&(i+=l),i=o>0?$(0,i,l):$(-1,i,l-1),i}function Dr(t,e,n){let s=n.length;for(let t=0;t<n.length;t++)if(n[t]>1){s=t;break}for(let r=s+1;r<n.length;r++)if(e[r]>0||n[r]!==t[r])return!1;return!0}function Fr(t,e){let n=t.length>0?t[t.length-1]:1;for(let s=0;s<t.length-1;s++)n+=t[s]*e[s];return n}function _r(t,e,n){let s;const r=t.shape.length;let a;return s="number"==typeof e?[e,...new Array(r-1).fill(0)]:e.length<r?e.concat(new Array(r-e.length).fill(0)):e.slice(),s.forEach((t=>{A(-1!==t,(()=>"slice() does not support negative begin indexing."))})),a=null==n?new Array(r).fill(-1):"number"==typeof n?[n,...new Array(r-1).fill(-1)]:n.length<r?n.concat(new Array(r-n.length).fill(-1)):n,a=a.map(((e,n)=>e>=0?e:(A(-1===e,(()=>`Negative size values should be exactly -1 but got ${e} for the slice() size at index ${n}.`)),t.shape[n]-s[n]))),[s,a]}class Or{getClassName(){return this.constructor.className}static fromConfig(t,e){return new t(e)}}class Mr{constructor(){this.classNameMap={}}static getMap(){return null==Mr.instance&&(Mr.instance=new Mr),Mr.instance}static register(t){Mr.getMap().classNameMap[t.className]=[t,t.fromConfig]}}function Lr(t){A(null!=t.className,(()=>"Class being registered does not have the static className property defined.")),A("string"==typeof t.className,(()=>"className is required to be a string, but got type "+typeof t.className)),A(t.className.length>0,(()=>"Class being registered has an empty-string as its className, which is disallowed.")),Mr.register(t)}function zr(t){ct().getBool("DEPRECATION_WARNINGS_ENABLED")&&console.warn(t+" You can disable deprecation warnings with tf.disableDeprecationWarnings().")}function Br(){return fs}function Pr(){return fs.memory()}function Wr(t,e){return fs.tidy(t,e)}function Vr(t){us(t).forEach((t=>t.dispose()))}function Ur(t){return fs.keep(t)}function Gr(t){return fs.setBackend(t)}function Hr(t,e,n=1){return fs.registerBackend(t,e,n)}function jr(t){return fs.customGrad(t)}function qr(t,e){if((j(t)&&"string"!==e||Array.isArray(t))&&"complex64"!==e)throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");if("string"===e&&j(t)&&!(t instanceof Uint8Array))throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");return Cs(t,[],[],e)}Yn=zr;class Kr extends Or{minimize(t,e=!1,n){const{value:s,grads:r}=this.computeGradients(t,n);if(null!=n){const t=n.map((t=>({name:t.name,tensor:r[t.name]})));this.applyGradients(t)}else this.applyGradients(r);return Vr(r),e?s:(s.dispose(),null)}get iterations(){return null==this.iterations_&&(this.iterations_=0),this.iterations_}incrementIterations(){this.iterations_=this.iterations+1}computeGradients(t,e){return function(t,e){A(J(t),(()=>"The f passed in variableGrads(f) must be a function")),A(null==e||Array.isArray(e)&&e.every((t=>t instanceof Zn)),(()=>"The varList passed in variableGrads(f, varList) must be an array of variables"));const n=null!=e;if(!n){e=[];for(const t in fs.registeredVariables)e.push(fs.registeredVariables[t])}const s=n?e.filter((t=>!t.trainable)):null,r=e.length;A((e=e.filter((t=>t.trainable))).length>0,(()=>`variableGrads() expects at least one of the input variables to be trainable, but none of the ${r} variables is trainable.`));const{value:a,grads:i}=fs.gradients(t,e,null,!0);A(i.some((t=>null!=t)),(()=>"Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().")),A(0===a.rank,(()=>`The f passed in variableGrads(f) must return a scalar, but it returned a rank-${a.rank} tensor`));const o={};return e.forEach(((t,e)=>{null!=i[e]&&(o[t.name]=i[e])})),null!=s&&s.forEach((t=>o[t.name]=null)),{value:a,grads:o}}(t,e)}dispose(){null!=this.iterations_&&Vr(this.iterations_)}async saveIterations(){return null==this.iterations_&&(this.iterations_=0),{name:"iter",tensor:qr(this.iterations_,"int32")}}async getWeights(){throw new Error("getWeights() is not implemented for this optimizer yet.")}async setWeights(t){throw new Error("setWeights() is not implemented for this optimizer class "+this.getClassName())}async extractIterations(t){return this.iterations_=(await t[0].tensor.data())[0],t.slice(1)}}Object.defineProperty(Kr,Symbol.hasInstance,{value:t=>null!=t.minimize&&null!=t.computeGradients&&null!=t.applyGradients});const Xr=Ns({abs_:function(t){const e=vs(t,"x","abs"),n={x:e};return fs.runKernelFunc(((t,n)=>(n([e]),"complex64"===e.dtype?t.complexAbs(e):t.abs(e))),n,null,mt)}}),Yr=Ns({add_:function(t,e){let n=vs(t,"a","add"),s=vs(e,"b","add");[n,s]=os(n,s);const r={a:n,b:s};return fs.runKernelFunc(((t,e)=>{const r=t.add(n,s);return e([n,s]),r}),r,null,bt)}});function Jr(t,e){for(let n=0;n<t.length;++n)if(t[t.length-n-1]!==e-1-n)return!1;return!0}function Zr(t,e,n){const s=t.length+e.length,r=[];let a=0,i=0;for(let o=0;o<s;o++)-1===n.indexOf(o)?r.push(t[a++]):r.push(e[i++]);return r}function Qr(t,e){const n=[],s=t.length;for(let r=0;r<s;r++)-1===e.indexOf(r)&&n.push(t[r]);return[n,e.map((e=>t[e]))]}function ta(t,e){return Zr(t,e.map((t=>1)),e)}function ea(t,e,n){A(Jr(e,n),(()=>t+" supports only inner-most axes for now. "+`Got axes ${e} and rank-${n} input.`))}function na(t,e){if(Jr(t,e))return null;const n=[];for(let s=0;s<e;++s)-1===t.indexOf(s)&&n.push(s);return t.forEach((t=>n.push(t))),n}function sa(t){return t.map(((t,e)=>[e,t])).sort(((t,e)=>t[1]-e[1])).map((t=>t[0]))}function ra(t,e){const n=[];for(let s=e-t;s<e;++s)n.push(s);return n}const aa=Ns({reshape_:function(t,e){const n=vs(t,"x","reshape",null),s={x:n},r={shape:e};return fs.runKernelFunc(((t,s)=>(e=P(e,n.size),A(n.size===_(e),(()=>"new shape and old shape must have the same number of elements.")),s([n]),t.reshape(n,e))),s,null,Ge,r)}}),ia=Ns({transpose_:function(t,e){const n=vs(t,"x","transpose");if(null==e&&(e=n.shape.map(((t,e)=>e)).reverse()),A(n.rank===e.length,(()=>`Error in transpose: rank of input ${n.rank} must match length of perm ${e}.`)),e.forEach((t=>{A(t>=0&&t<n.rank,(()=>"All entries in 'perm' must be between 0 and "+(n.rank-1)+" but got "+e))})),n.rank<=1)return n.clone();const s={x:n},r={perm:e};return fs.runKernelFunc((t=>t.transpose(n,e)),s,null,gn,r)}}),oa=Ns({all_:function(t,e=null,n=!1){let s=vs(t,"x","all","bool");const r={x:s},a={axis:e,keepDims:n};return fs.runKernelFunc((t=>{const r=W(e,s.shape);let a=r;const i=na(a,s.rank);null!=i&&(s=ia(s,i),a=ra(a.length,s.rank));const o=t.all(s,a);if(n){const t=ta(o.shape,r);return aa(o,t)}return o}),r,null,"All",a)}}),la=Ns({any_:function(t,e=null,n=!1){let s=vs(t,"x","any","bool");const r={x:s},a={axis:e,keepDims:n};return fs.runKernelFunc((t=>{const r=W(e,s.shape);let a=r;const i=na(a,s.rank);null!=i&&(s=ia(s,i),a=ra(a.length,s.rank));const o=t.any(s,a);if(n){const t=ta(o.shape,r);return aa(o,t)}return o}),r,null,"Any",a)}}),ua=Ns({argMax_:function(t,e=0){let n=vs(t,"x","argMax");const s={x:n},r={axis:e};return fs.runKernelFunc(((t,s)=>{s([n]);let r=W(e,n.shape);const a=na(r,n.rank);return null!=a&&(n=ia(n,a),r=ra(r.length,n.rank)),t.argMax(n,r[0])}),s,null,wt,r)}});function ca(t,e,n,s,r="NHWC",a){return da(t,[...e,t[3]],n,a,s,null,null,ka(r))}function ha(t,e,n,s,r,a,i="channelsLast"){const[o,l]=ga(e);let u;if("channelsLast"===i)u=[o,l,t[3],t[3]];else{if("channelsFirst"!==i)throw new Error("Unknown dataFormat "+i);u=[o,l,t[1],t[1]]}return da(t,u,n,s,r,a,!1,i)}function pa(t,e,n,s,r,a,i="NDHWC"){const[o,l,u]=ya(e);let c,h;if("NDHWC"===i)h="channelsLast",c=[o,l,u,t[4],t[4]];else{if("NCDHW"!==i)throw new Error("Unknown dataFormat "+i);h="channelsFirst",c=[o,l,u,t[1],t[1]]}return fa(t,c,n,s,r,!1,h,a)}function da(t,e,n,s,r,a,i=!1,o="channelsLast"){let[l,u,c,h]=[-1,-1,-1,-1];if("channelsLast"===o)[l,u,c,h]=t;else{if("channelsFirst"!==o)throw new Error("Unknown dataFormat "+o);[l,h,u,c]=t}const[p,d,,f]=e,[m,g]=ga(n),[y,b]=ga(s),x=ba(p,y),w=ba(d,b),{padInfo:v,outHeight:k,outWidth:N}=function(t,e,n,s,r,a,i,o,l){let u,c,h;if("number"==typeof t){u={top:t,bottom:t,left:t,right:t,type:0===t?"VALID":"NUMBER"};const r=function(t,e,n,s,r){null==s&&(s=ma(t,e,n));const a=t[1],i=xa((t[0]-e+2*s)/n+1,r);A(M(i),(()=>`The output # of rows (${i}) must be an integer. Change the stride and/or zero pad parameters`));const o=xa((a-e+2*s)/n+1,r);return A(M(o),(()=>`The output # of columns (${o}) must be an integer. Change the stride and/or zero pad parameters`)),[i,o]}([e,n],a,s,t,o);c=r[0],h=r[1]}else if("same"===t){c=Math.ceil(e/s),h=Math.ceil(n/r);const t=Math.max(0,(c-1)*s+a-e),o=Math.max(0,(h-1)*r+i-n),l=Math.floor(t/2),p=t-l,d=Math.floor(o/2);u={top:l,bottom:p,left:d,right:o-d,type:"SAME"}}else if("valid"===t)u={top:0,bottom:0,left:0,right:0,type:"VALID"},c=Math.ceil((e-a+1)/s),h=Math.ceil((n-i+1)/r);else{if("object"!=typeof t)throw Error("Unknown padding parameter: "+t);{const p="channelsLast"===l?t[1][0]:t[2][0],d="channelsLast"===l?t[1][1]:t[2][1],f="channelsLast"===l?t[2][0]:t[3][0],m="channelsLast"===l?t[2][1]:t[3][1];u={top:p,bottom:d,left:f,right:m,type:0===p&&0===d&&0===f&&0===m?"VALID":"EXPLICIT"},c=xa((e-a+p+d)/s+1,o),h=xa((n-i+f+m)/r+1,o)}}return{padInfo:u,outHeight:c,outWidth:h}}(r,u,c,m,g,x,w,a,o),I=i?f*h:f;let C;return"channelsFirst"===o?C=[l,I,k,N]:"channelsLast"===o&&(C=[l,k,N,I]),{batchSize:l,dataFormat:o,inHeight:u,inWidth:c,inChannels:h,outHeight:k,outWidth:N,outChannels:I,padInfo:v,strideHeight:m,strideWidth:g,filterHeight:p,filterWidth:d,effectiveFilterHeight:x,effectiveFilterWidth:w,dilationHeight:y,dilationWidth:b,inShape:t,outShape:C,filterShape:e}}function fa(t,e,n,s,r,a=!1,i="channelsLast",o){let[l,u,c,h,p]=[-1,-1,-1,-1,-1];if("channelsLast"===i)[l,u,c,h,p]=t;else{if("channelsFirst"!==i)throw new Error("Unknown dataFormat "+i);[l,p,u,c,h]=t}const[d,f,m,,g]=e,[y,b,x]=ya(n),[w,v,k]=ya(s),N=ba(d,w),I=ba(f,v),C=ba(m,k),{padInfo:S,outDepth:T,outHeight:$,outWidth:E}=function(t,e,n,s,r,a,i,o,l,u,c){let h,p,d,f;if("number"==typeof t){h={top:t,bottom:t,left:t,right:t,front:t,back:t,type:0===t?"VALID":"NUMBER"};const a=function(t,e,n,s,r,a){null==r&&(r=ma(t,e,s));const i=t[1],o=t[2],l=xa((t[0]-e+2*r)/s+1,a);A(M(l),(()=>`The output # of depths (${l}) must be an integer. Change the stride and/or zero pad parameters`));const u=xa((i-e+2*r)/s+1,a);A(M(u),(()=>`The output # of rows (${u}) must be an integer. Change the stride and/or zero pad parameters`));const c=xa((o-e+2*r)/s+1,a);return A(M(c),(()=>`The output # of columns (${c}) must be an integer. Change the stride and/or zero pad parameters`)),[l,u,c,1]}([e,n,s,1],o,0,r,t,c);p=a[0],d=a[1],f=a[2]}else if("same"===t){p=Math.ceil(e/r),d=Math.ceil(n/a),f=Math.ceil(s/i);const t=(p-1)*r+o-e,c=(d-1)*a+l-n,m=(f-1)*i+u-s,g=Math.floor(t/2),y=t-g,b=Math.floor(c/2),x=c-b,w=Math.floor(m/2);h={top:b,bottom:x,left:w,right:m-w,front:g,back:y,type:"SAME"}}else{if("valid"!==t)throw Error("Unknown padding parameter: "+t);h={top:0,bottom:0,left:0,right:0,front:0,back:0,type:"VALID"},p=Math.ceil((e-o+1)/r),d=Math.ceil((n-l+1)/a),f=Math.ceil((s-u+1)/i)}return{padInfo:h,outDepth:p,outHeight:d,outWidth:f}}(r,u,c,h,y,b,x,N,I,C,o),R=a?g*p:g;let D;return"channelsFirst"===i?D=[l,R,T,$,E]:"channelsLast"===i&&(D=[l,T,$,E,R]),{batchSize:l,dataFormat:i,inDepth:u,inHeight:c,inWidth:h,inChannels:p,outDepth:T,outHeight:$,outWidth:E,outChannels:R,padInfo:S,strideDepth:y,strideHeight:b,strideWidth:x,filterDepth:d,filterHeight:f,filterWidth:m,effectiveFilterDepth:N,effectiveFilterHeight:I,effectiveFilterWidth:C,dilationDepth:w,dilationHeight:v,dilationWidth:k,inShape:t,outShape:D,filterShape:e}}function ma(t,e,n,s=1){const r=ba(e,s);return Math.floor((t[0]*(n-1)-n+r)/2)}function ga(t){return"number"==typeof t?[t,t,t]:2===t.length?[t[0],t[1],1]:t}function ya(t){return"number"==typeof t?[t,t,t]:t}function ba(t,e){return e<=1?t:t+(t-1)*(e-1)}function xa(t,e){if(!e)return t;switch(e){case"round":return Math.round(t);case"ceil":return Math.ceil(t);case"floor":return Math.floor(t);default:throw new Error("Unknown roundingMode "+e)}}function wa(t){const[e,n,s]=ga(t);return 1===e&&1===n&&1===s}function va(t,e){return wa(t)||wa(e)}function ka(t){if("NHWC"===t)return"channelsLast";if("NCHW"===t)return"channelsFirst";throw new Error("Unknown dataFormat "+t)}const Na=Ns({avgPool_:function(t,e,n,s,r){const a=vs(t,"x","avgPool","float32");A(va(n,1),(()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`));let i=a,o=!1;3===a.rank&&(o=!0,i=aa(a,[1,a.shape[0],a.shape[1],a.shape[2]])),A(4===i.rank,(()=>`Error in avgPool: x must be rank 4 but got rank ${i.rank}.`)),null!=r&&A(M(s),(()=>`Error in avgPool: pad must be an integer when using, dimRoundingMode ${r} but got pad ${s}.`));const l={x:i},u={filterSize:e,strides:n,pad:s,dimRoundingMode:r};let c=fs.runKernelFunc(((t,a)=>{const o=ha(i.shape,e,n,1,s,r);return a([i]),1===o.filterWidth&&1===o.filterHeight&&O(o.inShape,o.outShape)?i.clone():t.avgPool(i,o)}),l,null,Tt,u);return c=or(c,a.dtype),o?aa(c,[c.shape[1],c.shape[2],c.shape[3]]):c}}),Ia=Ns({avgPool3d_:function(t,e,n,s,r,a="NDHWC",i){null==i?i=[1,1,1]:zr("dilations is deprecated, this field will be gone in v3.0.0.");const o=vs(t,"x","avgPool3d","float32");let l=o,u=!1;4===o.rank&&(u=!0,l=aa(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]])),A(5===l.rank,(()=>`Error in avgPool3d: x must be rank 5 but got rank ${l.rank}.`)),A("NDHWC"===a,(()=>"Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of "+a)),A(va(n,i),(()=>`Error in avgPool3d: Either strides or dilations must be 1. Got strides ${n} and dilations '${i}'`)),null!=r&&A(M(s),(()=>`Error in avgPool3d: pad must be an integer when using, dimRoundingMode ${r} but got pad ${s}.`));const c={x:l},h={filterSize:e,strides:n,pad:s,dimRoundingMode:r,dataFormat:a,dilations:i};let p=fs.runKernelFunc(((t,o)=>{null==i&&(i=[1,1,1]);const u=pa(l.shape,e,n,i,s,r,a);return o([l]),t.avgPool3d(l,u)}),c,null,Et,h);return p=or(p,l.dtype),u?aa(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}});function Ca(t){return null==t?null:0===t.rank?aa(t,[t.size]):1===t.rank?t:2===t.rank?aa(t,[1,1,t.shape[0],t.shape[1]]):3===t.rank?aa(t,[1,t.shape[0],t.shape[1],t.shape[2]]):t}const Sa=Ns({batchNorm_:function(t,e,n,s,r,a){null==a&&(a=.001);const i=vs(t,"x","batchNorm"),o=vs(e,"mean","batchNorm"),l=vs(n,"variance","batchNorm");let u,c;null!=r&&(u=vs(r,"scale","batchNorm")),null!=s&&(c=vs(s,"offset","batchNorm")),A(o.rank===l.rank,(()=>"Batch normalization gradient requires mean and variance to have equal ranks.")),A(null==c||o.rank===c.rank,(()=>"Batch normalization gradient requires mean and offset to have equal ranks.")),A(null==u||o.rank===u.rank,(()=>"Batch normalization gradient requires mean and scale to have equal ranks."));const h=function(t){let e;return e=0===t.rank||1===t.rank?aa(t,[1,1,1,t.size]):2===t.rank?aa(t,[1,1,t.shape[0],t.shape[1]]):3===t.rank?aa(t,[1,t.shape[0],t.shape[1],t.shape[2]]):t,e}(i),p={x:h,scale:u,offset:c,mean:o,variance:l},d={varianceEpsilon:a},f=fs.runKernelFunc(((t,e)=>(e([h,o,l,u]),t.batchNorm(h,Ca(o),Ca(l),Ca(c),Ca(u),a))),p,null,ue,d);return aa(f,i.shape)}}),Ta=Ns({batchNorm2d_:function(t,e,n,s,r,a){const i=vs(t,"x","batchNorm"),o=vs(e,"mean","batchNorm"),l=vs(n,"variance","batchNorm");let u,c;return null!=r&&(u=vs(r,"scale","batchNorm")),null!=s&&(c=vs(s,"offset","batchNorm")),A(2===i.rank,(()=>"Error in batchNorm2D: x must be rank 2 but got rank "+i.rank+".")),A(2===o.rank||1===o.rank,(()=>`Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${o.rank}.`)),A(2===l.rank||1===l.rank,(()=>`Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${l.rank}.`)),null!=u&&A(2===u.rank||1===u.rank,(()=>`Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${u.rank}.`)),null!=c&&A(2===c.rank||1===c.rank,(()=>`Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${c.rank}.`)),Sa(i,o,l,c,u,a)}}),$a=Ns({batchNorm3d_:function(t,e,n,s,r,a){const i=vs(t,"x","batchNorm"),o=vs(e,"mean","batchNorm"),l=vs(n,"variance","batchNorm");let u,c;return null!=r&&(u=vs(r,"scale","batchNorm")),null!=s&&(c=vs(s,"offset","batchNorm")),A(3===i.rank,(()=>"Error in batchNorm3D: x must be rank 3 but got rank "+i.rank+".")),A(3===o.rank||1===o.rank,(()=>`Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${o.rank}.`)),A(3===l.rank||1===l.rank,(()=>`Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${l.rank}.`)),null!=u&&A(3===u.rank||1===u.rank,(()=>`Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${u.rank}.`)),null!=c&&A(3===c.rank||1===c.rank,(()=>`Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${c.rank}.`)),Sa(i,o,l,c,u,a)}}),Ea=Ns({batchNorm4d_:function(t,e,n,s,r,a){const i=vs(t,"x","batchNorm"),o=vs(e,"mean","batchNorm"),l=vs(n,"variance","batchNorm");let u,c;return null!=r&&(u=vs(r,"scale","batchNorm")),null!=s&&(c=vs(s,"offset","batchNorm")),A(4===i.rank,(()=>"Error in batchNorm4D: x must be rank 4 but got rank "+i.rank+".")),A(4===o.rank||1===o.rank,(()=>`Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${o.rank}.`)),A(4===l.rank||1===l.rank,(()=>`Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${l.rank}.`)),null!=u&&A(4===u.rank||1===u.rank,(()=>`Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${u.rank}.`)),null!=c&&A(4===c.rank||1===c.rank,(()=>`Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${c.rank}.`)),Sa(i,o,l,c,u,a)}}),Aa=Ns({clipByValue_:function(t,e,n){const s=vs(t,"x","clipByValue");A(e<=n,(()=>`Error in clip: min (${e}) must be less than or equal to max (${n}).`));const r={x:s},a={clipValueMin:e,clipValueMax:n};return fs.runKernelFunc(((t,r)=>{const a=t.clip(s,e,n);return r([s]),a}),r,null,Ot,a)}});function Ra(t,e){const n=t[0].length;t.forEach(((t,e)=>{A(t.length===n,(()=>`Error in concat${n}D: rank of tensors[${e}] must be the same as the rank of the rest (${n})`))})),A(e>=0&&e<n,(()=>`Error in concat${n}D: axis must be between 0 and ${n-1}.`));const s=t[0];t.forEach(((t,r)=>{for(let a=0;a<n;a++)A(a===e||t[a]===s[a],(()=>`Error in concat${n}D: Shape of tensors[${r}] (${t}) does not match the shape of the rest (${s}) along the non-concatenated axis ${r}.`))}))}function Da(t,e){const n=t[0].slice();for(let s=1;s<t.length;s++)n[e]+=t[s][e];return n}const Fa=Ns({concat_:function(t,e=0){A(t.length>=1,(()=>"Pass at least one tensor to concat"));let n=ks(t,"tensors","concat");"complex64"===n[0].dtype&&n.forEach((t=>{if("complex64"!==t.dtype)throw new Error(`Cannot concatenate complex64 tensors with a tensor\n          with dtype ${t.dtype}. `)}));const s=n,r={axis:e};return fs.runKernelFunc(((t,s)=>{const r=W(e,n[0].shape)[0],a=Da(n.map((t=>t.shape)),r);if(0===_(a))return Ss([],a);if(n=n.filter((t=>t.size>0)),1===n.length)return n[0];Ra(n.map((t=>t.shape)),r);const i=t.concat(n,r);return s(n),i}),s,null,Lt,r)}}),_a=Ns({concat1d_:function(t){return Fa(t,0)}}),Oa=Ns({concat2d_:function(t,e){return Fa(t,e)}}),Ma=Ns({concat3d_:function(t,e){return Fa(t,e)}}),La=Ns({concat4d_:function(t,e){return Fa(t,e)}}),za=Ns({conv2d_:function(t,e,n,s,r="NHWC",a=[1,1],i){const o=vs(t,"x","conv2d"),l=vs(e,"filter","conv2d");let u=o,c=!1;3===o.rank&&(c=!0,u=aa(o,[1,o.shape[0],o.shape[1],o.shape[2]])),A(4===u.rank,(()=>`Error in conv2d: input must be rank 4, but got rank ${u.rank}.`)),A(4===l.rank,(()=>"Error in conv2d: filter must be rank 4, but got rank "+l.rank+".")),null!=i&&A(M(s),(()=>`Error in conv2d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${s}.`));const h="NHWC"===r?u.shape[3]:u.shape[1];A(h===l.shape[2],(()=>`Error in conv2d: depth of input (${h}) must match input depth for filter ${l.shape[2]}.`)),A(va(n,a),(()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`));const p={x:u,filter:l},d={strides:n,pad:s,dataFormat:r,dilations:a,dimRoundingMode:i},f=fs.runKernelFunc(((t,e)=>{const o=ka(r),c=da(u.shape,l.shape,n,a,s,i,!1,o),h=t.conv2d(u,l,c);return e([u,l]),h}),p,null,zt,d);return c?aa(f,[f.shape[1],f.shape[2],f.shape[3]]):f}}),Ba=Ns({conv1d_:function(t,e,n,s,r="NWC",a=1,i){const o=vs(t,"x","conv1d"),l=vs(e,"filter","conv1d");let u=o,c=!1;2===o.rank&&(c=!0,u=aa(o,[1,o.shape[0],o.shape[1]])),A(3===u.rank,(()=>`Error in conv1d: input must be rank 3, but got rank ${u.rank}.`)),A(3===l.rank,(()=>"Error in conv1d: filter must be rank 3, but got rank "+l.rank+".")),null!=i&&A(M(s),(()=>`Error in conv1d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${s}.`)),A(u.shape[2]===l.shape[1],(()=>`Error in conv1d: depth of input (${u.shape[2]}) must match input depth for filter ${l.shape[1]}.`)),A(va(n,a),(()=>`Error in conv1D: Either stride or dilation must be 1. Got stride ${n} and dilation '${a}'`)),A("NWC"===r,(()=>`Error in conv1d: got dataFormat of ${r} but only NWC is currently supported.`));const h=aa(l,[1,l.shape[0],l.shape[1],l.shape[2]]),p=aa(u,[u.shape[0],1,u.shape[1],u.shape[2]]),d=za(p,h,[1,n],s,"NHWC",[1,a],i);return aa(d,c?[d.shape[2],d.shape[3]]:[d.shape[0],d.shape[2],d.shape[3]])}}),Pa=Ns({conv2DBackpropInput_:function(t,e,n,s,r,a="NHWC",i){A(t.length===e.rank,(()=>`Length of inShape (${t.length}) and rank of dy (${e.rank}) must match`));let o=t,l=e,u=!1;3===e.rank&&(u=!0,l=aa(e,[1,e.shape[0],e.shape[1],e.shape[2]]),o=[1,t[0],t[1],t[2]]),A(4===o.length,(()=>"Error in conv2dDerInput: inShape must be length 4, but got length "+o.length+".")),A(4===l.rank,(()=>"Error in conv2dDerInput: dy must be rank 4, but got rank "+l.rank)),A(4===n.rank,(()=>"Error in conv2dDerInput: filter must be rank 4, but got rank "+n.rank));const c="NHWC"===a?o[3]:o[1],h="NHWC"===a?l.shape[3]:l.shape[1];A(c===n.shape[2],(()=>`Error in conv2dDerInput: depth of input (${c}) must match input depth for filter ${n.shape[2]}.`)),A(h===n.shape[3],(()=>`Error in conv2dDerInput: depth of output (${h}) must match output depth for filter ${n.shape[3]}.`)),null!=i&&A(M(r),(()=>`Error in conv2dDerInput: pad must be an integer when using, dimRoundingMode ${i} but got pad ${r}.`));const p={dy:l,filter:n},d={strides:s,pad:r,dataFormat:a,dimRoundingMode:i,inputShape:o},f=fs.runKernelFunc(((t,e)=>{const u=ka(a),c=da(o,n.shape,s,1,r,i,!1,u),h=t.conv2dDerInput(l,n,c);return e([l,n]),h}),p,null,Pt,d);return u?aa(f,[f.shape[1],f.shape[2],f.shape[3]]):f}}),Wa=Ns({conv2dTranspose_:function(t,e,n,s,r,a){const i=vs(t,"x","conv2dTranspose"),o=vs(e,"filter","conv2dTranspose");return Pa(n,i,o,s,r,"NHWC",a)}}),Va=Ns({conv3d_:function(t,e,n,s,r="NDHWC",a=[1,1,1]){const i=vs(t,"x","conv3d"),o=vs(e,"filter","conv3d");let l=i,u=!1;4===i.rank&&(u=!0,l=aa(i,[1,i.shape[0],i.shape[1],i.shape[2],i.shape[3]])),A(5===l.rank,(()=>`Error in conv3d: input must be rank 5, but got rank ${l.rank}.`)),A(5===o.rank,(()=>"Error in conv3d: filter must be rank 5, but got rank "+o.rank+".")),A(l.shape[4]===o.shape[3],(()=>`Error in conv3d: depth of input (${l.shape[4]}) must match input depth for filter ${o.shape[3]}.`)),A(va(n,a),(()=>`Error in conv3D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`)),A("NDHWC"===r,(()=>`Error in conv3d: got dataFormat of ${r} but only NDHWC is currently supported.`));const c={x:l,filter:o},h={strides:n,pad:s,dataFormat:r,dilations:a},p=fs.runKernelFunc(((t,e)=>{const r=fa(l.shape,o.shape,n,a,s),i=t.conv3d(l,o,r);return e([l,o]),i}),c,null,Wt,h);return u?aa(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}}),Ua=Ns({depthwiseConv2d_:function(t,e,n,s,r="NHWC",a=[1,1],i){const o=vs(t,"x","depthwiseConv2d"),l=vs(e,"filter","depthwiseConv2d");let u=o,c=!1;3===o.rank&&(c=!0,u=aa(o,[1,o.shape[0],o.shape[1],o.shape[2]])),A(4===u.rank,(()=>`Error in depthwiseConv2d: input must be rank 4, but got rank ${u.rank}.`)),A(4===l.rank,(()=>"Error in depthwiseConv2d: filter must be rank 4, but got rank "+l.rank+".")),A(u.shape[3]===l.shape[2],(()=>`Error in depthwiseConv2d: number of input channels (${u.shape[3]}) must match the inChannels dimension in filter ${l.shape[2]}.`)),null!=i&&A(M(s),(()=>`Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${s}.`));const h={x:u,filter:l},p={strides:n,pad:s,dataFormat:r,dilations:a,dimRoundingMode:i},d=fs.runKernelFunc(((t,e)=>{null==a&&(a=[1,1]),A(va(n,a),(()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`));const r=da(u.shape,l.shape,n,a,s,i,!0),o=t.depthwiseConv2D(u,l,r);return e([u,l]),o}),h,null,qt,p);return c?aa(d,[d.shape[1],d.shape[2],d.shape[3]]):d}}),Ga=Ns({floorDiv_:function(t,e){let n=vs(t,"a","floorDiv"),s=vs(e,"b","floorDiv");[n,s]=os(n,s);const r={a:n,b:s};return fs.runKernelFunc(((t,e)=>{const r=t.floorDiv(n,s);return e([n,s]),r}),r,null,le)}}),Ha=Ns({div_:function(t,e){let n=vs(t,"a","div"),s=vs(e,"b","div");if([n,s]=os(n,s),"int32"===n.dtype&&"int32"===s.dtype)return Ga(n,s);const r={a:n,b:s};return fs.runKernelFunc(((t,e)=>{const r=t.realDivide(n,s);return e([n,s]),r}),r,null,Qt,{})}}),ja=Ns({elu_:function(t){const e=vs(t,"x","elu"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.elu(e);return n([s]),s}),n,null,te)}});function qa(t,e){const n=t.length,s=[];for(let r=0;r<n;r++){const a=n-1-r,i=t[a]||1;(e[e.length-1-r]||1)>1&&1===i&&s.unshift(a)}return s}function Ka(t,e){const n=[];for(let s=0;s<e.length;s++){const r=t[t.length-s-1],a=e.length-s-1,i=e[a];(null==r||1===r&&i>1)&&n.unshift(a)}return n}function Xa(t,e){const n=[],s=Math.max(t.length,e.length);for(let r=0;r<s;r++){let s=t[t.length-r-1];null==s&&(s=1);let a=e[e.length-r-1];if(null==a&&(a=1),1===s)n.unshift(a);else if(1===a)n.unshift(s);else{if(s!==a)throw Error(`Operands could not be broadcast together with shapes ${t} and ${e}.`);n.unshift(s)}}return n}const Ya=Ns({equal_:function(t,e){let n=vs(t,"a","equal"),s=vs(e,"b","equal");[n,s]=os(n,s),Xa(n.shape,s.shape);const r={a:n,b:s};return fs.runKernelFunc((t=>t.equal(n,s)),r,null,"Equal")}}),Ja=Ns({exp_:function(t){const e=vs(t,"x","exp"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.exp(e);return n([s]),s}),n,null,ne)}}),Za=Ns({expandDims_:function(t,e=0){const n=vs(t,"x","expandDims",null);A(e<=n.rank,(()=>"Axis must be <= rank of the tensor"));const s=n.shape.slice();return e<0&&(A(-(n.rank+1)<=e,(()=>`Axis must be in the interval [${-(n.rank+1)}, ${n.rank}]`)),e=n.rank+e+1),s.splice(e,0,1),aa(n,s)}}),Qa=Ns({tile_:function(t,e){const n=vs(t,"x","tile",null);A(n.rank===e.length,(()=>`Error in transpose: rank of input ${n.rank} must match length of reps ${e}.`));const s=[n],r={x:n},a={reps:e};return fs.runKernelFunc(((t,s)=>{const r=t.tile(n,e);return s([n]),r}),r,null,mn,a,s)}}),ti=Ns({eye_:function(t,e,n,s="float32"){null==e&&(e=t);const r=ir([t,e],s),a=t<=e?t:e;for(let t=0;t<a;++t)r.set(1,t,t);const i=aa(r.toTensor(),[t,e]);if(null==n)return i;if(1===n.length)return Qa(Za(i,0),[n[0],1,1]);if(2===n.length)return Qa(Za(Za(i,0),0),[n[0],n[1],1,1]);if(3===n.length)return Qa(Za(Za(Za(i,0),0),0),[n[0],n[1],n[2],1,1]);throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${n.length}D.`)}});function ei(t,e,n){const s={shape:t,value:e,dtype:n};return fs.runKernelFunc((s=>s.fill(t,e,n)),{},null,ae,s)}const ni=Ns({floor_:function(t){const e=vs(t,"x","floor"),n={x:e};return fs.runKernelFunc((t=>t.floor(e)),n,null,oe)}}),si=30;function ri(t){return t<=si?t:Z(t,Math.floor(Math.sqrt(t)))}function ai(t,e){let n,s=!1;for(t<=si?(n=t,s=!0):n=Z(t,Math.floor(Math.sqrt(t)));!s;)n>e||n===t?s=!0:n=Z(t,n+1);return n}function ii(t,e,n){const s=[],r=t.length;for(let a=0;a<r;a++)a!==e?s.push(t[a]):s.push(n);return s}function oi(t,e,n){const s=t.shape[n],r=[];let a=1,i=1;for(let e=0;e<n;e++)r.push(t.shape[e]),a*=t.shape[e];for(let t=0;t<e.rank;t++)r.push(e.shape[t]);for(let e=n+1;e<t.rank;e++)r.push(t.shape[e]),i*=t.shape[e];return{batchSize:a,sliceSize:i,dimSize:s,outputShape:r}}const li=Ns({gather_:function(t,e,n=0){const s=vs(t,"x","gather"),r=vs(e,"indices","gather","int32"),a={x:s,indices:r},i={axis:n};return fs.runKernelFunc(((t,e)=>{const a=W(n,s.shape)[0],i=oi(s,r,a),o=t.gather(s,aa(r,[r.size]),a);return e([s,r]),aa(o,i.outputShape)}),a,null,ce,i)}}),ui=Ns({greater_:function(t,e){let n=vs(t,"a","greater"),s=vs(e,"b","greater");[n,s]=os(n,s),Xa(n.shape,s.shape);const r={a:n,b:s};return fs.runKernelFunc((t=>t.greater(n,s)),r,null,"Greater")}}),ci=Ns({greaterEqual_:function(t,e){let n=vs(t,"a","greaterEqual"),s=vs(e,"b","greaterEqual");[n,s]=os(n,s),Xa(n.shape,s.shape);const r={a:n,b:s};return fs.runKernelFunc(((t,e)=>{const r=t.greaterEqual(n,s);return e([n,s]),r}),r,null,he)}}),hi=Ns({maximum_:function(t,e){let n=vs(t,"a","maximum"),s=vs(e,"b","maximum");[n,s]=os(n,s),"bool"===n.dtype&&(n=or(n,"int32"),s=or(s,"int32")),Xa(n.shape,s.shape);const r={a:n,b:s};return fs.runKernelFunc(((t,e)=>{const r=t.maximum(n,s);return e([n,s]),r}),r,null,Ne)}}),pi=Ns({mul_:function(t,e){let n=vs(t,"a","mul"),s=vs(e,"b","mul");[n,s]=os(n,s);const r={a:n,b:s};return fs.runKernelFunc(((t,e)=>{const r=t.multiply(n,s);return e([n,s]),r}),r,null,Re)}}),di=Ns({leakyRelu_:function(t,e=.2){const n=vs(t,"x","leakyRelu");return hi(pi(qr(e),n),n)}}),fi=Ns({log_:function(t){const e=vs(t,"x","log"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.log(e);return n([e]),s}),n,null,be)}}),mi=Ns({max_:function(t,e=null,n=!1){const s=vs(t,"x","max"),r={x:s},a={reductionIndices:e,keepDims:n};return fs.runKernelFunc(((t,r)=>{let a=W(e,s.shape);const i=na(a,s.rank);let o=s;null!=i&&(o=ia(s,i),a=ra(a.length,o.rank));const l=t.max(o,a);null!=i&&o.dispose();let u=l;if(n){const t=ta(u.shape,W(e,s.shape));u=aa(u,t),l.dispose()}return r([s,u]),u}),r,null,ke,a)}}),gi=Ns({sub_:function(t,e){let n=vs(t,"a","sub"),s=vs(e,"b","sub");[n,s]=os(n,s);const r={a:n,b:s};return fs.runKernelFunc(((t,e)=>{const r=t.subtract(n,s);return e([n,s]),r}),r,null,pn)}}),yi=Ns({sum_:function(t,e=null,n=!1){let s=vs(t,"x","sum");"bool"===s.dtype&&(s=or(s,"int32"));const r={x:s},a={axis:e,keepDims:n};return fs.runKernelFunc(((t,r)=>{r([s]);const a=W(e,s.shape),i=na(a,s.rank);let o=a,l=s;null!=i&&(l=ia(s,i),o=ra(o.length,s.rank));let u=t.sum(l,o);if(n){const t=ta(u.shape,a);u=aa(u,t)}return u}),r,null,"Sum",a)}}),bi=Ns({logSoftmax_:function(t,e=-1){const n=vs(t,"logits","logSoftmax");if(-1===e&&(e=n.rank-1),e!==n.rank-1)throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and axis was ${e}`);const s={logits:n},r={axis:e};return fs.runKernelFunc(((n,s)=>{const r=mi(t,e,!0),a=gi(t,r),i=gi(or(a,"float32"),fi(yi(Ja(a),e,!0)));return s([i]),i}),s,null,ve,r)}}),xi=Ns({logicalAnd_:function(t,e){const n=vs(t,"a","logicalAnd","bool"),s=vs(e,"b","logicalAnd","bool");Xa(n.shape,s.shape);const r={a:n,b:s};return fs.runKernelFunc((t=>t.logicalAnd(n,s)),r,null,"LogicalAnd")}}),wi=Ns({maxPool_:function(t,e,n,s,r){const a=vs(t,"x","maxPool");let i=a,o=!1;3===a.rank&&(o=!0,i=aa(a,[1,a.shape[0],a.shape[1],a.shape[2]])),A(4===i.rank,(()=>`Error in maxPool: input must be rank 4 but got rank ${i.rank}.`)),A(va(n,1),(()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`)),null!=r&&A(M(s),(()=>`Error in maxPool: pad must be an integer when using, dimRoundingMode ${r} but got pad ${s}.`));const l={x:i},u={filterSize:e,strides:n,pad:s,dimRoundingMode:r},c=fs.runKernelFunc(((t,a)=>{const o=ha(i.shape,e,n,1,s,r);let l;return l=1===o.filterWidth&&1===o.filterHeight&&O(o.inShape,o.outShape)?i.clone():t.maxPool(i,o),a([i,l]),l}),l,null,Ie,u);return o?aa(c,[c.shape[1],c.shape[2],c.shape[3]]):c}}),vi=Ns({maxPool3d_:function(t,e=[1,1,1],n,s,r,a="NDHWC",i){null==i?i=[1,1,1]:zr("dilations is deprecated, this field will be gone in v3.0.0.");const o=vs(t,"x","maxPool3d");let l=o,u=!1;4===o.rank&&(u=!0,l=aa(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]])),A(5===l.rank,(()=>`Error in maxPool3d: x must be rank 5 but got rank ${l.rank}.`)),A("NDHWC"===a,(()=>"Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of "+a)),A(va(n,i),(()=>`Error in maxPool3d: Either strides or dilations must be 1. Got strides ${n} and dilations '${i}'`)),null!=r&&A(M(s),(()=>`Error in maxPool3d: pad must be an integer when using, dimRoundingMode ${r} but got pad ${s}.`));const c={x:l},h={filterSize:e,strides:n,pad:s,dimRoundingMode:r,dataFormat:a,dilations:i},p=fs.runKernelFunc(((t,o)=>{null==i&&(i=[1,1,1]);const u=pa(l.shape,e,n,i,s,r,a),c=t.maxPool3d(l,u);return o([l,c]),c}),c,null,Se,h);return u?aa(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}});function ki(t,e="float32"){if("complex64"===e){const e=ki(t,"float32"),n=ki(t,"float32");return Is(e,n)}const n=st(_(t),e);return fs.makeTensor(n,t,e)}function Ni(t,e="float32"){if("complex64"===e){const e=Ni(t,"float32"),n=ki(t,"float32");return Is(e,n)}const n=nt(_(t),e);return fs.makeTensor(n,t,e)}const Ii=Ns({mean_:function(t,e=null,n=!1){const s=vs(t,"x","mean"),r=W(e,s.shape),a=_(Qr(s.shape,r)[1]),i={x:s},o={axis:e,keepDims:n},l=()=>{const t=qr(a),r=t.dtype===s.dtype?s:or(s,t.dtype),i=Ha(r,t);return yi(i,e,n)};return jr((t=>({value:fs.runKernelFunc(l,i,null,$e,o),gradFunc:e=>{const n=t.shape.slice();r.forEach((t=>{n[t]=1}));const s=aa(e,n);return Ha(pi(s,Ni(t.shape,"float32")),a)}})))(s)}}),Ci=Ns({min_:function(t,e=null,n=!1){const s=vs(t,"x","min"),r={x:s},a={axis:e,keepDims:n};return fs.runKernelFunc(((t,r)=>{const a=W(e,s.shape);let i=a;const o=na(i,s.rank);let l=s;null!=o&&(l=ia(s,o),i=ra(i.length,s.rank));const u=t.min(l,i);null!=o&&l.dispose();let c=u;if(n){const t=ta(c.shape,a);c=aa(u,t),u.dispose()}return r([s,c]),c}),r,null,"Min",a)}}),Si=Ns({minimum_:function(t,e){let n=vs(t,"a","minimum"),s=vs(e,"b","minimum");[n,s]=os(n,s),"bool"===n.dtype&&(n=or(n,"int32"),s=or(s,"int32")),Xa(n.shape,s.shape);const r={a:n,b:s};return fs.runKernelFunc(((t,e)=>{const r=t.minimum(n,s);return e([n,s]),r}),r,null,Ee)}}),Ti=Ns({square_:function(t){const e=vs(t,"x","square"),n=[e];return fs.runKernelFunc(((t,n)=>(n([e]),t.square(e))),{x:e},null,"Square",{},n,[])}}),$i=Ns({moments_:function(t,e=null,n=!1){const s=W(e,(t=vs(t,"x","moments")).shape),r=Ii(t,s,n);let a=r.shape;n||(a=ta(r.shape,s));const i=Ti(gi(or(t,"float32"),aa(r,a)));return{mean:r,variance:Ii(i,s,n)}}}),Ei=Ns({neg_:function(t){const e=vs(t,"x","neg"),n={x:e};return fs.runKernelFunc((t=>t.neg(e)),n,null,De)}}),Ai=Ns({notEqual_:function(t,e){let n=vs(t,"a","notEqual"),s=vs(e,"b","notEqual");[n,s]=os(n,s),Xa(n.shape,s.shape);const r={a:n,b:s};return fs.runKernelFunc((t=>t.notEqual(n,s)),r,null,Fe)}}),Ri=Ns({oneHot_:function(t,e,n=1,s=0){if(e<2)throw new Error("Error in oneHot: depth must be >=2, but it is "+e);const r=vs(t,"indices","oneHot","int32"),a=[...r.shape,e],i={indices:r},o={depth:e,onValue:n,offValue:s};return fs.runKernelFunc(((t,i)=>(i([r]),aa(t.oneHot(aa(r,[r.size]),e,n,s),a))),i,null,ze,o)}}),Di=Ns({imag_:function(t){const e=vs(t,"input","imag"),n={input:e};return fs.runKernelFunc((t=>t.imag(e)),n,null,fe)}}),Fi=Ns({real_:function(t){const e=vs(t,"input","real"),n={input:e};return fs.runKernelFunc((t=>t.real(e)),n,null,We)}}),_i=Ns({zerosLike_:function(t){const e=vs(t,"x","zerosLike"),n={x:e};return fs.runKernelFunc((t=>t.zerosLike(e)),n,null,wn)}}),Oi=Ns({onesLike_:function(t){const e=vs(t,"x","onesLike"),n={x:e};return fs.runKernelFunc(((t,n)=>{if("complex64"===e.dtype){const t=Oi(Fi(e)),n=_i(Di(e));return Is(t,n)}return t.onesLike(e)}),n,null,Le)}}),Mi=Ns({pad_:function(t,e,n=0){const s=vs(t,"x","pad");if(0===s.rank)throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");const r={paddings:e,constantValue:n},a={x:s};return fs.runKernelFunc(((t,r)=>(r([s]),t.pad(s,e,n))),a,null,Be,r)}}),Li=Ns({prelu_:function(t,e){const n=vs(t,"x","prelu"),s=vs(e,"alpha","prelu"),r={x:n,alpha:s};return fs.runKernelFunc(((t,e)=>{const r=t.prelu(n,s);return e([n,s]),r}),r,null,Pe)}});var zi=n(377);class Bi{constructor(t,e,n,s,r){this.mean=t,this.stdDev=e,this.dtype=n,this.nextVal=NaN,this.truncated=s,this.truncated&&(this.upper=this.mean+2*this.stdDev,this.lower=this.mean-2*this.stdDev);const a=r||Math.random();this.random=zi.alea(a.toString())}nextValue(){if(!isNaN(this.nextVal)){const t=this.nextVal;return this.nextVal=NaN,t}let t,e,n=!1;for(;!n;){let s,r,a;do{s=2*this.random()-1,r=2*this.random()-1,a=s*s+r*r}while(a>=1||0===a);const i=Math.sqrt(-2*Math.log(a)/a);t=this.mean+this.stdDev*s*i,e=this.mean+this.stdDev*r*i,this.truncated&&!this.isValidTruncated(t)||(n=!0)}return this.truncated&&!this.isValidTruncated(e)||(this.nextVal=this.convertValue(e)),this.convertValue(t)}convertValue(t){return null==this.dtype||"float32"===this.dtype?t:Math.round(t)}isValidTruncated(t){return t<=this.upper&&t>=this.lower}}class Pi{constructor(t=0,e=1,n,s){if(this.canReturnFloat=()=>null==this.dtype||"float32"===this.dtype,this.min=t,this.range=e-t,this.dtype=n,null==s&&(s=Math.random()),"number"==typeof s&&(s=s.toString()),!this.canReturnFloat()&&this.range<=1)throw new Error(`The difference between ${t} - ${e} <= 1 and dtype is not float`);this.random=zi.alea(s)}convertValue(t){return this.canReturnFloat()?t:Math.round(t)}nextValue(){return this.convertValue(this.min+this.range*this.random())}}const Wi=Ns({randomNormal_:function(t,e=0,n=1,s,r){if(null!=s&&"bool"===s)throw new Error("Unsupported data type "+s);const a=new Bi(e,n,s,!1,r),i=ir(t,s);for(let t=0;t<i.values.length;t++)i.values[t]=a.nextValue();return i.toTensor()}}),Vi=Ns({randomUniform_:function(t,e=0,n=1,s="float32",r){const a=ir(t,s),i=new Pi(e,n,null,r);for(let t=0;t<a.values.length;t++)a.values[t]=i.nextValue();return a.toTensor()}});function Ui(t,e){D(t);const n=bs(t,e);if(1!==n.length)throw new Error("tensor1d() requires values to be a flat/TypedArray");return Cs(t,null,n,e)}function Gi(t,e,n=1,s="float32"){if(0===n)throw new Error("Cannot have a step of zero");const r={start:t,stop:e,step:n,dtype:s};return fs.runKernelFunc((()=>{if(t===e||t<e&&n<0||e<t&&n>1)return ki([0],s);const r=st(Math.abs(Math.ceil((e-t)/n)),s);e<t&&1===n&&(n=-1),r[0]=t;for(let t=1;t<r.length;t++)r[t]=r[t-1]+n;return Ui(r,s)}),{},null,"Range",r)}const Hi=Ns({relu_:function(t){const e=vs(t,"x","relu"),n={x:e};return fs.runKernelFunc(((t,n)=>(n([e]),"bool"===e.dtype?or(e,"int32"):t.relu(e))),n,null,Ue)}}),ji=Ns({reverse_:function(t,e){const n=vs(t,"x","reverse"),s={x:n},r={dims:e};return fs.runKernelFunc((t=>{const s=W(e,n.shape);if(0===n.rank)return lr(n);const r=t.reverse(n,s);return aa(r,n.shape)}),s,null,Ke,r)}}),qi=Ns({selu_:function(t){const e=vs(t,"x","selu"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.selu(e);return n([e]),s}),n,null,Ze)}}),Ki=Ns({separableConv2d_:function(t,e,n,s,r,a=[1,1],i="NHWC"){const o=vs(t,"x","separableConv2d"),l=vs(e,"depthwiseFilter","separableConv2d"),u=vs(n,"pointwiseFilter","separableConv2d");let c=o,h=!1;if(3===o.rank&&(h=!0,c=aa(o,[1,o.shape[0],o.shape[1],o.shape[2]])),"NCHW"===i)throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");A(4===c.rank,(()=>`Error in separableConv2d: input must be rank 4, but got rank ${c.rank}.`)),A(4===l.rank,(()=>`Error in separableConv2d: depthwise filter must be rank 4, but got rank ${l.rank}.`)),A(4===u.rank,(()=>`Error in separableConv2d: pointwise filter must be rank 4, but got rank ${l.rank}.`)),A(1===u.shape[0],(()=>`Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${u.shape[0]}.`)),A(1===u.shape[1],(()=>`Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${u.shape[1]}.`));const p=l.shape[2],d=l.shape[3];A(u.shape[2]===p*d,(()=>`Error in separableConv2d: the third dimension of pointwise filter must be ${p*d}, but got ${u.shape[2]}.`));const f=Ua(c,l,s,r,i,a),m=za(f,u,1,"valid",i);return h?aa(m,[m.shape[1],m.shape[2],m.shape[3]]):m}}),Xi=Ns({sigmoid_:function(t){const e=vs(t,"x","sigmoid"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.sigmoid(e);return n([s]),s}),n,null,sn)}}),Yi=Ns({slice_:function(t,e,n){const s=vs(t,"x","slice");if(0===s.rank)throw new Error("Slicing scalar is not possible");const r={x:s},a={begin:e,size:n};return fs.runKernelFunc(((t,r)=>{const[a,i]=_r(s,e,n);return wr(s,a,i),r([s]),t.slice(s,a,i)}),r,null,Qe,a)}}),Ji=Ns({slice1d_:function(t,e,n){const s=vs(t,"x","slice1d");return A(1===s.rank,(()=>`slice1d expects a rank-1 tensor, but got a rank-${s.rank} tensor`)),Yi(s,[e],[n])}}),Zi=Ns({slice2d_:function(t,e,n){const s=vs(t,"x","slice2d");return A(2===s.rank,(()=>`slice2d expects a rank-2 tensor, but got a rank-${s.rank} tensor`)),Yi(s,e,n)}}),Qi=Ns({slice3d_:function(t,e,n){const s=vs(t,"x","slice3d");return A(3===s.rank,(()=>`slice3d expects a rank-3 tensor, but got a rank-${s.rank} tensor`)),Yi(s,e,n)}}),to=Ns({slice4d_:function(t,e,n){const s=vs(t,"x","slice4d");return A(4===s.rank,(()=>`slice4d expects a rank-4 tensor, but got a rank-${s.rank} tensor`)),Yi(s,e,n)}}),eo=Ns({softmax_:function(t,e=-1){const n=vs(t,"logits","softmax","float32");if(-1===e&&(e=n.rank-1),e!==n.rank-1)throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and dim was ${e}`);const s={logits:n},r={dim:e};return fs.runKernelFunc(((t,s)=>{const r=t.softmax(n,e);return s([r]),r}),s,null,un,r)}}),no=Ns({softplus_:function(t){const e=vs(t,"x","softplus"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.softplus(e);return n([e]),s}),n,null,rn)}});function so(t,e,n=0){let s=[];if("number"==typeof e)A(t.shape[n]%e==0,(()=>"Number of splits must evenly divide the axis.")),s=new Array(e).fill(t.shape[n]/e);else{A(e.reduce(((t,e)=>(-1===e&&(t+=1),t)),0)<=1,(()=>"There should be only one negative value in split array."));const r=e.indexOf(-1);if(-1!==r){const s=e.reduce(((t,e)=>e>0?t+e:t));e[r]=t.shape[n]-s}A(t.shape[n]===e.reduce(((t,e)=>t+e)),(()=>"The sum of sizes must match the size of the axis dimension.")),s=e}return s}const ro=Ns({split_:function(t,e,n=0){const s=vs(t,"x","split"),r={x:s},a={numOrSizeSplits:e,axis:n};return fs.runKernelFunc(((t,r)=>{const a=W(n,s.shape)[0],i=so(s,e,a);return t.split(s,i,a)}),r,null,ln,a)}}),ao=Ns({sqrt_:function(t){const e=vs(t,"x","sqrt"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.sqrt(e);return n([e]),s}),n,null,an)}}),io=Ns({squeeze_:function(t,e){const n=vs(t,"x","squeeze");return aa(n,V(n.shape,e).newShape)}}),oo=Ns({stack_:function(t,e=0){const n=ks(t,"tensors","stack");if(A(n.length>=1,(()=>"Pass at least one tensor to tf.stack")),1===n.length)return Za(n[0],e);const s=n[0].rank,r=n[0].shape,a=n[0].dtype;A(e<=s,(()=>"Axis must be <= rank of the tensor")),n.forEach((t=>{R(r,t.shape,"All tensors passed to stack must have matching shapes"),A(a===t.dtype,(()=>"All tensors passed to stack must have matching dtypes"))}));const i=n.map((t=>Za(t,e)));return Fa(i,e)}}),lo=Ns({tanh_:function(t){const e=vs(t,"x","tanh"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.tanh(e);return n([s]),s}),n,null,fn)}});function uo(t,e,n){if(D(t),null!=e&&2!==e.length)throw new Error("tensor2d() requires shape to have two numbers");const s=bs(t,n);if(2!==s.length&&1!==s.length)throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");if(1===s.length&&null==e)throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");return Cs(t,e,s,n)}function co(t,e,n){if(D(t),null!=e&&4!==e.length)throw new Error("tensor4d() requires shape to have four numbers");const s=bs(t,n);if(4!==s.length&&1!==s.length)throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");if(1===s.length&&null==e)throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");return Cs(t,e,s,n)}const ho=Ns({truncatedNormal_:function(t,e=0,n=1,s,r){if(null!=s&&"bool"===s)throw new Error("Unsupported data type $ { dtype }");const a=new Bi(e,n,s,!0,r),i=ir(t,s);for(let t=0;t<i.values.length;t++)i.values[t]=a.nextValue();return i.toTensor()}}),po=Ns({unstack_:function(t,e=0){const n=vs(t,"x","unstack");A(e>=-n.shape.length&&e<n.shape.length,(()=>`Axis = ${e} is not in [-${n.shape.length}, ${n.shape.length})`)),e<0&&(e+=n.shape.length);const s={value:n},r={axis:e};return fs.runKernelFunc((t=>t.unstack(n,e)),s,null,bn,r)}}),fo=Ns({broadcastTo_:function(t,e){let n=vs(t,"broadcastTo","x");const s=n.shape;if(e.some((t=>!(t>0)||t%1!=0)))throw new Error(`broadcastTo(): Invalid broadcast shape [${e}].`);if(e.length<n.rank)throw new Error(`broadcastTo(): shape.length=${e.length} < input.rank=${n.rank}.`);if(e.length>n.rank){const t=n.shape.slice();for(;t.length<e.length;)t.unshift(1);n=aa(n,t)}const r=n.shape,a=Array.from(e);for(let t=e.length-1;t>=0;t--)if(r[t]===e[t])a[t]=1;else if(1!==n.shape[t])throw new Error(`broadcastTo(): [${s}] cannot be broadcast to [${e}].`);if(0===a.map(((t,e)=>t>1?e:-1)).filter((t=>t>=0)).length)return lr(n);const i={x:n},o={shape:e,inputShape:r};return fs.runKernelFunc((t=>t.tile(n,a)),i,null,Dt,o)}}),mo=Ns({where_:function(t,e,n){const s=vs(e,"a","where"),r=vs(n,"b","where"),a=vs(t,"condition","where","bool"),i=Xa(s.shape,r.shape),o=fo(s,i),l=fo(r,i);1===a.rank&&A(a.shape[0]===s.shape[0],(()=>"The first dimension of `a` must match the size of `condition`.")),1!==a.rank&&R(a.shape,l.shape,"Error in where: ");const u={condition:a,t:o,e:l};return fs.runKernelFunc(((t,e)=>{const n=t.select(a,o,l);return e([a]),n}),u,null,Je)}}),go=Ns({dropout_:function(t,e,n,s){const r=vs(t,"x","dropout");if(A("float32"===r.dtype,(()=>`x has to be a floating point tensor since it's going to be scaled, but got a ${r.dtype} tensor instead.`)),A(e>=0&&e<1,(()=>`rate must be a float in the range [0, 1), but got ${e}.`)),0===e)return t instanceof Jn?r.clone():r;const a=function(t,e){if(null==e)return t.shape.slice();if(O(t.shape,e))return e;if(t.shape.length===e.length){const n=[];for(let s=0;s<t.shape.length;s++)null==e[s]&&null!=t.shape[s]?n.push(t.shape[s]):n.push(e[s]);return n}return e}(r,n),i=1-e,o=Ha(ni(Yr(Vi(a,0,1,"float32",s),i)),i);return pi(r,o)}}),yo=Ns({fft_:function(t){A("complex64"===t.dtype,(()=>`The dtype for tf.spectral.fft() must be complex64 but got ${t.dtype}.`));const e={input:t};return fs.runKernelFunc((e=>{const n=t.shape[t.shape.length-1],s=t.size/n,r=t.as2D(s,n);return e.fft(r).reshape(t.shape)}),e,null,re)}}),bo=Ns({rfft_:function(t,e){A("float32"===t.dtype,(()=>"The dtype for rfft() must be real value but got "+t.dtype));let n=t.shape[t.shape.length-1];const s=t.size/n;let r;if(null!=e&&e<n){const s=t.shape.map((t=>0)),a=t.shape.map((t=>t));a[t.shape.length-1]=e,r=Yi(t,s,a),n=e}else if(null!=e&&e>n){const s=t.shape.map((t=>t));s[t.shape.length-1]=e-n,r=Fa([t,ki(s)],t.shape.length-1),n=e}else r=t;const a=_i(r),i=aa(Is(r,a),[s,n]),o=yo(i),l=Math.floor(n/2)+1,u=Fi(o),c=Di(o),h=ro(u,[l,n-l],u.shape.length-1),p=ro(c,[l,n-l],c.shape.length-1),d=r.shape.slice();return d[r.shape.length-1]=l,aa(Is(h[0],p[0]),d)}}),xo=Ns({ifft_:function(t){A("complex64"===t.dtype,(()=>`The dtype for tf.spectral.ifft() must be complex64 but got ${t.dtype}.`));const e={input:t};return fs.runKernelFunc((e=>{const n=t.shape[t.shape.length-1],s=t.size/n,r=aa(t,[s,n]),a=e.ifft(r);return aa(a,t.shape)}),e,null,de)}}),wo=Ns({irfft_:function(t){const e=t.shape[t.shape.length-1],n=t.size/e;let s;if(e<=2){const r=aa(t,[n,e]);s=xo(r)}else{const r=[n,2*(e-1)],a=aa(Fi(t),[n,e]),i=aa(Di(t),[n,e]),o=ji(Yi(a,[0,1],[n,e-2]),1),l=pi(ji(Yi(i,[0,1],[n,e-2]),1),qr(-1)),u=Fa([a,o],1),c=Fa([i,l],1),h=aa(Is(u,c),[r[0],r[1]]);s=xo(h)}if(s=Fi(s),3===t.rank&&0!==t.shape[0]){const e=s,n=t.shape[0];s=aa(s,[n,s.shape[0]/n,s.shape[1]]),e.dispose()}return s}}),vo=Ns({conv2DBackpropFilter_:function(t,e,n,s,r,a="NHWC",i){let o=t;3===t.rank&&(o=aa(t,[1,t.shape[0],t.shape[1],t.shape[2]]));let l=e;3===l.rank&&(l=aa(e,[1,e.shape[0],e.shape[1],e.shape[2]])),A(4===o.rank,(()=>"Error in conv2dDerFilter: input must be rank 4, but got shape "+o.shape+".")),A(4===l.rank,(()=>"Error in conv2dDerFilter: dy must be rank 4, but got shape "+l.shape+".")),A(4===n.length,(()=>"Error in conv2dDerFilter: filterShape must be length 4, but got "+n+"."));const u="NHWC"===a?o.shape[3]:o.shape[1],c="NHWC"===a?l.shape[3]:l.shape[1];A(u===n[2],(()=>`Error in conv2dDerFilter: depth of input ${u}) must match input depth in filter (${n[2]}.`)),A(c===n[3],(()=>`Error in conv2dDerFilter: depth of dy (${c}) must match output depth for filter (${n[3]}).`)),null!=i&&A(M(r),(()=>`Error in conv2dDerFilter: pad must be an integer when using, dimRoundingMode ${i} but got pad ${r}.`));const h={x:o,dy:l},p={strides:s,pad:r,dataFormat:a,dimRoundingMode:i,filterShape:n};return fs.runKernelFunc((t=>{const e=ka(a),u=da(o.shape,n,s,1,r,i,!1,e);return t.conv2dDerFilter(o,l,u)}),h,null,Bt,p)}}),ko=Ns({relu6_:function(t){const e=vs(t,"x","relu6"),n={x:e};return fs.runKernelFunc(((t,n)=>(n([e]),"bool"===e.dtype?or(e,"int32"):t.relu6(e))),n,null,qe)}}),No=Ns({step_:function(t,e=0){const n=vs(t,"x","step"),s={x:n},r={alpha:e};return fs.runKernelFunc((t=>t.step(n,e)),s,null,vn,r)}});function Io(t,e,n){if(null==n||"linear"===n)return t;if("relu"===n)return pi(t,No(e));throw new Error(`Cannot compute gradient for fused activation ${n}.`)}function Co(t,e){let n=e;const s=Ka(t.shape,e.shape);return s.length>0&&(n=yi(n,s)),aa(n,t.shape)}function So(t,e,n){if("linear"===e)return t;if("relu"===e)return Hi(t);if("elu"===e)return ja(t);if("relu6"===e)return ko(t);if("prelu"===e)return Li(t,n);throw new Error(`Unknown fused activation ${e}.`)}const To=(t,e)=>!(t>0)||"linear"===e,$o=Ns({fusedConv2d_:function({x:t,filter:e,strides:n,pad:s,dataFormat:r="NHWC",dilations:a=[1,1],dimRoundingMode:i,bias:o,activation:l="linear",preluActivationWeights:u}){if(l=l||"linear",!1===To(fs.state.gradientDepth,l)){let c=za(t,e,n,s,r,a,i);return null!=o&&(c=Yr(c,o)),So(c,l,u)}const c=vs(t,"x","conv2d"),h=vs(e,"filter","conv2d");let p=c,d=!1;3===c.rank&&(d=!0,p=aa(c,[1,c.shape[0],c.shape[1],c.shape[2]])),A(4===p.rank,(()=>"Error in fused conv2d: input must be rank 4, but got rank "+p.rank+".")),A(4===h.rank,(()=>"Error in fused conv2d: filter must be rank 4, but got rank "+h.rank+".")),null!=i&&A(M(s),(()=>`Error in fused conv2d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${s}.`)),A(p.shape[3]===h.shape[2],(()=>`Error in conv2d: depth of input (${p.shape[3]}) must match input depth for filter ${h.shape[2]}.`)),A(va(n,a),(()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`)),A("NHWC"===r,(()=>`Error in conv2d: got dataFormat of ${r} but only NHWC is currently supported.`));const f=da(p.shape,h.shape,n,a,s,i);let m,g;null!=o&&(m=vs(o,"bias","fused conv2d"),[m]=os(m,c),Xa(f.outShape,m.shape)),null!=u&&(g=vs(u,"prelu weights","fused conv2d"));const y=(t,e)=>{const[r,i,o,u]=e,c=Io(t,o,l);A(wa(a),(()=>`Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${a}'`));const h=[Pa(i.shape,c,r,n,s),vo(i,c,r.shape,n,s)];if(null!=u){const t=Co(u,c);h.push(t)}return h},b=t=>t.fusedConv2d({input:p,filter:h,convInfo:f,bias:m,activation:l,preluActivationWeights:g}),x={x:p,filter:h,bias:m,preluActivationWeights:g},w={strides:n,pad:s,dataFormat:r,dilations:a,dimRoundingMode:i,activation:l};return null==o?jr(((t,e,n)=>{let s=fs.runKernelFunc(b,x,null,Cn,w);return n([e,t,s]),d&&(s=aa(s,[s.shape[1],s.shape[2],s.shape[3]])),{value:s,gradFunc:y}}))(p,h):jr(((t,e,n,s)=>{let r=fs.runKernelFunc(b,x,null,Cn,w);return s([e,t,r,n]),d&&(r=aa(r,[r.shape[1],r.shape[2],r.shape[3]])),{value:r,gradFunc:y}}))(p,h,m)}}),Eo=Ns({depthwiseConv2dNativeBackpropFilter_:function(t,e,n,s,r,a=[1,1],i){let o=t;3===t.rank&&(o=aa(t,[1,t.shape[0],t.shape[1],t.shape[2]]));let l=e;3===l.rank&&(l=aa(e,[1,e.shape[0],e.shape[1],e.shape[2]]));const u={x:o,dy:l},c={strides:s,pad:r,dimRoundingMode:i,dilations:a,filterShape:n};return fs.runKernelFunc((e=>{const u=da(t.shape,n,s,a,r,i,!0);return e.depthwiseConv2DDerFilter(o,l,u)}),u,null,Kt,c)}}),Ao=Ns({depthwiseConv2dNativeBackpropInput_:function(t,e,n,s,r,a=[1,1],i){let o=e,l=!1;3===e.rank&&(l=!0,o=aa(e,[1,e.shape[0],e.shape[1],e.shape[2]]));const u={dy:o,filter:n},c={strides:s,pad:r,dimRoundingMode:i,dilations:a,inputShape:t},h=fs.runKernelFunc((e=>{const l=da(t,n.shape,s,a,r,i,!0);return e.depthwiseConv2DDerInput(o,n,l)}),u,null,Xt,c);return l?aa(h,[h.shape[1],h.shape[2],h.shape[3]]):h}}),Ro=Ns({fusedDepthwiseConv2d_:function({x:t,filter:e,strides:n,pad:s,dataFormat:r="NHWC",dilations:a=[1,1],dimRoundingMode:i,bias:o,activation:l="linear",preluActivationWeights:u}){if(!1===To(fs.state.gradientDepth,l)){let c=Ua(t,e,n,s,r,a,i);return null!=o&&(c=Yr(c,o)),So(c,l,u)}const c=vs(t,"x","depthwiseConv2d"),h=vs(e,"filter","depthwiseConv2d");let p=c,d=!1;3===c.rank&&(d=!0,p=aa(c,[1,c.shape[0],c.shape[1],c.shape[2]])),A(4===p.rank,(()=>`Error in fused depthwiseConv2d: input must be rank 4, but got rank ${p.rank}.`)),A(4===h.rank,(()=>`Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${h.rank}.`)),A(p.shape[3]===h.shape[2],(()=>`Error in fused depthwiseConv2d: number of input channels (${p.shape[3]}) must match the inChannels dimension in filter ${h.shape[2]}.`)),null==a&&(a=[1,1]),A(va(n,a),(()=>`Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`)),null!=i&&A(M(s),(()=>`Error in fused depthwiseConv2d: pad must be an integer when using dimRoundingMode ${i} but got pad ${s}.`));const f=da(p.shape,h.shape,n,a,s,i,!0);let m,g;null!=o&&(m=vs(o,"bias","fused conv2d"),[m]=os(m,c),Xa(f.outShape,m.shape)),null!=u&&(g=vs(u,"prelu weights","fused depthwiseConv2d"));const y=(t,e)=>{A(wa(a),(()=>`Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${a}'`));const[r,o,u,c]=e,h=Io(t,u,l),p=Ao(o.shape,h,r,n,s,a,i),d=Eo(o,h,r.shape,n,s,a,i);return null!=c?[p,d,Co(m,h)]:[p,d]},b=t=>t.fusedDepthwiseConv2D({input:p,filter:h,convInfo:f,bias:m,activation:l,preluActivationWeights:g}),x={x:p,filter:h,bias:m,preluActivationWeights:g},w={strides:n,pad:s,dataFormat:r,dilations:a,dimRoundingMode:i,activation:l};return null==o?jr(((t,e,n)=>{let s=fs.runKernelFunc(b,x,null,Sn,w);return n([e,t,s]),d&&(s=aa(s,[s.shape[1],s.shape[2],s.shape[3]])),{value:s,gradFunc:y}}))(p,h):jr(((t,e,n,s)=>{let r=fs.runKernelFunc(b,x,null,Sn,w);return s([e,t,r,n]),d&&(r=aa(r,[r.shape[1],r.shape[2],r.shape[3]])),{value:r,gradFunc:y}}))(p,h,m)}}),Do=Ns({matMul_:function(t,e,n=!1,s=!1){let r=vs(t,"a","matMul"),a=vs(e,"b","matMul");[r,a]=os(r,a);const i={a:r,b:a},o={transposeA:n,transposeB:s};return fs.runKernelFunc(((t,e)=>{e([r,a]);const i=n?r.shape[r.rank-2]:r.shape[r.rank-1],o=s?a.shape[a.rank-1]:a.shape[a.rank-2],l=n?r.shape[r.rank-1]:r.shape[r.rank-2],u=s?a.shape[a.rank-2]:a.shape[a.rank-1],c=r.shape.slice(0,-2),h=a.shape.slice(0,-2),p=_(c),d=_(h),f=p===d||1===p||1===d;A(r.rank>=2&&a.rank>=2&&f,(()=>`Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (${c}) and (${h}).`)),A(i===o,(()=>`Error in matMul: inner shapes (${i}) and (${o}) of Tensors with shapes ${r.shape} and ${a.shape} and transposeA=${n} and transposeB=${s} must match.`));const m=(p>d?c:h).concat([l,u]),g=aa(r,n?[p,i,l]:[p,l,i]),y=aa(a,s?[d,u,o]:[d,o,u]),b=t.batchMatMul(g,y,n,s);return aa(b,m)}),i,null,At,o)}}),Fo=Ns({fusedMatMul_:function({a:t,b:e,transposeA:n=!1,transposeB:s=!1,bias:r,activation:a="linear",preluActivationWeights:i}){if(!1===To(fs.state.gradientDepth,a)){let o=Do(t,e,n,s);return null!=r&&(o=Yr(o,r)),So(o,a,i)}let o=vs(t,"a","fused matMul"),l=vs(e,"b","fused matMul");[o,l]=os(o,l);const u=n?o.shape[o.rank-2]:o.shape[o.rank-1],c=s?l.shape[l.rank-1]:l.shape[l.rank-2],h=n?o.shape[o.rank-1]:o.shape[o.rank-2],p=s?l.shape[l.rank-2]:l.shape[l.rank-1],d=o.shape.slice(0,-2),f=l.shape.slice(0,-2),m=_(d),g=_(f);A(o.rank>=2&&l.rank>=2&&o.rank===l.rank,(()=>`Error in fused matMul: inputs must have the same rank of at least 2, got ranks ${o.rank} and ${l.rank}.`)),A(O(d,f),(()=>`Error in fused matMul: outer dimensions (${d}) and (${f}) of Tensors with shapes ${o.shape} and `+l.shape+" must match.")),A(u===c,(()=>`Error in fused matMul: inner shapes (${u}) and (${c}) of Tensors with shapes ${o.shape} and ${l.shape} and transposeA=${n} and transposeB=${s} must match.`));const y=o.shape.slice(0,-2).concat([h,p]),b=aa(o,n?[m,u,h]:[m,h,u]),x=aa(l,s?[g,p,c]:[g,c,p]);let w,v;null!=r&&(w=vs(r,"bias","fused matMul"),[w]=os(w,o),Xa(y,w.shape)),null!=i&&(v=vs(i,"prelu weights","fused matMul"));const k=(t,e)=>{const[i,o,l,u]=e,c=Io(aa(t,l.shape),l,a);let h,p;return n||s?!n&&s?(h=Do(c,o,!1,!1),p=Do(c,i,!0,!1)):n&&!s?(h=Do(o,c,!1,!0),p=Do(i,c,!1,!1)):(h=Do(o,c,!0,!0),p=Do(c,i,!0,!0)):(h=Do(c,o,!1,!0),p=Do(i,c,!0,!1)),null!=r?[h,p,Co(u,c)]:[h,p]},N=t=>t.fusedBatchMatMul({a:b,b:x,transposeA:n,transposeB:s,bias:w,activation:a,preluActivationWeights:v}),I={a:b,b:x,bias:w,preluActivationWeights:v},C={transposeA:n,transposeB:s,activation:a};return null==r?jr(((t,e,n)=>{const s=fs.runKernelFunc(N,I,null,In,C);return n([t,e,s]),{value:aa(s,y),gradFunc:k}}))(b,x):jr(((t,e,n,s)=>{const r=fs.runKernelFunc(N,I,null,In,C);return s([t,e,r,n]),{value:aa(r,y),gradFunc:k}}))(b,x,w)}});function _o(t,e,n){const s=1-t%2,r=new Float32Array(t);for(let a=0;a<t;++a){const i=2*Math.PI*a/(t+s-1);r[a]=e-n*Math.cos(i)}return Ui(r,"float32")}Ns({hammingWindow_:function(t){return _o(t,.54,.46)}});const Oo=Ns({hannWindow_:function(t){return _o(t,.5,.5)}}),Mo=Ns({frame_:function(t,e,n,s=!1,r=0){let a=0;const i=[];for(;a+e<=t.size;)i.push(Yi(t,a,e)),a+=n;if(s)for(;a<t.size;){const s=a+e-t.size,o=Fa([Yi(t,a,e-s),ei([s],r)]);i.push(o),a+=n}return 0===i.length?uo([],[0,e]):aa(Fa(i),[i.length,e])}});Ns({stft_:function(t,e,n,s,r=Oo){var a;null==s&&(a=e,s=Math.floor(Math.pow(2,Math.ceil(Math.log(a)/Math.log(2)))));const i=Mo(t,e,n),o=pi(i,r(e)),l=[];for(let t=0;t<i.shape[0];t++)l.push(bo(Yi(o,[t,0],[1,e]),s));return Fa(l)}});const Lo=Ns({cropAndResize_:function(t,e,n,s,r,a){const i=vs(t,"image","cropAndResize"),o=vs(e,"boxes","cropAndResize","float32"),l=vs(n,"boxInd","cropAndResize","int32");r=r||"bilinear",a=a||0;const u=o.shape[0];A(4===i.rank,(()=>`Error in cropAndResize: image must be rank 4,but got rank ${i.rank}.`)),A(2===o.rank&&4===o.shape[1],(()=>`Error in cropAndResize: boxes must be have size [${u},4] but had shape ${o.shape}.`)),A(1===l.rank&&l.shape[0]===u,(()=>`Error in cropAndResize: boxInd must be have size [${u}] but had shape ${o.shape}.`)),A(2===s.length,(()=>`Error in cropAndResize: cropSize must be of length 2, but got length ${s.length}.`)),A(s[0]>=1&&s[1]>=1,(()=>"cropSize must be atleast [1,1], but was "+s)),A("bilinear"===r||"nearest"===r,(()=>"method must be bilinear or nearest, but was "+r));const c={image:i,boxes:o,boxInd:l},h={method:r,extrapolationValue:a,cropSize:s};return fs.runKernelFunc((t=>t.cropAndResize(i,o,l,s,r,a)),c,null,"CropAndResize",h)}}),zo=Ns({flipLeftRight_:function(t){const e=vs(t,"image","flipLeftRight","float32");A(4===e.rank,(()=>`Error in flipLeftRight: image must be rank 4,but got rank ${e.rank}.`));const n={image:e};return fs.runKernel(ie,n,{})}}),Bo=Ns({rotateWithOffset_:function(t,e,n=0,s=.5){const r=vs(t,"image","rotateWithOffset","float32");A(4===r.rank,(()=>`Error in rotateWithOffset: image must be rank 4,but got rank ${r.rank}.`));const a={image:r},i={radians:e,fillValue:n,center:s};return fs.runKernel(Nn,a,i)}});function Po(t,e,n,s,r,a){null==s&&(s=.5),null==r&&(r=Number.NEGATIVE_INFINITY),null==a&&(a=0);const i=t.shape[0];return n=Math.min(n,i),A(0<=s&&s<=1,(()=>`iouThreshold must be in [0, 1], but was '${s}'`)),A(2===t.rank,(()=>`boxes must be a 2D tensor, but was of rank '${t.rank}'`)),A(4===t.shape[1],(()=>"boxes must have 4 columns, but 2nd dimension was "+t.shape[1])),A(1===e.rank,(()=>"scores must be a 1D tensor")),A(e.shape[0]===i,(()=>`scores has incompatible shape with boxes. Expected ${i}, but was `+e.shape[0])),A(0<=a&&a<=1,(()=>`softNmsSigma must be in [0, 1], but was '${a}'`)),{maxOutputSize:n,iouThreshold:s,scoreThreshold:r,softNmsSigma:a}}const Wo=Ns({nonMaxSuppression_:function(t,e,n,s=.5,r=Number.NEGATIVE_INFINITY){const a=vs(t,"boxes","nonMaxSuppression"),i=vs(e,"scores","nonMaxSuppression"),o=Po(a,i,n,s,r);n=o.maxOutputSize,s=o.iouThreshold,r=o.scoreThreshold;const l={maxOutputSize:n,iouThreshold:s,scoreThreshold:r};return fs.runKernelFunc((t=>t.nonMaxSuppression(a,i,n,s,r)),{boxes:a,scores:i},null,_e,l)}});function Vo(t,e,n){const s=function(t,e,n){return function(t,e,n){let s=0,r=t.length,a=0,i=!1;for(;s<r;){a=s+(r-s>>>1);const o=n(e,t[a]);o>0?s=a+1:(r=a,i=!o)}return i?s:-s-1}(t,e,n||Uo)}(t,e,n),r=s<0?-(s+1):s;t.splice(r,0,e)}function Uo(t,e){return t>e?1:t<e?-1:0}function Go(t,e,n,s,r){return qo(t,e,n,s,r,0).selectedIndices}function Ho(t,e,n,s,r,a){return qo(t,e,n,s,r,0,!1,a,!0)}function jo(t,e,n,s,r,a){return qo(t,e,n,s,r,a,!0)}function qo(t,e,n,s,r,a,i=!1,o=!1,l=!1){const u=[];for(let t=0;t<e.length;t++)e[t]>r&&u.push({score:e[t],boxIndex:t,suppressBeginIndex:0});u.sort(Yo);const c=a>0?-.5/a:0,h=[],p=[];for(;h.length<n&&u.length>0;){const e=u.pop(),{score:n,boxIndex:a,suppressBeginIndex:i}=e;if(n<r)break;let o=!1;for(let n=h.length-1;n>=i;--n){const i=Ko(t,a,h[n]);if(i>=s){o=!0;break}if(e.score=e.score*Xo(s,c,i),e.score<=r)break}e.suppressBeginIndex=h.length,o||(e.score===n?(h.push(a),p.push(e.score)):e.score>r&&Vo(u,e,Yo))}const d=h.length,f=n-d;o&&f>0&&(h.push(...new Array(f).fill(0)),p.push(...new Array(f).fill(0)));const m={selectedIndices:Ui(h,"int32")};return i&&(m.selectedScores=Ui(p,"float32")),l&&(m.validOutputs=qr(d,"int32")),m}function Ko(t,e,n){const s=t.subarray(4*e,4*e+4),r=t.subarray(4*n,4*n+4),a=Math.min(s[0],s[2]),i=Math.min(s[1],s[3]),o=Math.max(s[0],s[2]),l=Math.max(s[1],s[3]),u=Math.min(r[0],r[2]),c=Math.min(r[1],r[3]),h=Math.max(r[0],r[2]),p=Math.max(r[1],r[3]),d=(o-a)*(l-i),f=(h-u)*(p-c);if(d<=0||f<=0)return 0;const m=Math.max(a,u),g=Math.max(i,c),y=Math.min(o,h),b=Math.min(l,p),x=Math.max(y-m,0)*Math.max(b-g,0);return x/(d+f-x)}function Xo(t,e,n){const s=Math.exp(e*n*n);return n<=t?s:0}function Yo(t,e){return t.score-e.score||t.score===e.score&&e.boxIndex-t.boxIndex}const Jo=Ns({nonMaxSuppressionWithScore_:function(t,e,n,s=.5,r=Number.NEGATIVE_INFINITY,a=0){const i=vs(t,"boxes","nonMaxSuppression"),o=vs(e,"scores","nonMaxSuppression"),l=Po(i,o,n,s,r,a),u={boxes:i,scores:o},c={maxOutputSize:n=l.maxOutputSize,iouThreshold:s=l.iouThreshold,scoreThreshold:r=l.scoreThreshold,softNmsSigma:a=l.softNmsSigma},h=fs.runKernel(Me,u,c);return{selectedIndices:h[0],selectedScores:h[1]}}}),Zo=Ns({nonMaxSuppressionPadded_:function(t,e,n,s=.5,r=Number.NEGATIVE_INFINITY,a=!1){const i=vs(t,"boxes","nonMaxSuppression"),o=vs(e,"scores","nonMaxSuppression"),l=Po(i,o,n,s,r,null),u={boxes:i,scores:o},c={maxOutputSize:l.maxOutputSize,iouThreshold:l.iouThreshold,scoreThreshold:l.scoreThreshold,padToMaxOutputSize:a},h=fs.runKernel(Oe,u,c);return{selectedIndices:h[0],validOutputs:h[1]}}}),Qo=Ns({resizeBilinear_:function(t,e,n=!1){const s=vs(t,"images","resizeBilinear");A(3===s.rank||4===s.rank,(()=>`Error in resizeBilinear: x must be rank 3 or 4, but got rank ${s.rank}.`)),A(2===e.length,(()=>"Error in resizeBilinear: new shape must 2D, but got shape "+e+"."));let r=s,a=!1;3===s.rank&&(a=!0,r=aa(s,[1,s.shape[0],s.shape[1],s.shape[2]]));const[i,o]=e,l={images:r},u={alignCorners:n,size:e},c=fs.runKernelFunc(((t,e)=>(e([r]),t.resizeBilinear(r,i,o,n))),l,null,je,u);return a?aa(c,[c.shape[1],c.shape[2],c.shape[3]]):c}}),tl=Ns({resizeNearestNeighbor_:function(t,e,n=!1){const s=vs(t,"images","resizeNearestNeighbor");A(3===s.rank||4===s.rank,(()=>`Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${s.rank}.`)),A(2===e.length,(()=>"Error in resizeNearestNeighbor: new shape must 2D, but got shape "+e+".")),A("float32"===s.dtype||"int32"===s.dtype,(()=>"`images` must have `int32` or `float32` as dtype"));let r=s,a=!1;3===s.rank&&(a=!0,r=aa(s,[1,s.shape[0],s.shape[1],s.shape[2]]));const[i,o]=e,l={images:r},u={alignCorners:n,size:e},c=fs.runKernelFunc(((t,e)=>(e([r]),t.resizeNearestNeighbor(r,i,o,n))),l,null,He,u);return a?aa(c,[c.shape[1],c.shape[2],c.shape[3]]):c}}),el=Ns({lessEqual_:function(t,e){let n=vs(t,"a","lessEqual"),s=vs(e,"b","lessEqual");[n,s]=os(n,s),Xa(n.shape,s.shape);const r={a:n,b:s};return fs.runKernelFunc(((t,e)=>{const r=t.lessEqual(n,s);return e([n,s]),r}),r,null,"LessEqual")}}),nl=Ns({bandPart_:function(t,e,n){A(e%1==0,(()=>`bandPart(): numLower must be an integer, got ${e}.`)),A(n%1==0,(()=>`bandPart(): numUpper must be an integer, got ${n}.`));const s=vs(t,"a","bandPart");A(s.rank>=2,(()=>`bandPart(): Rank must be at least 2, got ${s.rank}.`));const r=s.shape,[a,i]=s.shape.slice(-2);if(!(e<=a))throw new Error(`bandPart(): numLower (${e}) must not be greater than the number of rows (${a}).`);if(!(n<=i))throw new Error(`bandPart(): numUpper (${n}) must not be greater than the number of columns (${i}).`);e<0&&(e=a),n<0&&(n=i);const o=aa(Gi(0,a,1,"int32"),[-1,1]),l=Gi(0,i,1,"int32"),u=gi(o,l),c=xi(el(u,qr(+e,"int32")),ci(u,qr(-n,"int32"))),h=ki([a,i],s.dtype);return aa(oo(po(aa(s,[-1,a,i])).map((t=>mo(c,t,h)))),r)}}),sl=Ns({pow_:function(t,e){let n=vs(t,"base","pow"),s=vs(e,"exp","pow");[n,s]=os(n,s);const r={a:n,b:s};return fs.runKernelFunc(((t,e)=>{const r=t.pow(n,s);return e([n,s,r]),r}),r,null,"Pow")}});function rl(t,e,n=null){if(0===t.rank)return Xr(t);if(1!==t.rank&&null===n)return rl(aa(t,[-1]),e,n);if(1===t.rank||"number"==typeof n||Array.isArray(n)&&1===n.length){if(1===e)return yi(Xr(t),n);if(e===1/0)return mi(Xr(t),n);if(e===-1/0)return Ci(Xr(t),n);if("euclidean"===e||2===e)return ao(yi(sl(Xr(t),qr(2,"int32")),n));throw new Error("Error in norm: invalid ord value: "+e)}if(Array.isArray(n)&&2===n.length){if(1===e)return mi(yi(Xr(t),n[0]),n[1]-1);if(e===1/0)return mi(yi(Xr(t),n[1]),n[0]);if(e===-1/0)return Ci(yi(Xr(t),n[1]),n[0]);if("fro"===e||"euclidean"===e)return ao(yi(Ti(t),n));throw new Error("Error in norm: invalid ord value: "+e)}throw new Error("Error in norm: invalid axis: "+n)}const al=Ns({norm_:function(t,e="euclidean",n=null,s=!1){const r=rl(t=vs(t,"x","norm"),e,n);let a=r.shape;if(s){const e=W(n,t.shape);a=ta(r.shape,e)}return aa(r,a)}}),il=Ns({gramSchmidt_:function(t){let e;if(Array.isArray(t)){e=!1,A(null!=t&&t.length>0,(()=>"Gram-Schmidt process: input must not be null, undefined, or empty"));const n=t[0].shape[0];for(let e=1;e<t.length;++e)A(t[e].shape[0]===n,(()=>`Gram-Schmidt: Non-unique lengths found in the input vectors: (${t[e].shape[0]} vs. ${n})`))}else e=!0,t=ro(t,t.shape[0],0).map((t=>io(t,[0])));A(t.length<=t[0].shape[0],(()=>`Gram-Schmidt: Number of vectors (${t.length}) exceeds number of dimensions (${t[0].shape[0]}).`));const n=[],s=t;for(let e=0;e<t.length;++e)n.push(fs.tidy((()=>{let t=s[e];if(e>0)for(let s=0;s<e;++s){const e=pi(yi(pi(n[s],t)),n[s]);t=gi(t,e)}return Ha(t,al(t,"euclidean"))})));return e?oo(n,0):n}});function ol(t,e=!1){return fs.tidy((()=>{A(2===t.shape.length,(()=>`qr2d() requires a 2D Tensor, but got a ${t.shape.length}D Tensor.`));const n=t.shape[0],s=t.shape[1];let r=ti(n),a=lr(t);const i=uo([[1]],[1,1]);let o=lr(i);const l=n>=s?s:n;for(let t=0;t<l;++t){const e=a,l=o,u=r;[o,a,r]=fs.tidy((()=>{const e=Yi(a,[t,t],[n-t,1]),l=al(e),u=Yi(a,[t,t],[1,1]),c=mo(ui(u,0),uo([[-1]]),uo([[1]])),h=gi(u,pi(c,l)),p=Ha(e,h);o=1===p.shape[0]?lr(i):Fa([i,Yi(p,[1,0],[p.shape[0]-1,p.shape[1]])],0);const d=Ei(Ha(Do(c,h),l)),f=Yi(a,[t,0],[n-t,s]),m=pi(d,o),g=ia(o);if(0===t)a=gi(f,Do(m,Do(g,f)));else{const e=gi(f,Do(m,Do(g,f)));a=Fa([Yi(a,[0,0],[t,s]),e],0)}const y=ia(m),b=Yi(r,[0,t],[n,r.shape[1]-t]);if(0===t)r=gi(b,Do(Do(b,o),y));else{const e=gi(b,Do(Do(b,o),y));r=Fa([Yi(r,[0,0],[n,t]),e],1)}return[o,a,r]})),Vr([e,l,u])}return!e&&n>s&&(r=Yi(r,[0,0],[n,s]),a=Yi(a,[0,0],[s,s])),[r,a]}))}const ll=Ns({qr_:function(t,e=!1){if(A(t.rank>=2,(()=>"qr() requires input tensor to have a rank >= 2, but got rank "+t.rank)),2===t.rank)return ol(t,e);{const n=t.shape.slice(0,t.shape.length-2).reduce(((t,e)=>t*e)),s=po(aa(t,[n,t.shape[t.shape.length-2],t.shape[t.shape.length-1]]),0),r=[],a=[];return s.forEach((t=>{const[n,s]=ol(t,e);r.push(n),a.push(s)})),[aa(oo(r,0),t.shape),aa(oo(a,0),t.shape)]}}});var ul;!function(t){t[t.NONE=0]="NONE",t[t.MEAN=1]="MEAN",t[t.SUM=2]="SUM",t[t.SUM_BY_NONZERO_WEIGHTS=3]="SUM_BY_NONZERO_WEIGHTS"}(ul||(ul={}));const cl=Ns({computeWeightedLoss_:function(t,e,n=ul.SUM_BY_NONZERO_WEIGHTS){const s=vs(t,"losses","computeWeightedLoss");let r=null;null!=e&&(r=vs(e,"weights","computeWeightedLoss"));const a=null==r?s:pi(s,r);if(n===ul.NONE)return a;if(n===ul.SUM)return yi(a);if(n===ul.MEAN){if(null==r)return Ii(a);{const t=s.size/r.size,e=Ha(yi(a),yi(r));return t>1?Ha(e,qr(t)):e}}if(n===ul.SUM_BY_NONZERO_WEIGHTS){if(null==r)return Ha(yi(a),qr(s.size));{const t=pi(r,Ni(s.shape)),e=or(yi(Ai(t,qr(0))),"float32");return Ha(yi(a),e)}}throw Error("Unknown reduction: "+n)}});Ns({absoluteDifference_:function(t,e,n,s=ul.SUM_BY_NONZERO_WEIGHTS){const r=vs(t,"labels","absoluteDifference"),a=vs(e,"predictions","absoluteDifference");let i=null;null!=n&&(i=vs(n,"weights","absoluteDifference")),R(r.shape,a.shape,"Error in absoluteDifference: ");const o=Xr(gi(r,a));return cl(o,i,s)}}),Ns({cosineDistance_:function(t,e,n,s,r=ul.SUM_BY_NONZERO_WEIGHTS){const a=vs(t,"labels","cosineDistance"),i=vs(e,"predictions","cosineDistance");let o=null;null!=s&&(o=vs(s,"weights","cosineDistance")),R(a.shape,i.shape,"Error in cosineDistance: ");const l=qr(1),u=gi(l,yi(pi(a,i),n,!0));return cl(u,o,r)}}),Ns({hingeLoss_:function(t,e,n,s=ul.SUM_BY_NONZERO_WEIGHTS){let r=vs(t,"labels","hingeLoss");const a=vs(e,"predictions","hingeLoss");let i=null;null!=n&&(i=vs(n,"weights","hingeLoss")),R(r.shape,a.shape,"Error in hingeLoss: ");const o=qr(1);r=gi(pi(qr(2),r),o);const l=Hi(gi(o,pi(r,a)));return cl(l,i,s)}}),Ns({huberLoss_:function(t,e,n,s=1,r=ul.SUM_BY_NONZERO_WEIGHTS){const a=vs(t,"labels","huberLoss"),i=vs(e,"predictions","huberLoss");let o=null;null!=n&&(o=vs(n,"weights","huberLoss")),R(a.shape,i.shape,"Error in huberLoss: ");const l=qr(s),u=Xr(gi(i,a)),c=Si(u,l),h=gi(u,c),p=Yr(pi(qr(.5),Ti(c)),pi(l,h));return cl(p,o,r)}}),Ns({logLoss_:function(t,e,n,s=1e-7,r=ul.SUM_BY_NONZERO_WEIGHTS){const a=vs(t,"labels","logLoss"),i=vs(e,"predictions","logLoss");let o=null;null!=n&&(o=vs(n,"weights","logLoss")),R(a.shape,i.shape,"Error in logLoss: ");const l=qr(1),u=qr(s),c=Ei(pi(a,fi(Yr(i,u)))),h=pi(gi(l,a),fi(Yr(gi(l,i),u))),p=gi(c,h);return cl(p,o,r)}});const hl=Ns({squaredDifference_:function(t,e){let n=vs(t,"a","squaredDifference"),s=vs(e,"b","squaredDifference");[n,s]=os(n,s),Xa(n.shape,s.shape);const r={a:n,b:s};return fs.runKernelFunc(((t,e)=>{const r=t.squaredDifference(n,s);return e([n,s]),r}),r,null,cn,{})}});Ns({meanSquaredError_:function(t,e,n,s=ul.SUM_BY_NONZERO_WEIGHTS){const r=vs(t,"labels","meanSquaredError"),a=vs(e,"predictions","meanSquaredError");let i=null;null!=n&&(i=vs(n,"weights","meanSquaredError")),R(r.shape,a.shape,"Error in meanSquaredError: ");const o=hl(r,a);return cl(o,i,s)}});const pl=Ns({log1p_:function(t){const e=vs(t,"x","log1p"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.log1p(e);return n([e]),s}),n,null,xe)}});Ns({sigmoidCrossEntropy_:function(t,e,n,s=0,r=ul.SUM_BY_NONZERO_WEIGHTS){let a=vs(t,"multiClassLabels","sigmoidCrossEntropy");const i=vs(e,"logits","sigmoidCrossEntropy");let o=null;if(null!=n&&(o=vs(n,"weights","sigmoidCrossEntropy")),R(a.shape,i.shape,"Error in sigmoidCrossEntropy: "),s>0){const t=qr(s),e=qr(1),n=qr(.5);a=Yr(pi(a,gi(e,t)),pi(n,t))}const l=function(t,e){const n=vs(t,"labels","sigmoidCrossEntropyWithLogits"),s=vs(e,"logits","sigmoidCrossEntropyWithLogits");R(n.shape,s.shape,"Error in sigmoidCrossEntropyWithLogits: ");const r=Hi(s),a=pi(s,n),i=pl(Ja(Ei(Xr(s))));return Yr(gi(r,a),i)}(a,i);return cl(l,o,r)}});const dl=Ns({logSumExp_:function(t,e=null,n=!1){const s=vs(t,"x","logSumExp"),r=W(e,s.shape),a=mi(s,r,!0),i=gi(s,a),o=Ja(i),l=yi(o,r),u=fi(l),c=Yr(aa(a,u.shape),u);if(n){const t=ta(c.shape,r);return aa(c,t)}return c}});Ns({softmaxCrossEntropy_:function(t,e,n,s=0,r=ul.SUM_BY_NONZERO_WEIGHTS){let a=vs(t,"onehotLabels","softmaxCrossEntropy");const i=vs(e,"logits","softmaxCrossEntropy");let o=null;if(null!=n&&(o=vs(n,"weights","softmaxCrossEntropy")),R(a.shape,i.shape,"Error in softmaxCrossEntropy: "),s>0){const t=qr(s),e=qr(1),n=qr(a.shape[1]);a=Yr(pi(a,gi(e,t)),Ha(t,n))}const l=function(t,e,n=-1){if(-1===n&&(n=e.rank-1),n!==e.rank-1)throw Error(`Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ${e.rank} and dim was `+n);return jr(((t,e,s)=>{const r=dl(e,[n],!0),a=gi(or(e,"float32"),r);s([t,a]);const i=Ei(pi(a,t));return{value:yi(i,[n]),gradFunc:(t,e)=>{const[s,r]=e,a=ta(t.shape,[n]);return[pi(aa(t,a),gi(or(s,"float32"),Ja(r))),pi(aa(t,a),gi(Ja(r),or(s,"float32")))]}}}))(t,e)}(a,i);return cl(l,o,r)}});const fl={flipLeftRight:zo,resizeNearestNeighbor:tl,resizeBilinear:Qo,rotateWithOffset:Bo,cropAndResize:Lo,nonMaxSuppression:Wo,nonMaxSuppressionAsync:async function(t,e,n,s=.5,r=Number.NEGATIVE_INFINITY){const a=vs(t,"boxes","nonMaxSuppressionAsync"),i=vs(e,"scores","nonMaxSuppressionAsync"),o=Po(a,i,n,s,r);n=o.maxOutputSize,s=o.iouThreshold,r=o.scoreThreshold;const l=await Promise.all([a.data(),i.data()]),u=Go(l[0],l[1],n,s,r);return a!==t&&a.dispose(),i!==e&&i.dispose(),u},nonMaxSuppressionWithScore:Jo,nonMaxSuppressionWithScoreAsync:async function(t,e,n,s=.5,r=Number.NEGATIVE_INFINITY,a=0){const i=vs(t,"boxes","nonMaxSuppressionAsync"),o=vs(e,"scores","nonMaxSuppressionAsync"),l=Po(i,o,n,s,r,a);n=l.maxOutputSize,s=l.iouThreshold,r=l.scoreThreshold,a=l.softNmsSigma;const u=await Promise.all([i.data(),o.data()]),c=jo(u[0],u[1],n,s,r,a);return i!==t&&i.dispose(),o!==e&&o.dispose(),c},nonMaxSuppressionPadded:Zo,nonMaxSuppressionPaddedAsync:async function(t,e,n,s=.5,r=Number.NEGATIVE_INFINITY,a=!1){const i=vs(t,"boxes","nonMaxSuppressionAsync"),o=vs(e,"scores","nonMaxSuppressionAsync"),l=Po(i,o,n,s,r,null),u=l.maxOutputSize,c=l.iouThreshold,h=l.scoreThreshold,[p,d]=await Promise.all([i.data(),o.data()]),f=Ho(p,d,u,c,h,a);return i!==t&&i.dispose(),o!==e&&o.dispose(),f}},ml={bandPart:nl,gramSchmidt:il,qr:ll};class gl extends Kr{constructor(t,e,n=null){super(),this.learningRate=t,this.rho=e,this.epsilon=n,this.accumulatedGrads=[],this.accumulatedUpdates=[],null==n&&(this.epsilon=fs.backend.epsilon())}applyGradients(t){(Array.isArray(t)?t.map((t=>t.name)):Object.keys(t)).forEach(((e,n)=>{const s=fs.registeredVariables[e];null==this.accumulatedGrads[n]&&(this.accumulatedGrads[n]={originalName:e+"/accum_grad",variable:Wr((()=>_i(s).variable(!1)))}),null==this.accumulatedUpdates[n]&&(this.accumulatedUpdates[n]={originalName:e+"/accum_var",variable:Wr((()=>_i(s).variable(!1)))});const r=Array.isArray(t)?t[n].tensor:t[e];if(null==r)return;const a=this.accumulatedGrads[n].variable,i=this.accumulatedUpdates[n].variable;Wr((()=>{const t=Yr(pi(a,this.rho),pi(Ti(r),1-this.rho)),e=pi(Ha(ao(Yr(i,this.epsilon)),ao(Yr(a,this.epsilon))),r),n=Yr(pi(i,this.rho),pi(Ti(e),1-this.rho));a.assign(t),i.assign(n);const o=Yr(pi(e,-this.learningRate),s);s.assign(o)}))})),this.incrementIterations()}dispose(){null!=this.accumulatedUpdates&&(Vr(this.accumulatedGrads.map((t=>t.variable))),Vr(this.accumulatedUpdates.map((t=>t.variable))))}async getWeights(){const t=[...this.accumulatedGrads,...this.accumulatedUpdates];return[await this.saveIterations()].concat(t.map((t=>({name:t.originalName,tensor:t.variable}))))}async setWeights(t){const e=(t=await this.extractIterations(t)).length/2;this.accumulatedGrads=t.slice(0,e).map((t=>({originalName:t.name,variable:t.tensor.variable(!1)}))),this.accumulatedUpdates=t.slice(e,2*e).map((t=>({originalName:t.name,variable:t.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,rho:this.rho,epsilon:this.epsilon}}static fromConfig(t,e){return new t(e.learningRate,e.rho,e.epsilon)}}gl.className="Adadelta",Lr(gl);class yl extends Kr{constructor(t,e=.1){super(),this.learningRate=t,this.initialAccumulatorValue=e,this.accumulatedGrads=[]}applyGradients(t){(Array.isArray(t)?t.map((t=>t.name)):Object.keys(t)).forEach(((e,n)=>{const s=fs.registeredVariables[e];if(null==this.accumulatedGrads[n]){const t=!1;this.accumulatedGrads[n]={originalName:e+"/accumulator",variable:Wr((()=>ei(s.shape,this.initialAccumulatorValue).variable(t)))}}const r=Array.isArray(t)?t[n].tensor:t[e];if(null==r)return;const a=this.accumulatedGrads[n].variable;Wr((()=>{const t=Yr(a,Ti(r));a.assign(t);const e=Yr(pi(Ha(r,ao(Yr(t,fs.backend.epsilon()))),-this.learningRate),s);s.assign(e)}))})),this.incrementIterations()}dispose(){null!=this.accumulatedGrads&&Vr(this.accumulatedGrads.map((t=>t.variable)))}async getWeights(){return[await this.saveIterations()].concat(this.accumulatedGrads.map((t=>({name:t.originalName,tensor:t.variable}))))}async setWeights(t){t=await this.extractIterations(t),this.accumulatedGrads=t.map((t=>({originalName:t.name,variable:t.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,initialAccumulatorValue:this.initialAccumulatorValue}}static fromConfig(t,e){return new t(e.learningRate,e.initialAccumulatorValue)}}yl.className="Adagrad",Lr(yl);class bl extends Kr{constructor(t,e,n,s=null){super(),this.learningRate=t,this.beta1=e,this.beta2=n,this.epsilon=s,this.accumulatedFirstMoment=[],this.accumulatedSecondMoment=[],Wr((()=>{this.accBeta1=qr(e).variable(),this.accBeta2=qr(n).variable()})),null==s&&(this.epsilon=fs.backend.epsilon())}applyGradients(t){const e=Array.isArray(t)?t.map((t=>t.name)):Object.keys(t);Wr((()=>{const n=gi(1,this.accBeta1),s=gi(1,this.accBeta2);e.forEach(((e,r)=>{const a=fs.registeredVariables[e];null==this.accumulatedFirstMoment[r]&&(this.accumulatedFirstMoment[r]={originalName:e+"/m",variable:Wr((()=>_i(a).variable(!1)))}),null==this.accumulatedSecondMoment[r]&&(this.accumulatedSecondMoment[r]={originalName:e+"/v",variable:Wr((()=>_i(a).variable(!1)))});const i=Array.isArray(t)?t[r].tensor:t[e];if(null==i)return;const o=this.accumulatedFirstMoment[r].variable,l=this.accumulatedSecondMoment[r].variable,u=Yr(pi(o,this.beta1),pi(i,1-this.beta1)),c=Yr(pi(l,this.beta2),pi(Ti(i),1-this.beta2)),h=Ha(u,n),p=Ha(c,s);o.assign(u),l.assign(c);const d=Yr(pi(Ha(h,Yr(ao(p),this.epsilon)),-this.learningRate),a);a.assign(d)})),this.accBeta1.assign(pi(this.accBeta1,this.beta1)),this.accBeta2.assign(pi(this.accBeta2,this.beta2))})),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.accBeta2.dispose(),null!=this.accumulatedFirstMoment&&Vr(this.accumulatedFirstMoment.map((t=>t.variable))),null!=this.accumulatedSecondMoment&&Vr(this.accumulatedSecondMoment.map((t=>t.variable)))}async getWeights(){const t=[...this.accumulatedFirstMoment,...this.accumulatedSecondMoment];return[await this.saveIterations()].concat(t.map((t=>({name:t.originalName,tensor:t.variable}))))}async setWeights(t){t=await this.extractIterations(t),Wr((()=>{this.accBeta1.assign(sl(this.beta1,this.iterations_+1)),this.accBeta2.assign(sl(this.beta2,this.iterations_+1))}));const e=t.length/2;this.accumulatedFirstMoment=t.slice(0,e).map((t=>({originalName:t.name,variable:t.tensor.variable(!1)}))),this.accumulatedSecondMoment=t.slice(e,2*e).map((t=>({originalName:t.name,variable:t.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon}}static fromConfig(t,e){return new t(e.learningRate,e.beta1,e.beta2,e.epsilon)}}bl.className="Adam",Lr(bl);class xl extends Kr{constructor(t,e,n,s=null,r=0){super(),this.learningRate=t,this.beta1=e,this.beta2=n,this.epsilon=s,this.decay=r,this.accumulatedFirstMoment=[],this.accumulatedWeightedInfNorm=[],Wr((()=>{this.iteration=qr(0).variable(),this.accBeta1=qr(e).variable()})),null==s&&(this.epsilon=fs.backend.epsilon())}applyGradients(t){const e=Array.isArray(t)?t.map((t=>t.name)):Object.keys(t);Wr((()=>{const n=gi(1,this.accBeta1),s=Ha(-this.learningRate,Yr(pi(this.iteration,this.decay),1));e.forEach(((e,r)=>{const a=fs.registeredVariables[e];null==this.accumulatedFirstMoment[r]&&(this.accumulatedFirstMoment[r]={originalName:e+"/m",variable:_i(a).variable(!1)}),null==this.accumulatedWeightedInfNorm[r]&&(this.accumulatedWeightedInfNorm[r]={originalName:e+"/v",variable:_i(a).variable(!1)});const i=Array.isArray(t)?t[r].tensor:t[e];if(null==i)return;const o=this.accumulatedFirstMoment[r].variable,l=this.accumulatedWeightedInfNorm[r].variable,u=Yr(pi(o,this.beta1),pi(i,1-this.beta1)),c=pi(l,this.beta2),h=Xr(i),p=hi(c,h);o.assign(u),l.assign(p);const d=Yr(pi(Ha(s,n),Ha(u,Yr(p,this.epsilon))),a);a.assign(d)})),this.iteration.assign(Yr(this.iteration,1)),this.accBeta1.assign(pi(this.accBeta1,this.beta1))})),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.iteration.dispose(),null!=this.accumulatedFirstMoment&&Vr(this.accumulatedFirstMoment.map((t=>t.variable))),null!=this.accumulatedWeightedInfNorm&&Vr(this.accumulatedWeightedInfNorm.map((t=>t.variable)))}async getWeights(){throw new Error("getWeights() is not implemented for Adamax yet.")}async setWeights(t){throw new Error("setWeights() is not implemented for Adamax yet.")}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon,decay:this.decay}}static fromConfig(t,e){return new t(e.learningRate,e.beta1,e.beta2,e.epsilon,e.decay)}}xl.className="Adamax",Lr(xl);class wl extends Kr{constructor(t){super(),this.learningRate=t,this.setLearningRate(t)}applyGradients(t){(Array.isArray(t)?t.map((t=>t.name)):Object.keys(t)).forEach(((e,n)=>{const s=Array.isArray(t)?t[n].tensor:t[e];if(null==s)return;const r=fs.registeredVariables[e];Wr((()=>{const t=Yr(pi(this.c,s),r);r.assign(t)}))})),this.incrementIterations()}setLearningRate(t){this.learningRate=t,null!=this.c&&this.c.dispose(),this.c=Ur(qr(-t))}dispose(){this.c.dispose()}async getWeights(){return[await this.saveIterations()]}async setWeights(t){if(0!==(t=await this.extractIterations(t)).length)throw new Error("SGD optimizer does not have settable weights.")}getConfig(){return{learningRate:this.learningRate}}static fromConfig(t,e){return new t(e.learningRate)}}wl.className="SGD",Lr(wl);class vl extends wl{constructor(t,e,n=!1){super(t),this.learningRate=t,this.momentum=e,this.useNesterov=n,this.accumulations=[],this.m=qr(this.momentum)}applyGradients(t){(Array.isArray(t)?t.map((t=>t.name)):Object.keys(t)).forEach(((e,n)=>{const s=fs.registeredVariables[e];if(null==this.accumulations[n]){const t=!1;this.accumulations[n]={originalName:e+"/momentum",variable:Wr((()=>_i(s).variable(t)))}}const r=this.accumulations[n].variable,a=Array.isArray(t)?t[n].tensor:t[e];null!=a&&Wr((()=>{let t;const e=Yr(pi(this.m,r),a);t=this.useNesterov?Yr(pi(this.c,Yr(a,pi(e,this.m))),s):Yr(pi(this.c,e),s),r.assign(e),s.assign(t)}))})),this.incrementIterations()}dispose(){this.m.dispose(),null!=this.accumulations&&Vr(this.accumulations.map((t=>t.variable)))}setMomentum(t){this.momentum=t}async getWeights(){return[await this.saveIterations()].concat(this.accumulations.map((t=>({name:t.originalName,tensor:t.variable}))))}async setWeights(t){t=await this.extractIterations(t),this.accumulations=t.map((t=>({originalName:t.name,variable:t.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,momentum:this.momentum,useNesterov:this.useNesterov}}static fromConfig(t,e){return new t(e.learningRate,e.momentum,e.useNesterov)}}vl.className="Momentum",Lr(vl);class kl extends Kr{constructor(t,e=.9,n=0,s=null,r=!1){if(super(),this.learningRate=t,this.decay=e,this.momentum=n,this.epsilon=s,this.accumulatedMeanSquares=[],this.accumulatedMoments=[],this.accumulatedMeanGrads=[],this.centered=r,null==s&&(this.epsilon=fs.backend.epsilon()),null==t)throw new Error("learningRate for RMSPropOptimizer must be defined.")}applyGradients(t){(Array.isArray(t)?t.map((t=>t.name)):Object.keys(t)).forEach(((e,n)=>{const s=fs.registeredVariables[e],r=!1;null==this.accumulatedMeanSquares[n]&&(this.accumulatedMeanSquares[n]={originalName:e+"/rms",variable:Wr((()=>_i(s).variable(r)))}),null==this.accumulatedMoments[n]&&(this.accumulatedMoments[n]={originalName:e+"/momentum",variable:Wr((()=>_i(s).variable(r)))}),null==this.accumulatedMeanGrads[n]&&this.centered&&(this.accumulatedMeanGrads[n]={originalName:e+"/mg",variable:Wr((()=>_i(s).variable(r)))});const a=Array.isArray(t)?t[n].tensor:t[e];if(null==a)return;const i=this.accumulatedMeanSquares[n].variable,o=this.accumulatedMoments[n].variable;Wr((()=>{const t=Yr(pi(i,this.decay),pi(Ti(a),1-this.decay));if(this.centered){const e=this.accumulatedMeanGrads[n].variable,r=Yr(pi(e,this.decay),pi(a,1-this.decay)),l=Ha(pi(a,this.learningRate),ao(gi(t,Yr(Ti(r),this.epsilon)))),u=Yr(pi(o,this.momentum),l);i.assign(t),e.assign(r),o.assign(u);const c=gi(s,u);s.assign(c)}else{const t=Yr(pi(i,this.decay),pi(Ti(a),1-this.decay)),e=Yr(pi(o,this.momentum),Ha(pi(a,this.learningRate),ao(Yr(t,this.epsilon))));i.assign(t),o.assign(e);const n=gi(s,e);s.assign(n)}}))})),this.incrementIterations()}dispose(){null!=this.accumulatedMeanSquares&&Vr(this.accumulatedMeanSquares.map((t=>t.variable))),null!=this.accumulatedMeanGrads&&this.centered&&Vr(this.accumulatedMeanGrads.map((t=>t.variable))),null!=this.accumulatedMoments&&Vr(this.accumulatedMoments.map((t=>t.variable)))}async getWeights(){const t=[...this.accumulatedMeanSquares,...this.accumulatedMoments];return this.centered&&t.push(...this.accumulatedMeanGrads),[await this.saveIterations()].concat(t.map((t=>({name:t.originalName,tensor:t.variable}))))}async setWeights(t){t=await this.extractIterations(t);const e=this.centered?t.length/3:t.length/2,n=!1;this.accumulatedMeanSquares=t.slice(0,e).map((t=>({originalName:t.name,variable:t.tensor.variable(n)}))),this.accumulatedMoments=t.slice(e,2*e).map((t=>({originalName:t.name,variable:t.tensor.variable(n)}))),this.centered&&(this.accumulatedMeanGrads=t.slice(2*e,3*e).map((t=>({originalName:t.name,variable:t.tensor.variable(n)}))))}getConfig(){return{learningRate:this.learningRate,decay:this.decay,momentum:this.momentum,epsilon:this.epsilon,centered:this.centered}}static fromConfig(t,e){return new t(e.learningRate,e.decay,e.momentum,e.epsilon,e.centered)}}kl.className="RMSProp",Lr(kl);class Nl{static sgd(t){return new wl(t)}static momentum(t,e,n=!1){return new vl(t,e,n)}static rmsprop(t,e=.9,n=0,s=null,r=!1){return new kl(t,e,n,s,r)}static adam(t=.001,e=.9,n=.999,s=null){return new bl(t,e,n,s)}static adadelta(t=.001,e=.95,n=null){return new gl(t,e,n)}static adamax(t=.002,e=.9,n=.999,s=null,r=0){return new xl(t,e,n,s,r)}static adagrad(t,e=.1){return new yl(t,e)}}const Il={sgd:Nl.sgd,momentum:Nl.momentum,adadelta:Nl.adadelta,adagrad:Nl.adagrad,rmsprop:Nl.rmsprop,adamax:Nl.adamax,adam:Nl.adam},Cl="undefined"!=typeof requestAnimationFrame?requestAnimationFrame:"undefined"!=typeof setImmediate?setImmediate:t=>t();function Sl(){return new Promise((t=>Cl((()=>t()))))}function Tl(t,e,n){return[n*("number"==typeof t?t:t[0]),e*("number"==typeof t?t:t[1])]}function $l(t,e,n,s=!0){let r=[];if(s)r=r.concat(e.slice(0)),r.push(t[0]/n),r=r.concat(t.slice(1));else{r=r.concat(t[0]);const n=e.length;for(let s=0;s<n;++s)r=r.concat([t[s+1]/e[s],e[s]]);r=r.concat(t.slice(n+1))}return r}function El(t,e,n=!0){const s=[];if(n){s.push(e);for(let n=e+1;n<t;++n)n<=2*e?(s.push(n),s.push(n-(e+1))):s.push(n)}else{const n=[],r=[];for(let s=1;s<t;++s)s>=2*e+1||s%2==1?r.push(s):n.push(s);s.push(...n),s.push(0),s.push(...r)}return s}function Al(t,e,n,s=!0){const r=[];s?r.push(t[0]/n):r.push(t[0]*n);for(let n=1;n<t.length;++n)n<=e.length?s?r.push(e[n-1]*t[n]):r.push(t[n]/e[n-1]):r.push(t[n]);return r}function Rl(t,e){const n=[0];for(let s=0;s<e;++s)n.push(t[s][0]);return n}function Dl(t,e,n){const s=t.slice(0,1);for(let r=0;r<n;++r)s.push(t[r+1]-e[r][0]-e[r][1]);return s}function Fl(t,e){if(t.rank<1)throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${t.rank}.`);if(e.rank<1)throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${e.rank}.`);if("int32"!==e.dtype)throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${e.dtype}.`);if(e.shape[e.rank-1]>t.rank)throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${e.shape[e.rank-1]} vs. ${t.rank}`);if(0===t.size)throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${t.shape}.`);const n=e.shape,s=n[n.length-1];let r=1;for(let t=0;t<n.length-1;++t)r*=n[t];const a=t.shape,i=n.slice();i.pop();let o=1;for(let e=s;e<t.rank;++e)o*=a[e],i.push(a[e]);const l=[...Q(t.shape).map((t=>t/o)),1].slice(0,s);return[i,r,o,l]}function _l(t,e,n){const s=e.rank>1?e.shape[e.rank-1]:1,r=e.rank>1?e.rank-1:1,a="Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: "+n.shape+`, indices.shape: ${e.shape}, shape: ${t}`+`, sliceDim: ${s}, and batchDim: ${r}.`;if(n.rank<r)throw new Error(a+` update.rank < ${r}. `);if(t.length<s+(n.rank-r))throw new Error(a+" Output shape length < "+(s+(n.rank-r)));if(n.rank!==r+t.length-s)throw new Error(a+" update.rank != "+(r+t.length-s));for(let t=0;t<r;++t)if(n.shape[t]!==e.shape[t])throw new Error(a+` updates.shape[${t}] (${n.shape[t]}) != indices.shape[${t}] (${e.shape[t]}).`);for(let e=0;e<n.rank-r;++e)if(n.shape[e+r]!==t[e+s])throw new Error(a+` updates.shape[${e+r}] (${n.shape[e+r]}) != shape[${e+r}] (${t[e+r]})`)}function Ol(t,e,n){if(e.rank<1)throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${e.rank}.`);if(t.rank<1)throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${t.rank}.`);if("int32"!==e.dtype)throw new Error("The dtype of 'indices' should be int32, but got dtype: "+e.dtype);if(n.length<1)throw new Error("Output rank must be greater or equal to 1, but got shape: "+n);if(0===n.length){if(0===e.size)throw new Error("Indices specified for empty output. indices shape: "+e.shape);if(0===t.size)throw new Error("Updates specified for empty output. updates shape: "+t.shape)}_l(n,e,t)}function Ml(t,e,n){const s=e.shape.length,r=s>1?e.shape[s-1]:1,a=n.length;let i=1;for(let t=r;t<a;++t)i*=n[t];const o=r<1?1:r;return{sliceRank:r,numUpdates:_(e.shape)/o,sliceSize:i,strides:[...Q(n.slice(0,r)),1],outputSize:_(n)}}const Ll=1.7580993408473768,zl=1.0507009873554805,Bl=.3275911,Pl=.254829592,Wl=-.284496736,Vl=1.421413741,Ul=-1.453152027,Gl=1.061405429;function Hl(...t){ct().getBool("IS_TEST")||console.warn(...t)}function jl(...t){ct().getBool("IS_TEST")||console.log(...t)}function ql(t,e){if(t.length!==e.length)throw new Error(`Cannot merge real and imag arrays of different lengths. real:${t.length}, imag: ${e.length}.`);const n=new Float32Array(2*t.length);for(let s=0;s<n.length;s+=2)n[s]=t[s/2],n[s+1]=e[s/2];return n}function Kl(t){const e=new Float32Array(t.length/2),n=new Float32Array(t.length/2);for(let s=0;s<t.length;s+=2)e[s/2]=t[s],n[s/2]=t[s+1];return{real:e,imag:n}}function Xl(t){const e=Math.ceil(t.length/4),n=new Float32Array(e),s=new Float32Array(e);for(let e=0;e<t.length;e+=4)n[Math.floor(e/4)]=t[e],s[Math.floor(e/4)]=t[e+1];return{real:n,imag:s}}function Yl(t){const e=Math.floor(t.length/4),n=new Float32Array(e),s=new Float32Array(e);for(let e=2;e<t.length;e+=4)n[Math.floor(e/4)]=t[e],s[Math.floor(e/4)]=t[e+1];return{real:n,imag:s}}function Jl(t,e){return{real:t[2*e],imag:t[2*e+1]}}function Zl(t,e,n,s){t[2*s]=e,t[2*s+1]=n}function Ql(t,e){const n=new Float32Array(t/2),s=new Float32Array(t/2);for(let r=0;r<Math.ceil(t/2);r++){const a=(e?2:-2)*Math.PI*(r/t);n[r]=Math.cos(a),s[r]=Math.sin(a)}return{real:n,imag:s}}function tu(t,e,n){const s=(n?2:-2)*Math.PI*(t/e);return{real:Math.cos(s),imag:Math.sin(s)}}function eu(t,e,n){if("complex64"===e){if("complex64"===t.dtype)return t.clone();const e=ki(t.shape),s=or(t,"float32"),r=n.complex(s,e);return e.dispose(),s.dispose(),r}if(!H(t.dtype,e))return fs.makeTensorFromDataId(t.dataId,t.shape,e);if("complex64"===t.dtype){const s=n.real(t),r=or(s,e);return s.dispose(),r}if("int32"===e)return n.int(t);if("bool"===e){const e=qr(0,t.dtype),s=n.notEqual(t,e);return e.dispose(),s}throw new Error(`Error in Cast: failed to cast ${t.dtype} to ${e}`)}function nu(t,e){return fs.makeTensorFromDataId(t.dataId,e,t.dtype)}function su(t,e,n){const s=(e-t)/(n-1),r=st(n,"float32");r[0]=t;for(let t=1;t<r.length;t++)r[t]=r[t-1]+s;return Ui(r,"float32")}function ru(t,e,n){const s=new Array(t.rank).fill(0),r=t.shape.slice();return e.map((e=>{const a=[...r];a[n]=e;const i=Yi(t,s,a);return s[n]+=e,i}))}function au(t,e){const n=new Array(t.rank);for(let s=0;s<n.length;s++)n[s]=t.shape[s]*e[s];const s=ir(n,t.dtype);for(let e=0;e<s.values.length;++e){const n=s.indexToLoc(e),r=new Array(t.rank);for(let e=0;e<r.length;e++)r[e]=n[e]%t.shape[e];const a=t.locToIndex(r);s.values[e]=t.values[a]}return s.toTensor()}function iu(t,e,n,s,r){const a=e[e.length-1],[i,o]=[t.length/a,a],l=U(n,i*s),u=U("int32",i*s);for(let e=0;e<i;e++){const n=e*o,r=t.subarray(n,n+o),a=[];for(let t=0;t<r.length;t++)a.push({value:r[t],index:t});a.sort(((t,e)=>e.value-t.value));const i=e*s,c=l.subarray(i,i+s),h=u.subarray(i,i+s);for(let t=0;t<s;t++)c[t]=a[t].value,h[t]=a[t].index}const c=e.slice();return c[c.length-1]=s,[Ss(l,c,n),Ss(u,c,"int32")]}function ou(t,e){const n=[];for(let t=0;t<e.length;t++)e[t]&&n.push(t);const s=ir(t,"int32"),r=ir([n.length,t.length],"int32");for(let e=0;e<n.length;e++){const a=s.indexToLoc(n[e]),i=e*t.length;r.values.set(a,i)}return r.toTensor()}const lu={kernelName:mt,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>pi(t,No(or(n,"float32"),-1))}}},uu={kernelName:gt,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>{const e=Ti(or(n,"float32")),s=ao(gi(qr(1),e));return Ei(Ha(t,s))}}}},cu={kernelName:yt,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>{const e=ao(gi(Ti(or(n,"float32")),1));return Ha(t,e)}}}},hu={kernelName:bt,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e,r=Xa(n.shape,s.shape);return{a:()=>{let e=t;const s=Ka(n.shape,r);return s.length>0&&(e=yi(e,s)),aa(e,n.shape)},b:()=>{let e=t;const n=Ka(s.shape,r);return n.length>0&&(e=yi(e,n)),aa(e,s.shape)}}}},pu={kernelName:xt,saveAllInputs:!0,gradFunc:(t,e)=>{const n={};return e.forEach(((e,s)=>{n[s]=()=>t.clone()})),n}},du={kernelName:wt,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>_i(n)}}},fu={kernelName:vt,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>_i(n)}}},mu={kernelName:kt,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Ha(t,ao(gi(qr(1),Ti(or(n,"float32")))))}}},gu={kernelName:Nt,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>{const e=ao(Yr(qr(1),Ti(or(n,"float32"))));return Ha(t,e)}}}},yu={kernelName:St,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e,r=Xa(n.shape,s.shape);return{a:()=>{const e=Yr(Ti(n),Ti(s));let a=pi(t,Ha(s,e));const i=Ka(n.shape,r);return i.length>0&&(a=yi(a,i)),aa(a,n.shape)},b:()=>{const e=Yr(Ti(n),Ti(s));let a=Ei(pi(t,Ha(n,e)));const i=Ka(s.shape,r);return i.length>0&&(a=yi(a,i)),aa(a,s.shape)}}}},bu={kernelName:It,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Ha(t,Yr(Ti(or(n,"float32")),1))}}},xu={kernelName:Ct,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Ha(t,gi(qr(1),Ti(or(n,"float32"))))}}},wu=Ns({avgPool3dBackprop_:function(t,e,n,s,r=[1,1,1],a,i){const o=vs(t,"dy","avgPool3dBackprop"),l=vs(e,"input","avgPool3dBackprop");let u=o,c=l,h=!1;4===l.rank&&(h=!0,u=aa(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]]),c=aa(l,[1,l.shape[0],l.shape[1],l.shape[2],l.shape[3]])),A(5===u.rank,(()=>"Error in avgPool3dBackprop: dy must be rank 5 but got rank "+u.rank+".")),A(5===c.rank,(()=>"Error in avgPool3dBackprop: input must be rank 5 but got rank "+c.rank+".")),A(va(s,r),(()=>`Error in avgPool3dBackprop: Either strides or dilations must be 1. Got strides ${s} and dilations '${r}'`)),null!=i&&A(M(a),(()=>`Error in maxPool3dBackprop: pad must be an integer when using, dimRoundingMode ${i} but got pad ${a}.`));const p={dy:u,input:c},d={filterSize:n,strides:s,dilations:r,pad:a,dimRoundingMode:i},f=fs.runKernelFunc((t=>{const e=pa(c.shape,n,s,r,a,i);return t.avgPool3dBackprop(u,c,e)}),p,null,"AvgPool3DBackprop",d);return h?aa(f,[f.shape[1],f.shape[2],f.shape[3],f.shape[4]]):f}}),vu={kernelName:Et,inputsToSave:["x"],gradFunc:(t,e,n)=>{const[s]=e,{filterSize:r,strides:a,dilations:i,pad:o,dimRoundingMode:l}=n,u=null==i?[1,1,1]:i;return{x:()=>wu(t,s,r,a,u,o,l)}}},ku=Ns({avgPoolBackprop_:function(t,e,n,s,r){const a=vs(t,"dy","avgPoolBackprop"),i=vs(e,"input","avgPoolBackprop");A(i.rank===a.rank,(()=>`Rank of input (${i.rank}) does not match rank of dy (${a.rank})`));let o=i,l=a,u=!1;3===i.rank&&(u=!0,o=aa(i,[1,i.shape[0],i.shape[1],i.shape[2]]),l=aa(a,[1,a.shape[0],a.shape[1],a.shape[2]])),A(4===l.rank,(()=>"Error in avgPoolBackprop: dy must be rank 4 but got rank "+l.rank+".")),A(4===o.rank,(()=>"Error in avgPoolBackprop: input must be rank 4 but got rank "+o.rank+"."));const c={dy:l,input:o},h={filterSize:n,strides:s,pad:r},p=fs.runKernelFunc((t=>{const e=ha(o.shape,n,s,1,r);return t.avgPoolBackprop(l,o,e)}),c,null,$t,h);return u?aa(p,[p.shape[1],p.shape[2],p.shape[3]]):p}}),Nu={kernelName:Tt,inputsToSave:["x"],gradFunc:(t,e,n)=>{const[s]=e,{filterSize:r,strides:a,pad:i}=n;return{x:()=>ku(t,s,r,a,i)}}},Iu={kernelName:At,inputsToSave:["a","b"],gradFunc:(t,e,n)=>{const[s,r]=e,{transposeA:a,transposeB:i}=n;return a||i?!a&&i?{a:()=>Do(t,r,!1,!1),b:()=>Do(t,s,!0,!1)}:a&&!i?{a:()=>Do(r,t,!1,!0),b:()=>Do(s,t,!1,!1)}:{a:()=>Do(r,t,!0,!0),b:()=>Do(t,s,!0,!0)}:{a:()=>Do(t,r,!1,!0),b:()=>Do(s,t,!0,!1)}}},Cu=Ns({spaceToBatchND_:function(t,e,n){const s=vs(t,"x","spaceToBatchND");A(s.rank>=1+e.length,(()=>`input rank ${s.rank} should be > than [blockShape] ${e.length}`)),A(n.length===e.length,(()=>`paddings.shape[0] ${n.length} must be equal to [blockShape] ${e.length}`)),A(s.shape.reduce(((t,s,r)=>r>0&&r<=e.length?t&&(s+n[r-1][0]+n[r-1][1])%e[r-1]==0:t),!0),(()=>`input spatial dimensions ${s.shape.slice(1)} with paddings ${n.toString()} must be divisible by blockShapes ${e.toString()}`));const r={x:s},a={blockShape:e,paddings:n};return fs.runKernelFunc((t=>t.spaceToBatchND(s,e,n)),r,null,on,a)}}),Su={kernelName:Rt,gradFunc:(t,e,n)=>{const{blockShape:s,crops:r}=n;return{x:()=>Cu(t,s,r)}}},Tu={kernelName:Dt,gradFunc:(t,e,n)=>{const s=n,r=s.inputShape,a=s.shape,i=Array.from(a);for(let t=r.length-1;t>=0;t--)if(r[t]===a[t])i[t]=1;else if(1!==r[t])throw new Error(`broadcastTo(): [${r}] cannot be broadcast to [${a}].`);const o=[];for(let t=0;t<i.length;t++)i[t]>1&&o.push(t);return{x:()=>yi(t,o,!0)}}},$u={kernelName:Ft,gradFunc:t=>({x:()=>t.clone()})},Eu={kernelName:_t,gradFunc:t=>({x:()=>_i(t)})},Au={kernelName:Ot,inputsToSave:["x"],gradFunc:(t,e,n)=>{const[s]=e,{clipValueMin:r,clipValueMax:a}=n;return{x:()=>mo(xi(ci(s,r),el(s,a)),t,_i(t))}}},Ru={kernelName:Lt,saveAllInputs:!0,gradFunc:(t,e,n)=>{const s=e.map((t=>t.shape)),{axis:r}=n,a=W(r,e[0].shape)[0],i=s.map((t=>t[a]));return ro(t,i,a).map((t=>()=>t))}},Du={kernelName:zt,inputsToSave:["x","filter"],gradFunc:(t,e,n)=>{const[s,r]=e,{dilations:a,strides:i,pad:o,dataFormat:l}=n;return A(wa(a),(()=>`Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${a}'`)),{x:()=>Pa(s.shape,t,r,i,o,l),filter:()=>vo(s,t,r.shape,i,o,l)}}},Fu={kernelName:Pt,inputsToSave:["dy","filter"],gradFunc:(t,e,n)=>{const[s,r]=e,{strides:a,pad:i,dataFormat:o,dimRoundingMode:l}=n;return{dy:()=>za(t,r,a,i,o,1,l),filter:()=>vo(t,s,r.shape,a,i,o,l)}}},_u=Ns({conv3DBackpropFilter_:function(t,e,n,s,r){let a=t;4===t.rank&&(a=aa(t,[1,t.shape[0],t.shape[1],t.shape[2],t.shape[3]]));let i=e;4===i.rank&&(i=aa(e,[1,e.shape[0],e.shape[1],e.shape[2],e.shape[3]])),A(5===a.rank,(()=>"Error in conv3dDerFilter: input must be rank 5, but got shape "+a.shape+".")),A(5===i.rank,(()=>"Error in conv3dDerFilter: dy must be rank 5, but got shape "+i.shape+".")),A(5===n.length,(()=>"Error in conv3dDerFilter: filterShape must be length 5, but got "+n+".")),A(a.shape[4]===n[3],(()=>`Error in conv3dDerFilter: depth of input ${a.shape[4]}) must match input depth in filter (${n[3]}.`)),A(i.shape[4]===n[4],(()=>`Error in conv3dDerFilter: depth of dy (${i.shape[4]}) must match output depth for filter (${n[4]}).`));const o={x:a,dy:i},l={strides:s,pad:r,filterShape:n};return fs.runKernelFunc((t=>{const e=fa(a.shape,n,s,1,r);return t.conv3dDerFilter(a,i,e)}),o,null,Vt,l)}}),Ou=Ns({conv3DBackpropInput_:function(t,e,n,s,r){A(t.length===e.rank,(()=>`Length of inShape (${t.length}) and rank of dy (${e.rank}) must match`));let a=t,i=e,o=!1;4===e.rank&&(o=!0,i=aa(e,[1,e.shape[0],e.shape[1],e.shape[2],e.shape[3]]),a=[1,t[0],t[1],t[2],t[3]]);const l=a[4],u=i.shape[4];A(5===a.length,(()=>"Error in conv3dDerInput: inShape must be length 5, but got length "+a.length+".")),A(5===i.rank,(()=>"Error in conv3dDerInput: dy must be rank 5, but got rank "+i.rank)),A(5===n.rank,(()=>"Error in conv3dDerInput: filter must be rank 5, but got rank "+n.rank)),A(l===n.shape[3],(()=>`Error in conv3dDerInput: depth of input (${l}) must match input depth for filter ${n.shape[3]}.`)),A(u===n.shape[4],(()=>`Error in conv3dDerInput: depth of output (${u}) must match output depth for filter ${n.shape[4]}.`));const c={dy:i,filter:n},h={pad:r,strides:s,inputShape:a},p=fs.runKernelFunc((t=>{const e=fa(a,n.shape,s,1,r);return t.conv3dDerInput(i,n,e)}),c,null,Ut,h);return o?aa(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}}),Mu={kernelName:Wt,inputsToSave:["x","filter"],gradFunc:(t,e,n)=>{const{dilations:s,strides:r,pad:a}=n;A(wa(s),(()=>`Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${s}'`));const[i,o]=e;return{x:()=>Ou(i.shape,t,o,r,a),filter:()=>_u(i,t,o.shape,r,a)}}},Lu=Ns({sin_:function(t){const e=vs(t,"x","sin"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.sin(e);return n([e]),s}),n,null,tn)}}),zu={kernelName:Gt,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>pi(Ei(Lu(or(n,"float32"))),t)}}},Bu=Ns({sinh_:function(t){const e=vs(t,"x","sinh"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.sinh(e);return n([e]),s}),n,null,en)}}),Pu={kernelName:Ht,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>pi(Bu(or(n,"float32")),t)}}},Wu=Ns({cumsum_:function(t,e=0,n=!1,s=!1){const r=vs(t,"x","cumsum"),a={x:r},i={axis:e,exclusive:n,reverse:s};return fs.runKernelFunc(((t,a)=>{const i=na([e],r.rank);let o=r;null!=i&&(o=ia(r,i));const l=ra(1,r.rank)[0];let u=t.cumsum(o,l,n,s);if(a([r]),null!=i){const t=sa(i);u=ia(u,t)}return u}),a,null,jt,i)}}),Vu={kernelName:jt,inputsToSave:["x"],gradFunc:(t,e,n)=>{const[s]=e,{axis:r,exclusive:a,reverse:i}=n;return{x:()=>{const e=na([r],s.rank);let n=Wu(t,r,a,!i);return null!=e&&(n=ia(n,e)),n}}}},Uu={kernelName:qt,inputsToSave:["x","filter"],gradFunc:(t,e,n)=>{const{dilations:s,strides:r,pad:a,dimRoundingMode:i}=n,o=null==s?[1,1]:s;A(wa(o),(()=>`Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '${o}'`));const[l,u]=e;return A(4===l.rank,(()=>`Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ${l.rank}.`)),A(4===u.rank,(()=>`Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ${u.rank}.`)),A(l.shape[3]===u.shape[2],(()=>`Error in gradient of depthwiseConv2d: number of input channels (${l.shape[3]}) must match the inChannels dimension in filter ${u.shape[2]}.`)),A(va(r,o),(()=>`Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ${r} and dilations '${o}'.`)),null!=i&&A(M(a),(()=>`Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${a}.`)),{x:()=>Ao(l.shape,t,u,r,a,s,i),filter:()=>Eo(l,t,u.shape,r,a,s,i)}}},Gu={kernelName:Yt,inputsToSave:["x","filter"],gradFunc:(t,e,n)=>{const[s,r]=e,a={x:s,filter:r,dy:t},i={x:s,filter:r,dy:t};return{x:()=>fs.runKernel(Jt,a,n),filter:()=>fs.runKernel(Zt,i,n)}}},Hu={kernelName:Qt,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e,r=Xa(n.shape,s.shape);return{a:()=>{const e=Ha(t,or(s,"float32")),a=Ka(n.shape,r);return a.length>0?aa(yi(e,a),n.shape):e},b:()=>{let e=pi(t,or(n,"float32"));const a=Ka(s.shape,r);a.length>0&&(e=aa(yi(e,a),s.shape));const i=Ti(s);return Ei(Ha(e,or(i,"float32")))}}}},ju={kernelName:te,outputsToSave:[!0],gradFunc:(t,e)=>{const[n]=e,s=e=>e.eluDer(t,n),r={dy:t,y:n};return{x:()=>fs.runKernelFunc(s,r,null,"EluGrad")}}},qu={kernelName:ee,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e,s=pi(Ja(Ei(Ti(n))),2/Math.sqrt(Math.PI));return{x:()=>pi(t,s)}}},Ku={kernelName:ne,outputsToSave:[!0],gradFunc:(t,e)=>{const[n]=e;return{x:()=>pi(t,n)}}},Xu={kernelName:se,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>pi(t,Ja(n))}}},Yu={kernelName:oe,gradFunc:t=>({x:()=>_i(t)})},Ju={kernelName:le,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e,r=Xa(n.shape,s.shape);return{a:()=>{const e=Ha(t,or(s,"float32")),a=Ka(n.shape,r);return a.length>0?aa(yi(e,a),n.shape):e},b:()=>{let e=pi(t,or(n,"float32"));const a=Ka(s.shape,r);a.length>0&&(e=aa(yi(e,a),s.shape));const i=Ti(s);return Ei(Ha(e,or(i,"float32")))}}}},Zu=Ns({rsqrt_:function(t){const e=vs(t,"x","rsqrt"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.rsqrt(e);return n([e]),s}),n,null,Ye)}}),Qu={kernelName:ue,inputsToSave:["x","mean","variance","scale"],gradFunc:(t,e,n)=>{const{varianceEpsilon:s}=n,[r,a,i,o]=e,l=null==o?qr(1):o,u=Ka(a.shape,r.shape),c=[];if(1===a.rank){for(let t=0;t<r.shape.length-1;++t)c.push(r.shape[t]);c.push(1)}const h=gi(r,a),p=pi(t,l),d=Zu(Yr(i,qr(s))),f=pi(pi(pi(d,d),d),qr(-.5));return{x:()=>1===a.rank?aa(pi(pi(t,Qa(aa(d,[1,1,1,a.shape[0]]),c)),l),r.shape):aa(pi(pi(t,d),l),r.shape),mean:()=>{let t=pi(pi(d,qr(-1)),p);return 1===a.rank&&(t=yi(t,u)),aa(t,a.shape)},variance:()=>{let t=pi(pi(f,h),p);return 1===a.rank&&(t=yi(t,u)),aa(t,a.shape)},scale:()=>{const e=pi(h,d);let n=pi(t,e);return 1===a.rank&&(n=yi(n,u)),aa(n,a.shape)},offset:()=>{let e=t;return 1===a.rank&&(e=yi(e,u)),aa(e,a.shape)}}}},tc=Ns({unsortedSegmentSum_:function(t,e,n){const s=vs(t,"x","unsortedSegmentSum"),r=vs(e,"segmentIds","unsortedSegmentSum","int32");A(M(n),(()=>"numSegments must be of dtype int"));const a={x:s,segmentIds:r},i={numSegments:n};return fs.runKernelFunc(((t,e)=>{const a=t.unsortedSegmentSum(s,r,n);return e([r]),a}),a,null,xn,i)}}),ec={kernelName:ce,inputsToSave:["x","indices"],gradFunc:(t,e,n)=>{const[s,r]=e,{axis:a}=n,i=W(a,s.shape)[0];return{x:()=>{const e=s.shape,n=r.size,o=e.slice(0,i),l=o.length,u=e.slice(a,e.length).slice(1),c=u.length,h=nc(0,l),p=nc(l+1,l+1+c),d=sc([o,[n],u]),f=aa(t,d),m=aa(r,[n]),g=sc([[l],h,p]),y=ia(f,g);let b=tc(y,m,s.shape[i]);const x=sa(g);return b=ia(b,x),b},indices:()=>r}}};function nc(t,e){const n=[];for(let s=t;s<e;++s)n.push(s);return n}function sc(t){const e=[];for(let n=0;n<t.length;++n)for(let s=0;s<t[n].length;++s)e.push(t[n][s]);return e}const rc={kernelName:he,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e;return{a:()=>_i(n),b:()=>_i(s)}}},ac={kernelName:pe,gradFunc:t=>({x:()=>or(t,"float32")})},ic={kernelName:me,gradFunc:t=>({x:()=>_i(t)})},oc={kernelName:ge,gradFunc:t=>({x:()=>_i(t)})},lc={kernelName:ye,gradFunc:t=>({x:()=>_i(t)})},uc={kernelName:xe,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Ha(t,Yr(n,1))}}},cc={kernelName:be,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Ha(t,or(n,"float32"))}}},hc={kernelName:ve,inputsToSave:[],outputsToSave:[!0],gradFunc:(t,e,n)=>{const[s]=e,{axis:r}=n;return{logits:()=>{const e=Ja(s);return gi(t,pi(yi(t,r,!0),e))}}}},pc=Ns({localResponseNormalizationBackprop_:function(t,e,n,s=5,r=1,a=1,i=.5){const o={x:t,y:e,dy:n},l={depthRadius:s,bias:r,alpha:a,beta:i};return fs.runKernelFunc((o=>o.LRNGrad(n,t,e,s,r,a,i)),o,null,"LRNBackprop",l)}}),dc={kernelName:"LRN",inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,n)=>{const[s,r]=e,{depthRadius:a,bias:i,alpha:o,beta:l}=n;return{x:()=>pc(s,r,t,a,i,o,l)}}};function fc(t,e,n,s){return e.rank<n.rank&&(e=aa(e,ta(e.shape,s))),t.rank<n.rank&&(t=aa(t,ta(t.shape,s))),{x:()=>pi(t,or(Ya(n,e),t.dtype))}}const mc={kernelName:ke,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,n)=>{const s=n,{reductionIndices:r}=s,a=e[0],i=fc(t,e[1],a,W(r,a.shape));return{x:()=>i.x()}}},gc=Ns({less_:function(t,e){let n=vs(t,"a","less"),s=vs(e,"b","less");[n,s]=os(n,s),Xa(n.shape,s.shape);const r={a:n,b:s};return fs.runKernelFunc((t=>t.less(n,s)),r,null,"Less")}}),yc={kernelName:Ne,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e;return{a:()=>pi(t,or(ci(n,s),"float32")),b:()=>pi(t,or(gc(n,s),"float32"))}}},bc=Ns({maxPool3dBackprop_:function(t,e,n,s,r,a=[1,1,1],i,o){const l=vs(t,"dy","maxPool3dBackprop"),u=vs(e,"input","maxPool3dBackprop"),c=vs(n,"output","maxPool3dBackprop");let h=l,p=u,d=c,f=!1;4===u.rank&&(f=!0,h=aa(l,[1,l.shape[0],l.shape[1],l.shape[2],l.shape[3]]),p=aa(u,[1,u.shape[0],u.shape[1],u.shape[2],u.shape[3]]),d=aa(c,[1,c.shape[0],c.shape[1],c.shape[2],c.shape[3]])),A(5===h.rank,(()=>"Error in maxPool3dBackprop: dy must be rank 5 but got rank "+h.rank+".")),A(5===p.rank,(()=>"Error in maxPool3dBackprop: input must be rank 5 but got rank "+p.rank+".")),A(5===d.rank,(()=>"Error in maxPool3dBackprop: output must be rank 5 but got rank "+d.rank+".")),A(va(r,a),(()=>`Error in maxPool3dBackprop: Either strides or dilations must be 1. Got strides ${r} and dilations '${a}'`)),null!=o&&A(M(i),(()=>`Error in maxPool3dBackprop: pad must be an integer when using, dimRoundingMode ${o} but got pad ${i}.`));const m={dy:h,input:p,output:d},g={filterSize:s,strides:r,dilations:a,pad:i,dimRoundingMode:o},y=fs.runKernelFunc((t=>{const e=pa(p.shape,s,r,a,i,o);return t.maxPool3dBackprop(h,p,d,e)}),m,null,"MaxPool3DBackprop",g);return f?aa(y,[y.shape[1],y.shape[2],y.shape[3],y.shape[4]]):y}}),xc={kernelName:Se,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,n)=>{const[s,r]=e,{filterSize:a,strides:i,dilations:o,pad:l,dimRoundingMode:u}=n,c=null==o?[1,1,1]:o;return{x:()=>bc(t,s,r,a,i,c,l,u)}}},wc=Ns({maxPoolBackprop_:function(t,e,n,s,r,a,i){const o=vs(t,"dy","maxPoolBackprop"),l=vs(e,"input","maxPoolBackprop"),u=vs(n,"output","maxPoolBackprop");A(l.rank===o.rank,(()=>`Rank of input (${l.rank}) does not match rank of dy (${o.rank})`)),A(4===o.rank,(()=>"Error in maxPoolBackprop: dy must be rank 4 but got rank "+o.rank+".")),A(4===l.rank,(()=>"Error in maxPoolBackprop: input must be rank 4 but got rank "+l.rank+".")),null!=i&&A(M(a),(()=>`Error in maxPoolBackprop: pad must be an integer when using, dimRoundingMode ${i} but got pad ${a}.`));const c={dy:o,input:l,output:u},h={filterSize:s,strides:r,pad:a,dimRoundingMode:i};return fs.runKernelFunc((t=>{const e=ha(l.shape,s,r,1,a,i);return t.maxPoolBackprop(o,l,u,e)}),c,null,Ce,h)}}),vc={kernelName:Ie,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,n)=>{const[s,r]=e,{filterSize:a,strides:i,pad:o}=n;return{x:()=>wc(t,s,r,a,i,o)}}},kc={kernelName:"Min",inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,n)=>{const s=n,{axis:r}=s,[a,i]=e,o=fc(t,i,a,W(r,a.shape));return{x:()=>o.x()}}},Nc={kernelName:Ee,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e;return{a:()=>pi(t,or(el(n,s),"float32")),b:()=>pi(t,or(ui(n,s),"float32"))}}},Ic={kernelName:Ae,inputsToSave:["x"],gradFunc:(t,e,n)=>{const s=e[0],{paddings:r}=n,a=r.map((t=>t[0]));return{x:()=>Yi(t,a,s.shape)}}},Cc={kernelName:"Mod",inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e,r=Xa(n.shape,s.shape);return{a:()=>{const e=Ka(n.shape,r);return e.length>0?aa(yi(t,e),n.shape):t},b:()=>{const e=pi(t,Ei(ni(Ha(n,s)))),a=Ka(s.shape,r);return a.length>0?aa(yi(e,a),s.shape):e}}}},Sc={kernelName:Re,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e,r=Xa(n.shape,s.shape);return{a:()=>{const e=pi(t,or(s,"float32")),a=Ka(n.shape,r);return a.length>0?aa(yi(e,a),n.shape):e},b:()=>{const e=pi(t,or(n,"float32")),a=Ka(s.shape,r);return a.length>0?aa(yi(e,a),s.shape):e}}}},Tc={kernelName:De,gradFunc:t=>({x:()=>Ei(t)})},$c={kernelName:ze,inputsToSave:["indices"],gradFunc:(t,e)=>{const n=e[0];return{indices:()=>ki(n.shape,"float32")}}},Ec={kernelName:Le,gradFunc:t=>({x:()=>_i(t)})},Ac={kernelName:Be,inputsToSave:["x"],gradFunc:(t,e,n)=>{const s=e[0],{paddings:r}=n,a=r.map((t=>t[0]));return{x:()=>Yi(t,a,s.shape)}}},Rc={kernelName:"Pow",inputsToSave:["a","b"],outputsToSave:[!0],gradFunc:(t,e)=>{const[n,s,r]=e,a=n,i=s,o=Xa(a.shape,i.shape);return{a:()=>{const e=or(i,"float32");let n=pi(t,pi(e,sl(a,gi(e,qr(1)))));const s=Ka(a.shape,o);return s.length>0&&(n=yi(n,s)),aa(n,a.shape)},b:()=>{const e=ui(a,0),n=mo(e,fi(a),_i(a));let s=pi(t,pi(r,n));const l=Ka(i.shape,o);return l.length>0&&(s=yi(s,l)),aa(s,i.shape)}}}},Dc={kernelName:Pe,inputsToSave:["x","alpha"],gradFunc:(t,e)=>{const[n,s]=e,r=ui(n,0);return{x:()=>mo(r,t,pi(t,s)),alpha:()=>{let e=mo(r,_i(t),pi(t,n));const a=Ka(s.shape,t.shape);return a.length>0&&(e=yi(e,a)),aa(e,s.shape)}}}},Fc={kernelName:Ve,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Ha(t,Ei(Ti(n)))}}},_c={kernelName:qe,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e,s=pi(el(n,6),No(n));return{x:()=>pi(t,or(s,"float32"))}}},Oc={kernelName:Ue,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>pi(t,or(No(n),"float32"))}}},Mc={kernelName:Ge,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>aa(t,n.shape)}}},Lc={kernelName:je,inputsToSave:["images"],gradFunc:(t,e,n)=>{const[s]=e,r=e=>{const{alignCorners:r}=n;return e.resizeBilinearBackprop(t,s,r)},a={images:s};return{images:()=>fs.runKernelFunc(r,a,null,"ResizeBilinearGrad",n)}}},zc={kernelName:He,inputsToSave:["images"],gradFunc:(t,e,n)=>{const[s]=e,r=e=>{const{alignCorners:r}=n;return e.resizeNearestNeighborBackprop(t,s,r)},a={images:s};return{images:()=>fs.runKernelFunc(r,a,null,"ResizeNearestNeighborGrad",n)}}},Bc={kernelName:Ke,gradFunc:(t,e,n)=>{const{dims:s}=n,r=W(s,t.shape);return{x:()=>ji(t,r)}}},Pc={kernelName:Xe,gradFunc:t=>({x:()=>_i(t)})},Wc={kernelName:Ye,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Ei(Ha(t,pi(sl(n,1.5),2)))}}},Vc=Ns({logicalNot_:function(t){const e=vs(t,"x","logicalNot","bool"),n={x:e};return fs.runKernelFunc((t=>t.logicalNot(e)),n,null,we)}}),Uc={kernelName:Je,inputsToSave:["condition"],gradFunc:(t,e)=>{const[n]=e;return{condition:()=>or(_i(n),"float32"),t:()=>pi(t,or(n,t.dtype)),e:()=>pi(t,or(Vc(n),t.dtype))}}},Gc={kernelName:Ze,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>{const e=ui(n,qr(0)),s=qr(Ll),r=qr(zl),a=pi(t,r),i=pi(pi(t,s),Ja(or(n,"float32")));return mo(e,a,i)}}}},Hc={kernelName:sn,outputsToSave:[!0],gradFunc:(t,e)=>{const[n]=e;return{x:()=>pi(t,pi(n,gi(qr(1),n)))}}},jc={kernelName:nn,gradFunc:t=>({x:()=>_i(t)})},qc=Ns({cos_:function(t){const e=vs(t,"x","cos"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.cos(e);return n([e]),s}),n,null,Gt)}}),Kc={kernelName:tn,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>pi(qc(or(n,"float32")),t)}}},Xc=Ns({cosh_:function(t){const e=vs(t,"x","cosh"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.cosh(e);return n([e]),s}),n,null,Ht)}}),Yc={kernelName:en,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>pi(Xc(or(n,"float32")),t)}}},Jc={kernelName:Qe,inputsToSave:["x"],gradFunc:(t,e,n)=>{const[s]=e,{begin:r,size:a}=n,i=s.shape,[o,l]=_r(s,r,a),u=[];for(let e=0;e<t.rank;e++)u.push([o[e],i[e]-o[e]-l[e]]);return{x:()=>Mi(t,u)}}},Zc={kernelName:un,outputsToSave:[!0],gradFunc:(t,e,n)=>{const[s]=e,{dim:r}=n,a=pi(t,s);return{logits:()=>gi(a,pi(yi(a,[r],!0),s))}}},Qc={kernelName:rn,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>pi(t,Xi(n))}}},th=Ns({batchToSpaceND_:function(t,e,n){const s=vs(t,"x","batchToSpaceND"),r=e.reduce(((t,e)=>t*e));A(s.rank>=1+e.length,(()=>`input rank is ${s.rank} but should be > than blockShape.length ${e.length}`)),A(n.length===e.length,(()=>`crops.length is ${n.length} but should be equal to blockShape.length  ${e.length}`)),A(s.shape[0]%r==0,(()=>`input tensor batch is ${s.shape[0]} but is not divisible by the product of the elements of blockShape ${e.join(" * ")} === ${r}`));const a={x:s},i={blockShape:e,crops:n};return fs.runKernelFunc((t=>t.batchToSpaceND(s,e,n)),a,null,Rt,i)}}),eh={kernelName:on,gradFunc:(t,e,n)=>{const{blockShape:s,paddings:r}=n;return{x:()=>th(t,s,r)}}},nh={kernelName:ln,gradFunc:(t,e,n)=>{const{axis:s}=n;return{x:()=>Fa(t,s)}}},sh=[lu,uu,cu,hu,pu,du,fu,mu,gu,yu,bu,xu,vu,Nu,Iu,Su,Tu,$u,Eu,Au,Ru,Fu,Du,Mu,zu,Pu,Vu,Uu,Gu,Hu,ju,qu,Ku,Xu,Ju,Yu,Qu,ec,rc,ac,ic,oc,lc,uc,cc,hc,dc,mc,mc,yc,xc,vc,kc,Nc,Ic,Cc,Sc,Tc,$c,Ec,Ac,Ac,Rc,Dc,Fc,_c,Oc,Mc,Lc,zc,Bc,Pc,Wc,Uc,Gc,Hc,jc,Kc,Yc,Jc,Zc,Qc,eh,eh,nh,nh,{kernelName:an,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Ha(t,pi(ao(or(n,"float32")),2))}}},{kernelName:cn,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e,r=qr(2);return{a:()=>pi(t,pi(r,gi(n,s))),b:()=>pi(t,pi(r,gi(s,n)))}}},{kernelName:hn,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>pi(t,pi(or(n,"float32"),2))}}},{kernelName:vn,gradFunc:t=>({x:()=>_i(t)})},{kernelName:pn,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e,r=Xa(n.shape,s.shape);return{a:()=>{let e=t;const s=Ka(n.shape,r);return s.length>0&&(e=yi(e,s)),aa(e,n.shape)},b:()=>{let e=t;const n=Ka(s.shape,r);return n.length>0&&(e=yi(e,n)),aa(Ei(e),s.shape)}}}},{kernelName:"Sum",inputsToSave:["x"],gradFunc:(t,e,n)=>{const[s]=e,r=s.shape.slice(),{axis:a}=n;W(a,s.shape).forEach((t=>{r[t]=1}));const i=aa(t,r),o=pi(i,Ni(s.shape,"float32"));return{x:()=>o}}},{kernelName:dn,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Ha(t,Ti(qc(n)))}}},{kernelName:fn,outputsToSave:[!0],gradFunc:(t,e)=>{const[n]=e;return{x:()=>pi(gi(qr(1),Ti(n)),t)}}},{kernelName:mn,inputsToSave:["x"],gradFunc:(t,e,n)=>{const[s]=e,{reps:r}=n;return{x:()=>{let e=_i(s);if(1===s.rank)for(let n=0;n<r[0];++n)e=Yr(e,Yi(t,[n*s.shape[0]],[s.shape[0]]));else if(2===s.rank)for(let n=0;n<r[0];++n)for(let a=0;a<r[1];++a)e=Yr(e,Yi(t,[n*s.shape[0],a*s.shape[1]],[s.shape[0],s.shape[1]]));else if(3===s.rank)for(let n=0;n<r[0];++n)for(let a=0;a<r[1];++a)for(let i=0;i<r[2];++i)e=Yr(e,Yi(t,[n*s.shape[0],a*s.shape[1],i*s.shape[2]],[s.shape[0],s.shape[1],s.shape[2]]));else{if(4!==s.rank)throw new Error("Gradient for tile operation is not implemented for rank-"+s.rank+" tensors yet.");for(let n=0;n<r[0];++n)for(let a=0;a<r[1];++a)for(let i=0;i<r[2];++i)for(let o=0;o<r[3];++o)e=Yr(e,Yi(t,[n*s.shape[0],a*s.shape[1],i*s.shape[2],o*s.shape[3]],[s.shape[0],s.shape[1],s.shape[2],s.shape[3]]))}return e}}}},{kernelName:gn,gradFunc:(t,e,n)=>{const s=n,{perm:r}=s,a=sa(r);return{x:()=>ia(t,a)}}},{kernelName:bn,gradFunc:(t,e,n)=>{const s=n,{axis:r}=s;return{value:()=>oo(t,r)}}},{kernelName:xn,inputsToSave:["segmentIds"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>function(t,e){const n=hi(e,_i(e)),s=li(t,n);let r=ci(e,qr(0,"int32"));const a=s.rank-r.rank;for(let t=0;t<a;++t)r=Za(r,t+1);r=xi(r,Ni(s.shape,"bool"));const i=_i(s);return mo(r,s,i)}(t,n)}}},{kernelName:wn,gradFunc:t=>({x:()=>_i(t)})}];for(const t of sh)Fn(t);Jn.prototype.abs=function(){return this.throwIfDisposed(),Xr(this)};const rh=Ns({acos_:function(t){const e=vs(t,"x","acos"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.acos(e);return n([e]),s}),n,null,gt)}});Jn.prototype.acos=function(){return this.throwIfDisposed(),rh(this)};const ah=Ns({acosh_:function(t){const e=vs(t,"x","acosh"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.acosh(e);return n([e]),s}),n,null,yt)}});Jn.prototype.acosh=function(){return this.throwIfDisposed(),ah(this)};const ih=Ns({mod_:function(t,e){let n=vs(t,"a","mod"),s=vs(e,"b","mod");[n,s]=os(n,s);const r={a:n,b:s};return fs.runKernelFunc(((t,e)=>{const r=t.mod(n,s);return e([n,s]),r}),r,null,"Mod")}}),oh=Ns({addStrict_:function(t,e){zr("strict variants of ops have been deprecated and will be removed in future");const n=vs(t,"a","addStrict"),s=vs(e,"b","addStrict");return R(n.shape,s.shape,"Error in addStrict: "),Yr(n,s)}}),lh=Ns({divStrict_:function(t,e){zr("strict variants of ops have been deprecated and will be removed in future");const n=vs(t,"a","div"),s=vs(e,"b","div");return R(n.shape,s.shape,"Error in divideStrict: "),Ha(n,s)}}),uh=Ns({maximumStrict_:function(t,e){zr("strict variants of ops have been deprecated and will be removed in future");const n=vs(t,"a","maximumStrict"),s=vs(e,"b","maximumStrict");return R(n.shape,s.shape,"Error in maximumStrict: "),hi(n,s)}}),ch=Ns({minimumStrict_:function(t,e){zr("strict variants of ops have been deprecated and will be removed in future");const n=vs(t,"a","minimumStrict"),s=vs(e,"b","minimumStrict");return R(n.shape,s.shape,"Error in minimumStrict: "),Si(n,s)}}),hh=Ns({modStrict_:function(t,e){zr("strict variants of ops have been deprecated and will be removed in future");const n=vs(t,"a","modStrict"),s=vs(e,"b","modStrict");return R(n.shape,s.shape,"Error in modStrict: "),ih(n,s)}}),ph=Ns({mulStrict_:function(t,e){zr("strict variants of ops have been deprecated and will be removed in future");const n=vs(t,"a","mul"),s=vs(e,"b","mul");return R(n.shape,s.shape,"Error in multiplyStrict: "),pi(n,s)}}),dh=Ns({powStrict_:function(t,e){return zr("strict variants of ops have been deprecated and will be removed in future"),R(t.shape,e.shape,"Error in powStrict: "),sl(t,e)}}),fh=Ns({squaredDifferenceStrict_:function(t,e){zr("strict variants of ops have been deprecated and will be removed in future");const n=vs(t,"a","squaredDifferenceStrict"),s=vs(e,"b","squaredDifferenceStrict");return R(n.shape,s.shape,"Error in squaredDifferenceStrict: "),hl(n,s)}}),mh=Ns({subStrict_:function(t,e){zr("strict variants of ops have been deprecated and will be removed in future");const n=vs(t,"a","subStrict"),s=vs(e,"b","subStrict");return R(n.shape,s.shape,"Error in subStrict: "),gi(n,s)}});Jn.prototype.addStrict=function(t){return this.throwIfDisposed(),oh(this,t)},Jn.prototype.add=function(t){return this.throwIfDisposed(),Yr(this,t)},Jn.prototype.all=function(t,e){return this.throwIfDisposed(),oa(this,t,e)},Jn.prototype.any=function(t,e){return this.throwIfDisposed(),la(this,t,e)},Jn.prototype.argMax=function(t){return this.throwIfDisposed(),ua(this,t)};const gh=Ns({argMin_:function(t,e=0){let n=vs(t,"x","argMin");const s={x:n},r={axis:e};return fs.runKernelFunc(((t,s)=>{s([n]),null==e&&(e=0);let r=W(e,n.shape);const a=na(r,n.rank);return null!=a&&(n=ia(n,a),r=ra(r.length,n.rank)),t.argMin(n,r[0])}),s,null,vt,r)}});Jn.prototype.argMin=function(t){return this.throwIfDisposed(),gh(this,t)},Jn.prototype.asScalar=function(){return this.throwIfDisposed(),A(1===this.size,(()=>"The array must have only 1 element.")),aa(this,[])},Jn.prototype.asType=function(t){return this.throwIfDisposed(),or(this,t)},Jn.prototype.as1D=function(){return this.throwIfDisposed(),aa(this,[this.size])},Jn.prototype.as2D=function(t,e){return this.throwIfDisposed(),aa(this,[t,e])},Jn.prototype.as3D=function(t,e,n){return this.throwIfDisposed(),aa(this,[t,e,n])},Jn.prototype.as4D=function(t,e,n,s){return this.throwIfDisposed(),aa(this,[t,e,n,s])},Jn.prototype.as5D=function(t,e,n,s,r){return this.throwIfDisposed(),aa(this,[t,e,n,s,r])};const yh=Ns({asin_:function(t){const e=vs(t,"x","asin"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.asin(e);return n([e]),s}),n,null,kt)}});Jn.prototype.asin=function(){return this.throwIfDisposed(),yh(this)};const bh=Ns({asinh_:function(t){const e=vs(t,"x","asinh"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.asinh(e);return n([e]),s}),n,null,Nt)}});Jn.prototype.asinh=function(){return this.throwIfDisposed(),bh(this)};const xh=Ns({atan_:function(t){const e=vs(t,"x","atan"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.atan(e);return n([e]),s}),n,null,It)}});Jn.prototype.atan=function(){return this.throwIfDisposed(),xh(this)};const wh=Ns({atan2_:function(t,e){let n=vs(t,"a","atan2"),s=vs(e,"b","atan2");[n,s]=os(n,s);const r={a:n,b:s};return fs.runKernelFunc(((t,e)=>{const r=t.atan2(n,s);return e([n,s]),r}),r,null,St)}});Jn.prototype.atan2=function(t){return this.throwIfDisposed(),wh(this,t)};const vh=Ns({atanh_:function(t){const e=vs(t,"x","atanh"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.atanh(e);return n([e]),s}),n,null,Ct)}});Jn.prototype.atanh=function(){return this.throwIfDisposed(),vh(this)},Jn.prototype.avgPool=function(t,e,n,s){return this.throwIfDisposed(),Na(this,t,e,n,s)},Jn.prototype.batchToSpaceND=function(t,e){return this.throwIfDisposed(),th(this,t,e)},Jn.prototype.batchNorm=function(t,e,n,s,r){return this.throwIfDisposed(),Sa(this,t,e,n,s,r)},Jn.prototype.broadcastTo=function(t){return this.throwIfDisposed(),fo(this,t)},Jn.prototype.cast=function(t){return this.throwIfDisposed(),or(this,t)};const kh=Ns({ceil_:function(t){const e=vs(t,"x","ceil"),n={x:e};return fs.runKernelFunc((t=>t.ceil(e)),n,null,_t)}});Jn.prototype.ceil=function(){return this.throwIfDisposed(),kh(this)},Jn.prototype.clipByValue=function(t,e){return this.throwIfDisposed(),Aa(this,t,e)},Jn.prototype.concat=function(t,e){return this.throwIfDisposed(),t instanceof Jn&&(t=[t]),Fa([this,...t],e)},Jn.prototype.conv1d=function(t,e,n,s,r,a){return this.throwIfDisposed(),Ba(this,t,e,n,s,r,a)},Jn.prototype.conv2dTranspose=function(t,e,n,s,r){return this.throwIfDisposed(),Wa(this,t,e,n,s,r)},Jn.prototype.conv2d=function(t,e,n,s,r,a){return this.throwIfDisposed(),za(this,t,e,n,s,r,a)},Jn.prototype.cos=function(){return this.throwIfDisposed(),qc(this)},Jn.prototype.cosh=function(){return this.throwIfDisposed(),Xc(this)},Jn.prototype.cumsum=function(t,e,n){return this.throwIfDisposed(),Wu(this,t,e,n)};const Nh=Ns({depthToSpace_:function(t,e,n="NHWC"){const s=vs(t,"x","depthToSpace"),r="NHWC"===n?s.shape[1]:s.shape[2],a="NHWC"===n?s.shape[2]:s.shape[3],i="NHWC"===n?s.shape[3]:s.shape[1];A(r*e>=0,(()=>`Negative dimension size caused by overflow when multiplying\n    ${r} and ${e}  for depthToSpace with input shape\n    ${s.shape}`)),A(a*e>=0,(()=>`Negative dimension size caused by overflow when multiplying\n    ${a} and ${e} for depthToSpace with input shape\n        ${s.shape}`)),A(i%(e*e)==0,(()=>`Dimension size must be evenly divisible by ${e*e} but is ${i} for depthToSpace with input shape ${s.shape}`));const o={x:s},l={blockSize:e,dataFormat:n};return fs.runKernelFunc((t=>t.depthToSpace(s,e,n)),o,null,"DepthToSpace",l)}});Jn.prototype.depthToSpace=function(t,e){return this.throwIfDisposed(),Nh(this,t,e)},Jn.prototype.depthwiseConv2D=function(t,e,n,s,r,a){return zr("depthwiseConv2D is deprecated, use depthwiseConv2d instead"),this.throwIfDisposed(),Ua(this,t,e,n,s,r,a)},Jn.prototype.depthwiseConv2d=function(t,e,n,s,r,a){return this.throwIfDisposed(),Ua(this,t,e,n,s,r,a)};const Ih=Ns({dilation2d_:function(t,e,n,s,r=[1,1],a="NHWC"){const i=vs(t,"x","dilation2d"),o=vs(e,"filter","dilation2d");A(3===i.rank||4===i.rank,(()=>"Error in dilation2d: input must be rank 3 or 4, but got rank "+i.rank+".")),A(3===o.rank,(()=>"Error in dilation2d: filter must be rank 3, but got rank "+o.rank+".")),A("NHWC"===a,(()=>"Error in dilation2d: Only NHWC is currently supported, but got dataFormat of "+a));let l=i,u=!1;3===i.rank&&(l=aa(i,[1,i.shape[0],i.shape[1],i.shape[2]]),u=!0);const c={x:l,filter:o},h={strides:n,pad:s,dilations:r},p=fs.runKernel(Yt,c,h);return u?aa(p,[p.shape[1],p.shape[2],p.shape[3]]):p}});Jn.prototype.dilation2d=function(t,e,n,s,r){return this.throwIfDisposed(),Ih(this,t,e,n,s,r)};const Ch=Ns({divNoNan_:function(t,e){let n=vs(t,"a","div"),s=vs(e,"b","div");[n,s]=os(n,s);const r=Ha(n,s),a=_i(r),i=Ya(s,a);return mo(i,a,r)}});Jn.prototype.divNoNan=function(t){return this.throwIfDisposed(),Ch(this,t)},Jn.prototype.divStrict=function(t){return this.throwIfDisposed(),lh(this,t)},Jn.prototype.div=function(t){return this.throwIfDisposed(),Ha(this,t)};const Sh=Ns({dot_:function(t,e){const n=vs(t,"t1","dot"),s=vs(e,"t2","dot");A(!(1!==n.rank&&2!==n.rank||1!==s.rank&&2!==s.rank),(()=>`Error in dot: inputs must all be rank 1 or 2, but got ranks ${n.rank} and ${s.rank}.`));const r=1===n.rank?n.size:n.shape[1],a=1===s.rank?s.size:s.shape[0];if(A(r===a,(()=>`Error in dot: inner dimensions of inputs must match, but got ${r} and ${a}.`)),1===n.rank&&1===s.rank){const t=aa(n,[1,-1]),e=aa(s,[-1,1]),r=Do(t,e);return aa(r,[])}if(1===n.rank&&2===s.rank){const t=aa(n,[1,-1]),e=aa(s,[s.shape[0],s.shape[1]]),r=Do(t,e);return aa(r,[r.size])}if(2===n.rank&&1===s.rank){const t=aa(s,[-1,1]),e=Do(n,t);return aa(e,[e.size])}{const t=aa(s,[s.shape[0],s.shape[1]]);return Do(n,t)}}});Jn.prototype.dot=function(t){return this.throwIfDisposed(),Sh(this,t)},Jn.prototype.elu=function(){return this.throwIfDisposed(),ja(this)};const Th=Ns({equalStrict_:function(t,e){zr("strict variants of ops have been deprecated and will be removed in future");const n=vs(t,"a","equalStrict"),s=vs(e,"b","equalStrict");return R(n.shape,s.shape,"Error in equalStrict: "),Ya(n,s)}}),$h=Ns({greaterEqualStrict_:function(t,e){zr("strict variants of ops have been deprecated and will be removed in future");const n=vs(t,"a","greaterEqualStrict"),s=vs(e,"b","greaterEqualStrict");return R(n.shape,s.shape,"Error in greaterEqualStrict: "),ci(n,s)}}),Eh=Ns({greaterStrict_:function(t,e){zr("strict variants of ops have been deprecated and will be removed in future");const n=vs(t,"a","greaterStrict"),s=vs(e,"b","greaterStrict");return R(n.shape,s.shape,"Error in greaterStrict: "),ui(n,s)}}),Ah=Ns({lessEqualStrict_:function(t,e){zr("strict variants of ops have been deprecated and will be removed in future");const n=vs(t,"a","lessEqualStrict"),s=vs(e,"b","lessEqualStrict");return R(n.shape,s.shape,"Error in lessEqualStrict: "),el(n,s)}}),Rh=Ns({lessStrict_:function(t,e){zr("strict variants of ops have been deprecated and will be removed in future");const n=vs(t,"a","lessStrict"),s=vs(e,"b","lessStrict");return R(n.shape,s.shape,"Error in lessStrict: "),gc(n,s)}}),Dh=Ns({notEqualStrict_:function(t,e){zr("strict variants of ops have been deprecated and will be removed in future");const n=vs(t,"a","notEqualStrict"),s=vs(e,"b","notEqualStrict");return R(n.shape,s.shape,"Error in notEqualStrict: "),Ai(n,s)}});Jn.prototype.equalStrict=function(t){return this.throwIfDisposed(),Th(this,t)},Jn.prototype.equal=function(t){return this.throwIfDisposed(),Ya(this,t)};const Fh=Ns({erf_:function(t){let e=vs(t,"x","erf");A("int32"===e.dtype||"float32"===e.dtype,(()=>"Input dtype must be `int32` or `float32`.")),"int32"===e.dtype&&(e=or(e,"float32"));const n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.erf(e);return n([e]),s}),n,null,ee)}});Jn.prototype.erf=function(){return this.throwIfDisposed(),Fh(this)},Jn.prototype.exp=function(){return this.throwIfDisposed(),Ja(this)},Jn.prototype.expandDims=function(t){return this.throwIfDisposed(),Za(this,t)};const _h=Ns({expm1_:function(t){const e=vs(t,"x","expm1"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.expm1(e);return n([e]),s}),n,null,se)}});Jn.prototype.expm1=function(){return this.throwIfDisposed(),_h(this)},Jn.prototype.fft=function(){return this.throwIfDisposed(),yo(this)},Jn.prototype.flatten=function(){return this.throwIfDisposed(),aa(this,[this.size])},Jn.prototype.floor=function(){return this.throwIfDisposed(),ni(this)},Jn.prototype.floorDiv=function(t){return this.throwIfDisposed(),Ga(this,t)},Jn.prototype.gather=function(t,e){return this.throwIfDisposed(),li(this,t,e)},Jn.prototype.greaterEqualStrict=function(t){return this.throwIfDisposed(),$h(this,t)},Jn.prototype.greaterEqual=function(t){return this.throwIfDisposed(),ci(this,t)},Jn.prototype.greaterStrict=function(t){return this.throwIfDisposed(),Eh(this,t)},Jn.prototype.greater=function(t){return this.throwIfDisposed(),ui(this,t)},Jn.prototype.ifft=function(){return this.throwIfDisposed(),xo(this)},Jn.prototype.irfft=function(){return this.throwIfDisposed(),wo(this)};const Oh=Ns({isFinite_:function(t){const e=vs(t,"x","isFinite"),n={x:e};return fs.runKernelFunc((t=>t.isFinite(e)),n,null,me)}});Jn.prototype.isFinite=function(){return this.throwIfDisposed(),Oh(this)};const Mh=Ns({isInf_:function(t){const e=vs(t,"x","isInf"),n={x:e};return fs.runKernelFunc((t=>t.isInf(e)),n,null,ge)}});Jn.prototype.isInf=function(){return this.throwIfDisposed(),Mh(this)};const Lh=Ns({isNaN_:function(t){const e=vs(t,"x","isNaN"),n={x:e};return fs.runKernelFunc((t=>t.isNaN(e)),n,null,ye)}});Jn.prototype.isNaN=function(){return this.throwIfDisposed(),Lh(this)},Jn.prototype.leakyRelu=function(t){return this.throwIfDisposed(),di(this,t)},Jn.prototype.lessEqualStrict=function(t){return this.throwIfDisposed(),Ah(this,t)},Jn.prototype.lessEqual=function(t){return this.throwIfDisposed(),el(this,t)},Jn.prototype.lessStrict=function(t){return this.throwIfDisposed(),Rh(this,t)},Jn.prototype.less=function(t){return this.throwIfDisposed(),gc(this,t)};const zh=Ns({localResponseNormalization_:function(t,e=5,n=1,s=1,r=.5){const a=vs(t,"x","localResponseNormalization");A(4===a.rank||3===a.rank,(()=>`Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ${a.rank}.`)),A(M(e),(()=>`Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${e}.`));let i=a,o=!1;3===a.rank&&(o=!0,i=aa(a,[1,a.shape[0],a.shape[1],a.shape[2]]));const l={x:i},u={depthRadius:e,bias:n,alpha:s,beta:r},c=fs.runKernelFunc(((t,a)=>{const o=t.localResponseNormalization4D(i,e,n,s,r);return a([i,o]),o}),l,null,"LRN",u);return o?aa(c,[c.shape[1],c.shape[2],c.shape[3]]):c}});Jn.prototype.localResponseNormalization=function(t,e,n,s){return this.throwIfDisposed(),zh(this,t,e,n,s)};const Bh=Ns({logSigmoid_:function(t){const e=vs(t,"x","logSigmoid");return jr((t=>({value:Ei(no(Ei(t))),gradFunc:e=>pi(e,Xi(Ei(t)))})))(e)}});Jn.prototype.logSigmoid=function(){return this.throwIfDisposed(),Bh(this)},Jn.prototype.logSoftmax=function(t){return this.throwIfDisposed(),bi(this,t)},Jn.prototype.logSumExp=function(t,e){return this.throwIfDisposed(),dl(this,t,e)},Jn.prototype.log=function(){return this.throwIfDisposed(),fi(this)},Jn.prototype.log1p=function(){return this.throwIfDisposed(),pl(this)},Jn.prototype.logicalAnd=function(t){return this.throwIfDisposed(),xi(this,t)},Jn.prototype.logicalNot=function(){return this.throwIfDisposed(),Vc(this)};const Ph=Ns({logicalOr_:function(t,e){const n=vs(t,"a","logicalOr","bool"),s=vs(e,"b","logicalOr","bool");Xa(n.shape,s.shape);const r={a:n,b:s};return fs.runKernelFunc((t=>t.logicalOr(n,s)),r,null,"LogicalOr")}});Jn.prototype.logicalOr=function(t){return this.throwIfDisposed(),Ph(this,t)};const Wh=Ns({logicalXor_:function(t,e){const n=vs(t,"a","logicalXor","bool"),s=vs(e,"b","logicalXor","bool");return Xa(n.shape,s.shape),xi(Ph(t,e),Vc(xi(t,e)))}});Jn.prototype.logicalXor=function(t){return this.throwIfDisposed(),Wh(this,t)},Jn.prototype.matMul=function(t,e,n){return this.throwIfDisposed(),Do(this,t,e,n)},Jn.prototype.maxPool=function(t,e,n,s){return this.throwIfDisposed(),wi(this,t,e,n,s)},Jn.prototype.max=function(t,e){return this.throwIfDisposed(),mi(this,t,e)},Jn.prototype.maximumStrict=function(t){return this.throwIfDisposed(),uh(this,t)},Jn.prototype.maximum=function(t){return this.throwIfDisposed(),hi(this,t)},Jn.prototype.mean=function(t,e){return this.throwIfDisposed(),Ii(this,t,e)},Jn.prototype.min=function(t,e){return this.throwIfDisposed(),Ci(this,t,e)},Jn.prototype.minimumStrict=function(t){return this.throwIfDisposed(),ch(this,t)},Jn.prototype.minimum=function(t){return this.throwIfDisposed(),Si(this,t)};const Vh=Ns({mirrorPad_:function(t,e,n){A("reflect"===n||"symmetric"===n,(()=>`Invalid mode. Mode must be either reflect or symmetric. Got ${n}.`));const s=vs(t,"x","mirrorPad");if(0===s.rank)throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");A(e.length===s.rank,(()=>`Padding doesn't match input. Must be ${s.rank}. Got ${e.length}.`));const r="reflect"===n?1:0;for(let t=0;t<s.rank;t++)A(2===e[t].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),A(e[t][0]>=0&&e[t][0]<=s.shape[t]-r&&e[t][1]>=0&&e[t][1]<=s.shape[t]-r,(()=>`Padding in dimension ${t} cannot be greater than or equal to ${s.shape[t]-r} or less than 0 for input of shape `+s.shape));const a={paddings:e,mode:n},i={x:s};return fs.runKernel(Ae,i,a)}});Jn.prototype.mirrorPad=function(t,e){return this.throwIfDisposed(),Vh(this,t,e)},Jn.prototype.modStrict=function(t){return this.throwIfDisposed(),hh(this,t)},Jn.prototype.mod=function(t){return this.throwIfDisposed(),ih(this,t)},Jn.prototype.mulStrict=function(t){return this.throwIfDisposed(),ph(this,t)},Jn.prototype.mul=function(t){return this.throwIfDisposed(),pi(this,t)},Jn.prototype.neg=function(){return this.throwIfDisposed(),Ei(this)},Jn.prototype.norm=function(t,e,n){return this.throwIfDisposed(),al(this,t,e,n)},Jn.prototype.notEqualStrict=function(t){return this.throwIfDisposed(),Dh(this,t)},Jn.prototype.notEqual=function(t){return this.throwIfDisposed(),Ai(this,t)},Jn.prototype.oneHot=function(t,e=1,n=0){return this.throwIfDisposed(),Ri(this,t,e,n)},Jn.prototype.onesLike=function(){return this.throwIfDisposed(),Oi(this)},Jn.prototype.pad=function(t,e){return this.throwIfDisposed(),Mi(this,t,e)};const Uh=Ns({pool_:function(t,e,n,s,r,a){null==r&&(r=[1,1]),null==a&&(a=1),0===s&&(s="valid");const i=vs(t,"x","maxPool");let o=i,l=!1;3===i.rank&&(l=!0,o=aa(i,[1,i.shape[0],i.shape[1],i.shape[2]])),A(va(a,r),(()=>`Error in pool: Either strides or dilations must be 1. Got strides ${a} and dilations '${r}'`));const u=ha(o.shape,e,a,r,s),c=[u.dilationHeight,u.dilationWidth];let h;h="same"===s?function(t,e){const n=t.map(((t,n)=>t+(t-1)*(e[n]-1))).map((t=>t-1)),s=n.map((t=>Math.floor(t/2))),r=n.map(((t,e)=>t-s[e]));return n.map(((t,e)=>[s[e],r[e]]))}([u.filterHeight,u.filterWidth],c):[[0,0],[0,0]];const p=1===c[0]&&1===c[1],[d,f]=function(t,e,n){const s=n.map((t=>t[0])),r=n.map((t=>t[1])),a=t.concat(s,r),i=e.map(((t,e)=>(t-a[e]%t)%t)),o=r.map(((t,e)=>t+i[e]));return[e.map(((t,e)=>[s[e],o[e]])),e.map(((t,e)=>[0,i[e]]))]}([u.inHeight,u.inWidth],c,h),m=p?s:"valid",g=p?o:Cu(o,c,d),y=("avg"===n?()=>Na(g,e,a,m):()=>wi(g,e,a,m))(),b=p?y:th(y,c,f);return l?aa(b,[b.shape[1],b.shape[2],b.shape[3]]):b}});Jn.prototype.pool=function(t,e,n,s,r){return this.throwIfDisposed(),Uh(this,t,e,n,s,r)},Jn.prototype.powStrict=function(t){return this.throwIfDisposed(),dh(this,t)},Jn.prototype.pow=function(t){return this.throwIfDisposed(),sl(this,t)},Jn.prototype.prelu=function(t){return this.throwIfDisposed(),Li(this,t)};const Gh=Ns({prod_:function(t,e=null,n=!1){let s=vs(t,"x","prod");"bool"===s.dtype&&(s=or(s,"int32"));const r={x:s},a={axis:e,keepDims:n};return fs.runKernelFunc((t=>{const r=W(e,s.shape),a=na(r,s.rank);let i=r,o=s;null!=a&&(o=ia(s,a),i=ra(i.length,s.rank));let l=t.prod(o,i);if(n){const t=ta(l.shape,r);l=aa(l,t)}return l}),r,null,"Prod",a)}});Jn.prototype.prod=function(t,e){return this.throwIfDisposed(),Gh(this,t,e)};const Hh=Ns({reciprocal_:function(t){const e=vs(t,"x","reciprocal"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.reciprocal(e);return n([e]),s}),n,null,Ve)}});Jn.prototype.reciprocal=function(){return this.throwIfDisposed(),Hh(this)},Jn.prototype.relu=function(){return this.throwIfDisposed(),Hi(this)},Jn.prototype.relu6=function(){return this.throwIfDisposed(),ko(this)},Jn.prototype.reshapeAs=function(t){return this.throwIfDisposed(),aa(this,t.shape)},Jn.prototype.reshape=function(t){return this.throwIfDisposed(),aa(this,t)},Jn.prototype.resizeBilinear=function(t,e){return this.throwIfDisposed(),Qo(this,t,e)},Jn.prototype.resizeNearestNeighbor=function(t,e){return this.throwIfDisposed(),tl(this,t,e)},Jn.prototype.reverse=function(t){return this.throwIfDisposed(),ji(this,t)},Jn.prototype.rfft=function(){return this.throwIfDisposed(),bo(this)};const jh=Ns({round_:function(t){const e=vs(t,"x","round"),n={x:e};return fs.runKernelFunc((t=>t.round(e)),n,null,Xe)}});Jn.prototype.round=function(){return this.throwIfDisposed(),jh(this)},Jn.prototype.rsqrt=function(){return this.throwIfDisposed(),Zu(this)},Jn.prototype.selu=function(){return this.throwIfDisposed(),qi(this)},Jn.prototype.separableConv2d=function(t,e,n,s,r,a){return this.throwIfDisposed(),Ki(this,t,e,n,s,r,a)},Jn.prototype.sigmoid=function(){return this.throwIfDisposed(),Xi(this)};const qh=Ns({sign_:function(t){const e=vs(t,"x","sign"),n={x:e};return fs.runKernelFunc((t=>t.sign(e)),n,null,nn)}});Jn.prototype.sign=function(){return this.throwIfDisposed(),qh(this)},Jn.prototype.sin=function(){return this.throwIfDisposed(),Lu(this)},Jn.prototype.sinh=function(){return this.throwIfDisposed(),Bu(this)},Jn.prototype.slice=function(t,e){return this.throwIfDisposed(),Yi(this,t,e)},Jn.prototype.softmax=function(t){return this.throwIfDisposed(),eo(this,t)},Jn.prototype.softplus=function(){return this.throwIfDisposed(),no(this)},Jn.prototype.spaceToBatchND=function(t,e){return this.throwIfDisposed(),Cu(this,t,e)},Jn.prototype.split=function(t,e){return this.throwIfDisposed(),ro(this,t,e)},Jn.prototype.sqrt=function(){return this.throwIfDisposed(),ao(this)},Jn.prototype.square=function(){return this.throwIfDisposed(),Ti(this)},Jn.prototype.squaredDifference=function(t){return this.throwIfDisposed(),hl(this,t)},Jn.prototype.squaredDifferenceStrict=function(t){return this.throwIfDisposed(),fh(this,t)},Jn.prototype.squeeze=function(t){return this.throwIfDisposed(),io(this,t)},Jn.prototype.stack=function(t,e){this.throwIfDisposed();const n=t instanceof Jn?[this,t]:[this,...t];return oo(n,e)},Jn.prototype.step=function(t){return this.throwIfDisposed(),No(this,t)};const Kh=Ns({stridedSlice_:function(t,e,n,s,r=0,a=0,i=0,o=0,l=0){let u=vs(t,"x","stridedSlice");const c={x:u},h={begin:e,end:n,strides:s,beginMask:r,endMask:a,ellipsisMask:i,newAxisMask:o,shrinkAxisMask:l};return fs.runKernelFunc((t=>{null==s&&(s=new Array(e.length));const c=vr(i);if(c.length>1)throw new Error("Multiple ellipses in slice is not allowed.");if(0!==i&&0!==o)throw new Error("Using both ellipsisMask and newAxisMask is not yet supported.");if(0!==i&&0!==l)throw new Error("Using both ellipsisMask and shrinkAxisMask is not yet supported.");const h=u.rank-e.length,p=vr(o),d=u.shape.slice();p.forEach((t=>{e[t]=0,n[t]=1,d.splice(t,0,1)})),u=aa(u,d);const{begin:f,end:m,strides:g}=Sr(u.shape,c,h,e,n,s,r,a,i);e=f,n=m,s=g;const y=vr(l);y.forEach((t=>{n[t]=e[t]+1,s[t]=1}));const b=kr(e,n,s),x=b.filter(((t,e)=>-1===y.indexOf(e)));if(s.every((t=>1===t)))return aa(Yi(u,e,b),x);const w=t.stridedSlice(u,e,n,s);return aa(w,x)}),c,null,"StridedSlice",h)}});Jn.prototype.stridedSlice=function(t,e,n,s,r,a,i,o){return this.throwIfDisposed(),Kh(this,t,e,n,s,r,a,i,o)},Jn.prototype.subStrict=function(t){return this.throwIfDisposed(),mh(this,t)},Jn.prototype.sub=function(t){return this.throwIfDisposed(),gi(this,t)},Jn.prototype.sum=function(t,e){return this.throwIfDisposed(),yi(this,t,e)};const Xh=Ns({tan_:function(t){const e=vs(t,"x","tan"),n={x:e};return fs.runKernelFunc(((t,n)=>{const s=t.tan(e);return n([e]),s}),n,null,dn)}});Jn.prototype.tan=function(){return this.throwIfDisposed(),Xh(this)},Jn.prototype.tanh=function(){return this.throwIfDisposed(),lo(this)},Jn.prototype.tile=function(t){return this.throwIfDisposed(),Qa(this,t)},Jn.prototype.toBool=function(){return this.throwIfDisposed(),or(this,"bool")},Jn.prototype.toFloat=function(){return this.throwIfDisposed(),or(this,"float32")},Jn.prototype.toInt=function(){return this.throwIfDisposed(),or(this,"int32")};const Yh=Ns({topk_:function(t,e=1,n=!0){const s=vs(t,"x","topk");if(0===s.rank)throw new Error("topk() expects the input to be of rank 1 or higher");const r=s.shape[s.shape.length-1];if(e>r)throw new Error(`'k' passed to topk() must be <= the last dimension (${r}) but got `+e);const a={x:s},i={k:e,sorted:n},[o,l]=fs.runKernelFunc((t=>t.topk(s,e,n)),a,null,"TopK",i);return{values:o,indices:l}}});Jn.prototype.topk=function(t,e){return this.throwIfDisposed(),Yh(this,t,e)},Jn.prototype.transpose=function(t){return this.throwIfDisposed(),ia(this,t)};const Jh=Ns({unique_:function(t,e=0){const n=vs(t,"x","unique",null);A(n.rank>0,(()=>"The input tensor must be at least 1D"));const s={x:n},r={axis:e},[a,i]=fs.runKernel(yn,s,r);return{values:a,indices:i}}});var Zh,Qh;Jn.prototype.unique=function(t){return this.throwIfDisposed(),Jh(this,t)},Jn.prototype.unsortedSegmentSum=function(t,e){return this.throwIfDisposed(),tc(this,t,e)},Jn.prototype.unstack=function(t){return this.throwIfDisposed(),po(this,t)},Jn.prototype.where=function(t,e){return this.throwIfDisposed(),mo(t,this,e)},Jn.prototype.zerosLike=function(){return this.throwIfDisposed(),_i(this)},function(t){t[t.DT_INVALID=0]="DT_INVALID",t[t.DT_FLOAT=1]="DT_FLOAT",t[t.DT_DOUBLE=2]="DT_DOUBLE",t[t.DT_INT32=3]="DT_INT32",t[t.DT_UINT8=4]="DT_UINT8",t[t.DT_INT16=5]="DT_INT16",t[t.DT_INT8=6]="DT_INT8",t[t.DT_STRING=7]="DT_STRING",t[t.DT_COMPLEX64=8]="DT_COMPLEX64",t[t.DT_INT64=9]="DT_INT64",t[t.DT_BOOL=10]="DT_BOOL",t[t.DT_QINT8=11]="DT_QINT8",t[t.DT_QUINT8=12]="DT_QUINT8",t[t.DT_QINT32=13]="DT_QINT32",t[t.DT_BFLOAT16=14]="DT_BFLOAT16",t[t.DT_FLOAT_REF=101]="DT_FLOAT_REF",t[t.DT_DOUBLE_REF=102]="DT_DOUBLE_REF",t[t.DT_INT32_REF=103]="DT_INT32_REF",t[t.DT_UINT8_REF=104]="DT_UINT8_REF",t[t.DT_INT16_REF=105]="DT_INT16_REF",t[t.DT_INT8_REF=106]="DT_INT8_REF",t[t.DT_STRING_REF=107]="DT_STRING_REF",t[t.DT_COMPLEX64_REF=108]="DT_COMPLEX64_REF",t[t.DT_INT64_REF=109]="DT_INT64_REF",t[t.DT_BOOL_REF=110]="DT_BOOL_REF",t[t.DT_QINT8_REF=111]="DT_QINT8_REF",t[t.DT_QUINT8_REF=112]="DT_QUINT8_REF",t[t.DT_QINT32_REF=113]="DT_QINT32_REF",t[t.DT_BFLOAT16_REF=114]="DT_BFLOAT16_REF"}(Zh||(Zh={})),function(t){let e;!function(t){t[t.LEGACY=0]="LEGACY",t[t.V1=1]="V1",t[t.V2=2]="V2"}(e=t.CheckpointFormatVersion||(t.CheckpointFormatVersion={}))}(Qh||(Qh={}));const tp={};function ep(t){return tp[t]}function np(t,e,n,s,r){const a=e.inputParams[t];if(a&&void 0!==a.inputIndexStart){const t=a.inputIndexStart,i=0===a.inputIndexEnd?void 0:void 0===a.inputIndexEnd?t+1:a.inputIndexEnd;if("tensor"===a.type)return sp(e.inputNames[a.inputIndexStart],n,s,r);if("tensors"===a.type)return e.inputNames.slice(t,i).map((t=>sp(t,n,s,r)));const o=sp(e.inputNames.slice(t)[0],n,s,r),l=o.dataSync();return"number"===a.type?l[0]:et(o.shape,l)}const i=e.attrParams[t];return i&&i.value}function sp(t,e,n,s){const[r,a]=ip(t);if(null!=s){const t=s.getHashTableHandleByName(r);if(null!=t)return t}const i=n.currentContextIds.find((t=>!!e[ap(r,t)]));return void 0!==i?e[ap(r,i)][a]:void 0}function rp(t,e){const[n,s]=ip(t);return[ap(n,e&&e.currentContextId),s]}function ap(t,e){return e?`${t}-${e}`:t}function ip(t){const e=t.split(":");return 1===e.length?[t,0]:[e[0],Number(e[e.length-1])]}function op(t,e,n){let s=np("pad",t,e,n);if("explicit"===s){s=np("explicitPaddings",t,e,n);const r=[[0,0],[0,0],[0,0],[0,0]];for(let t=0;t<4;t++)r[t][0]=s[2*t],r[t][1]=s[2*t+1];return r}return s}function lp(t){return t.kept?t:lr(t)}const up=[{tfOpName:"Add",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AddV2",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AddN",category:"arithmetic",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}]},{tfOpName:"BiasAdd",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sub",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"RealDiv",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Div",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"DivNoNan",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"FloorDiv",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Mul",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Maximum",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}]},{tfOpName:"Minimum",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}]},{tfOpName:"Pow",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"SquaredDifference",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Mod",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"FloorMod",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],cp=[{tfOpName:"Abs",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Acos",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Asin",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atan2",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"y",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Ceil",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ClipByValue",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"clip_value_min",name:"clipValueMin",type:"number"},{tfName:"clip_value_max",name:"clipValueMax",type:"number"}]},{tfOpName:"Complex",category:"basic_math",inputs:[{start:0,name:"real",type:"tensor"},{start:1,name:"imag",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ComplexAbs",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Cos",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Cosh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Elu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Exp",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Floor",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Log",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Imag",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"Tout",name:"outputType",type:"dtype",notSupported:!0}]},{tfOpName:"Neg",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Real",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"Tout",name:"outputType",type:"dtype",notSupported:!0}]},{tfOpName:"Prelu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"alpha",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Relu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Relu6",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"clipValueMin",name:"clipValueMin",type:"number",defaultValue:0},{tfName:"clipValueMax",name:"clipValueMax",type:"number",defaultValue:6}]},{tfOpName:"Selu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sigmoid",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sin",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sinh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sqrt",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Rsqrt",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Square",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Tan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Tanh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sign",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Round",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Expm1",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Log1p",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Reciprocal",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Softplus",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Asinh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Acosh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atanh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Erf",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Prod",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axes",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool",notSupported:!0},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LeakyRelu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"alpha",name:"alpha",type:"number",defaultValue:.2},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],hp=[{tfOpName:"LoopCond",category:"control",inputs:[{start:0,name:"pred",type:"tensor"}]},{tfOpName:"Switch",category:"control",inputs:[{start:0,name:"data",type:"tensor"},{start:1,name:"pred",type:"tensor"}]},{tfOpName:"Merge",category:"control",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}]},{tfOpName:"Enter",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"frame_name",name:"frameName",type:"string"},{tfName:"is_constant",name:"isConstant",type:"bool"}]},{tfOpName:"Exit",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"NextIteration",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayV3",category:"control",inputs:[{start:0,name:"size",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape",name:"elementShape",type:"shape"},{tfName:"dynamic_size",name:"dynamicSize",type:"bool"},{tfName:"clear_after_read",name:"clearAfterRead",type:"bool"},{tfName:"identical_element_shapes",name:"identicalElementShapes",type:"bool"},{tfName:"tensor_array_name",name:"name",type:"string"}]},{tfOpName:"TensorArrayWriteV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"tensor",type:"tensor"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayReadV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayGatherV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape",name:"elementShape",type:"shape"}]},{tfOpName:"TensorArrayScatterV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"tensor",type:"tensor"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"TensorArrayConcatV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape_except0",name:"elementShapeExcept0",type:"shape",notSupported:!0}]},{tfOpName:"TensorArraySplitV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"tensor",type:"tensor"},{start:2,name:"lengths",type:"number[]"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"TensorArraySizeV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"flowIn",type:"number"}]},{tfOpName:"TensorArrayCloseV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"}]},{tfOpName:"StatelessIf",category:"control",inputs:[{start:0,name:"cond",type:"tensor"},{start:1,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"then_branch",name:"thenBranch",type:"func"},{tfName:"else_branch",name:"elseBranch",type:"func"}]},{tfOpName:"If",category:"control",inputs:[{start:0,name:"cond",type:"tensor"},{start:1,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"then_branch",name:"thenBranch",type:"func"},{tfName:"else_branch",name:"elseBranch",type:"func"}]},{tfOpName:"StatelessWhile",category:"control",inputs:[{start:0,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"cond",name:"cond",type:"func"},{tfName:"body",name:"body",type:"func"}]},{tfOpName:"While",category:"control",inputs:[{start:0,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"cond",name:"cond",type:"func"},{tfName:"body",name:"body",type:"func"}]},{tfOpName:"TensorListScatter",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListScatterV2",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"},{start:3,name:"numElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListGather",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListGetItem",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListSetItem",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"tensor",type:"tensor"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListReserve",category:"control",inputs:[{start:0,name:"elementShape",type:"shape"},{start:1,name:"numElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListFromTensor",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListStack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"},{tfName:"num_elements",name:"numElements",type:"dtype"}]},{tfOpName:"TensorListSplit",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"elementShape",type:"shape"},{start:2,name:"lengths",type:"number[]"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListConcat",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"}],attrs:[{tfName:"element_shape",name:"elementShape",type:"shape"},{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListPopBack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListPushBack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"tensor",type:"tensor"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]}],pp=[{tfOpName:"AvgPool",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPool",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPoolWithArgmax",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"include_batch_in_index",name:"includeBatchInIndex",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AvgPool3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPool3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Conv1D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"stride",name:"stride",type:"number"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NWC"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"dilation",name:"dilation",type:"number",defaultValue:1}]},{tfOpName:"Conv2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"useCudnnOnGpu",name:"useCudnnOnGpu",type:"bool"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"_FusedConv2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"use_cudnn_on_gpu",name:"useCudnnOnGpu",type:"bool",defaultValue:!0},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]",defaultValue:[1,1,1,1]},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:1e-4}]},{tfOpName:"Conv2DBackpropInput",category:"convolution",inputs:[{start:2,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:0,name:"outputShape",type:"number[]"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]}]},{tfOpName:"DepthwiseConv2d",category:"convolution",inputs:[{start:0,name:"input",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"DepthwiseConv2dNative",category:"convolution",inputs:[{start:0,name:"input",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"FusedDepthwiseConv2dNative",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]",defaultValue:[1,1,1,1]},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]}]},{tfOpName:"Conv3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"Dilation2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"rates",name:"dilations",type:"number[]"},{tfName:"padding",name:"pad",type:"string"}]}],dp=[{tfOpName:"Fill",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"},{start:1,name:"value",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"LinSpace",category:"creation",inputs:[{start:0,name:"start",type:"number"},{start:1,name:"stop",type:"number"},{start:2,name:"num",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"OneHot",category:"creation",inputs:[{start:0,name:"indices",type:"tensor"},{start:1,name:"depth",type:"number"},{start:2,name:"onValue",type:"number",defaultValue:1},{start:3,name:"offValue",type:"number",defaultValue:0}],attrs:[{tfName:"axis",name:"axis",type:"number",notSupported:!0},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Ones",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"OnesLike",category:"creation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"RandomUniform",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"minval",name:"minval",type:"number",defaultValue:0},{tfName:"maxval",name:"maxval",type:"number",defaultValue:1},{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"seed",name:"seed",type:"number",defaultValue:0},{tfName:"seed2",name:"seed2",type:"number",defaultValue:0,notSupported:!0},{tfName:"T",name:"T",type:"number",notSupported:!0}]},{tfOpName:"Range",category:"creation",inputs:[{start:0,name:"start",type:"number"},{start:1,name:"stop",type:"number"},{start:2,name:"step",type:"number",defaultValue:0}],attrs:[{tfName:"Tidx",name:"dtype",type:"dtype"}]},{tfOpName:"TruncatedNormal",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"means",name:"mean",type:"number",defaultValue:0},{tfName:"stddev",name:"stdDev",type:"number",defaultValue:1},{tfName:"seed",name:"seed",type:"number"},{tfName:"seed2",name:"seed2",type:"number",defaultValue:0,notSupported:!0},{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"T",name:"T",type:"number",notSupported:!0}]},{tfOpName:"Zeros",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"ZerosLike",category:"creation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"Multinomial",category:"creation",inputs:[{start:0,name:"logits",type:"tensor"},{start:1,name:"numSamples",type:"number"}],attrs:[{tfName:"seed",name:"seed",type:"number"},{tfName:"seed2",name:"seed2",type:"number"},{tfName:"T",name:"dtype",type:"dtype"},{tfName:"output_dtype",name:"output_dtype",type:"dtype"}]}],fp=[{tfOpName:"NonMaxSuppressionV2",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"}]},{tfOpName:"NonMaxSuppressionV3",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"}]},{tfOpName:"NonMaxSuppressionV4",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"T_threshold",name:"threshold",type:"dtype",notSupported:!0},{tfName:"pad_to_max_output_size",name:"padToMaxOutputSize",type:"bool"}]},{tfOpName:"NonMaxSuppressionV5",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"},{start:5,name:"softNmsSigma",type:"number"}]},{tfOpName:"Where",category:"dynamic",inputs:[{start:0,name:"condition",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ListDiff",category:"dynamic",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"y",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],mp=[{tfOpName:"TopKV2",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"k",type:"number"}],attrs:[{tfName:"sorted",name:"sorted",type:"bool"}]},{tfOpName:"Unique",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"UniqueV2",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]}],gp=[{tfOpName:"PlaceholderWithDefault",category:"graph",inputs:[{start:0,name:"default",type:"tensor"}],attrs:[{tfName:"shape",name:"shape",type:"shape"},{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"Placeholder",category:"graph",attrs:[{tfName:"shape",name:"shape",type:"shape"},{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"Const",category:"graph"},{tfOpName:"Identity",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"IdentityN",category:"graph",inputs:[{start:0,end:0,name:"x",type:"tensors"}]},{tfOpName:"Snapshot",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Rank",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Size",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Shape",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"ShapeN",category:"graph",inputs:[{start:0,end:0,name:"x",type:"tensors"}]},{tfOpName:"Print",category:"graph",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"data",type:"tensors"}],attrs:[{tfName:"message",name:"message",type:"string"},{tfName:"first_n",name:"firstN",type:"number",notSupported:!0},{tfName:"summarize",name:"summarize",type:"number",defaultValue:3}]},{tfOpName:"NoOp",category:"graph",inputs:[]},{tfOpName:"StopGradient",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"FakeQuantWithMinMaxVars",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"min",name:"min",type:"number"},{tfName:"max",name:"max",type:"number"}]}],yp=[{tfOpName:"HashTable",category:"hash_table",inputs:[],attrs:[{tfName:"shared_name",name:"sharedName",type:"string"},{tfName:"use_node_name_sharing",name:"useNodeNameSharing",type:"bool"},{tfName:"key_dtype",name:"keyDType",type:"dtype"},{tfName:"value_dtype",name:"valueDType",type:"dtype"}]},{tfOpName:"HashTableV2",category:"hash_table",inputs:[],attrs:[{tfName:"shared_name",name:"sharedName",type:"string"},{tfName:"use_node_name_sharing",name:"useNodeNameSharing",type:"bool"},{tfName:"key_dtype",name:"keyDType",type:"dtype"},{tfName:"value_dtype",name:"valueDType",type:"dtype"}]},{tfOpName:"LookupTableImport",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"values",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableImportV2",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"values",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableFind",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableFindV2",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]}],bp=[{tfOpName:"ResizeBilinear",category:"image",inputs:[{start:0,name:"images",type:"tensor"},{start:1,name:"size",type:"number[]"}],attrs:[{tfName:"align_corners",name:"alignCorners",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ResizeNearestNeighbor",category:"image",inputs:[{start:0,name:"images",type:"tensor"},{start:1,name:"size",type:"number[]"}],attrs:[{tfName:"align_corners",name:"alignCorners",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"CropAndResize",category:"image",inputs:[{start:0,name:"image",type:"tensor"},{start:1,name:"boxes",type:"tensor"},{start:2,name:"boxInd",type:"tensor"},{start:3,name:"cropSize",type:"number[]"}],attrs:[{tfName:"method",name:"method",type:"string"},{tfName:"extrapolation_value",name:"extrapolationValue",type:"number"}]}],xp=[{tfOpName:"Equal",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"NotEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Greater",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"GreaterEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Less",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LessEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalAnd",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalNot",category:"logical",inputs:[{start:0,name:"a",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalOr",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Select",category:"logical",inputs:[{start:0,name:"condition",type:"tensor"},{start:1,name:"a",type:"tensor"},{start:2,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"SelectV2",category:"logical",inputs:[{start:0,name:"condition",type:"tensor"},{start:1,name:"a",type:"tensor"},{start:2,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],wp=[{tfOpName:"_FusedMatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:1e-4},{tfName:"transpose_a",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"transpose_b",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"transpose_a",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"transpose_b",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"BatchMatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"adj_x",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"adj_y",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"BatchMatMulV2",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"adj_x",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"adj_y",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Transpose",category:"matrices",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"perm",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],vp=[{tfOpName:"FusedBatchNorm",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"FusedBatchNormV2",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"FusedBatchNormV3",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"LRN",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"depth_radius",name:"radius",type:"number",defaultValue:5},{tfName:"bias",name:"bias",type:"number",defaultValue:1},{tfName:"alpha",name:"alpha",type:"number",defaultValue:1},{tfName:"beta",name:"beta",type:"number",defaultValue:.5}]},{tfOpName:"Softmax",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"LogSoftmax",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"SparseToDense",category:"normalization",inputs:[{start:0,name:"sparseIndices",type:"tensor"},{start:1,name:"outputShape",type:"number[]"},{start:2,name:"sparseValues",type:"tensor"},{start:3,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",defaultValue:!0,notSupported:!0}]}],kp=[{tfOpName:"Max",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Mean",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Min",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Sum",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"All",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Any",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"ArgMax",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"ArgMin",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"Prod",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Cumsum",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}],attrs:[{tfName:"exclusive",name:"exclusive",type:"bool"},{tfName:"reverse",name:"reverse",type:"bool"}]}],Np=[{tfOpName:"ConcatV2",category:"slice_join",inputs:[{start:0,end:-1,name:"tensors",type:"tensors"},{start:-1,name:"axis",type:"number"}],attrs:[{tfName:"N",name:"n",type:"number",defaultValue:2}]},{tfOpName:"Concat",category:"slice_join",inputs:[{start:1,end:0,name:"tensors",type:"tensors"},{start:0,name:"axis",type:"number"}],attrs:[{tfName:"N",name:"n",type:"number",defaultValue:2}]},{tfOpName:"GatherV2",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"},{start:2,name:"axis",type:"number",defaultValue:0}]},{tfOpName:"Gather",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"}],attrs:[{tfName:"axis",name:"axis",type:"number",defaultValue:0},{tfName:"validate_indices",name:"validateIndices",type:"bool",notSupported:!0}]},{tfOpName:"Reverse",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"dims",type:"bool",notSupported:!0}]},{tfOpName:"ReverseV2",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}]},{tfOpName:"Slice",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"begin",type:"number[]"},{start:2,name:"size",type:"number[]"}]},{tfOpName:"StridedSlice",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"begin",type:"number[]"},{start:2,name:"end",type:"number[]"},{start:3,name:"strides",type:"number[]"}],attrs:[{tfName:"begin_mask",name:"beginMask",type:"number",defaultValue:0},{tfName:"end_mask",name:"endMask",type:"number",defaultValue:0},{tfName:"new_axis_mask",name:"newAxisMask",type:"number",defaultValue:0},{tfName:"ellipsis_mask",name:"ellipsisMask",type:"number",defaultValue:0},{tfName:"shrink_axis_mask",name:"shrinkAxisMask",type:"number",defaultValue:0}]},{tfOpName:"Pack",category:"slice_join",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}],attrs:[{tfName:"axis",name:"axis",type:"number",defaultValue:0}]},{tfOpName:"Unpack",category:"slice_join",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"axis",name:"axis",type:"number",defaultValue:0},{tfName:"num",name:"num",type:"number",defaultValue:0,notSupported:!0}]},{tfOpName:"Tile",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"reps",type:"number[]"}]},{tfOpName:"Split",category:"slice_join",inputs:[{start:0,name:"axis",type:"number",defaultValue:0},{start:1,name:"x",type:"tensor"}],attrs:[{tfName:"num_split",name:"numOrSizeSplits",type:"number",defaultValue:1}]},{tfOpName:"SplitV",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"numOrSizeSplits",type:"number[]"},{start:2,name:"axis",type:"number",defaultValue:0}]},{tfOpName:"ScatterNd",category:"slice_join",inputs:[{start:0,name:"indices",type:"tensor"},{start:1,name:"values",type:"tensor"},{start:2,name:"shape",type:"number[]"}]},{tfOpName:"GatherNd",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"}]},{tfOpName:"SparseToDense",category:"slice_join",inputs:[{start:0,name:"sparseIndices",type:"tensor"},{start:1,name:"outputShape",type:"number[]"},{start:2,name:"sparseValues",type:"tensor"},{start:3,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",defaultValue:!1,notSupported:!0}]}],Ip=[{tfOpName:"FFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"IFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"RFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"fft_length",type:"number",notSupported:!0}]},{tfOpName:"IRFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"fft_length",type:"number",notSupported:!0}]}],Cp=[{tfOpName:"Cast",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"SrcT",name:"sdtype",type:"dtype",notSupported:!0},{tfName:"DstT",name:"dtype",type:"dtype"}]},{tfOpName:"ExpandDims",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"MirrorPad",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"}],attrs:[{tfName:"mode",name:"mode",type:"string"}]},{tfOpName:"Pad",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"}],attrs:[{tfName:"constant_value",name:"constantValue",type:"number",defaultValue:0}]},{tfOpName:"PadV2",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"},{start:2,name:"constantValue",type:"number",defaultValue:0}]},{tfOpName:"Reshape",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"shape",type:"number[]"}]},{tfOpName:"Squeeze",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"axis",tfDeprecatedName:"squeeze_dims",name:"axis",type:"number[]"}]},{tfOpName:"SpaceToBatchND",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"blockShape",type:"number[]"},{start:2,name:"paddings",type:"number[]"}]},{tfOpName:"BatchToSpaceND",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"blockShape",type:"number[]"},{start:2,name:"crops",type:"number[]"}]},{tfOpName:"DepthToSpace",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"block_size",name:"blockSize",type:"number"},{tfName:"data_format",name:"dataFormat",type:"string"}]},{tfOpName:"BroadcastTo",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"shape",type:"number[]"}],attrs:[]}];class Sp{static get Instance(){return this._instance||(this._instance=new this)}constructor(){const t=[].concat(...[r,a,i,o,l,u,c,f,d,h,m,g,y,b,x,w,p].map((t=>t.json)));this.opMappers=t.reduce(((t,e)=>(t[e.tfOpName]=e,t)),{})}transformGraph(t,e={}){const n=t.node,s=[],r=[],a=[],i=n.reduce(((t,e)=>(t[e.name]=this.mapNode(e),e.op.startsWith("Placeholder")?s.push(t[e.name]):"Const"===e.op?r.push(t[e.name]):null!=e.input&&0!==e.input.length||a.push(t[e.name]),t)),{});let o=[];const l=[];let u={},c={};null!=e&&(u=this.mapSignatureEntries(e.inputs),c=this.mapSignatureEntries(e.outputs));const h=Object.keys(i);h.forEach((t=>{const e=i[t];e.inputNames.forEach((t=>{const[n]=rp(t);e.inputs.push(i[n]),i[n].children.push(e)}))})),0===Object.keys(c).length?h.forEach((t=>{const e=i[t];0===e.children.length&&l.push(e)})):Object.keys(c).forEach((t=>{const[e]=rp(t),n=i[e];null!=n&&(n.signatureKey=c[t],l.push(n))})),Object.keys(u).length>0?Object.keys(u).forEach((t=>{const[e]=rp(t),n=i[e];n&&(n.signatureKey=u[t],o.push(n))})):o=s;let p={};null!=t.library&&null!=t.library.function&&(p=t.library.function.reduce(((t,e)=>(t[e.signature.name]=this.mapFunction(e),t)),{}));const d={nodes:i,inputs:o,outputs:l,weights:r,placeholders:s,signature:e,functions:p};return a.length>0&&(d.initNodes=a),d}mapSignatureEntries(t){return Object.keys(t||{}).reduce(((e,n)=>(e[t[n].name]=n,e)),{})}mapNode(t){const e=ep(t.op)||this.opMappers[t.op]||{};null==t.attr&&(t.attr={});const n={name:t.name,op:t.op,category:e.category,inputNames:(t.input||[]).map((t=>t.startsWith("^")?t.substr(1):t)),inputs:[],children:[],inputParams:{},attrParams:{},rawAttrs:t.attr};return null!=e.inputs&&(n.inputParams=e.inputs.reduce(((t,e)=>(t[e.name]={type:e.type,inputIndexStart:e.start,inputIndexEnd:e.end},t)),{})),null!=e.attrs&&(n.attrParams=e.attrs.reduce(((e,n)=>{const s=n.type;let r=void 0;switch(n.type){case"string":r=$p(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=$p(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"string[]":r=zp(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=zp(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"number":r=Ap(t.attr,n.tfName,n.defaultValue||0),void 0===r&&n.tfDeprecatedName&&(r=Ap(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"number[]":r=Lp(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=Lp(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"bool":r=Ep(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=Ep(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"bool[]":r=Pp(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=Pp(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"shape":r=Mp(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=Mp(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"shape[]":r=Bp(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=Bp(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"dtype":r=Fp(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=Fp(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"dtype[]":r=_p(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=_p(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"func":r=Dp(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=Dp(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"tensor":case"tensors":break;default:throw new Error(`Unsupported param type: ${n.type} for op: ${t.op}`)}return e[n.name]={value:r,type:s},e}),{})),n}mapFunction(t){const e=t.nodeDef,n=[];let s={};null!=e&&(s=e.reduce(((t,e)=>(t[e.name]=this.mapNode(e),"Const"===e.op&&n.push(t[e.name]),t)),{}));const r=[],a=[];t.signature.inputArg.forEach((t=>{const[e]=rp(t.name),n={name:e,op:"Placeholder",inputs:[],inputNames:[],category:"graph",inputParams:{},attrParams:{dtype:{value:Rp(t.type),type:"dtype"}},children:[]};n.signatureKey=t.name,r.push(n),s[e]=n})),Object.keys(s).forEach((t=>{const e=s[t];e.inputNames.forEach((t=>{const[n]=rp(t);e.inputs.push(s[n]),s[n].children.push(e)}))}));const i=t.ret;t.signature.outputArg.forEach((t=>{const[e,n]=rp(i[t.name]),r=s[e];null!=r&&(r.defaultOutput=n,a.push(r))}));const o=this.mapArgsToSignature(t);return{nodes:s,inputs:r,outputs:a,weights:n,placeholders:[],signature:o}}mapArgsToSignature(t){return{methodName:t.signature.name,inputs:t.signature.inputArg.reduce(((t,e)=>(t[e.name]=this.mapArgToTensorInfo(e),t)),{}),outputs:t.signature.outputArg.reduce(((e,n)=>(e[n.name]=this.mapArgToTensorInfo(n,t.ret),e)),{})}}mapArgToTensorInfo(t,e){let n=t.name;return null!=e&&(n=e[n]),{name:n,dtype:t.type}}}function Tp(t,e){const n=Array.isArray(t)?String.fromCharCode.apply(null,t):function(t){const e=ct().global;if(void 0!==e.atob)return e.atob(t);if("undefined"!=typeof Buffer)return new Buffer(t,"base64").toString();throw new Error("Unable to decode base64 in this environment. Missing built-in atob() or Buffer()")}(t);return e?n:n.toLowerCase()}function $p(t,e,n,s=!1){const r=t[e];return null!=r?Tp(r.s,s):n}function Ep(t,e,n){const s=t[e];return s?s.b:n}function Ap(t,e,n){const s=t[e]||{},r=null!=s.i?s.i:null!=s.f?s.f:n;return"number"==typeof r?r:parseInt(r,10)}function Rp(t){switch("string"==typeof t&&(t=Zh[t]),t){case Zh.DT_FLOAT:return"float32";case Zh.DT_INT32:case Zh.DT_INT64:case Zh.DT_INT8:case Zh.DT_UINT8:return"int32";case Zh.DT_BOOL:return"bool";case Zh.DT_DOUBLE:return"float32";case Zh.DT_STRING:return"string";default:return null}}function Dp(t,e,n){const s=t[e];return s&&s.func?s.func.name:n}function Fp(t,e,n){const s=t[e];return s&&s.type?Rp(s.type):n}function _p(t,e,n){const s=t[e];return s&&s.list&&s.list.type?s.list.type.map((t=>Rp(t))):n}function Op(t){if(!t.unknownRank)return null!=t.dim?t.dim.map((t=>"number"==typeof t.size?t.size:parseInt(t.size,10))):[]}function Mp(t,e,n){const s=t[e];return s&&s.shape?Op(s.shape):n}function Lp(t,e,n){const s=t[e];return s?((s.list.f&&s.list.f.length?s.list.f:s.list.i)||[]).map((t=>"number"==typeof t?t:parseInt(t,10))):n}function zp(t,e,n,s=!1){const r=t[e];return r&&r.list&&r.list.s?r.list.s.map((t=>Tp(t,s))):n}function Bp(t,e,n){const s=t[e];return s&&s.list&&s.list.shape?s.list.shape.map((t=>Op(t))):n}function Pp(t,e,n){const s=t[e];return s&&s.list&&s.list.b?s.list.b:n}class Wp{constructor(t,e,n){this.node=t,this.tensorMap=e,this.context=n,this.inputs=[],this.attrs={},this.inputs=t.inputNames.map((t=>this.getInput(t))),null!=t.rawAttrs&&(this.attrs=Object.keys(t.rawAttrs).reduce(((t,e)=>(t[e]=this.getAttr(e),t)),{}))}getInput(t){return sp(t,this.tensorMap,this.context)}getAttr(t,e){const n=this.node.rawAttrs[t];if(null!=n.tensor)return sp(t,this.tensorMap,this.context);if(null!=n.i||null!=n.f)return Ap(this.node.rawAttrs,t,e);if(null!=n.s)return $p(this.node.rawAttrs,t,e);if(null!=n.b)return Ep(this.node.rawAttrs,t,e);if(null!=n.shape)return Mp(this.node.rawAttrs,t,e);if(null!=n.type)return Fp(this.node.rawAttrs,t,e);if(null!=n.list){if(null!=n.list.i||null!=n.list.f)return Lp(this.node.rawAttrs,t,e);if(null!=n.list.s)return zp(this.node.rawAttrs,t,e);if(null!=n.list.shape)return Bp(this.node.rawAttrs,t,e);if(null!=n.list.b)return Pp(this.node.rawAttrs,t,e);if(null!=n.list.type)return _p(this.node.rawAttrs,t,e)}return e}}const Vp=Ns({addN_:function(t){A(Array.isArray(t),(()=>"The argument passed to tf.addN() must be a list of tensors")),A(t.length>=1,(()=>"Must pass at least one tensor to tf.addN(), but got "+t.length));const e=t.map(((t,e)=>vs(t,"tensors"+e,"addN"))),n=e[0];e.forEach((t=>{if(t.dtype!==n.dtype)throw new Error("All tensors passed to tf.addN() must have the same dtype")})),e.forEach((t=>{if(!O(t.shape,n.shape))throw new Error("All tensors passed to tf.addN() must have the same shape")}));const s=e;return fs.runKernelFunc(((t,n)=>{const s=t.addN(e);return n(e),s}),s,null,xt)}});function Up(t,e,n=""){A(function(t,e){if(t.length!==e.length)return!1;for(let n=0;n<t.length;n++)if(-1!==t[n]&&-1!==e[n]&&t[n]!==e[n])return!1;return!0}(t,e),(()=>n+` Shapes ${t} and ${e} must match`))}class Gp{constructor(t,e,n,s,r,a,i){this.name=t,this.dtype=e,this.maxSize=n,this.elementShape=s,this.identicalElementShapes=r,this.dynamicSize=a,this.clearAfterRead=i,this.tensors=[],this.closed_=!1,this.idTensor=qr(0),Ur(this.idTensor)}get id(){return this.idTensor.id}get closed(){return this.closed_}clearAndClose(t){this.tensors.forEach((e=>{null!=t&&t.has(e.tensor.id)||e.tensor.dispose()})),this.tensors=[],this.closed_=!0,this.idTensor.dispose()}size(){return this.tensors.length}read(t){if(this.closed_)throw new Error(`TensorArray ${this.name} has already been closed.`);if(t<0||t>=this.size())throw new Error(`Tried to read from index ${t}, but array size is: ${this.size()}`);const e=this.tensors[t];if(e.cleared)throw new Error(`TensorArray ${this.name}: Could not read index ${t} twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?).`);return this.clearAfterRead&&(e.cleared=!0),e.read=!0,e.tensor}readMany(t){return t.map((t=>this.read(t)))}write(t,e){if(this.closed_)throw new Error(`TensorArray ${this.name} has already been closed.`);if(t<0||!this.dynamicSize&&t>=this.maxSize)throw new Error(`Tried to write to index ${t}, but array is not resizeable and size is: ${this.maxSize}`);const n=this.tensors[t]||{};if(e.dtype!==this.dtype)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${t},\n          because the value dtype is ${e.dtype}, but TensorArray dtype is ${this.dtype}.`);if(0!==this.size()||null!=this.elementShape&&0!==this.elementShape.length||(this.elementShape=e.shape),Up(this.elementShape,e.shape,`TensorArray ${this.name}: Could not write to TensorArray index ${t}.`),n.read)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${t}, because it has already been read.`);if(n.written)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${t}, because it has already been written.`);n.tensor=e,Ur(e),n.written=!0,this.tensors[t]=n}writeMany(t,e){if(t.length!==e.length)throw new Error(`TensorArray ${this.name}: could not write multiple tensors,because the index size: ${t.length} is not the same as tensors size: ${e.length}.`);t.forEach(((t,n)=>this.write(t,e[n])))}gather(t,e){if(e&&e!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but gather requested dtype ${e}`);if(t)t=t.slice(0,this.size());else{t=[];for(let e=0;e<this.size();e++)t.push(e)}if(0===t.length)return Ss([],[0].concat(this.elementShape));const n=this.readMany(t);return Up(this.elementShape,n[0].shape,"TensorArray shape mismatch: "),oo(n,0)}concat(t){if(t&&t!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but concat requested dtype ${t}`);if(0===this.size())return Ss([],[0].concat(this.elementShape));const e=[];for(let t=0;t<this.size();t++)e.push(t);const n=this.readMany(e);return Up(this.elementShape,n[0].shape,`TensorArray shape mismatch: tensor array shape (${this.elementShape}) vs first tensor shape (${n[0].shape})`),Fa(n,0)}scatter(t,e){if(e.dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${e.dtype}`);if(t.length!==e.shape[0])throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${t.length} vs. ${e.shape[0]}`);const n=Math.max(...t);if(!this.dynamicSize&&n>=this.maxSize)throw new Error(`Max index must be < array size (${n}  vs. ${this.maxSize})`);this.writeMany(t,po(e,0))}split(t,e){if(e.dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${e.dtype}`);let n=0;const s=t.map((t=>(n+=t,n)));if(n!==e.shape[0])throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${n}, and tensor's shape is: ${e.shape}`);if(!this.dynamicSize&&t.length!==this.maxSize)throw new Error(`TensorArray's size is not equal to the size of lengths (${this.maxSize} vs. ${t.length}), and the TensorArray is not marked as dynamically resizeable`);const r=0===n?0:e.size/n,a=[];Wr((()=>{e=aa(e,[1,n,r]);for(let n=0;n<t.length;++n){const i=[0,0===n?0:s[n-1],0],o=[1,t[n],r];a[n]=aa(Yi(e,i,o),this.elementShape)}return a}));const i=[];for(let e=0;e<t.length;e++)i[e]=e;this.writeMany(i,a)}}class Hp{constructor(t,e,n,s=-1){this.tensors=t,this.elementShape=e,this.elementDtype=n,null!=t&&t.forEach((t=>{if(n!==t.dtype)throw new Error(`Invalid data types; op elements ${n}, but list elements ${t.dtype}`);Up(e,t.shape,"TensorList shape mismatch: "),Ur(t)})),this.idTensor=qr(0),this.maxNumElements=s,Ur(this.idTensor)}get id(){return this.idTensor.id}copy(){return new Hp([...this.tensors],this.elementShape,this.elementDtype)}clearAndClose(t){this.tensors.forEach((e=>{null!=t&&t.has(e.id)||e.dispose()})),this.tensors.length=0,this.idTensor.dispose()}size(){return this.tensors.length}stack(t,e,n=-1){if(e!==this.elementDtype)throw new Error(`Invalid data types; op elements ${e}, but list elements ${this.elementDtype}`);if(-1!==n&&this.tensors.length!==n)throw new Error(`Operation expected a list with ${n} elements but got a list with ${this.tensors.length} elements.`);return Up(t,this.elementShape,"TensorList shape mismatch: "),Wr((()=>{const e=this.tensors.map((e=>aa(e,t)));return oo(e,0)}))}popBack(t,e){if(e!==this.elementDtype)throw new Error(`Invalid data types; op elements ${e}, but list elements ${this.elementDtype}`);if(0===this.size())throw new Error("Trying to pop from an empty list.");const n=this.tensors.pop();return Up(n.shape,t,"TensorList shape mismatch: "),aa(n,t)}pushBack(t){if(t.dtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${t.dtype}, but list elements ${this.elementDtype}`);if(Up(t.shape,this.elementShape,"TensorList shape mismatch: "),this.maxNumElements===this.size())throw new Error("Trying to push element into a full list.");Ur(t),this.tensors.push(t)}resize(t){if(t<0)throw new Error("TensorListResize expects size to be non-negative. Got: "+t);if(-1!==this.maxNumElements&&t>this.maxNumElements)throw new Error(`TensorListResize input size ${t} is greater maxNumElement ${this.maxNumElements}.`);this.tensors.length=t}getItem(t,e,n){if(n!==this.elementDtype)throw new Error(`Invalid data types; op elements ${n}, but list elements ${this.elementDtype}`);if(t<0||t>this.tensors.length)throw new Error(`Trying to access element ${t} in a list with ${this.tensors.length} elements.`);if(null==this.tensors[t])throw new Error(`element at index ${t} is null.`);return Up(this.tensors[t].shape,e,"TensorList shape mismatch: "),this.tensors[t]}setItem(t,e){if(e.dtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${e.dtype}, but list elements ${this.elementDtype}`);if(t<0||-1!==this.maxNumElements&&t>=this.maxNumElements)throw new Error(`Trying to set element ${t} in a list with max ${this.maxNumElements} elements.`);Up(this.elementShape,e.shape,"TensorList shape mismatch: "),Ur(e),this.tensors[t]=e}gather(t,e,n){if(e!==this.elementDtype)throw new Error(`Invalid data types; op elements ${e}, but list elements ${this.elementDtype}`);return Up(this.elementShape,n,"TensorList shape mismatch: "),0===(t=t.slice(0,this.size())).length?Ss([],[0].concat(this.elementShape)):Wr((()=>{const e=t.map((t=>aa(this.tensors[t],n)));return oo(e,0)}))}concat(t,e){if(t&&t!==this.elementDtype)throw new Error(`TensorList dtype is ${this.elementDtype} but concat requested dtype ${t}`);return Up(this.elementShape,e,"TensorList shape mismatch: "),0===this.size()?Ss([],[0].concat(this.elementShape)):Wr((()=>{const t=this.tensors.map((t=>aa(t,e)));return Fa(t,0)}))}}const jp=Ns({maxPoolWithArgmax_:function(t,e,n,s,r=!1){const a={x:vs(t,"x","maxPoolWithArgmax")},i={filterSize:e,strides:n,pad:s,includeBatchInIndex:r},o=fs.runKernel(Te,a,i);return{result:o[0],indexes:o[1]}}});function qp(t,e,n){const[s,r]=np("fusedOps",t,e,n),a="biasadd"===s,i="prelu"===r,o="fusedbatchnorm"===s,l=np("numArgs",t,e,n);if(a){if(i&&2!==l)throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu must have two extra arguments: bias and alpha.");if(!i&&1!==l)throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd must have one extra argument: bias.")}if(o)throw new Error("FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported.");const u=np("strides",t,e,n),c=op(t,e,n),h=np("dataFormat",t,e,n).toUpperCase(),p=np("dilations",t,e,n),[d,f]=np("args",t,e,n);return{stride:u,pad:c,dataFormat:h,dilations:p,biasArg:d,preluArg:f,activationFunc:r}}function Kp(t,e,n){if(n<=0)throw new Error("The number of values should be positive.");const s={start:t,stop:e,num:n};return fs.runKernelFunc((s=>s.linspace(t,e,n)),{},null,"LinSpace",s)}const Xp=Ns({multinomial_:function(t,e,n,s=!1){const r=vs(t,"logits","multinomial"),a=r.size,i=r.rank;if(a<2)throw new Error("Error in multinomial: you need at least 2 outcomes, but got "+a+".");if(i>2)throw new Error("Rank of probabilities must be 1 or 2, but is "+i);n=n||Math.random();const o=1===i?aa(r,[1,-1]):r,l=fs.runKernelFunc((t=>t.multinomial(o,s,e,n)),{logits2D:o});return 1===i?aa(l,[l.size]):l}}),Yp=async function(t){const e=vs(t,"condition","whereAsync","bool"),n=await e.data(),s=ou(e.shape,n);return t!==e&&e.dispose(),s};function Jp(t,e,n){return{boxes:np("boxes",t,e,n),scores:np("scores",t,e,n),maxOutputSize:np("maxOutputSize",t,e,n),iouThreshold:np("iouThreshold",t,e,n),scoreThreshold:np("scoreThreshold",t,e,n),softNmsSigma:np("softNmsSigma",t,e,n)}}class Zp{constructor(t,e){this.keyDType=t,this.valueDType=e,this.handle=qr(0),this.tensorMap=new Map,Ur(this.handle)}get id(){return this.handle.id}clearAndClose(){this.tensorMap.forEach((t=>t.dispose())),this.tensorMap.clear(),this.handle.dispose()}size(){return this.tensorMap.size}async import(t,e){this.checkKeyAndValueTensor(t,e);const n=await t.data();return this.tensorMap.forEach((t=>t.dispose())),this.tensorMap.clear(),Wr((()=>{const t=po(e),s=n.length,r=t.length;A(s===r,(()=>`The number of elements doesn't match, keys has ${s} elements, the values has ${r} elements.`));for(let e=0;e<s;e++){const s=n[e],r=t[e];Ur(r),this.tensorMap.set(s,r)}return this.handle}))}async find(t,e){this.checkKeyAndValueTensor(t,e);const n=await t.data();return Wr((()=>{const t=[];for(let s=0;s<n.length;s++){const r=n[s],a=this.findWithDefault(r,e);t.push(a)}return oo(t)}))}findWithDefault(t,e){const n=this.tensorMap.get(t);return null!=n?n:e}checkKeyAndValueTensor(t,e){if(t.dtype!==this.keyDType)throw new Error(`Expect key dtype ${this.keyDType}, but got `+t.dtype);if(e.dtype!==this.valueDType)throw new Error(`Expect value dtype ${this.valueDType}, but got `+e.dtype)}}const Qp=Ns({sparseToDense_:function(t,e,n,s=0){const r=vs(t,"sparseIndices","sparseToDense","int32"),a=vs(e,"sparseValues","sparseToDense"),i=vs(s,"defaultValue","sparseToDense",a.dtype);!function(t,e,n,s){if("int32"!==t.dtype)throw new Error(`tf.sparseToDense() expects the indices to be int32 type, but the dtype was ${t.dtype}.`);if(t.rank>2)throw new Error(`sparseIndices should be a scalar, vector, or matrix, but got shape ${t.shape}.`);const r=t.rank>0?t.shape[0]:1,a=t.rank>1?t.shape[1]:1;if(n.length!==a)throw new Error(`outputShape has incorrect number of elements:, ${n.length}, should be: ${a}.`);const i=e.size;if(0!==e.rank&&(1!==e.rank||i!==r))throw new Error(`sparseValues has incorrect shape ${e.shape}, should be [] or [${r}]`);if(e.dtype!==s.dtype)throw new Error("sparseValues.dtype must match defaultValues.dtype")}(r,a,n,i);const o={sparseIndices:r,sparseValues:a,defaultValue:i},l={outputShape:n};return fs.runKernelFunc((t=>t.sparseToDense(r,a,n,i)),o,null,"SparseToDense",l)}}),td=Ns({scatterND_:function(t,e,n){const s=vs(t,"indices","scatterND","int32"),r=vs(e,"updates","scatterND");Ol(r,s,n);const a={indices:s,updates:r},i={shape:n};return fs.runKernelFunc((t=>t.scatterND(s,r,n)),a,null,"ScatterNd",i)}}),ed=Ns({gatherND_:function(t,e){const n=vs(e,"indices","gatherND","int32"),s=vs(t,"x","gatherND"),r={params:s,indices:n};return fs.runKernelFunc((t=>t.gatherND(s,n)),r,null,"GatherNd")}});function nd(t,e,n,s){const r=((t,e,n)=>{switch(t.category){case"arithmetic":return Wr((()=>((t,e,n)=>{switch(t.op){case"BiasAdd":case"AddV2":case"Add":return[Yr(np("a",t,e,n),np("b",t,e,n))];case"AddN":return[Vp(np("tensors",t,e,n))];case"FloorMod":case"Mod":return[ih(np("a",t,e,n),np("b",t,e,n))];case"Mul":return[pi(np("a",t,e,n),np("b",t,e,n))];case"RealDiv":case"Div":return[Ha(np("a",t,e,n),np("b",t,e,n))];case"DivNoNan":return[Ch(np("a",t,e,n),np("b",t,e,n))];case"FloorDiv":return[Ga(np("a",t,e,n),np("b",t,e,n))];case"Sub":return[gi(np("a",t,e,n),np("b",t,e,n))];case"Minimum":return[Si(np("a",t,e,n),np("b",t,e,n))];case"Maximum":return[hi(np("a",t,e,n),np("b",t,e,n))];case"Pow":return[sl(np("a",t,e,n),np("b",t,e,n))];case"SquaredDifference":return[hl(np("a",t,e,n),np("b",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"basic_math":return Wr((()=>((t,e,n)=>{switch(t.op){case"Abs":case"ComplexAbs":return[Xr(np("x",t,e,n))];case"Acos":return[rh(np("x",t,e,n))];case"Acosh":return[ah(np("x",t,e,n))];case"Asin":return[yh(np("x",t,e,n))];case"Asinh":return[bh(np("x",t,e,n))];case"Atan":return[xh(np("x",t,e,n))];case"Atan2":return[wh(np("x",t,e,n),np("y",t,e,n))];case"Atanh":return[vh(np("x",t,e,n))];case"Ceil":return[kh(np("x",t,e,n))];case"Complex":return[Is(np("real",t,e,n),np("imag",t,e,n))];case"Cos":return[qc(np("x",t,e,n))];case"Cosh":return[Xc(np("x",t,e,n))];case"Elu":return[ja(np("x",t,e,n))];case"Erf":return[Fh(np("x",t,e,n))];case"Exp":return[Ja(np("x",t,e,n))];case"Expm1":return[_h(np("x",t,e,n))];case"Floor":return[ni(np("x",t,e,n))];case"Log":return[fi(np("x",t,e,n))];case"Log1p":return[pl(np("x",t,e,n))];case"Imag":return[Di(np("x",t,e,n))];case"Neg":return[Ei(np("x",t,e,n))];case"Reciprocal":return[Hh(np("x",t,e,n))];case"Real":return[Fi(np("x",t,e,n))];case"Relu":return[Hi(np("x",t,e,n))];case"Round":return[jh(np("x",t,e,n))];case"Selu":return[qi(np("x",t,e,n))];case"Sigmoid":return[Xi(np("x",t,e,n))];case"Sin":return[Lu(np("x",t,e,n))];case"Sign":return[qh(np("x",t,e,n))];case"Sinh":return[Bu(np("x",t,e,n))];case"Softplus":return[no(np("x",t,e,n))];case"Sqrt":return[ao(np("x",t,e,n))];case"Square":return[Ti(np("x",t,e,n))];case"Tanh":return[lo(np("x",t,e,n))];case"Tan":return[Xh(np("x",t,e,n))];case"Relu6":case"ClipByValue":return[Aa(np("x",t,e,n),np("clipValueMin",t,e,n),np("clipValueMax",t,e,n))];case"Rsqrt":return[Zu(sp(t.inputNames[0],e,n))];case"Prod":return[Gh(np("x",t,e,n),np("axes",t,e,n))];case"LeakyRelu":return[di(np("x",t,e,n),np("alpha",t,e,n))];case"Prelu":return[Li(np("x",t,e,n),np("alpha",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"control":return(async(t,e,n)=>{switch(t.op){case"If":case"StatelessIf":{const s=np("thenBranch",t,e,n),r=np("elseBranch",t,e,n),a=np("cond",t,e,n),i=np("args",t,e,n);return(await a.data())[0]?n.functionMap[s].executeFunctionAsync(i,n.tensorArrayMap,n.tensorListMap):n.functionMap[r].executeFunctionAsync(i,n.tensorArrayMap,n.tensorListMap)}case"While":case"StatelessWhile":{const s=np("body",t,e,n),r=np("cond",t,e,n),a=np("args",t,e,n),i=await n.functionMap[r].executeFunctionAsync(a,n.tensorArrayMap,n.tensorListMap),o=a.map((t=>t.id));let l=await i[0].data();i.forEach((t=>{t.kept||-1!==o.indexOf(t.id)||t.dispose()}));let u=a;for(;l[0];){const t=u;u=await n.functionMap[s].executeFunctionAsync(u,n.tensorArrayMap,n.tensorListMap);const e=u.map((t=>t.id));t.forEach((t=>{t.kept||-1!==o.indexOf(t.id)||-1!==e.indexOf(t.id)||t.dispose()}));const a=await n.functionMap[r].executeFunctionAsync(u,n.tensorArrayMap,n.tensorListMap);l=await a[0].data(),a.forEach((t=>{t.kept||-1!==o.indexOf(t.id)||-1!==e.indexOf(t.id)||t.dispose()}))}return u}case"LoopCond":return[lp(np("pred",t,e,n))];case"Switch":{const s=np("pred",t,e,n);let r=np("data",t,e,n);return r.kept||(r=lp(r)),(await s.data())[0]?[void 0,r]:[r,void 0]}case"Merge":{const s=t.inputNames.find((t=>void 0!==sp(t,e,n)));return s?[lp(sp(s,e,n))]:void 0}case"Enter":{const s=np("frameName",t,e,n),r=np("tensor",t,e,n);return n.enterFrame(s),[lp(r)]}case"Exit":{const s=np("tensor",t,e,n);return n.exitFrame(),[lp(s)]}case"NextIteration":{const s=np("tensor",t,e,n);return n.nextIteration(),[lp(s)]}case"TensorArrayV3":{const s=np("size",t,e,n),r=np("dtype",t,e,n),a=np("elementShape",t,e,n),i=np("dynamicSize",t,e,n),o=np("clearAfterRead",t,e,n),l=np("identicalElementShapes",t,e,n),u=np("name",t,e,n),c=new Gp(u,r,s,a,l,i,o);return n.addTensorArray(c),[c.idTensor,qr(1)]}case"TensorArrayWriteV3":{const s=np("tensorArrayId",t,e,n),r=np("index",t,e,n),a=np("tensor",t,e,n),i=n.getTensorArray(s.id);return i.write(r,a),[i.idTensor]}case"TensorArrayReadV3":{const s=np("tensorArrayId",t,e,n),r=np("index",t,e,n);return[n.getTensorArray(s.id).read(r)]}case"TensorArrayGatherV3":{const s=np("tensorArrayId",t,e,n),r=np("indices",t,e,n),a=np("dtype",t,e,n);return[n.getTensorArray(s.id).gather(r,a)]}case"TensorArrayScatterV3":{const s=np("tensorArrayId",t,e,n),r=np("indices",t,e,n),a=np("tensor",t,e,n),i=n.getTensorArray(s.id);return i.scatter(r,a),[i.idTensor]}case"TensorArrayConcatV3":{const s=np("tensorArrayId",t,e,n),r=n.getTensorArray(s.id),a=np("dtype",t,e,n);return[r.concat(a)]}case"TensorArraySplitV3":{const s=np("tensorArrayId",t,e,n),r=np("tensor",t,e,n),a=np("lengths",t,e,n),i=n.getTensorArray(s.id);return i.split(a,r),[i.idTensor]}case"TensorArraySizeV3":{const s=np("tensorArrayId",t,e,n);return[qr(n.getTensorArray(s.id).size(),"int32")]}case"TensorArrayCloseV3":{const s=np("tensorArrayId",t,e,n),r=n.getTensorArray(s.id);return r.clearAndClose(),[r.idTensor]}case"TensorListSetItem":{const s=np("tensorListId",t,e,n),r=np("index",t,e,n),a=np("tensor",t,e,n),i=n.getTensorList(s.id);return i.setItem(r,a),[i.idTensor]}case"TensorListGetItem":{const s=np("tensorListId",t,e,n),r=np("index",t,e,n),a=np("elementShape",t,e,n),i=np("elementDType",t,e,n);return[n.getTensorList(s.id).getItem(r,a,i)]}case"TensorListScatterV2":case"TensorListScatter":{const s=np("indices",t,e,n),r=function(t,e,n,s){if(e.length!==t.shape[0])throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${e.length} vs. ${t.shape[0]}`);const r=Math.max(...e);if(null!=s&&-1!==s&&r>=s)throw new Error(`Max index must be < array size (${r}  vs. ${s})`);const a=new Hp([],n,t.dtype,s),i=po(t,0);return e.forEach(((t,e)=>{a.setItem(t,i[e])})),a}(np("tensor",t,e,n),s,np("elementShape",t,e,n),np("numElements",t,e,n));return n.addTensorList(r),[r.idTensor]}case"TensorListReserve":{const i=(s=np("elementShape",t,e,n),r=np("elementDType",t,e,n),a=np("numElements",t,e,n),new Hp([],s,r,a));return n.addTensorList(i),[i.idTensor]}case"TensorListGather":{const s=np("tensorListId",t,e,n),r=np("indices",t,e,n),a=np("elementShape",t,e,n),i=np("elementDType",t,e,n);return[n.getTensorList(s.id).gather(r,i,a)]}case"TensorListStack":{const s=np("tensorListId",t,e,n),r=np("elementShape",t,e,n),a=np("elementDType",t,e,n),i=np("numElements",t,e,n);return[n.getTensorList(s.id).stack(r,a,i)]}case"TensorListFromTensor":{const s=function(t,e,n){const s=t.dtype;if(t.shape.length<1)throw new Error("Tensor must be at least a vector, but saw shape: "+t.shape);if(t.dtype!==n)throw new Error(`Invalid data types; op elements ${t.dtype}, but list elements ${n}`);Up(t.shape.slice(1),e,"TensorList shape mismatch: ");const r=po(t);return new Hp(r,e,s)}(np("tensor",t,e,n),np("elementShape",t,e,n),np("elementDType",t,e,n));return n.addTensorList(s),[s.idTensor]}case"TensorListConcat":{const s=np("tensorListId",t,e,n),r=n.getTensorList(s.id),a=np("dtype",t,e,n),i=np("elementShape",t,e,n);return[r.concat(a,i)]}case"TensorListPushBack":{const s=np("tensorListId",t,e,n),r=np("tensor",t,e,n),a=n.getTensorList(s.id);return a.pushBack(r),[a.idTensor]}case"TensorListPopBack":{const s=np("tensorListId",t,e,n),r=np("elementShape",t,e,n),a=np("elementDType",t,e,n);return[n.getTensorList(s.id).popBack(r,a)]}case"TensorListSplit":{const s=np("tensor",t,e,n),r=np("elementShape",t,e,n),a=function(t,e,n){let s=0;const r=e.map((t=>(s+=t,s)));if(s!==t.shape[0])throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${s}, and tensor's shape is: ${t.shape}`);const a=0===s?0:t.size/s,i=Wr((()=>{const i=[];t=aa(t,[1,s,a]);for(let s=0;s<e.length;++s){const o=[0,0===s?0:r[s-1],0],l=[1,e[s],a];i[s]=aa(Yi(t,o,l),n)}return t.dispose(),i})),o=new Hp([],n,t.dtype,e.length);for(let t=0;t<i.length;t++)o.setItem(t,i[t]);return o}(s,np("lengths",t,e,n),r);return n.addTensorList(a),[a.idTensor]}default:throw TypeError(`Node type ${t.op} is not implemented`)}var s,r,a})(t,e,n);case"convolution":return Wr((()=>((t,e,n)=>{switch(t.op){case"Conv1D":{const s=np("stride",t,e,n),r=np("pad",t,e,n),a=np("dataFormat",t,e,n).toUpperCase(),i=np("dilation",t,e,n);return[Ba(np("x",t,e,n),np("filter",t,e,n),s,r,a,i)]}case"Conv2D":{const s=np("strides",t,e,n),r=op(t,e,n),a=np("dataFormat",t,e,n).toUpperCase(),i=np("dilations",t,e,n);return[za(np("x",t,e,n),np("filter",t,e,n),[s[1],s[2]],r,a,[i[1],i[2]])]}case"_FusedConv2D":{const{stride:s,pad:r,dataFormat:a,dilations:i,biasArg:o,preluArg:l,activationFunc:u}=qp(t,e,n);return[$o({x:np("x",t,e,n),filter:np("filter",t,e,n),strides:[s[1],s[2]],pad:r,dataFormat:a,dilations:[i[1],i[2]],bias:o,activation:u,preluActivationWeights:l})]}case"FusedDepthwiseConv2dNative":{const{stride:s,pad:r,dataFormat:a,dilations:i,biasArg:o,preluArg:l,activationFunc:u}=qp(t,e,n);return[Ro({x:np("x",t,e,n),filter:np("filter",t,e,n),strides:[s[1],s[2]],pad:r,dataFormat:a,dilations:[i[1],i[2]],bias:o,activation:u,preluActivationWeights:l})]}case"Conv2DBackpropInput":case"Conv2dTranspose":{const s=np("outputShape",t,e,n),r=np("strides",t,e,n),a=op(t,e,n);return[Wa(np("x",t,e,n),np("filter",t,e,n),s,[r[1],r[2]],a)]}case"DepthwiseConv2dNative":case"DepthwiseConv2d":{const s=np("strides",t,e,n),r=op(t,e,n),a=np("dilations",t,e,n),i=np("dataFormat",t,e,n).toUpperCase();return[Ua(np("input",t,e,n),np("filter",t,e,n),[s[1],s[2]],r,i,[a[1],a[2]])]}case"Conv3D":{const s=np("strides",t,e,n),r=np("pad",t,e,n),a=np("dataFormat",t,e,n).toUpperCase(),i=np("dilations",t,e,n);return[Va(np("x",t,e,n),np("filter",t,e,n),[s[1],s[2],s[3]],r,a,[i[1],i[2],i[3]])]}case"AvgPool":{const s=np("strides",t,e,n),r=np("pad",t,e,n),a=np("kernelSize",t,e,n);return[Na(np("x",t,e,n),[a[1],a[2]],[s[1],s[2]],r)]}case"MaxPool":{const s=np("strides",t,e,n),r=np("pad",t,e,n),a=np("kernelSize",t,e,n);return[wi(np("x",t,e,n),[a[1],a[2]],[s[1],s[2]],r)]}case"MaxPoolWithArgmax":{const s=np("strides",t,e,n),r=np("pad",t,e,n),a=np("kernelSize",t,e,n),i=np("includeBatchInIndex",t,e,n),{result:o,indexes:l}=jp(np("x",t,e,n),[a[1],a[2]],[s[1],s[2]],r,i);return[o,l]}case"AvgPool3D":{const s=np("strides",t,e,n),r=np("pad",t,e,n),a=np("kernelSize",t,e,n);return[Ia(np("x",t,e,n),[a[1],a[2],a[3]],[s[1],s[2],s[3]],r)]}case"MaxPool3D":{const s=np("strides",t,e,n),r=np("pad",t,e,n),a=np("kernelSize",t,e,n);return[vi(np("x",t,e,n),[a[1],a[2],a[3]],[s[1],s[2],s[3]],r)]}case"Dilation2D":{const s=np("strides",t,e,n),r=np("pad",t,e,n),a=np("dilations",t,e,n),i=s[1],o=s[2],l=a[1],u=a[2];return[Ih(np("x",t,e,n),np("filter",t,e,n),[i,o],r,[l,u],"NHWC")]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"creation":return Wr((()=>((t,e,n)=>{switch(t.op){case"Fill":{const s=np("shape",t,e,n),r=np("dtype",t,e,n);return[ei(s,np("value",t,e,n),r)]}case"LinSpace":return[Kp(np("start",t,e,n),np("stop",t,e,n),np("num",t,e,n))];case"Multinomial":{const s=np("logits",t,e,n),r=np("numSamples",t,e,n),a=np("seed",t,e,n);return[Xp(s,r,a)]}case"OneHot":{const s=np("indices",t,e,n),r=np("depth",t,e,n),a=np("onValue",t,e,n),i=np("offValue",t,e,n);return[Ri(s,r,a,i)]}case"Ones":return[Ni(np("shape",t,e,n),np("dtype",t,e,n))];case"OnesLike":return[Oi(np("x",t,e,n))];case"RandomUniform":return[Vi(np("shape",t,e,n),np("minval",t,e,n),np("maxval",t,e,n),np("dtype",t,e,n))];case"Range":return[Gi(np("start",t,e,n),np("stop",t,e,n),np("step",t,e,n),np("dtype",t,e,n))];case"TruncatedNormal":{const s=np("shape",t,e,n),r=np("mean",t,e,n),a=np("stdDev",t,e,n),i=np("seed",t,e,n);return[ho(s,r,a,np("dtype",t,e,n),i)]}case"Zeros":return[ki(np("shape",t,e,n),np("dtype",t,e,n))];case"ZerosLike":return[_i(np("x",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"dynamic":return(async(t,e,n)=>{switch(t.op){case"NonMaxSuppressionV5":{const{boxes:s,scores:r,maxOutputSize:a,iouThreshold:i,scoreThreshold:o,softNmsSigma:l}=Jp(t,e,n),u=await fl.nonMaxSuppressionWithScoreAsync(s,r,a,i,o,l);return[u.selectedIndices,u.selectedScores]}case"NonMaxSuppressionV4":{const{boxes:s,scores:r,maxOutputSize:a,iouThreshold:i,scoreThreshold:o}=Jp(t,e,n),l=np("padToMaxOutputSize",t,e,n),u=await fl.nonMaxSuppressionPaddedAsync(s,r,a,i,o,l);return[u.selectedIndices,u.validOutputs]}case"NonMaxSuppressionV3":case"NonMaxSuppressionV2":{const{boxes:s,scores:r,maxOutputSize:a,iouThreshold:i,scoreThreshold:o}=Jp(t,e,n);return[await fl.nonMaxSuppressionAsync(s,r,a,i,o)]}case"Where":{const s=or(np("condition",t,e,n),"bool"),r=[await Yp(s)];return s.dispose(),r}case"ListDiff":return async function(t,e){const n=vs(t,"x","setdiff1d"),s=vs(e,"y","setdiff1d");A(n.dtype===s.dtype,(()=>`x and y should have the same dtype, but got x (${n.dtype}) and y (${s.dtype}).`)),A(1===n.rank,(()=>`x should be 1D tensor, but got x (${n.shape}).`)),A(1===s.rank,(()=>`y should be 1D tensor, but got y (${s.shape}).`));const r=await n.data(),a=await s.data(),i=new Set(a);let o=0;for(let t=0;t<r.length;t++)i.has(r[t])||o++;const l=new qn([o],n.dtype),u=new qn([o],"int32");for(let t=0,e=0;t<r.length;t++)i.has(r[t])||(l.values[e]=r[t],u.values[e]=t,e++);return[l.toTensor(),u.toTensor()]}(np("x",t,e,n),np("y",t,e,n));default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n);case"evaluation":return Wr((()=>((t,e,n)=>{switch(t.op){case"TopKV2":{const s=np("x",t,e,n),r=np("k",t,e,n),a=np("sorted",t,e,n),i=Yh(s,r,a);return[i.values,i.indices]}case"Unique":{const s=np("x",t,e,n),r=Jh(s);return[r.values,r.indices]}case"UniqueV2":{const s=np("x",t,e,n),r=np("axis",t,e,n),a=Jh(s,r);return[a.values,a.indices]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"image":return Wr((()=>((t,e,n)=>{switch(t.op){case"ResizeBilinear":{const s=np("images",t,e,n),r=np("size",t,e,n),a=np("alignCorners",t,e,n);return[fl.resizeBilinear(s,[r[0],r[1]],a)]}case"ResizeNearestNeighbor":{const s=np("images",t,e,n),r=np("size",t,e,n),a=np("alignCorners",t,e,n);return[fl.resizeNearestNeighbor(s,[r[0],r[1]],a)]}case"CropAndResize":{const s=np("image",t,e,n),r=np("boxes",t,e,n),a=np("boxInd",t,e,n),i=np("cropSize",t,e,n),o=np("method",t,e,n),l=np("extrapolationValue",t,e,n);return[fl.cropAndResize(s,r,a,i,o,l)]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"graph":return Wr((()=>((t,e,n)=>{switch(t.op){case"Const":return e[t.name];case"PlaceholderWithDefault":const s=np("default",t,e,n);return[sp(t.name,e,n)||s];case"Placeholder":return[sp(t.name,e,n)];case"Identity":case"StopGradient":case"FakeQuantWithMinMaxVars":return[lp(np("x",t,e,n))];case"IdentityN":return np("x",t,e,n).map((t=>lp(t)));case"Snapshot":return[lp(np("x",t,e,n))];case"Shape":return[Ui(np("x",t,e,n).shape,"int32")];case"ShapeN":return np("x",t,e,n).map((t=>Ui(t.shape)));case"Size":return[qr(np("x",t,e,n).size,"int32")];case"Rank":return[qr(np("x",t,e,n).rank,"int32")];case"NoOp":return[qr(1)];case"Print":const r=np("x",t,e,n),a=np("data",t,e,n),i=np("message",t,e,n),o=np("summarize",t,e,n);console.warn("The graph has a tf.print() operation,usually used for debugging, which slows down performance."),console.log(i);for(let t=0;t<a.length;t++)console.log(Array.prototype.slice.call(a[t].dataSync()).slice(0,o));return[r];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"logical":return Wr((()=>((t,e,n)=>{switch(t.op){case"Equal":return[Ya(np("a",t,e,n),np("b",t,e,n))];case"NotEqual":return[Ai(np("a",t,e,n),np("b",t,e,n))];case"Greater":return[ui(np("a",t,e,n),np("b",t,e,n))];case"GreaterEqual":return[ci(np("a",t,e,n),np("b",t,e,n))];case"Less":return[gc(np("a",t,e,n),np("b",t,e,n))];case"LessEqual":return[el(np("a",t,e,n),np("b",t,e,n))];case"LogicalAnd":return[xi(np("a",t,e,n),np("b",t,e,n))];case"LogicalNot":return[Vc(np("a",t,e,n))];case"LogicalOr":return[Ph(np("a",t,e,n),np("b",t,e,n))];case"Select":case"SelectV2":return[mo(np("condition",t,e,n),np("a",t,e,n),np("b",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"matrices":return Wr((()=>((t,e,n)=>{switch(t.op){case"BatchMatMul":case"BatchMatMulV2":case"MatMul":return[Do(np("a",t,e,n),np("b",t,e,n),np("transposeA",t,e,n),np("transposeB",t,e,n))];case"Transpose":return[ia(np("x",t,e,n),np("perm",t,e,n))];case"_FusedMatMul":const[s,r]=np("fusedOps",t,e,n),a="biasadd"===s,i="prelu"===r,o=np("numArgs",t,e,n);if(a){if(i&&2!==o)throw new Error("Fused MatMul with BiasAdd and Prelu must have two extra arguments: bias and alpha.");if(!i&&1!==o)throw new Error("Fused MatMul with BiasAdd must have one extra argument: bias.")}const[l,u]=np("args",t,e,n);return[Fo({a:np("a",t,e,n),b:np("b",t,e,n),transposeA:np("transposeA",t,e,n),transposeB:np("transposeB",t,e,n),bias:l,activation:r,preluActivationWeights:u})];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"normalization":return Wr((()=>((t,e,n)=>{switch(t.op){case"FusedBatchNorm":case"FusedBatchNormV2":case"FusedBatchNormV3":return[Sa(np("x",t,e,n),np("mean",t,e,n),np("variance",t,e,n),np("offset",t,e,n),np("scale",t,e,n),np("epsilon",t,e,n))];case"LRN":return[zh(np("x",t,e,n),np("radius",t,e,n),np("bias",t,e,n),np("alpha",t,e,n),np("beta",t,e,n))];case"Softmax":return[eo(np("x",t,e,n))];case"LogSoftmax":return[bi(np("x",t,e,n))];case"SparseToDense":return[Qp(np("sparseIndices",t,e,n),np("outputShape",t,e,n),np("sparseValues",t,e,n),np("defaultValue",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"reduction":return Wr((()=>((t,e,n)=>{switch(t.op){case"Max":{const s=np("axis",t,e,n),r=np("keepDims",t,e,n);return[mi(np("x",t,e,n),s,r)]}case"Mean":{const s=np("axis",t,e,n),r=np("keepDims",t,e,n);return[Ii(np("x",t,e,n),s,r)]}case"Min":{const s=np("axis",t,e,n),r=np("keepDims",t,e,n);return[Ci(np("x",t,e,n),s,r)]}case"Sum":{const s=np("axis",t,e,n),r=np("keepDims",t,e,n);return[yi(np("x",t,e,n),s,r)]}case"All":{const s=np("axis",t,e,n),r=np("keepDims",t,e,n);return[oa(np("x",t,e,n),s,r)]}case"Any":{const s=np("axis",t,e,n),r=np("keepDims",t,e,n);return[la(np("x",t,e,n),s,r)]}case"ArgMax":{const s=np("axis",t,e,n);return[ua(np("x",t,e,n),s)]}case"ArgMin":{const s=np("axis",t,e,n);return[gh(np("x",t,e,n),s)]}case"Prod":{const s=np("axis",t,e,n),r=np("keepDims",t,e,n);return[Gh(np("x",t,e,n),s,r)]}case"Cumsum":{const s=np("axis",t,e,n),r=np("exclusive",t,e,n),a=np("reverse",t,e,n);return[Wu(np("x",t,e,n),s,r,a)]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"slice_join":return Wr((()=>((t,e,n)=>{switch(t.op){case"ConcatV2":case"Concat":{const s=np("n",t,e,n),r=np("axis",t,e,n);let a=np("tensors",t,e,n);return a=a.slice(0,s),[Fa(a,r)]}case"GatherV2":case"Gather":{const s=np("axis",t,e,n),r=np("x",t,e,n),a=np("indices",t,e,n);return[li(r,or(a,"int32"),s)]}case"ReverseV2":case"Reverse":{const s=np("axis",t,e,n),r=np("x",t,e,n);return[ji(r,s)]}case"Slice":{const s=np("begin",t,e,n),r=np("size",t,e,n);return[Yi(np("x",t,e,n),s,r)]}case"StridedSlice":{const s=np("begin",t,e,n),r=np("end",t,e,n),a=np("strides",t,e,n),i=np("beginMask",t,e,n),o=np("endMask",t,e,n),l=np("ellipsisMask",t,e,n),u=np("newAxisMask",t,e,n),c=np("shrinkAxisMask",t,e,n),h=np("x",t,e,n);return[Kh(h,s,r,a,i,o,l,u,c)]}case"Pack":return Wr((()=>{const s=np("axis",t,e,n),r=np("tensors",t,e,n),a=r[0].shape,i=io(r[0]).shape,o=r.map((t=>{const e=O(t.shape,a);if(!e&&!O(io(t).shape,i))throw new Error("the input tensors shape does not match");return e?t:aa(t,a)}));return[oo(o,s)]}));case"Unpack":{const s=np("axis",t,e,n),r=np("tensor",t,e,n);return po(r,s)}case"Tile":{const s=np("reps",t,e,n);return[Qa(np("x",t,e,n),s)]}case"Split":case"SplitV":{const s=np("axis",t,e,n),r=np("numOrSizeSplits",t,e,n),a=np("x",t,e,n);return ro(a,r,s)}case"ScatterNd":{const s=np("indices",t,e,n),r=np("values",t,e,n),a=np("shape",t,e,n);return[td(s,r,a)]}case"GatherNd":{const s=np("x",t,e,n),r=np("indices",t,e,n);return[ed(s,r)]}case"SparseToDense":{const s=np("sparseIndices",t,e,n),r=np("outputShape",t,e,n),a=np("sparseValues",t,e,n),i=np("defaultValue",t,e,n);return[Qp(s,a,r,a.dtype===i.dtype?i:or(i,a.dtype))]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"spectral":return Wr((()=>((t,e,n)=>{switch(t.op){case"FFT":return[yo(np("x",t,e,n))];case"IFFT":return[xo(np("x",t,e,n))];case"RFFT":return[bo(np("x",t,e,n))];case"IRFFT":return[wo(np("x",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"transformation":return Wr((()=>((t,e,n)=>{switch(t.op){case"Cast":return[or(np("x",t,e,n),np("dtype",t,e,n))];case"ExpandDims":{const s=np("axis",t,e,n);return[Za(np("x",t,e,n),s)]}case"Squeeze":{const s=np("axis",t,e,n);return[io(np("x",t,e,n),s)]}case"Reshape":return[aa(np("x",t,e,n),np("shape",t,e,n))];case"MirrorPad":return[Vh(np("x",t,e,n),np("padding",t,e,n),np("mode",t,e,n))];case"PadV2":case"Pad":return[Mi(np("x",t,e,n),np("padding",t,e,n),np("constantValue",t,e,n))];case"SpaceToBatchND":{const s=np("blockShape",t,e,n),r=np("paddings",t,e,n);return[Cu(np("x",t,e,n),s,r)]}case"BatchToSpaceND":{const s=np("blockShape",t,e,n),r=np("crops",t,e,n);return[th(np("x",t,e,n),s,r)]}case"DepthToSpace":{const s=np("blockSize",t,e,n),r=np("dataFormat",t,e,n).toUpperCase();return[Nh(np("x",t,e,n),s,r)]}case"BroadcastTo":return[fo(np("x",t,e,n),np("shape",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"hash_table":return(async(t,e,n,s)=>{switch(t.op){case"HashTable":case"HashTableV2":{const r=np("keyDType",t,e,n),a=np("valueDType",t,e,n),i=new Zp(r,a);return s.addHashTable(t.name,i),[i.handle]}case"LookupTableImport":case"LookupTableImportV2":{const r=np("tableHandle",t,e,n,s),a=np("keys",t,e,n),i=np("values",t,e,n),o=s.getHashTableById(r.id);return[await o.import(a,i)]}case"LookupTableFind":case"LookupTableFindV2":{const r=np("tableHandle",t,e,n,s),a=np("keys",t,e,n),i=np("defaultValue",t,e,n),o=s.getHashTableById(r.id);return[await o.find(a,i)]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n,s);case"custom":const r=ep(t.op);if(r&&r.customExecutor)return r.customExecutor(new Wp(t,e,n));throw TypeError(`Custom op ${t.op} is not registered.`);default:throw TypeError(`Unknown op '${t.op}'. File an issue at https://github.com/tensorflow/tfjs/issues so we can add it, or register a custom execution with tf.registerOp()`)}})(t,e,n);return lt(r)?r.then((t=>[].concat(t))):[].concat(r)}class sd{constructor(t={},e={},n={},s={}){this.weightMap=t,this.tensorArrayMap=e,this.tensorListMap=n,this.functionMap=s,this.rootContext={id:0,frameName:"",iterationId:0},this.contexts=[this.rootContext],this.lastId=0,this.generateCurrentContextIds()}newFrame(t,e){return{id:t,frameName:e,iterationId:0}}set currentContext(t){this.contexts!==t&&(this.contexts=t,this.generateCurrentContextIds())}get currentContext(){return this.contexts}get currentContextId(){return this._currentContextIds[0]}get currentContextIds(){return this._currentContextIds}generateCurrentContextIds(){const t=[];for(let e=0;e<this.contexts.length-1;e++){const n=this.contexts.slice(0,this.contexts.length-e);t.push(this.contextIdforContexts(n))}t.push(""),this._currentContextIds=t}contextIdforContexts(t){return t?t.map((t=>0===t.id&&0===t.iterationId?"":`${t.frameName}-${t.iterationId}`)).join("/"):""}enterFrame(t){this.contexts&&(this.lastId++,this.contexts=this.contexts.slice(),this.contexts.push(this.newFrame(this.lastId,t)),this._currentContextIds.unshift(this.contextIdforContexts(this.contexts)))}exitFrame(){if(!(this.contexts&&this.contexts.length>1))throw new Error("Cannot exit frame, the context is empty");this.contexts=this.contexts.slice(),this.contexts.splice(-1),this.currentContextIds.shift()}nextIteration(){if(!(this.contexts&&this.contexts.length>0))throw new Error("Cannot increase frame iteration, the context is empty");{this.contexts=this.contexts.slice(),this.lastId++;const t=Object.assign({},this.contexts[this.contexts.length-1]);t.iterationId+=1,t.id=this.lastId,this.contexts.splice(-1,1,t),this._currentContextIds.splice(0,1,this.contextIdforContexts(this.contexts))}}getWeight(t){return this.weightMap[t]}addTensorArray(t){this.tensorArrayMap[t.id]=t}getTensorArray(t){return this.tensorArrayMap[t]}addTensorList(t){this.tensorListMap[t.id]=t}getTensorList(t){return this.tensorListMap[t]}dispose(t){for(const e in this.tensorArrayMap)this.tensorArrayMap[e].clearAndClose(t);for(const e in this.tensorListMap)this.tensorListMap[e].clearAndClose(t)}}function rd(t,e,n,s){const r=new Set,a=[];let i=null,o=null;const l=new Set,u=Object.keys(t).map((t=>ip(t)[0]));let c=[];null!=s&&(c=s.map((t=>ip(t.name)[0])));const h=[...e];for(;h.length>0;){const t=h.pop();(ld(t)||ud(t)||cd(t))&&null==i&&(i=t,o=i.children.map((t=>t.name)).filter((t=>r.has(t)))),r.add(t.name),null==n[t.name]&&-1===u.indexOf(t.name)&&-1===c.indexOf(t.name)&&(0!==t.inputs.length?t.inputs.forEach((t=>{l.has(t.name)||(l.add(t.name),h.push(t))})):a.push(t.name))}return{inputs:t,outputs:e,usedNodes:r,missingInputs:a,dynamicNode:i,syncInputs:o}}const ad=["Switch","Merge","Enter","Exit","NextIteration","StatelessIf","StatelessWhile","if","While"],id=["NonMaxSuppressionV2","NonMaxSuppressionV3","NonMaxSuppressionV5","Where"],od=["HashTable","HashTableV2","LookupTableImport","LookupTableImportV2","LookupTableFind","LookupTableFindV2"];function ld(t){return ad.indexOf(t.op)>=0}function ud(t){return id.indexOf(t.op)>=0}function cd(t){return od.indexOf(t.op)>=0}class hd{constructor(t,e){this.graph=t,this.parent=e,this.compiledMap=new Map,this._weightMap={},this.SEPERATOR=",",this._functions={},this._functionExecutorMap={},this._outputs=t.outputs,this._inputs=t.inputs,this._initNodes=t.initNodes,this._signature=t.signature,this._functions=t.functions,null!=t.functions&&Object.keys(t.functions).forEach((e=>{this._functionExecutorMap[e]=new hd(t.functions[e],this)}))}get weightIds(){return this.parent?this.parent.weightIds:this._weightIds}get functionExecutorMap(){return this.parent?this.parent.functionExecutorMap:this._functionExecutorMap}get weightMap(){return this.parent?this.parent.weightMap:this._weightMap}set weightMap(t){const e=Object.keys(t).map((e=>t[e].map((t=>t.id))));this._weightIds=[].concat(...e),this._weightMap=t}set resourceManager(t){this._resourceManager=t}get inputs(){return this._inputs.map((t=>({name:t.name,shape:t.attrParams.shape?t.attrParams.shape.value:void 0,dtype:t.attrParams.dtype?t.attrParams.dtype.value:void 0})))}get outputs(){return this._outputs.map((t=>({name:t.name,shape:t.attrParams.shape?t.attrParams.shape.value:void 0,dtype:t.attrParams.dtype?t.attrParams.dtype.value:void 0})))}get inputNodes(){return this._inputs.map((t=>t.signatureKey||t.name))}get outputNodes(){return this._outputs.map((t=>{const e=t.signatureKey||t.name;return t.defaultOutput?`${e}:${t.defaultOutput}`:e}))}get functions(){return Object.keys(this._functions).reduce(((t,e)=>(t[e]=this._functions[e].signature,t)),{})}getCompilationKey(t,e){const n=t.map((t=>t.name)).sort(),s=e.map((t=>t.name)).sort();return n.join(this.SEPERATOR)+"--"+s.join(this.SEPERATOR)}compile(t,e){const n=rd(t,e,this.weightMap,this._initNodes),{missingInputs:s,dynamicNode:r,syncInputs:a}=n;if(null!=r)throw new Error(`This execution contains the node '${r.name}', which has the dynamic op '${r.op}'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [${a}]`);if(s.length>0){const n=e.map((t=>t.name)),r=Object.keys(t);throw new Error(`Cannot compute the outputs [${n}] from the provided inputs [${r}]. Missing the following inputs: [${s}]`)}return function(t,e,n){const{usedNodes:s,inputs:r}=n,a=[],i=Object.keys(r).map((t=>ip(t)[0])).map((e=>t.nodes[e])),o=t.initNodes;i.forEach((t=>{s.has(t.name)&&a.push(t)})),t.weights.forEach((t=>{s.has(t.name)&&a.push(t)})),null!=o&&o.forEach((t=>{s.has(t.name)&&a.push(t)}));const l=new Set,u=[];for(;a.length>0;){const t=a.pop();l.add(t.name),e[t.name]||u.push(t),t.children.forEach((t=>{!l.has(t.name)&&s.has(t.name)&&t.inputs.every((t=>l.has(t.name)))&&a.push(t)}))}return u}(this.graph,this.weightMap,n)}execute(t,e){t=this.mapInputs(t);const n=Object.keys(t).sort();this.checkInputs(t),this.checkInputShapeAndType(t),e=this.mapOutputs(e),this.checkOutputs(e);const s=n.map((t=>this.graph.nodes[ip(t)[0]])),r=e.map((t=>ip(t)[0]));let a=r.map((t=>this.graph.nodes[t]));0===a.length&&(a=this._outputs);const i=this.getCompilationKey(s,a);let o=this.compiledMap.get(i);null==o&&(o=this.compile(t,a),this.compiledMap.set(i,o));const l={},u={};return Wr((()=>{const n=new sd(this.weightMap,l,u,this.functionExecutorMap),s=Object.assign({},this.weightMap);Object.keys(t).forEach((e=>{const[n,r]=ip(e),a=[];a[r]=t[e],s[n]=a}));const a=this.getFrozenTensorIds(s),i={};for(let t=0;t<o.length;t++){const e=o[t];if(!s[e.name]){const t=nd(e,s,n,this._resourceManager);if(lt(t))throw new Error(`The execution of the op '${e.op}' returned a promise. Please use model.executeAsync() instead.`);s[e.name]=t,this.checkTensorForDisposal(e.name,e,s,n,a,r,i)}}return null==this.parent&&n.dispose(a),e.map((t=>sp(t,s,n)))}))}getFrozenTensorIds(t){const e=[].concat.apply([],Object.keys(t).map((e=>t[e])).map((t=>t.map((t=>t.id)))));return new Set(e)}checkTensorForDisposal(t,e,n,s,r,a,i){"control"!==e.category&&-1===a.indexOf(t)&&(n[t].forEach((t=>{null!=t&&(i[t.id]=(i[t.id]||0)+e.children.length)})),e.inputs.forEach((t=>{if("control"!==t.category){const e=function(t,e,n){return e[ap(t,n.currentContextId)]}(t.name,n,s);null!=e&&e.forEach((t=>{if(t&&!r.has(t.id)){const e=i[t.id];1===e?(t.dispose(),delete i[t.id]):null!=e&&i[t.id]--}}))}})))}async executeAsync(t,e){return this._executeAsync(t,e)}async _executeAsync(t,e,n=!1,s={},r={}){n||(t=this.mapInputs(t),this.checkInputs(t),this.checkInputShapeAndType(t),e=this.mapOutputs(e),this.checkOutputs(e));const a=new sd(this.weightMap,s,r,this.functionExecutorMap),i=await this.executeWithControlFlow(t,a,e,n),o=e.map((t=>sp(t,i,a))),l=o.map((t=>t.id)),u=Object.keys(t).map((e=>t[e].id)),c=new Set([...l,...u,...this.weightIds]);return Object.keys(i).forEach((t=>{i[t].forEach((t=>{!t||t.isDisposed||c.has(t.id)||t.dispose()}))})),null==this.parent&&a.dispose(c),o}async executeFunctionAsync(t,e,n){const s=t.reduce(((t,e,n)=>(t[this.inputs[n].name]=e,t)),{});return this._executeAsync(s,this.outputNodes,!0,e,n)}async executeWithControlFlow(t,e,n,s){const r=Object.keys(t),a=r.map((t=>this.graph.nodes[ip(t)[0]])),i=n.map((t=>ip(t)[0]));let o=i.map((t=>this.graph.nodes[t]));0===o.length&&(o=this._outputs);const{usedNodes:l,missingInputs:u,dynamicNode:c,syncInputs:h}=rd(t,o,this.weightMap,this._initNodes),p=[...a,...this.graph.weights,...this._initNodes||[]].map((t=>({node:t,contexts:e.currentContext}))),d=Object.assign({},this.weightMap);Object.keys(t).forEach((e=>{const[n,s]=ip(e),r=[];r[s]=t[e],d[n]=r}));const f={},m=this.getFrozenTensorIds(d),g={};for(;p.length>0;){const t=this.processStack(a,p,e,d,g,m,i,f,l);await Promise.all(t)}null!=c||s||console.warn("This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.");const y=o.filter((t=>!ld(t)&&!sp(t.name,d,e))).map((t=>t.name));if(y.length>0){let t="";throw null!=c&&(t=`Alternatively, to avoid the dynamic ops, use model.execute() and specify the inputs [${h}]`),new Error(`Cannot compute the outputs [${y}] from the provided inputs [${r}]. Consider providing the following inputs: [${u}]. ${t}`)}return d}processStack(t,e,n,s,r,a,i,o,l){const u=[];for(;e.length>0;){const t=e.pop();n.currentContext=t.contexts;let c="";if("Enter"===t.node.op&&np("isConstant",t.node,s,n)&&([c]=rp(t.node.name,n)),null==s[t.node.name]){const h=nd(t.node,s,n,this._resourceManager);c||([c]=rp(t.node.name,n));const p=n.currentContext;lt(h)?u.push(h.then((u=>(s[c]=u,n.currentContext=p,this.checkTensorForDisposal(c,t.node,s,n,a,i,o),this.processChildNodes(t.node,e,n,s,r,l),u)))):(s[c]=h,this.checkTensorForDisposal(c,t.node,s,n,a,i,o),this.processChildNodes(t.node,e,n,s,r,l))}else this.processChildNodes(t.node,e,n,s,r,l)}return u}processChildNodes(t,e,n,s,r,a){t.children.forEach((t=>{const[i]=rp(t.name,n);!r[i]&&a.has(t.name)&&("Merge"===t.op?t.inputNames.some((t=>!!sp(t,s,n)))&&(r[i]=!0,e.push({contexts:n.currentContext,node:t})):t.inputNames.every((t=>!!sp(t,s,n)))&&(r[i]=!0,e.push({contexts:n.currentContext,node:t})))}))}dispose(){Object.keys(this.weightMap).forEach((t=>this.weightMap[t].forEach((t=>t.dispose()))))}checkInputShapeAndType(t){Object.keys(t).forEach((e=>{const n=t[e],[s]=ip(e),r=this.graph.nodes[s];if(r.attrParams.shape&&r.attrParams.shape.value){const t=r.attrParams.shape.value;A(t.length===n.shape.length&&n.shape.every(((e,n)=>-1===t[n]||t[n]===e)),(()=>`The shape of dict['${r.name}'] provided in model.execute(dict) must be [${t}], but was [${n.shape}]`))}r.attrParams.dtype&&r.attrParams.dtype.value&&A(n.dtype===r.attrParams.dtype.value,(()=>`The dtype of dict['${r.name}'] provided in model.execute(dict) must be ${r.attrParams.dtype.value}, but was ${n.dtype}`))}))}mapInputs(t){const e={};for(const n in t)null!=this._signature&&null!=this._signature.inputs&&null!=this._signature.inputs[n]?e[this._signature.inputs[n].name]=t[n]:e[n]=t[n];return e}checkInputs(t){const e=Object.keys(t).filter((t=>{const[e]=ip(t);return null==this.graph.nodes[e]}));if(e.length>0)throw new Error(`The dict provided in model.execute(dict) has keys: [${e}] that are not part of graph`)}mapOutputs(t){return t.map((t=>null!=this._signature&&null!=this._signature.outputs&&null!=this._signature.outputs[t]?this._signature.outputs[t].name:t),{})}checkOutputs(t){t.forEach((t=>{const[e]=ip(t);if(!this.graph.nodes[e])throw new Error(`The output '${t}' is not found in the graph`)}))}}class pd{constructor(t={},e={}){this.hashTableNameToHandle=t,this.hashTableMap=e}addHashTable(t,e){this.hashTableNameToHandle[t]=e.handle,this.hashTableMap[e.id]=e}getHashTableHandleByName(t){return this.hashTableNameToHandle[t]}getHashTableById(t){return this.hashTableMap[t]}dispose(){for(const t in this.hashTableMap)this.hashTableMap[t].clearAndClose(),delete this.hashTableMap[t];for(const t in this.hashTableNameToHandle)this.hashTableNameToHandle[t].dispose(),delete this.hashTableNameToHandle[t]}}class dd{constructor(t,e={}){this.modelUrl=t,this.loadOptions=e,this.version="n/a",null==e&&(this.loadOptions={}),this.resourceManager=new pd}get modelVersion(){return this.version}get inputNodes(){return this.executor.inputNodes}get outputNodes(){return this.executor.outputNodes}get inputs(){return this.executor.inputs}get outputs(){return this.executor.outputs}get weights(){return this.executor.weightMap}findIOHandler(){const t=this.modelUrl;if(null!=t.load)this.handler=t;else if(null!=this.loadOptions.requestInit)this.handler=yr(t,this.loadOptions);else{const s=(e=t,n=this.loadOptions,Os.getLoadHandlers(e,n));if(0===s.length)s.push(yr(t,this.loadOptions));else if(s.length>1)throw new Error(`Found more than one (${s.length}) load handlers for URL '${[t]}'`);this.handler=s[0]}var e,n}async load(){if(this.findIOHandler(),null==this.handler.load)throw new Error("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");const t=await this.handler.load();return this.loadSync(t)}loadSync(t){this.artifacts=t;const e=this.artifacts.modelTopology;let n={};null!=this.artifacts.userDefinedMetadata&&(n=this.artifacts.userDefinedMetadata.signature),this.version=`${e.versions.producer}.${e.versions.minConsumer}`;const s=function(t,e){const n={};let s,r=0;for(const a of e){const e=a.name,i=a.dtype,o=a.shape,l=_(o);let u;if("quantization"in a){const n=a.quantization;if("uint8"===n.dtype||"uint16"===n.dtype){if(!("min"in n)||!("scale"in n))throw new Error(`Weight ${a.name} with quantization ${n.dtype} doesn't have corresponding metadata min and scale.`)}else{if("float16"!==n.dtype)throw new Error(`Weight ${a.name} has unknown quantization dtype ${n.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);if("float32"!==i)throw new Error(`Weight ${a.name} is quantized with ${n.dtype} which only supports weights of type float32 not ${i}.`)}const o=Ts[n.dtype],c=t.slice(r,r+l*o),h="uint8"===n.dtype?new Uint8Array(c):new Uint16Array(c);if("float32"===i)if("uint8"===n.dtype||"uint16"===n.dtype){u=new Float32Array(h.length);for(let t=0;t<h.length;t++){const e=h[t];u[t]=e*n.scale+n.min}}else{if("float16"!==n.dtype)throw new Error(`Unsupported quantization type ${n.dtype} for weight type float32.`);void 0===s&&(s=_s()),u=s(h)}else{if("int32"!==i)throw new Error(`Unsupported dtype in weight '${e}': ${i}`);if("uint8"!==n.dtype&&"uint16"!==n.dtype)throw new Error(`Unsupported quantization type ${n.dtype} for weight type int32.`);u=new Int32Array(h.length);for(let t=0;t<h.length;t++){const e=h[t];u[t]=Math.round(e*n.scale+n.min)}}r+=l*o}else if("string"===i){const e=_(a.shape);u=[];for(let n=0;n<e;n++){const e=new Uint32Array(t.slice(r,r+4))[0];r+=4;const n=new Uint8Array(t.slice(r,r+e));u.push(n),r+=e}}else{const s=Ts[i],a=t.slice(r,r+l*s);if("float32"===i)u=new Float32Array(a);else if("int32"===i)u=new Int32Array(a);else if("bool"===i)u=new Uint8Array(a);else{if("complex64"!==i)throw new Error(`Unsupported dtype in weight '${e}': ${i}`);{u=new Float32Array(a);const t=new Float32Array(u.length/2),s=new Float32Array(u.length/2);for(let e=0;e<t.length;e++)t[e]=u[2*e],s[e]=u[2*e+1];const r=Ss(t,o,"float32"),i=Ss(s,o,"float32");n[e]=Is(r,i),r.dispose(),i.dispose()}}r+=l*s}"complex64"!==i&&(n[e]=Ss(u,o,i))}return n}(this.artifacts.weightData,this.artifacts.weightSpecs);if(this.executor=new hd(Sp.Instance.transformGraph(e,n)),this.executor.weightMap=this.convertTensorMapToTensorsMap(s),this.executor.resourceManager=this.resourceManager,null!=t.modelInitializer){const e=Sp.Instance.transformGraph(t.modelInitializer);this.initializer=new hd(e),this.initializer.weightMap=this.executor.weightMap,this.initializer.resourceManager=this.resourceManager,this.initializer.executeAsync({},[])}return!0}async save(t,e){if("string"==typeof t){const e=Ms(t);if(0===e.length)throw new Error(`Cannot find any save handlers for URL '${t}'`);if(e.length>1)throw new Error(`Found more than one (${e.length}) save handlers for URL '${t}'`);t=e[0]}if(null==t.save)throw new Error("GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");return t.save(this.artifacts)}predict(t,e){return this.execute(t,this.outputNodes)}normalizeInputs(t){if(!(t instanceof Jn||Array.isArray(t)))return t;if((t=Array.isArray(t)?t:[t]).length!==this.inputNodes.length)throw new Error(`Input tensor count mismatch,the graph model has ${this.inputNodes.length} placeholders, while there are ${t.length} input tensors.`);return this.inputNodes.reduce(((e,n,s)=>(e[n]=t[s],e)),{})}normalizeOutputs(t){return t=t||this.outputNodes,Array.isArray(t)?t:[t]}execute(t,e){t=this.normalizeInputs(t),e=this.normalizeOutputs(e);const n=this.executor.execute(t,e);return n.length>1?n:n[0]}async executeAsync(t,e){t=this.normalizeInputs(t),e=this.normalizeOutputs(e);const n=await this.executor.executeAsync(t,e);return n.length>1?n:n[0]}convertTensorMapToTensorsMap(t){return Object.keys(t).reduce(((e,n)=>(e[n]=[t[n]],e)),{})}dispose(){this.executor.dispose(),this.initializer&&this.initializer.dispose(),this.resourceManager.dispose()}}const fd=t=>({startEndTensor:t,startPoint:Yi(t,[0,0],[-1,2]),endPoint:Yi(t,[0,2],[-1,2])}),md={strides:[8,16],anchors:[2,6]};function gd(t,e){let n,s,r;if(t.topLeft instanceof Jn&&t.bottomRight instanceof Jn){const[a,i]=Wr((()=>[Fa([gi(e-1,t.topLeft.slice(0,1)),t.topLeft.slice(1,1)]),Fa([gi(e-1,t.bottomRight.slice(0,1)),t.bottomRight.slice(1,1)])]));n=a,s=i,null!=t.landmarks&&(r=Wr((()=>{const n=gi(Ui([e-1,0]),t.landmarks),s=Ui([1,-1]);return pi(n,s)})))}else{const[a,i]=t.topLeft,[o,l]=t.bottomRight;n=[e-1-a,i],s=[e-1-o,l],null!=t.landmarks&&(r=t.landmarks.map((t=>[e-1-t[0],t[1]])))}const a={topLeft:n,bottomRight:s};return null!=r&&(a.landmarks=r),null!=t.probability&&(a.probability=t.probability instanceof Jn?t.probability.clone():t.probability),a}function yd(t,e){return Wr((()=>{let n;return n=t.hasOwnProperty("box")?t.box:t,((t,e)=>{const n=pi(t.startPoint,e),s=pi(t.endPoint,e),r=Oa([n,s],1);return fd(r)})(n,e).startEndTensor.squeeze()}))}class bd{constructor(t,e,n,s,r,a){this.blazeFaceModel=t,this.width=e,this.height=n,this.maxFaces=s,this.anchorsData=function(t,e,n){const s=[];for(let r=0;r<n.strides.length;r++){const a=n.strides[r],i=Math.floor((e+a-1)/a),o=Math.floor((t+a-1)/a),l=n.anchors[r];for(let t=0;t<i;t++){const e=a*(t+.5);for(let t=0;t<o;t++){const n=a*(t+.5);for(let t=0;t<l;t++)s.push([n,e])}}}return s}(e,n,md),this.anchors=uo(this.anchorsData),this.inputSizeData=[e,n],this.inputSize=Ui([e,n]),this.iouThreshold=r,this.scoreThreshold=a}async getBoundingBoxes(t,e,n=!0){const[s,r,a]=Wr((()=>{const e=t.resizeBilinear([this.width,this.height]),n=pi(gi(e.div(255),.5),2),s=this.blazeFaceModel.predict(n).squeeze(),r=function(t,e,n){const s=Yi(t,[0,1],[-1,2]),r=Yr(s,e),a=Yi(t,[0,3],[-1,2]),i=Ha(a,n),o=Ha(r,n),l=Ha(i,2),u=gi(o,l),c=Yr(o,l),h=pi(u,n),p=pi(c,n);return Oa([h,p],1)}(s,this.anchors,this.inputSize),a=Yi(s,[0,0],[-1,1]);return[s,r,Xi(a).squeeze()]})),i=console.warn;console.warn=()=>{};const o=fl.nonMaxSuppression(r,a,this.maxFaces,this.iouThreshold,this.scoreThreshold);console.warn=i;const l=await o.array();o.dispose();let u=l.map((t=>Yi(r,[t,0],[1,-1])));e||(u=await Promise.all(u.map((async t=>{const e=await t.array();return t.dispose(),e}))));const c=t.shape[1],h=t.shape[2];let p;p=e?Ha([h,c],this.inputSize):[h/this.inputSizeData[0],c/this.inputSizeData[1]];const d=[];for(let t=0;t<u.length;t++){const r=u[t],i=Wr((()=>{const i=fd(r instanceof Jn?r:uo(r));if(!n)return i;const o=l[t];let u;return u=e?this.anchors.slice([o,0],[1,2]):this.anchorsData[o],{box:i,landmarks:Yi(s,[o,5],[1,-1]).squeeze().reshape([6,-1]),probability:Yi(a,[o],[1]),anchor:u}}));d.push(i)}return r.dispose(),a.dispose(),s.dispose(),{boxes:d,scaleFactor:p}}async estimateFaces(t,e=!1,n=!1,s=!0){const[,r]=function(t){return t instanceof Jn?[t.shape[0],t.shape[1]]:[t.height,t.width]}(t),a=Wr((()=>(t instanceof Jn||(t=xr(t)),t.toFloat().expandDims(0)))),{boxes:i,scaleFactor:o}=await this.getBoundingBoxes(a,e,s);return a.dispose(),e?i.map((t=>{const e=yd(t,o);let a={topLeft:e.slice([0],[2]),bottomRight:e.slice([2],[2])};if(s){const{landmarks:e,probability:n,anchor:s}=t,r=e.add(s).mul(o);a.landmarks=r,a.probability=n}return n&&(a=gd(a,r)),a})):Promise.all(i.map((async t=>{const e=yd(t,o);let a;if(s){const[n,s,r]=await Promise.all([t.landmarks,e,t.probability].map((async t=>t.array()))),i=t.anchor,[l,u]=o,c=n.map((t=>[(t[0]+i[0])*l,(t[1]+i[1])*u]));a={topLeft:s.slice(0,2),bottomRight:s.slice(2),landmarks:c,probability:r},(t=>{t.startEndTensor.dispose(),t.startPoint.dispose(),t.endPoint.dispose()})(t.box),t.landmarks.dispose(),t.probability.dispose()}else{const t=await e.array();a={topLeft:t.slice(0,2),bottomRight:t.slice(2)}}return e.dispose(),n&&(a=gd(a,r)),a})))}}let xd;function wd(){return null==xd&&(xd=fs.backend.epsilon()),xd}class vd extends Error{constructor(t){super(t),Object.setPrototypeOf(this,vd.prototype)}}class kd extends Error{constructor(t){super(t),Object.setPrototypeOf(this,kd.prototype)}}class Nd extends Error{constructor(t){super(t),Object.setPrototypeOf(this,Nd.prototype)}}class Id extends Error{constructor(t){super(t),Object.setPrototypeOf(this,Id.prototype)}}class Cd extends Error{constructor(t){super(t),Object.setPrototypeOf(this,Cd.prototype)}}function Sd(t,e){if(Array.isArray(t)){let n=[];for(let s=0;s<e;s++)n=n.concat(t);return n}{const n=new Array(e);return n.fill(t),n}}function Td(t,e){if(!t)throw new Cd(e)}function $d(t,e){let n=0;for(const s of t)s===e&&n++;return n}function Ed(t){return 1===t.length?t[0]:t}function Ad(t){return Array.isArray(t)?t:[t]}function Rd(t){const e=t.replace(/(.)([A-Z][a-z0-9]+)/g,"$1_$2").replace(/([a-z])([A-Z])/g,"$1_$2").toLowerCase();return"_"!==e[0]?e:"private"+e}function Dd(t){return t.length<=1||-1===t.indexOf("_")?t:t.replace(/[_]+(\w|$)/g,((t,e)=>e.toUpperCase()))}Error;let Fd={};function _d(t){if(null==t)return null;const e={};return e.className=t.getClassName(),e.config=t.getConfig(),e}function Od(t){if(null!=t&&"object"==typeof t)if(Array.isArray(t))t.forEach((t=>Od(t)));else{const e=Object.keys(t);for(const n of e){const e=t[n];null!=e&&"object"==typeof e&&(Array.isArray(e)||"ndarray"!==e.type||"number"!=typeof e.value?Od(e):t[n]=e.value)}}}function Md(t,e={},n={},s="object",r=!1){if("string"==typeof t){const r=t;let a;if(r in n)a=n[r];else if(r in Fd)a=Fd[r];else if(a=e[r],null==a)throw new Nd(`Unknown ${s}: ${t}. This may be due to one of the following reasons:\n1. The ${s} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${s} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);return a}{const a=t;if(null==a.className||null==a.config)throw new Nd(s+": Improper config format: "+JSON.stringify(a)+".\n'className' and 'config' must set.");const i=a.className;let o,l;if(i in n?[o,l]=n[i]:i in Fd?[o,l]=Fd.className:i in e&&([o,l]=e[i]),null==o)throw new Nd(`Unknown ${s}: ${i}. This may be due to one of the following reasons:\n1. The ${s} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${s} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);if(null!=l){const t={};for(const e of Object.keys(Fd))t[e]=Fd[e];for(const e of Object.keys(n))t[e]=n[e];a.config.customObjects=t;const e=Object.assign({},Fd);for(const t of Object.keys(n))Fd[t]=n[t];Od(a.config);const s=l(o,a.config,n,r);return Fd=Object.assign({},e),s}{const t=Object.assign({},Fd);for(const t of Object.keys(n))Fd[t]=n[t];const e=new o(a.config);return Fd=Object.assign({},t),e}}}function Ld(t,e){return-1*function(t,e){return t<e?-1:t>e?1:0}(t,e)}function zd(t){if(null==t)return t;const e=[];for(const n of t)-1===e.indexOf(n)&&e.push(n);return e}function Bd(t){if(null==t)throw new Nd("Invalid value in obj: "+JSON.stringify(t));for(const e in t)if(t.hasOwnProperty(e))return!1;return!0}function Pd(t,e,n){if(null!=n&&t.indexOf(n)<0)throw new Nd(`${n} is not a valid ${e}.  Valid values are ${t} or null/undefined.`)}function Wd(t,e,n=0,s=1/0){return Td(n>=0),Td(s>=n),Array.isArray(t)&&t.length>=n&&t.length<=s&&t.every((t=>typeof t===e))}function Vd(t,e){Array.isArray(t)?(A(t.length>0,(()=>e+" is unexpectedly an empty array.")),t.forEach(((t,n)=>Vd(t,`element ${n+1} of ${e}`)))):A(Number.isInteger(t)&&t>0,(()=>`Expected ${e} to be a positive integer, but got `+Ud(t)+"."))}function Ud(t){return null===t?"null":Array.isArray(t)?"["+t.map((t=>Ud(t))).join(",")+"]":"string"==typeof t?`"${t}"`:""+t}function Gd(t){return"relu"===t?"relu":"linear"===t?"linear":"elu"===t?"elu":null}function Hd(t,e){return Wr((()=>ao(yi(pi(t,t),e,!0))))}class jd extends Or{getConfig(){return{}}}class qd extends jd{constructor(t){super(),this.defaultMaxValue=2,this.defaultAxis=0,this.maxValue=null!=t.maxValue?t.maxValue:this.defaultMaxValue,this.axis=null!=t.axis?t.axis:this.defaultAxis}apply(t){return Wr((()=>{const e=Hd(t,this.axis),n=Aa(e,0,this.maxValue);return pi(t,Ha(n,Yr(wd(),e)))}))}getConfig(){return{maxValue:this.maxValue,axis:this.axis}}}qd.className="MaxNorm",Lr(qd);class Kd extends jd{constructor(t){super(),this.defaultAxis=0,this.axis=null!=t.axis?t.axis:this.defaultAxis}apply(t){return Wr((()=>Ha(t,Yr(wd(),Hd(t,this.axis)))))}getConfig(){return{axis:this.axis}}}Kd.className="UnitNorm",Lr(Kd);class Xd extends jd{apply(t){return Hi(t)}}Xd.className="NonNeg",Lr(Xd);class Yd extends jd{constructor(t){super(),this.defaultMinValue=0,this.defaultMaxValue=1,this.defaultRate=1,this.defaultAxis=0,this.minValue=null!=t.minValue?t.minValue:this.defaultMinValue,this.maxValue=null!=t.maxValue?t.maxValue:this.defaultMaxValue,this.rate=null!=t.rate?t.rate:this.defaultRate,this.axis=null!=t.axis?t.axis:this.defaultAxis}apply(t){return Wr((()=>{const e=Hd(t,this.axis),n=Yr(pi(this.rate,Aa(e,this.minValue,this.maxValue)),pi(1-this.rate,e));return pi(t,Ha(n,Yr(wd(),e)))}))}getConfig(){return{minValue:this.minValue,maxValue:this.maxValue,rate:this.rate,axis:this.axis}}}Yd.className="MinMaxNorm",Lr(Yd);const Jd={maxNorm:"MaxNorm",minMaxNorm:"MinMaxNorm",nonNeg:"NonNeg",unitNorm:"UnitNorm"};function Zd(t){return _d(t)}function Qd(t,e={}){return Md(t,Mr.getMap().classNameMap,e,"constraint")}function tf(t){return null==t?null:"string"==typeof t?Qd({className:t in Jd?Jd[t]:t,config:{}}):t instanceof jd?t:Qd(t)}const ef=["channelsFirst","channelsLast"],nf=["valid","same","causal"],sf=["max","avg"],rf=["sum","mul","concat","ave"],af=new Map;function of(t){Pd(ef,"DataFormat",t)}function lf(t){Pd(nf,"PaddingMode",t)}function uf(t){Pd(sf,"PoolMode",t)}const cf=[];function hf(t,e){cf.push(t);try{const t=e();return cf.pop(),t}catch(t){throw cf.pop(),t}}function pf(t){if(!mf(t))throw new Error("Not a valid tensor name: '"+t+"'");return(0===cf.length?"":cf.join("/")+"/")+t}function df(t){if(!mf(t))throw new Error("Not a valid tensor name: '"+t+"'");af.has(t)||af.set(t,0);const e=af.get(t);if(af.set(t,af.get(t)+1),e>0){const n=`${t}_${e}`;return af.set(n,1),n}return t}const ff=new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);function mf(t){return!!t.match(ff)}function gf(t,e,n){null==e&&(e=0),null==n&&(n=t.length);let s=1;for(let r=e;r<n;++r)s*=t[r];return s}function yf(t){return Ui(t=Array.isArray(t)?new Float32Array(t):t)}function bf(t){return Ci(yf(t)).dataSync()[0]}function xf(t){return mi(yf(t)).dataSync()[0]}function wf(t,e){if(e<t)throw new Nd(`end (${e}) < begin (${t}) is forbidden.`);const n=[];for(let s=t;s<e;++s)n.push(s);return n}function vf(t,e){return t.asType(e)}function kf(t,e=-1){const n=t.shape.slice();return e<0&&(e=n.length+e+1),n.splice(e,0,1),t.reshape(n)}function Nf(t,e,n){return Wr((()=>{switch(t.rank){case 1:return Ji(t,e,n);case 2:return Zi(t,[e,0],[n,t.shape[1]]);case 3:return Qi(t,[e,0,0],[n,t.shape[1],t.shape[2]]);case 4:return to(t,[e,0,0,0],[n,t.shape[1],t.shape[2],t.shape[3]]);case 5:return Yi(t,[e,0,0,0,0],[n,t.shape[1],t.shape[2],t.shape[3],t.shape[4]]);case 6:return Yi(t,[e,0,0,0,0,0],[n,t.shape[1],t.shape[2],t.shape[3],t.shape[4],t.shape[5]]);default:throw new Nd("sliceAlongFirstAxis() received an unsupported tensor rank: "+t.rank)}}))}function If(t,e,n){return Wr((()=>{switch(t.rank){case 1:return Ji(t,e,n);case 2:return Zi(t,[0,e],[t.shape[0],n]);case 3:return Qi(t,[0,0,e],[t.shape[0],t.shape[1],n]);case 4:return to(t,[0,0,0,e],[t.shape[0],t.shape[1],t.shape[2],n]);default:throw new Nd("sliceAlongLastAxis() received an unsupported tensor rank: "+t.rank)}}))}function Cf(t,e,n,s){return Wr((()=>{switch(t.rank){case 1:return Ji(t,e,n);case 2:switch(s){case 1:return Nf(t,e,n);case 2:return If(t,e,n);default:throw new Nd("The axis is not within the rank of the tensor "+s)}case 3:switch(s){case 1:return Nf(t,e,n);case 2:return Qi(t,[0,e,0],[t.shape[0],n,t.shape[2]]);case 3:return If(t,e,n);default:throw new Nd("The axis is not within the rank of the tensor "+s)}case 4:switch(s){case 1:return Nf(t,e,n);case 2:return to(t,[0,e,0,0],[t.shape[0],n,t.shape[2],t.shape[3]]);case 3:return to(t,[0,0,e,0],[t.shape[0],t.shape[1],n,t.shape[3]]);case 4:return If(t,e,n);default:throw new Nd("The axis is not within the rank of the tensor "+s)}default:throw new Nd("sliceAlongLastAxis() received an unsupported tensor rank: "+t.rank)}}))}function Sf(t,e=-1){let n;return e<0&&(n=t[0].rank,e=0!==n?n:0),e===t[0].rank&&(e=-1),Fa(t,e)}function Tf(t,e){switch(t.rank){case 1:return _a([t,e]);case 2:return Oa([t,e],0);case 3:return Ma([t,e],0);case 4:return La([t,e],0);default:throw new Nd("concatAlongFirstAxis() received an unsupported tensor rank: "+t.rank)}}function $f(t,e){if(Array.isArray(e)||(e=[e]),t.rank!==e.length)throw new Nd(`The length of input n (${e.length}) does not match the number of dimensions in input x (${t.rank})`);return Qa(t,e)}function Ef(t,e=0,n=1,s,r){return Wi(t,e,n,s,r)}function Af(t,e,n,s){if(t.rank<2||e.rank<2)throw new Id(`dot requires both inputs to be rank >= 2 but got x shape = ${t.shape} and y shape = ${e.shape}`);if(e.rank>=3&&t.shape.slice(-1)[0]!==e.shape.slice(-2)[0])throw new Id(`If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ${t.shape} and  y shape = `+e.shape);if(2===t.rank&&2===e.rank)return Fo({a:t,b:e,transposeA:!1,transposeB:!1,bias:s?Ff(t.rank,s,"channelsLast"):null,activation:n});{const r=t.shape.slice(),a=r.pop();t=t.reshape([-1,a]);const i=e.shape.slice(),o=i.pop(),l=i.pop(),u=[...i,o],c=Array.from({length:e.rank},((t,n)=>0===n?e.rank-2:n<=e.rank-2?n-1:n));e=e.transpose(c).reshape([l,-1]);const h=[...r,...u];return Fo({a:t,b:e,transposeA:!1,transposeB:!1,bias:s?Ff(t.rank,s,"channelsLast"):null,activation:n}).reshape(h)}}function Rf(t,e,n){return Wr((()=>(e=Array.isArray(e)?Ui(e,"int32"):e.toInt(),li(t,e,n))))}function Df(t){return pi(t,t)}function Ff(t,e,n){const s=e.shape;if(1!==e.rank&&e.rank!==t)throw new Nd("Unexpected bias dimensions: "+e.rank+"; expected it to be 1 or "+t);if(5===t){if("channelsFirst"===n)return 1===s.length?e.reshape([1,s[0],1,1,1]):e.reshape([1,s[3],s[0],s[1],s[2]]);if("channelsLast"===n)return 1===s.length?e.reshape([1,1,1,1,s[0]]):e.reshape([1].concat(s))}else if(4===t){if("channelsFirst"===n)return 1===s.length?e.reshape([1,s[0],1,1]):e.reshape([1,s[2],s[0],s[1]]);if("channelsLast"===n)return 1===s.length?e.reshape([1,1,1,s[0]]):e.reshape([1].concat(s))}else if(3===t){if("channelsFirst"===n)return 1===s.length?e.reshape([1,s[0],1]):e.reshape([1,s[1],s[0]]);if("channelsLast"===n)return 1===s.length?e.reshape([1,1,s[0]]):e.reshape([1].concat(s))}else if(t<3)return e;throw new Nd("Unsupported input rank by biasAdd: "+e.rank)}function _f(t,e,n){return Wr((()=>(null==n&&(n="channelsLast"),of(n),t.add(Ff(t.rank,e,n)))))}function Of(t,e,n,s){return Wr((()=>go(t,e,n,s)))}function Mf(t,e,n=!1){return n?t():e()}const Lf=["fanIn","fanOut","fanAvg"],zf=["normal","uniform","truncatedNormal"];class Bf extends Or{fromConfigUsesCustomObjects(){return!1}getConfig(){return{}}}class Pf extends Bf{apply(t,e){return ki(t,e)}}Pf.className="Zeros",Lr(Pf);class Wf extends Bf{apply(t,e){return Ni(t,e)}}Wf.className="Ones",Lr(Wf);class Vf extends Bf{constructor(t){if(super(),"object"!=typeof t)throw new Nd("Expected argument of type ConstantConfig but got "+t);if(void 0===t.value)throw new Nd("config must have value set but got "+t);this.value=t.value}apply(t,e){return Wr((()=>pi(qr(this.value),Ni(t,e))))}getConfig(){return{value:this.value}}}Vf.className="Constant",Lr(Vf);class Uf extends Bf{constructor(t){super(),this.DEFAULT_MINVAL=-.05,this.DEFAULT_MAXVAL=.05,this.minval=t.minval||this.DEFAULT_MINVAL,this.maxval=t.maxval||this.DEFAULT_MAXVAL,this.seed=t.seed}apply(t,e){return Vi(t,this.minval,this.maxval,e)}getConfig(){return{minval:this.minval,maxval:this.maxval,seed:this.seed}}}Uf.className="RandomUniform",Lr(Uf);class Gf extends Bf{constructor(t){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=t.mean||this.DEFAULT_MEAN,this.stddev=t.stddev||this.DEFAULT_STDDEV,this.seed=t.seed}apply(t,e){if("float32"!==(e=e||"float32")&&"int32"!==e)throw new Id(`randomNormal does not support dType ${e}.`);return Ef(t,this.mean,this.stddev,e,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}Gf.className="RandomNormal",Lr(Gf);class Hf extends Bf{constructor(t){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=t.mean||this.DEFAULT_MEAN,this.stddev=t.stddev||this.DEFAULT_STDDEV,this.seed=t.seed}apply(t,e){if("float32"!==(e=e||"float32")&&"int32"!==e)throw new Id(`truncatedNormal does not support dType ${e}.`);return ho(t,this.mean,this.stddev,e,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}Hf.className="TruncatedNormal",Lr(Hf);class jf extends Bf{constructor(t){super(),this.gain=null!=t.gain?t.gain:1}apply(t,e){return Wr((()=>{if(2!==t.length||t[0]!==t[1])throw new Nd("Identity matrix initializer can only be used for 2D square matrices.");return pi(this.gain,ti(t[0]))}))}getConfig(){return{gain:this.gain}}}jf.className="Identity",Lr(jf);class qf extends Bf{constructor(t){if(super(),t.scale<0)throw new Nd("scale must be a positive float. Got: "+t.scale);var e;this.scale=null==t.scale?1:t.scale,this.mode=null==t.mode?"fanIn":t.mode,e=this.mode,Pd(Lf,"FanMode",e),this.distribution=null==t.distribution?"normal":t.distribution,function(t){Pd(zf,"Distribution",t)}(this.distribution),this.seed=t.seed}apply(t,e){const n=function(t,e="channelsLast"){let n,s;if(of(e),2===t.length)n=t[0],s=t[1];else if(-1!==[3,4,5].indexOf(t.length)){if("channelsFirst"===e){const e=gf(t,2);n=t[1]*e,s=t[0]*e}else if("channelsLast"===e){const e=gf(t,0,t.length-2);n=t[t.length-2]*e,s=t[t.length-1]*e}}else{const e=gf(t);n=Math.sqrt(e),s=Math.sqrt(e)}return[n,s]}(t),s=n[0],r=n[1];let a=this.scale;if("fanIn"===this.mode?a/=Math.max(1,s):"fanOut"===this.mode?a/=Math.max(1,r):a/=Math.max(1,(s+r)/2),"normal"===this.distribution){const n=Math.sqrt(a);if("float32"!==(e=e||"float32")&&"int32"!==e)throw new Id(`${this.getClassName()} does not support dType ${e}.`);return ho(t,0,n,e,this.seed)}{const n=Math.sqrt(3*a);return Vi(t,-n,n,e)}}getConfig(){return{scale:this.scale,mode:this.mode,distribution:this.distribution,seed:this.seed}}}qf.className="VarianceScaling",Lr(qf);class Kf extends qf{constructor(t){super({scale:1,mode:"fanAvg",distribution:"uniform",seed:null==t?null:t.seed})}getClassName(){return qf.className}}Kf.className="GlorotUniform",Lr(Kf);class Xf extends qf{constructor(t){super({scale:1,mode:"fanAvg",distribution:"normal",seed:null==t?null:t.seed})}getClassName(){return qf.className}}Xf.className="GlorotNormal",Lr(Xf);class Yf extends qf{constructor(t){super({scale:2,mode:"fanIn",distribution:"normal",seed:null==t?null:t.seed})}getClassName(){return qf.className}}Yf.className="HeNormal",Lr(Yf);class Jf extends qf{constructor(t){super({scale:2,mode:"fanIn",distribution:"uniform",seed:null==t?null:t.seed})}getClassName(){return qf.className}}Jf.className="HeUniform",Lr(Jf);class Zf extends qf{constructor(t){super({scale:1,mode:"fanIn",distribution:"normal",seed:null==t?null:t.seed})}getClassName(){return qf.className}}Zf.className="LeCunNormal",Lr(Zf);class Qf extends qf{constructor(t){super({scale:1,mode:"fanIn",distribution:"uniform",seed:null==t?null:t.seed})}getClassName(){return qf.className}}Qf.className="LeCunNormal",Lr(Qf);class tm extends Bf{constructor(t){if(super(),this.DEFAULT_GAIN=1,this.gain=null==t.gain?this.DEFAULT_GAIN:t.gain,this.seed=t.seed,null!=this.seed)throw new Id("Random seed is not implemented for Orthogonal Initializer yet.")}apply(t,e){return Wr((()=>{if(t.length<2)throw new Id("Shape must be at least 2D.");t[0]*t[1]>2e3&&console.warn(`Orthogonal initializer is being called on a matrix with more than 2000 (${t[0]*t[1]}) elements: Slowness may result.`);const e=Ef(t[0]>t[1]?[t[1],t[0]]:t,0,1,"float32");let n=ml.gramSchmidt(e);return t[0]>t[1]&&(n=n.transpose()),pi(this.gain,n)}))}getConfig(){return{gain:this.gain,seed:this.seed}}}tm.className="Orthogonal",Lr(tm);const em={constant:"Constant",glorotNormal:"GlorotNormal",glorotUniform:"GlorotUniform",heNormal:"HeNormal",heUniform:"HeUniform",identity:"Identity",leCunNormal:"LeCunNormal",leCunUniform:"LeCunUniform",ones:"Ones",orthogonal:"Orthogonal",randomNormal:"RandomNormal",randomUniform:"RandomUniform",truncatedNormal:"TruncatedNormal",varianceScaling:"VarianceScaling",zeros:"Zeros"};function nm(t,e={}){return Md(t,Mr.getMap().classNameMap,e,"initializer")}function sm(t){return _d(t)}function rm(t){if("string"==typeof t){const e=t in em?em[t]:t;if("GlorotNormal"===e)return new Xf;if("GlorotUniform"===e)return new Kf;if("HeNormal"===e)return new Yf;if("HeUniform"===e)return new Jf;if("LeCunNormal"===e)return new Zf;if("LeCunUniform"===e)return new Qf;{const t={};return t.className=e,t.config={},nm(t)}}return t instanceof Bf?t:nm(t)}let am=0;function im(){return am++}const om={};function lm(t=""){return t in om||(om[t]=0),om[t]+=1,t+om[t].toString()}function um(t){return Array.isArray(t)&&Array.isArray(t[0])}function cm(t){return 0===t.length?[]:Array.isArray(t[0])?t:[t]}function hm(t){let e;if(Array.isArray(t)){if(1!==t.length)throw new Nd("Expected Tensor length to be 1; got "+t.length);e=t[0]}else e=t;return e}function pm(t){if(Array.isArray(t)&&Array.isArray(t[0])){if(1===t.length)return(t=t)[0];throw new Nd("Expected exactly 1 Shape; got "+t.length)}return t}function dm(t){let e=0;for(const n of t)0===n.shape.length?e+=1:e+=n.shape.reduce(((t,e)=>t*e));return e}class fm{constructor(t,e="float32",n="Variable",s=!0,r=null){this.dtype=null==e?"float32":e,this.shape=t.shape,this.id=im(),n=null==n?"Variable":n,this.originalName=pf(n),this.name=df(this.originalName),this.trainable_=s,this.constraint=r,this.val=function(t,e=!0,n,s){return fs.makeVariable(t,e,n,s)}(t,this.trainable_,this.name,this.dtype)}read(){return this.assertNotDisposed(),this.val}write(t){return this.assertNotDisposed(),function(t,e){if(t.shape.toString()!==e.shape.toString())throw new Error("Shape mismatch: "+JSON.stringify(t.shape)+" vs. "+JSON.stringify(e.shape))}(this.val,t),this.val.id!==t.id&&(this.val.assign(t),null!=this.constraint&&this.val.assign(this.constraint.apply(this.val))),this}dispose(){this.assertNotDisposed(),this.val.dispose()}assertNotDisposed(){if(this.val.isDisposed)throw new Error(`LayersVariable ${this.name} is already disposed.`)}get trainable(){return this.trainable_}set trainable(t){this.trainable_=t,this.val.trainable=t}}function mm(t){return t.map((t=>t.read()))}function gm(t){t.forEach((t=>{t[0].write(t[1])}))}class ym{constructor(t){this.dtype=t.dtype,this.shape=t.shape,null!=t.shape?this.ndim=t.shape.length:this.ndim=t.ndim,this.maxNDim=t.maxNDim,this.minNDim=t.minNDim,this.axes=t.axes||{}}}class bm{constructor(t,e,n,s,r,a,i){this.dtype=t,this.shape=e,this.sourceLayer=n,this.inputs=s,this.callArgs=r,this.outputTensorIndex=i,this.id=im(),null!=a&&(this.originalName=pf(a),this.name=df(this.originalName)),this.rank=e.length}}let xm=0;class wm{constructor(t,e){this.callArgs=e,this.id=xm++,this.outboundLayer=t.outboundLayer,this.inboundLayers=t.inboundLayers,this.nodeIndices=t.nodeIndices,this.tensorIndices=t.tensorIndices,this.inputTensors=t.inputTensors,this.outputTensors=t.outputTensors,this.inputMasks=t.inputMasks,this.outputMasks=t.outputMasks,this.inputShapes=t.inputShapes,this.outputShapes=t.outputShapes;for(const e of t.inboundLayers)null!=e&&e.outboundNodes.push(this);t.outboundLayer.inboundNodes.push(this)}getConfig(){const t=[];for(const e of this.inboundLayers)null!=e?t.push(e.name):t.push(null);return{outboundLayer:this.outboundLayer?this.outboundLayer.name:null,inboundLayers:t,nodeIndices:this.nodeIndices,tensorIndices:this.tensorIndices}}}let vm=0;class km extends Or{constructor(t={}){super(),this._callHook=null,this._addedWeightNames=[],this._stateful=!1,this.id=vm++,this.activityRegularizer=null,this.inputSpec=null,this.supportsMasking=!1,this._trainableWeights=[],this._nonTrainableWeights=[],this._losses=[],this._updates=[],this._built=!1,this.inboundNodes=[],this.outboundNodes=[];let e=t.name;if(!e){const t=this.getClassName();e=Rd(t)+"_"+lm(t)}if(this.name=e,this.trainable_=null==t.trainable||t.trainable,null!=t.inputShape||null!=t.batchInputShape){let e;if(null!=t.batchInputShape)e=t.batchInputShape;else if(null!=t.inputShape){let n=null;null!=t.batchSize&&(n=t.batchSize),e=[n].concat(t.inputShape)}this.batchInputShape=e;let n=t.dtype;null==n&&(n=t.inputDType),null==n&&(n="float32"),this.dtype=n}null!=t.weights?this.initialWeights=t.weights:this.initialWeights=null,this._refCount=null,this.fastWeightInitDuringBuild=!1}static nodeKey(t,e){return t.name+"_ib-"+e.toString()}getNodeAtIndex(t,e){if(0===this.inboundNodes.length)throw new kd(`The layer has never been called and thus has no defined ${e}.`);if(this.inboundNodes.length<=t)throw new Nd(`Asked to get ${e} at node ${t}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);return this.inboundNodes[t]}getInputAt(t){return Ed(this.getNodeAtIndex(t,"input").inputTensors)}getOutputAt(t){return Ed(this.getNodeAtIndex(t,"output").outputTensors)}get input(){if(this.inboundNodes.length>1)throw new vd("Layer "+this.name+' has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use `getInputAt(nodeIndex)` instead.');if(0===this.inboundNodes.length)throw new vd("Layer "+this.name+" is not connected, no input to return.");return Ed(this.getNodeAtIndex(0,"input").inputTensors)}get output(){if(0===this.inboundNodes.length)throw new vd("Layer "+this.name+" has no inbound nodes.");if(this.inboundNodes.length>1)throw new vd("Layer "+this.name+' has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use `getOutputAt(nodeIndex)` instead.');return Ed(this.getNodeAtIndex(0,"output").outputTensors)}get losses(){return this._losses}calculateLosses(){return this.losses.map((t=>t()))}get updates(){return this._updates}get built(){return this._built}set built(t){this._built=t}get trainable(){return this.trainable_}set trainable(t){this._trainableWeights.forEach((e=>e.trainable=t)),this.trainable_=t}get trainableWeights(){return this.trainable_?this._trainableWeights.filter((t=>t.trainable)):[]}set trainableWeights(t){this._trainableWeights=t}get nonTrainableWeights(){return this.trainable?this._trainableWeights.filter((t=>!t.trainable)).concat(this._nonTrainableWeights):this._trainableWeights.concat(this._nonTrainableWeights)}set nonTrainableWeights(t){this._nonTrainableWeights=t}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}get stateful(){return this._stateful}resetStates(){if(!this.stateful)throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.")}assertInputCompatibility(t){if(t=Ad(t),null==this.inputSpec||0===this.inputSpec.length)return;const e=Ad(this.inputSpec);if(t.length!==e.length)throw new Nd(`Layer ${this.name} expects ${e.length} inputs, but it received ${t.length} input tensors. Input received: `+t);for(let n=0;n<t.length;n++){const s=t[n],r=e[n];if(null==r)continue;const a=s.rank;if(null!=r.ndim&&a!==r.ndim)throw new Nd(`Input ${n} is incompatible with layer ${this.name}: expected ndim=${r.ndim}, found ndim=${a}`);if(null!=r.maxNDim&&a>r.maxNDim)throw new Nd(`Input ${n} is incompatible with layer ${this.name}: expected max_ndim=${r.maxNDim}, found ndim=${a}`);if(null!=r.minNDim&&a<r.minNDim)throw new Nd(`Input ${n} is incompatible with layer ${this.name}: expected min_ndim=${r.minNDim}, found ndim=${a}.`);if(null!=r.dtype&&s.dtype!==r.dtype)throw new Nd(`Input ${n} is incompatible with layer ${this.name} : expected dtype=${r.dtype}, found dtype=${s.dtype}.`);if(r.axes){const t=s.shape;for(const e in r.axes){const s=Number(e),a=r.axes[e],i=s>=0?t[s]:t[t.length+s];if(null!=a&&-1===[a,null].indexOf(i))throw new Nd(`Input ${n} is incompatible with layer ${this.name}: expected axis ${s} of input shape to have value ${a} but got shape ${t}.`)}}if(null!=r.shape)for(let t=0;t<r.shape.length;++t){const e=r.shape[t],a=s.shape[t];if(null!=e&&null!=a&&e!==a)throw new Nd(`Input ${n} is incompatible with layer ${this.name}: expected shape=${r.shape}, found shape=${s.shape}.`)}}}call(t,e){return t}invokeCallHook(t,e){null!=this._callHook&&this._callHook(t,e)}setCallHook(t){this._callHook=t}clearCallHook(){this._callHook=null}apply(t,e){e=e||{},this.assertNotDisposed();const n=Ad(t);let s=!0;for(const t of n)if(!(t instanceof bm)){s=!1;break}let r=!0;for(const t of n)if(t instanceof bm){r=!1;break}if(s===r)throw new Nd("Arguments to apply() must be all SymbolicTensors or all Tensors");return hf(this.name,(()=>{if(!this.built){this.assertInputCompatibility(t);const e=[];for(const n of Ad(t))e.push(n.shape);this.build(Ed(e)),this.built=!0,this.initialWeights&&this.setWeights(this.initialWeights),null===this._refCount&&r&&(this._refCount=1)}if(this.assertInputCompatibility(t),r){let s=this.call(t,e);const r=Ad(s),a=[];for(let t of r)-1!==n.indexOf(t)&&(t=t.clone()),a.push(t);if(s=Ed(a),null!=this.activityRegularizer)throw new Id("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return s}{const n=function(t){t=Ad(t);const e=[];for(const n of t)e.push(n.shape);return Ed(e)}(t),s=this.computeOutputShape(n);let r;const a="float32";if(this.warnOnIncompatibleInputShape(Array.isArray(t)?n[0]:n),r=null!=s&&s.length>0&&Array.isArray(s[0])?s.map(((n,s)=>new bm(a,n,this,Ad(t),e,this.name,s))):new bm(a,s,this,Ad(t),e,this.name),this.addInboundNode(t,r,null,null,n,s,e),this._refCount++,null!=this.activityRegularizer)throw new Id("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return r}}))}warnOnIncompatibleInputShape(t){if(null!=this.batchInputShape)if(t.length!==this.batchInputShape.length)console.warn("The rank of the input tensor provided (shape: "+JSON.stringify(t)+") does not match that of the "+`batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer `+this.name);else{let e=!1;this.batchInputShape.forEach(((n,s)=>{null!=n&&null!=t[s]&&t[s]!==n&&(e=!0)})),e&&console.warn(`The shape of the input tensor (${JSON.stringify(t)}) does not match the expectation of layer ${this.name}: `+JSON.stringify(this.batchInputShape))}}get outputShape(){if(null==this.inboundNodes||0===this.inboundNodes.length)throw new vd(`The layer ${this.name} has never been called and thus has no defined output shape.`);const t=[];for(const e of this.inboundNodes){const n=JSON.stringify(e.outputShapes);-1===t.indexOf(n)&&t.push(n)}if(1===t.length){const t=this.inboundNodes[0].outputShapes;return Array.isArray(t)&&Array.isArray(t[0])&&1===t.length?t[0]:t}throw new vd(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`)}countParams(){if(!this.built)throw new kd(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);return dm(this.weights)}build(t){this.built=!0}getWeights(t=!1){return mm(t?this.trainableWeights:this.weights)}setWeights(t){Wr((()=>{const e=this.weights;if(e.length!==t.length)throw new Nd(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${t.length}, but the layer was expecting ${e.length} weights. Provided weights: ${t}...`);if(0===e.length)return;const n=[],s=mm(e);for(let r=0;r<s.length;++r){const a=s[r],i=e[r],o=t[r];if(!O(a.shape,o.shape))throw new Nd(`Layer weight shape ${a.shape} not compatible with provided weight shape `+o.shape);n.push([i,o])}gm(n)}))}addWeight(t,e,n,s,r,a,i){if(-1!==this._addedWeightNames.indexOf(t))throw new Nd(`Duplicate weight name ${t} for layer ${this.name}`);this._addedWeightNames.push(t),null==n&&(n="float32"),this.fastWeightInitDuringBuild&&(s=rm("zeros"));const o=s.apply(e,n),l=new fm(o,n,t,a,i);return o.dispose(),null!=r&&this.addLoss((()=>r.apply(l.read()))),null==a&&(a=!0),a?this._trainableWeights.push(l):this._nonTrainableWeights.push(l),l}setFastWeightInitDuringBuild(t){this.fastWeightInitDuringBuild=t}addLoss(t){null==t||Array.isArray(t)&&0===t.length||(t=Ad(t),void 0!==this._losses&&null!==this._losses&&this.losses.push(...t))}computeOutputShape(t){return t}computeMask(t,e){if(!this.supportsMasking){if(null!=e){if(!Array.isArray(e))throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);e.forEach((t=>{if(null!=t)throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`)}))}return null}return e}addInboundNode(t,e,n,s,r,a,i=null){const o=Ad(t);e=Ad(e),n=Ad(n),s=Ad(s),r=cm(r),a=cm(a);const l=[],u=[],c=[];for(const t of o)l.push(t.sourceLayer),u.push(t.nodeIndex),c.push(t.tensorIndex);new wm({outboundLayer:this,inboundLayers:l,nodeIndices:u,tensorIndices:c,inputTensors:o,outputTensors:e,inputMasks:n,outputMasks:s,inputShapes:r,outputShapes:a},i);for(let t=0;t<e.length;t++)e[t].sourceLayer=this,e[t].nodeIndex=this.inboundNodes.length-1,e[t].tensorIndex=t}getConfig(){const t={name:this.name,trainable:this.trainable};return null!=this.batchInputShape&&(t.batchInputShape=this.batchInputShape),null!=this.dtype&&(t.dtype=this.dtype),t}disposeWeights(){return this.weights.forEach((t=>t.dispose())),this.weights.length}assertNotDisposed(){if(0===this._refCount)throw new Error(`Layer '${this.name}' is already disposed.`)}dispose(){if(!this.built)throw new Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);if(null===this._refCount)throw new Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);this.assertNotDisposed();let t=0;return 0==--this._refCount&&(t=this.disposeWeights()),{refCountAfterDispose:this._refCount,numDisposedVariables:t}}}function Nm(t,e,n){if((null==e||null!=n&&n>0)&&(e=t.sourceLayer,n=t.nodeIndex),0===e.inboundNodes.length)return[t];{const t=e.inboundNodes[n];if(0===t.inboundLayers.length)return t.inputTensors;{const e=[];for(let n=0;n<t.inboundLayers.length;n++){const s=Nm(t.inputTensors[n],t.inboundLayers[n],t.nodeIndices[n]);for(const t of s)-1===e.indexOf(t)&&e.push(t)}return e}}}class Im extends km{constructor(t){if(super({dtype:t.dtype,name:null!=t.name?t.name:lm("input").toString()}),null==t.batchSize&&(t.batchSize=null),null==t.sparse&&(t.sparse=!1),this.trainable=!1,this.built=!0,this.sparse=t.sparse,null!=t.inputShape&&null!=t.batchInputShape)throw new Nd("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");let e=t.batchInputShape;if(null==e){if(null==t.inputShape)throw new Nd("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");e=[t.batchSize].concat(t.inputShape)}else if(null!=t.batchSize)throw new Nd("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");const n=t.dtype||"float32";this.batchInputShape=e,this.dtype=n,this.inputSpec=[{shape:e}];const s=new bm(this.dtype,this.batchInputShape,this,[],{},this.name);s.nodeIndex=0,s.tensorIndex=0,new wm({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:[s],outputTensors:[s],inputMasks:[null],outputMasks:[null],inputShapes:[e],outputShapes:[e]})}apply(t,e){throw new Nd("Cannot pass any input to an InputLayer's apply() method. InputLayer name: "+this.name)}dispose(){return{refCountAfterDispose:this._refCount,numDisposedVariables:0}}getConfig(){return{batchInputShape:this.batchInputShape,dtype:this.dtype,sparse:this.sparse,name:this.name}}}async function Cm(t){if(null==t)return;const e=[],n=[],s=[];for(const r in t){const a=t[r];if("number"!=typeof a){const t=a;e.push(t.data()),n.push(r),s.push(t)}}if(e.length>0){const r=await Promise.all(e);for(let e=0;e<r.length;++e)t[n[e]]=r[e][0];Vr(s)}}function Sm(t){if(null!=t)for(const e in t){const n=t[e];"number"!=typeof n&&n.dispose()}}var Tm;Im.className="InputLayer",Lr(Im),function(t){t[t.SILENT=0]="SILENT",t[t.VERBOSE=1]="VERBOSE"}(Tm||(Tm={}));class $m{constructor(){this.validationData=null}setParams(t){this.params=t}async onEpochBegin(t,e){}async onEpochEnd(t,e){}async onBatchBegin(t,e){}async onBatchEnd(t,e){}async onTrainBegin(t){}async onTrainEnd(t){}setModel(t){}}class Em{constructor(t,e=10){null==t&&(t=[]),this.callbacks=t,this.queueLength=e}append(t){this.callbacks.push(t)}setParams(t){for(const e of this.callbacks)e.setParams(t)}setModel(t){for(const e of this.callbacks)e.setModel(t)}async onEpochBegin(t,e){null==e&&(e={});for(const n of this.callbacks)await n.onEpochBegin(t,e)}async onEpochEnd(t,e){null==e&&(e={});for(const n of this.callbacks)await n.onEpochEnd(t,e)}async onBatchBegin(t,e){null==e&&(e={});for(const n of this.callbacks)await n.onBatchBegin(t,e)}async onBatchEnd(t,e){null==e&&(e={});for(const n of this.callbacks)await n.onBatchEnd(t,e)}async onTrainBegin(t){null==t&&(t={});for(const e of this.callbacks)await e.onTrainBegin(t)}async onTrainEnd(t){null==t&&(t={});for(const e of this.callbacks)await e.onTrainEnd(t)}}class Am extends $m{constructor(){super()}async onEpochBegin(t){this.seen=0,this.totals={}}async onBatchEnd(t,e){null==e&&(e={});const n=null==e.size?0:e.size;this.seen+=n;for(const t in e){const s=e[t];if("number"==typeof s)this.totals.hasOwnProperty(t)||(this.totals[t]=0),this.totals[t]=this.totals[t]+s*n;else{let e;t in this.totals?e=this.totals[t]:this.totals[t]=0;const r=Wr((()=>Yr(this.totals[t],pi(s,n))));this.totals[t]=r,null!=e&&e.dispose()}}}async onEpochEnd(t,e){if(null!=e)for(const t of this.params.metrics)null!=this.totals[t]&&("number"==typeof this.totals[t]?e[t]=this.totals[t]/this.seen:Wr((()=>{const n=pi(Ha(1,this.seen),this.totals[t]);e[t]=n,this.totals[t].dispose(),Ur(e[t])})))}}class Rm extends $m{async onTrainBegin(t){this.epoch=[],this.history={}}async onEpochEnd(t,e){null==e&&(e={}),this.epoch.push(t);for(const t in e)null==this.history[t]&&(this.history[t]=[]),this.history[t].push(e[t])}async syncData(){const t=[],e=[],n=[];for(const s in this.history){const r=this.history[s];for(let a=0;a<r.length;++a)if("number"!=typeof r[a]){const i=r[a];t.push(i.data()),e.push(s),n.push(a)}}const s=await Promise.all(t);for(let t=0;t<s.length;++t)this.history[e[t]][n[t]].dispose(),this.history[e[t]][n[t]]=s[t][0]}}class Dm extends $m{constructor(t,e){if(super(),this.currentEpoch=0,this.yieldEvery=e||"auto","auto"===this.yieldEvery&&(this.yieldEvery=125),"never"===this.yieldEvery&&null!=t.onYield)throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");X(this.yieldEvery)&&(this.maybeWait=function(t,e){let n,s=Gn();return(...r)=>{const a=Gn();return a-s<e||(s=a,n=t(...r)),n}}(this.maybeWait.bind(this),this.yieldEvery)),this.trainBegin=t.onTrainBegin,this.trainEnd=t.onTrainEnd,this.epochBegin=t.onEpochBegin,this.epochEnd=t.onEpochEnd,this.batchBegin=t.onBatchBegin,this.batchEnd=t.onBatchEnd,this.yield=t.onYield}async maybeWait(t,e,n){const s=[];null!=this.yield&&(await Cm(n),s.push(this.yield(t,e,n))),s.push(Sl()),await Promise.all(s)}async onEpochBegin(t,e){this.currentEpoch=t,null!=this.epochBegin&&(await Cm(e),await this.epochBegin(t,e))}async onEpochEnd(t,e){const n=[];null!=this.epochEnd&&(await Cm(e),n.push(this.epochEnd(t,e))),"epoch"===this.yieldEvery&&n.push(Sl()),await Promise.all(n)}async onBatchBegin(t,e){null!=this.batchBegin&&(await Cm(e),await this.batchBegin(t,e))}async onBatchEnd(t,e){const n=[];null!=this.batchEnd&&(await Cm(e),n.push(this.batchEnd(t,e))),"batch"===this.yieldEvery?n.push(Sl()):X(this.yieldEvery)&&n.push(this.maybeWait(this.currentEpoch,t,e)),await Promise.all(n)}async onTrainBegin(t){null!=this.trainBegin&&(await Cm(t),await this.trainBegin(t))}async onTrainEnd(t){null!=this.trainEnd&&(await Cm(t),await this.trainEnd(t))}}function Fm(t,e){return null==t&&(t={}),t instanceof $m?[t]:Array.isArray(t)&&t[0]instanceof $m?t:Ad(t).map((t=>new Dm(t,e)))}class _m{constructor(){}static registerCallbackConstructor(t,e){A(t>=0&&Number.isInteger(t),(()=>"Verbosity level is expected to be an integer >= 0, but got "+t)),_m.checkForDuplicate(e),null==_m.constructors[t]&&(_m.constructors[t]=[]),_m.constructors[t].push(e)}static checkForDuplicate(t){for(const e in _m.constructors)_m.constructors[+e].forEach((e=>{if(e===t)throw new Nd("Duplicate callback constructor.")}))}static clear(){_m.constructors={}}static createCallbacks(t){const e=[];for(const n in _m.constructors){const s=+n;t>=s&&e.push(..._m.constructors[s])}return e.map((t=>new t))}}function Om(t,e,n,s,r,a,i,o,l){const u=new Rm,c=[new Am,..._m.createCallbacks(e)];null!=t&&c.push(...t),c.push(u);const h=new Em(c);return h.setParams({epochs:n,initialEpoch:s,samples:r,steps:a,batchSize:i,verbose:e,doValidation:o,metrics:l}),{callbackList:h,history:u}}function Mm(t,e={},n=!1){return Md(t,Mr.getMap().classNameMap,e,"layer",n)}function Lm(t,e){return Wr((()=>{"float32"!==t.dtype&&(t=t.asType("float32"));const n=yi(Df(t),e,!0),s=ei(n.shape,wd()),r=ao(hi(n,s));return Ha(t,r)}))}function zm(t,e){return Wr((()=>Ii(Df(gi(e,t)),-1)))}function Bm(t,e){return Wr((()=>Ii(Xr(gi(e,t)),-1)))}function Pm(t,e){return Wr((()=>{const n=gi(t,e),s=Aa(Xr(t),wd(),Number.MAX_VALUE),r=Xr(Ha(n,s));return pi(100,Ii(r,-1))}))}function Wm(t,e,n=!1){return Wr((()=>{if(n)e=eo(e);else{const t=yi(e,e.shape.length-1,!0);e=Ha(e,t)}return e=Aa(e,wd(),1-wd()),Ei(yi(pi(t.toFloat(),fi(e)),e.shape.length-1))}))}function Vm(t,e,n=!1){return Wr((()=>{const s=ni(function(t){const e=[gf(t.shape)];return t.reshape(e)}(t)).toInt(),r=(e=Aa(e,wd(),1-wd())).shape;return Wm(Ri(s,r[r.length-1]).reshape(r),e,n)}))}function Um(t,e){return Wr((()=>{let n;return n=Aa(e,wd(),1-wd()),n=fi(Ha(n,gi(1,n))),Ii(function(t,e){if(!O(t.shape,e.shape))throw new Nd(`logits and labels must have the same shape, but got shapes ${JSON.stringify(t.shape)} and ${JSON.stringify(e.shape)}`);return Wr((()=>{const n=e.relu(),s=e.abs().neg();return n.sub(e.mul(t)).add(s.exp().log1p())}))}(t,n),-1)}))}function Gm(t,e){return Wr((()=>{const n=Lm(t,-1),s=Lm(e,-1),r=pi(n,s);return Ei(yi(r,-1))}))}_m.constructors={};const Hm={meanSquaredError:zm,meanAbsoluteError:Bm,meanAbsolutePercentageError:Pm,meanSquaredLogarithmicError:function(t,e){return Wr((()=>{const n=Aa(e,wd(),Number.MAX_VALUE),s=fi(Yr(1,n)),r=Aa(t,wd(),Number.MAX_VALUE),a=fi(Yr(1,r));return Ii(Df(gi(s,a)),-1)}))},squaredHinge:function(t,e){return Wr((()=>{const n=hi(0,gi(1,pi(t,e)));return Ii(Df(n),-1)}))},hinge:function(t,e){return Wr((()=>{const n=hi(0,gi(1,pi(t,e)));return Ii(n,-1)}))},categoricalHinge:function(t,e){return Wr((()=>{const n=yi(pi(t,e),-1),s=mi(pi(gi(1,t),e),-1);return hi(0,Yr(1,gi(s,n)))}))},logcosh:function(t,e){return Wr((()=>{const n=Math.log(2),s=gi(e,t),r=gi(Yr(s,no(pi(-2,s))),n);return Ii(r,-1)}))},categoricalCrossentropy:Wm,sparseCategoricalCrossentropy:Vm,binaryCrossentropy:Um,kullbackLeiblerDivergence:function(t,e){return Wr((()=>{const n=Aa(t,wd(),1),s=Aa(e,wd(),1);return yi(pi(t,fi(Ha(n,s))),-1)}))},poisson:function(t,e){return Wr((()=>{const n=fi(Yr(wd(),e));return Ii(gi(e,pi(t,n)),-1)}))},cosineProximity:Gm};function jm(t){if("string"==typeof t){if(t in Hm)return Hm[t];let e="Unknown loss "+t;throw t.toLowerCase().includes("softmaxcrossentropy")&&(e=`Unknown loss ${t}. Use "categoricalCrossentropy" as the string name for tf.losses.softmaxCrossEntropy`),new Nd(e)}return t}function qm(t,e){return Wr((()=>{const n=pi(.5,Oi(e)),s=vf(ui(e,n),t.dtype);return Ii(Ya(t,s),-1)}))}function Km(t,e){return Wr((()=>vf(Ya(ua(t,-1),ua(e,-1)),"float32")))}function Xm(t,e){return Um(t,e)}function Ym(t,e){return t.rank===e.rank&&(t=t.squeeze([t.rank-1])),(e=e.argMax(-1)).dtype!==t.dtype&&(e=e.asType(t.dtype)),Ya(t,e).asType("float32")}const Jm=Wm,Zm=Vm,Qm={binaryAccuracy:qm,categoricalAccuracy:Km,precision:function(t,e){return Wr((()=>{const n=function(t,e){return Wr((()=>xi(t.equal(1),e.equal(1)).sum().cast("float32")))}(t,e),s=function(t,e){return Wr((()=>xi(t.equal(0),e.equal(1)).sum().cast("float32")))}(t,e),r=n.add(s);return mo(ui(r,0),n.div(r),0).cast("float32")}))},categoricalCrossentropy:Jm,sparseCategoricalCrossentropy:Zm,mse:zm,MSE:zm,mae:Bm,MAE:Bm,mape:Pm,MAPE:Pm,cosine:Gm};function tg(t){if("string"==typeof t&&t in Qm)return Qm[t];if("string"!=typeof t&&null!=t)return t;throw new Nd("Unknown metric "+t)}function eg(t){if(Td(null!==t,"Unknown LossOrMetricFn "+t),"string"==typeof t)return t;{let e;for(const n of Object.keys(Hm))if(Hm[n]===t){e=n;break}if(void 0!==e)return e;for(const n of Object.keys(Qm))if(Qm[n]===t){e=n;break}return void 0!==e?e:t.name}}function ng(t,e,n=!1){if(null==t||"object"!=typeof t||Object.getPrototypeOf(t)!==Object.prototype||!sg(t))throw new Error("User-defined metadata is expected to be a JSON object, but is not.");if(n){const n=JSON.stringify(t);n.length>1048576&&console.warn(`User-defined metadata of model "${e}" is too large in size (length=${n.length} when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= 1048576.`)}}function sg(t){if(null===t)return!0;if("object"==typeof t){if(Object.getPrototypeOf(t)===Object.prototype){const e=Object.keys(t);for(const n of e){if("string"!=typeof n)return!1;if(!sg(t[n]))return!1}return!0}if(Array.isArray(t)){for(const e of t)if(!sg(e))return!1;return!0}return!1}{const e=typeof t;return"string"===e||"number"===e||"boolean"===e}}function rg(t,e,n=console.log){let s="";for(let n=0;n<t.length;++n)n>0&&(s=s.slice(0,s.length-1)+" "),s+=t[n],s=s.slice(0,e[n]),s+=" ".repeat(e[n]-s.length);n(s)}function ag(t,e,n){let s;try{s=JSON.stringify(t.outputShape)}catch(t){s="multiple"}rg([`${t.name} (${t.getClassName()})`,s,t.countParams().toString()],e,n)}function ig(t,e,n,s){let r;try{r=JSON.stringify(t.outputShape)}catch(t){r="multiple"}const a=[];for(const e of t.inboundNodes)if(!(null!=n&&n.length>0&&-1===n.indexOf(e)))for(let t=0;t<e.inboundLayers.length;++t){const n=e.inboundLayers[t].name,s=e.nodeIndices[t],r=e.tensorIndices[t];a.push(`${n}[${s}][${r}]`)}const i=t.name,o=t.getClassName(),l=0===a.length?"":a[0];rg([`${i} (${o})`,r,t.countParams().toString(),l],e,s);for(let t=1;t<a.length;++t)rg(["","","",a[t]],e,s)}function og(t,e,n){return("inboundNodes"===t||"outputLayers"===t||"inputLayers"===t)&&0===e&&"string"==typeof n}function lg(t,e){if(null===t)return null;if("string"==typeof t)return Dd(t);if("number"==typeof t||"boolean"==typeof t)return t;if(t instanceof Array){const n=[],s=t.length;for(let r=0;r<s;++r){const s=t[r];og(e,r,s)?n.push(s):n.push(lg(s,e))}return n}{const e={};for(const n of Object.keys(t)){const s=t[n];if("name"===n&&"string"==typeof s)e[n]=s;else{const t=Dd(n);e[t]=lg(s,t)}}return e}}function ug(t,e){if(null==t)return null;if("string"==typeof t)return Rd(t);if("number"==typeof t||"boolean"==typeof t)return t;if(t instanceof Array){const n=[],s=t.length;for(let r=0;r<s;++r){const s=t[r];og(e,r,s)?n.push(s):n.push(ug(s,e))}return n}{const e={};for(const n of Object.keys(t)){const s=t[n];e[Rd(n)]="name"!==n&&"className"!==n||"string"!=typeof s?ug(s,n):s}return e}}class cg{constructor(t){if(this.id2Value={},this.id2Mask={},this.name2Id={},t instanceof cg)for(const e in t.id2Value)this.id2Value[e]=t.id2Value[e],e in t.id2Mask&&(this.id2Mask[e]=t.id2Mask[e]);else{if(null==t)return;for(const e of t)this.add(e.key,e.value)}}add(t,e,n){if(null!=this.id2Value[t.id])throw new Nd(`Duplicate key: name=${t.name}, id=${t.id}`);return this.id2Value[t.id]=function(t,e){if(null==t.dtype||t.dtype===e.dtype)return e;try{return or(e,t.dtype)}catch(n){throw new Nd(`The dtype of the feed (${e.dtype}) can not be cast to the dtype of the key '${t.name}' (${t.dtype}).`)}}(t,e),this.name2Id[t.name]=t.id,null!=n&&(this.id2Mask[t.id]=n),this}addFeed(t){this.add(t.key,t.value)}hasKey(t){return null!=this.id2Value[t.id]}names(){return Object.keys(this.name2Id)}getValue(t){if(t instanceof bm){if(null==this.id2Value[t.id])throw new Nd("Nonexistent key: "+t.name);return this.id2Value[t.id]}{const e=this.name2Id[t];if(null==e)throw new Nd("Feed dict has no SymbolicTensor name: "+t);return this.id2Value[e]}}getMask(t){if(t instanceof bm){if(null==this.id2Value[t.id])throw new Nd("Nonexistent key: "+t.name);return this.id2Mask[t.id]}{const e=this.name2Id[t];if(null==e)throw new Nd("Feed dict has no SymbolicTensor name: "+t);return this.id2Mask[e]}}disposeMasks(){null!=this.id2Mask&&Vr(this.id2Mask)}}const hg={},pg={};function dg(t,e,n,s){const r=null!=n&&n.training,a=Array.isArray(t),i=a?t:[t],o=i.map((t=>t.name)),l=[],u=e.names();for(const t of o)-1!==u.indexOf(t)?l.push(e.getValue(t)):l.push(null);null!=s&&(s.maxNumTensors=-1/0,s.minNumTensors=1/0);const c=o.join(",")+"|"+e.names().join(",");let h,p;if(null==hg[c]){const t=function(t,e){A(null!=t&&t.length>0,(()=>"Expected at least one fetch, got none"));let n=[],s={};if(1===t.length){const r=mg(t[0],e);n=r.sorted,s=r.recipientMap}else{const r=new Set;for(const a of t){const{sorted:t,recipientMap:i}=mg(a,e);for(const e of t)r.has(e.name)||(n.push(e),r.add(e.name));for(const t in i)null==s[t]&&(s[t]=new Set),i[t].forEach((e=>s[t].add(e)))}}return{sorted:n,recipientCounts:fg(s)}}(i,e);h=t.sorted,p=t.recipientCounts,hg[c]=h,pg[c]=p}h=hg[c],p={},r||Object.assign(p,pg[c]);const d=new cg(e);for(let t=0;t<h.length;++t){if(null!=s){const t=Pr().numTensors;t>s.maxNumTensors&&(s.maxNumTensors=t),t<s.minNumTensors&&(s.minNumTensors=t)}const a=h[t],i=a.sourceLayer;if(i instanceof Im)continue;const u=[],c=[],f=[];let m=!1;for(const t of a.inputs){const n=d.getValue(t),s=d.getMask(t);u.push(n),c.push(s),null!=s&&(m=!0),r||(p[t.name]--,0!==p[t.name]||e.hasKey(t)||-1!==o.indexOf(t.name)||n.isDisposed||!0===t.sourceLayer.stateful||f.push(n))}m&&((n=n||{}).mask=c[0]);const g=Ad(i.apply(u,n));let y=null;i.supportsMasking&&(y=i.computeMask(u,c));const b=gg(a),x=Array.isArray(b)?b:[b];for(let t=0;t<x.length;++t){d.hasKey(x[t])||d.add(x[t],g[t],Array.isArray(y)?y[0]:y);const e=o.indexOf(x[t].name);-1!==e&&(l[e]=g[t])}r||Vr(f)}return d.disposeMasks(),a?l:l[0]}function fg(t){const e={};for(const n in t)e[n]=t[n].size;return e}function mg(t,e){const n=new Set,s=[],r={};for(const t of e.names())n.add(t);const a=[],i=[];for(a.push(t);a.length>0;){const t=a[a.length-1];if(n.has(t.name)){a.pop();continue}const e=i[i.length-1]===a.length-1;if(0===t.inputs.length||e)a.pop(),s.push(t),n.add(t.name),e&&i.pop();else{i.push(a.length-1);for(const e of t.inputs)null==r[e.name]&&(r[e.name]=new Set),r[e.name].add(t.name),n.has(e.name)||a.push(e)}}return{sorted:s,recipientMap:r}}function gg(t){let e;if(1===t.sourceLayer.inboundNodes.length)e=t.sourceLayer.output;else{let n=null;for(let e=0;e<t.sourceLayer.inboundNodes.length;++e)for(const s of t.sourceLayer.inboundNodes[e].outputTensors)if(s.id===t.id){n=e;break}e=t.sourceLayer.getOutputAt(n)}return e}class yg extends km{constructor(t){if(super({}),this.containerNodes=new Set,this.name=t.name,null==this.name){const t=this.getClassName().toLowerCase();this.name=lm(t)}if(this.supportsMasking=!1,this.trainable_=!0,Array.isArray(t.inputs)?this.inputs=t.inputs.slice():this.inputs=[t.inputs],Array.isArray(t.outputs)?this.outputs=t.outputs.slice():this.outputs=[t.outputs],zd(this.inputs).length!==this.inputs.length)throw new Nd("The list of inputs passed to the model is redundant. All inputs should only appear once. Found: "+this.inputs.map((t=>t.name)));zd(this.outputs).length!==this.outputs.length&&console.warn("The list of outputs passed to the model is redundant. All outputs should only appear once. Found: "+this.outputs.map((t=>t.name))),this.inputLayers=[],this.inputLayersNodeIndices=[],this.inputLayersTensorIndices=[],this.outputLayers=[],this.outputLayersNodeIndices=[],this.outputLayersTensorIndices=[],this.layers=[],this.internalContainerRefs=[];for(const t of this.outputs){const e=t.sourceLayer,n=t.nodeIndex,s=t.tensorIndex;this.outputLayers.push(e),this.outputLayersNodeIndices.push(n),this.outputLayersTensorIndices.push(s)}for(const t of this.inputs){const e=t.sourceLayer,n=t.nodeIndex,s=t.tensorIndex;Td(0===n,"input layer has >1 nodes"),Td(0===s,"input layer has >1 tensors"),this.inputLayers.push(e),this.inputLayersNodeIndices.push(n),this.inputLayersTensorIndices.push(s)}this.inputNames=[],this.outputNames=[],this.feedInputShapes=[],this.feedInputNames=[],this.feedOutputNames=[];for(let e=0;e<this.inputLayers.length;e++){const n=this.inputLayers[e];if(!(n instanceof Im))throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${t.inputs}. Input ${e} (0-based) originates from layer type ${n.getClassName()}.`);this.inputNames.push(n.name),this.feedInputShapes.push(n.batchInputShape),this.feedInputNames.push(n.name)}for(const t of this.outputLayers)this.outputNames.push(t.name);this.internalInputShapes=this.inputs.map((t=>t.shape)),this.internalOutputShapes=this.outputs.map((t=>t.shape));const e={},n={},s={},r={},a={},i=[],o=(t,e,n,s,r,l)=>{null!=s&&null!=r&&null!=l||(s=t.sourceLayer,r=t.nodeIndex,l=t.tensorIndex);const u=s.inboundNodes[r];if(-1!==n.indexOf(u))throw new kd(`The tensor ${t.name} at layer "${s.name}" is part of a cycle.`);if(-1!==e.indexOf(u))return;this.containerNodes.add(yg.nodeKey(s,r)),s.id in a||(a[s.id]=Object.keys(a).length),-1===n.indexOf(u)&&n.push(u);const c=u.inboundLayers.length;for(let t=0;t<c;t++){const s=u.inputTensors[t],r=u.inboundLayers[t],a=u.nodeIndices[t],i=u.tensorIndices[t];o(s,e,n,r,a,i)}for(e.push(u);n.indexOf(u)>=0;)n.splice(n.indexOf(u),1);i.push(u)},l=[],u=[];for(const t of this.outputs)o(t,l,u);const c=i.slice().reverse();for(const t of c){n[t.id]=t,t.id in e||(e[t.id]=0);let a=e[t.id];const i=null==s[t.outboundLayer.id]?0:s[t.outboundLayer.id];a=Math.max(a,i),s[t.outboundLayer.id]=a,r[t.outboundLayer.id]=t.outboundLayer,e[t.id]=a;for(let s=0;s<t.inboundLayers.length;s++){const r=t.inboundLayers[s],i=t.nodeIndices[s],o=r.inboundNodes[i],l=null==e[o.id]?0:e[o.id];e[o.id]=Math.max(a+1,l),n[o.id]=o}}const h={};for(const t in e){const s=e[t];s in h||(h[s]=[]),h[s].push(n[t])}const p={};for(const t in s){const e=s[t];e in p||(p[e]=[]),p[e].push(r[t])}let d=Object.keys(p).map((t=>parseInt(t,10))).sort(Ld);this.layers=[];for(const t of d){const e=p[t];e.sort(((t,e)=>{const n=a[t.id],s=a[e.id];return n<s?-1:n>s?1:0}));for(const t of e)t instanceof yg&&this.internalContainerRefs.push(t),this.layers.push(t)}this.layersByDepth=p,d=Object.keys(h).map((t=>parseInt(t,10))).sort(Ld);const f=this.inputs.slice(),m=[];for(const t of d)for(const e of h[t]){const t=e.outboundLayer;if(null!=t){for(const n of e.inputTensors)if(-1===f.indexOf(n))throw new kd("Graph disconnected: cannot obtain value for tensor "+n+` at layer "${t.name}". The following previous layers were accessed without issue: `+m);for(const t of e.outputTensors)f.push(t);m.push(t.name)}}this.nodesByDepth=h;const g=this.layers.map((t=>t.name));for(const t of g){const e=g.filter((e=>e===t)).length;if(1!==e)throw new kd(`The name "${t}" is used ${e} times in the model. All layer names should be unique. Layer names: `+JSON.stringify(g))}this.outboundNodes=[],this.inboundNodes=[],new wm({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:this.inputs.map((t=>null)),outputMasks:this.outputs.map((t=>null)),inputShapes:this.inputs.map((t=>t.shape)),outputShapes:this.outputs.map((t=>t.shape))}),this.built=!0,this._refCount=1}assertNotDisposed(){if(0===this._refCount)throw new Error(`Container '${this.name}' is already disposed.`)}dispose(){this.assertNotDisposed();const t={refCountAfterDispose:null,numDisposedVariables:0};if(0==--this._refCount){for(const e of this.layers)t.numDisposedVariables+=e.dispose().numDisposedVariables;for(const e of this.internalContainerRefs)t.numDisposedVariables+=e.dispose().numDisposedVariables}return t.refCountAfterDispose=this._refCount,t}get trainable(){return this.trainable_}set trainable(t){this.layers.forEach((e=>{e._trainableWeights.forEach((e=>e.trainable=t))})),this.trainable_=t}get trainableWeights(){if(this._trainableWeights.length>0)throw new Nd("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");if(!this.trainable)return[];let t=[];for(const e of this.layers)t=t.concat(e.trainableWeights);return t}get nonTrainableWeights(){const t=[];for(const e of this.layers)t.push(...e.nonTrainableWeights);if(!this.trainable){const e=[];for(const t of this.layers)e.push(...t.trainableWeights);return e.concat(t)}return t}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}loadWeights(t,e=!0){const n={};let s=0;for(const t of this.layers)for(const e of t.weights){if(null!=n[e.originalName])throw new Nd("Duplicate weight name: "+e.originalName);n[e.originalName]=e,s++}const r=[];for(const s in t){let a=s;if(null==n[s]){const t=s.split("/");a=t.slice(0,-2).concat([t[t.length-1]]).join("/")}if(null!=n[a])r.push([n[a],t[s]]);else if(e)throw new Nd("Provided weight data has no target variable: "+s);delete n[a]}if(e){const t=[];for(const e in n)t.push(e);if(t.length>0)throw new Nd(`${t.length} of ${s} weights are not set: `+t)}gm(r)}updatedConfig(){const t=this.getConfig(),e={};return e.className=this.getClassName(),e.config=t,e.kerasVersion="tfjs-layers 2.7.0",e.backend="TensorFlow.js",e}toJSON(t,e=!0){const n=ug(this.updatedConfig());return e?JSON.stringify(n):n}call(t,e){return Wr((()=>{t=Ad(t);const n=new cg;for(let e=0;e<this.inputs.length;++e)n.add(this.inputs[e],t[e]);return dg(this.outputs,n,e)}))}computeMask(t,e){return Wr((()=>{let n;return t=Ad(t),n=null==e?Sd(null,t.length):Ad(e),this.runInternalGraph(t,n)[1]}))}computeOutputShape(t){const e=cm(t);if(e.length!==this.inputLayers.length)throw new Nd(`Invalid inputShape argument ${t}: model has ${this.inputLayers.length} tensor inputs.`);const n={};for(let t=0;t<e.length;t++){const s=this.inputLayers[t],r=e[t];n[s.name+"_0_0"]=r}const s=Object.keys(this.nodesByDepth).map((t=>parseInt(t,10))).sort(Ld);if(s.length>1)for(const t of s){const e=this.nodesByDepth[t];for(const t of e){const e=t.outboundLayer;if(-1!==this.inputLayers.map((t=>t.id)).indexOf(e.id))continue;const s=[];for(let e=0;e<t.inboundLayers.length;e++){const r=t.inboundLayers[e],a=t.nodeIndices[e],i=t.tensorIndices[e],o=n[`${r.name}_${a}_${i}`];s.push(o)}const r=cm(e.computeOutputShape(Ed(s))),a=e.inboundNodes.indexOf(t);for(let t=0;t<r.length;t++)n[`${e.name}_${a}_${t}`]=r[t]}}const r=[],a=[];for(let t=0;t<this.outputLayers.length;t++){const e=this.outputLayers[t],n=this.outputLayersNodeIndices[t],s=this.outputLayersTensorIndices[t],r=`${e.name}_${n}_${s}`;a.push(r)}for(let t=0;t<a.length;t++){const e=a[t];Td(e in n),r.push(n[e])}return Ed(r)}runInternalGraph(t,e){null==e&&(e=Sd(null,t.length));const n={};for(let s=0;s<this.inputs.length;++s){const r=this.inputs[s],a=t[s],i=e[s];n[r.id]=[a,i]}const s=Object.keys(this.nodesByDepth).map((t=>parseInt(t,10))).sort(Ld);for(const t of s){const e=this.nodesByDepth[t];for(const t of e){const e=t.outboundLayer,s=t.inputTensors,r=t.outputTensors,a=new Array;for(const t of s)t.id in n&&a.push(n[t.id]);if(a.length===s.length){let s,i,o,l,u={};if(null!=t.callArgs&&(u=t.callArgs),1===a.length){const[t,n]=a[0];null==u.mask&&(u.mask=n),o=Ad(e.call(t,u)),l=Ad(e.computeMask(t,n)),s=[t],i=[n]}else s=a.map((t=>t[0])),i=a.map((t=>t[1])),null==u.mask&&(u.mask=i),o=Ad(e.call(s,u)),l=Ad(e.computeMask(s,i));if(e.activityRegularizer)throw new Id("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");for(let t=0;t<r.length;++t){const e=r[t],s=o[t],a=l[t];n[e.id]=[s,a]}}}}const r=[],a=[],i=[];for(const t of this.outputs){Td(t.id in n,`Could not compute output ${t.name} : ${t.id}`);const[e,s]=n[t.id];i.push(e.shape),r.push(e),a.push(s)}return[r,a,i]}buildNodeConversionMap(t){const e={};let n;for(const t of this.layers){n=t instanceof yg?1:0;for(let s=0;s<t.inboundNodes.length;s++){const r=yg.nodeKey(t,s);this.containerNodes.has(r)&&(e[r]=n,n+=1)}}return e}getLayer(t,e){if(null!=e){if(this.layers.length<=e)throw new Nd(`Was asked to retrieve layer at index ${e}, but model only has ${this.layers.length} layer(s).`);return this.layers[e]}if(null==t)throw new Nd("Provide either a layer name or layer index");for(const e of this.layers)if(e.name===t)return e;throw new Nd("No such layer: "+t)}calculateLosses(){return Wr((()=>{const t=[];for(const e of this.layers)for(let n=0;n<e.inboundNodes.length;++n){const s=yg.nodeKey(e,n);this.containerNodes.has(s)&&t.push(...e.calculateLosses())}return t}))}getConfig(){const t={name:this.name},e=this.buildNodeConversionMap(this.layers),n=[];for(const t of this.layers){const s=t.getClassName(),r=t.getConfig(),a=[];for(let n=0;n<t.inboundNodes.length;n++){const s=t.inboundNodes[n],r=yg.nodeKey(t,n);let i={};if(this.containerNodes.has(r)){if(s.callArgs)try{JSON.stringify(s.callArgs),i=s.callArgs}catch(e){console.warn(`Layer ${t.name} was passed non-serializable keyword arguments: `+s.callArgs+". They will not be included in the serialized model (and thus will be missing at deserialization time)."),i={}}if(s.inboundLayers.length>0){const t=[];for(let n=0;n<s.inboundLayers.length;n++){const r=s.inboundLayers[n],a=s.nodeIndices[n],o=s.tensorIndices[n];let l=e[yg.nodeKey(r,a)];null==l&&(l=0),t.push([r.name,l,o,i])}a.push(t)}}}const i={};i.name=t.name,i.className=s,i.config=r,i.inboundNodes=a,n.push(i)}t.layers=n;const s=[];for(let t=0;t<this.inputLayers.length;t++){const n=this.inputLayers[t],r=this.inputLayersNodeIndices[t],a=yg.nodeKey(n,r);if(!this.containerNodes.has(a))continue;let i=e[a];null==i&&(i=0);const o=this.inputLayersTensorIndices[t];s.push([n.name,i,o])}t.inputLayers=s;const r=[];for(let t=0;t<this.outputLayers.length;t++){const n=this.outputLayers[t],s=this.outputLayersNodeIndices[t],a=yg.nodeKey(n,s);if(!this.containerNodes.has(a))continue;let i=e[a];null==i&&(i=0);const o=this.outputLayersTensorIndices[t];r.push([n.name,i,o])}return t.outputLayers=r,t}static fromConfig(t,e,n={},s=!1){const r={},a={};function i(t,e){t.name in a?a[t.name].push(e):a[t.name]=[e]}function o(t,e){const n=[];let s;for(const a of e){const o=a[0],l=a[1],u=a[2];if(s=null==a[3]?{}:a[3],!(o in r))return void i(t,e);const c=r[o];if(c.inboundNodes.length<=l)return void i(t,e);const h=c.inboundNodes[l];n.push(h.outputTensors[u])}n.length>0&&t.apply(Ed(n),s)}function l(t){const n=t.name,a=Mm(t,null!=e.customObjects?e.customObjects:{});a.setFastWeightInitDuringBuild(s),r[n]=a,t.inboundNodes.forEach((t=>{if(!(t instanceof Array))throw new Nd("Corrupted configuration, expected array for nodeData: "+t);i(a,t)}))}const u=e.name,c=e.layers;for(const t of c)l(t);for(;!Bd(a);)for(const t of c){const e=r[t.name];if(e.name in a){const t=a[e.name];delete a[e.name];for(const n of t)o(e,n)}}const h=[],p=[],d=e.inputLayers;for(const t of d){const e=t[0],n=t[1],s=t[2];Td(e in r);const a=r[e].inboundNodes[n].outputTensors;h.push(a[s])}const f=e.outputLayers;for(const t of f){const e=t[0],n=t[1],s=t[2];Td(e in r);const a=r[e].inboundNodes[n].outputTensors;p.push(a[s])}return new t({inputs:h,outputs:p,name:u})}get stateful(){if(this._stateful)throw new Nd("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");for(const t of this.layers)if(t.stateful)return!0;return!1}resetStates(){Wr((()=>{this.layers.forEach((t=>{t.stateful&&t.resetStates()}))}))}}function bg(t,e){return function(t,e,n){const s=e.length;if(null==t||Array.isArray(t)&&0===t.length)return e.map((t=>null));if(1===s)return Array.isArray(t)&&1===t.length?t:"object"==typeof t&&e[0]in t?[t[e[0]]]:[t];if(Array.isArray(t)){if(t.length!==s)throw new Error(`Provided ${n} is an array of ${t.length} element(s), but the model has ${s} outputs. Make sure a set of weights is provided for each model output.`);return t}if("object"==typeof t&&Object.keys(t).length>0&&"object"==typeof t[Object.keys(t)[0]]){const n=[];return e.forEach((e=>{e in t?n.push(t[e]):n.push(null)})),n}throw new Error(`The model has multiple (${s}) outputs, so ${n} must be either an array with ${s} elements or an object with ${e} keys. Provided ${n} not understood: ${JSON.stringify(t)}`)}(t,e,"classWeight")}async function xg(t,e,n,s){if(null!=e||null!=s)throw new Error("Support sampleWeight is not implemented yet");if(null!=n){const e=Wr((()=>{if(1===t.shape.length)return t.clone();if(2===t.shape.length){if(t.shape[1]>1){const e=1;return t.argMax(e)}if(1===t.shape[1])return t.reshape([t.shape[0]]);throw new Error(`Encountered unexpected last-dimension size (${t.shape[1]}) during handling of class weights. The size is expected to be >= 1.`)}throw new Error(`Unexpected rank of target (y) tensor (${t.rank}) during handling of class weights. The rank is expected to be 1 or 2.`)})),s=Array.from(await e.data());Vr(e);const r=[];return s.forEach((t=>{if(null==n[t])throw new Error(`classWeight must contain all classes in the training data. The class ${t} exists in the data but not in classWeight`);r.push(n[t])})),Ui(r,"float32")}return null}function wg(t,e){return pi(t,e)}function vg(t,e){let n,s;const r=e;n=r.xs,s=r.ys,A(null!=n&&null!=s,(()=>"A Dataset iterator for fitDataset() is expected to generate objects of the form `{xs: xVal, ys: yVal}`, where the two values may be `tf.Tensor`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates "+e));const a=kg("input",t.inputNames,n),i=kg("output",t.outputNames,s),o=a[0].shape[0];A(a.length===t.inputs.length,(()=>`LayersModel has ${t.inputs.length} inputs, but the dataset provides ${a.length} inputs.  (Expected input keys: `+JSON.stringify(t.inputNames)+")")),A(i.length===t.outputs.length,(()=>`LayersModel has ${t.outputs.length} outputs, but the dataset provides ${i.length} outputs.  (Expected output keys: `+JSON.stringify(t.outputNames)+")"));for(let e=0;e<a.length;e++)A(a[e].shape[0]===o,(()=>`Batch size mismatch: input ${t.inputNames[e]} has ${a[e].shape[0]}; expected  ${o} based on input ${t.inputNames[0]}.`));for(let e=0;e<i.length;e++)A(i[e].shape[0]===o,(()=>`Batch size mismatch: output ${t.outputNames[e]} has ${i[e].shape[0]}; expected  ${o} based on input ${t.inputNames[0]}.`));return{xs:a,ys:i}}function kg(t,e,n){if(n instanceof Jn)return[n];if(Array.isArray(n))return A(n.length===e.length,(()=>`Received an array of ${n.length} Tensors, but expected ${e.length} to match the ${t} keys ${e}.`)),n;{const s=[];for(const r of e){if(null==n[r])throw new Nd(`The feature data generated by the dataset lacks the required ${t} key '${r}'.`);s.push(n[r])}return s}}function Ng(t){return"function"==typeof t.iterator}function Ig(t){A(t>0&&Number.isInteger(t),(()=>"batchSize is required to be a positive integer, but got "+t))}function Cg(t,e,n){return null==t?[null]:Array.isArray(t)?t.map((t=>Nf(t,e,n-e))):Nf(t,e,n-e)}function Sg(t,e){return Wr((()=>null==t?null:Array.isArray(t)?t.map((t=>Sg(t,e))):Rf(t,"int32"===e.dtype?e:e.toInt())))}function Tg(t,e){const n=[];let s=0,r=null;for(;s<t;)r=s+e,r>=t&&(r=t),n.push([s,r]),s=r;return n}function $g(t){const e=[];t instanceof Jn&&(t=[t]);for(let n=0;n<t.length;++n){const s=t[n];if(1===s.rank)e.push(kf(s,1));else{if(0===s.rank)throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");e.push(s)}}return e}function Eg(t,e){if(null==t)return;const n=[];if(e instanceof Jn)n.push(e.id);else if(Array.isArray(e))e.forEach((t=>n.push(t.id)));else if(null!=e)for(const t in e){const s=e[t];n.push(s.id)}const s=[];if(t instanceof Jn)-1===n.indexOf(t.id)&&s.push(t);else if(Array.isArray(t))t.forEach((t=>{-1===n.indexOf(t.id)&&s.push(t)}));else if(null!=t)for(const e in t){const r=t[e];-1===n.indexOf(r.id)&&s.push(r)}s.forEach((t=>{t.isDisposed||t.dispose()}))}function Ag(t){return Array.isArray(t)}function Rg(t){return!function(t){return t instanceof Jn}(t)&&!Ag(t)}function Dg(t,e,n,s=!0,r=""){if(null==e||0===e.length){if(null!=t){let e=!1;if(Ag(t)&&t.length>0)e=!0;else if(Rg(t)){for(const n in t)if(t.hasOwnProperty(n)){e=!0;break}}else e=!0;if(e)throw new Nd(`Error when checking model ${r} expected no data, but got `+t)}return[]}if(null==t)return e.map((t=>null));let a;if(Rg(t)){t=t,a=[];for(const n of e){if(null==t[n])throw new Nd(`No data provided for "${n}". Need data for each key in: `+e);a.push(t[n])}}else if(Ag(t)){if((t=t).length!==e.length)throw new Nd(`Error when checking model ${r}: the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ${e.length} Tensor(s), but instead got the following list of Tensor(s): `+t);a=t}else{if(t=t,e.length>1)throw new Nd(`The model ${r} expects ${e.length} Tensor(s), but only received one Tensor. Found: Tensor with shape `+t.shape);a=[t]}if(a=$g(a),null!=n)for(let t=0;t<e.length;++t){if(null==n[t])continue;const i=a[t];if(i.shape.length!==n[t].length)throw new Nd(`Error when checking ${r}: expected ${e[t]} to have ${n[t].length} dimension(s). but got array with shape `+i.shape);for(let a=0;a<n[t].length;++a){if(0===a&&!s)continue;const o=i.shape[a],l=n[t][a];if(null!=l&&l>=0&&o!==l)throw new Nd(`Error when checking ${r}: expected ${e[t]} to have shape [${n[t]}], but got array with shape [${i.shape}].`)}}return a}function Fg(t,e,n,s=!0,r=""){let a;if(Array.isArray(t)){if(t.length!==e.length)throw new Nd(`Error when checking model ${r}: the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ${e.length} Tensor(s), but instead got ${t.length} Tensors(s).`);a=t}else{if(e.length>1)throw new Nd(`The model expects ${e.length} ${r} Tensors, but only received one Tensor. Found: array with shape `+JSON.stringify(t.shape)+".");a=[t]}if(null!=n)for(let t=0;t<e.length;++t){if(null==n[t])continue;const i=a[t];if(i.shape.length!==n[t].length)throw new Nd(`Error when checking ${r}: expected ${e[t]} to have ${n[t].length} dimension(s), but got array with shape `+JSON.stringify(i.shape));for(let a=0;a<n[t].length;++a){if(0===a&&!s)continue;const o=i.shape[a],l=n[t][a];if(null!=l&&l!==o)throw new Nd(`Error when checking ${r}: expected ${e[t]} to have shape ${JSON.stringify(n[t])} but got array with shape ${JSON.stringify(i.shape)}.`)}}}class _g extends yg{constructor(t){super(t),this.isTraining=!1}summary(t,e,n=console.log){if(!this.built)throw new Nd("This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).");!function(t,e,n,s=console.log){const r=function(t){let e=!0;const n=[],s=[];for(const e in t.nodesByDepth)n.push(t.nodesByDepth[e]);for(const t of n){if(t.length>1||1===t.length&&t[0].inboundLayers.length>1){e=!1;break}s.push(...t)}if(e)for(const n of t.layers){let t=!1;for(const r of n.inboundNodes)if(-1!==s.indexOf(r)){if(t){e=!1;break}t=!0}if(!e)break}return e}(t),a=["Layer (type)","Output shape","Param #"];let i;if(r?(e=e||65,n=n||[.45,.85,1]):(e=e||98,n=n||[.33,.55,.67,1]),n[n.length-1]<=1&&(n=n.map((t=>Math.floor(e*t)))),!r){a.push("Receives inputs"),i=[];for(const e in t.nodesByDepth)i.push(...t.nodesByDepth[e])}s("_".repeat(e)),rg(a,n,s),s("=".repeat(e));const o=t.layers;for(let t=0;t<o.length;++t)r?ag(o[t],n,s):ig(o[t],n,i,s),s((t===o.length-1?"=":"_").repeat(e));t.checkTrainableWeightsConsistency();const l=function(t){let e;return e=null!=t.collectedTrainableWeights?dm(t.collectedTrainableWeights):dm(t.trainableWeights),e}(t),u=dm(t.nonTrainableWeights);s("Total params: "+(l+u)),s("Trainable params: "+l),s("Non-trainable params: "+u),s("_".repeat(e))}(this,t,e,n)}compile(t){if(null==t.loss&&(t.loss=[]),this.loss=t.loss,"string"==typeof t.optimizer)this.optimizer_=function(t){const e={Adagrad:()=>Il.adagrad(.01),Adadelta:()=>Il.adadelta(1,.95,wd()),Adam:()=>Il.adam(.001,.9,.999,wd()),Adamax:()=>Il.adamax(.002,.9,.999,wd(),0),RMSProp:()=>Il.rmsprop(.001,.9,0,wd()),SGD:()=>Il.sgd(.01)};if(e.adagrad=e.Adagrad,e.adadelta=e.Adadelta,e.adam=e.Adam,e.adamax=e.Adamax,e.rmsprop=e.RMSProp,e.sgd=e.SGD,t in e)return e[t]();throw new Nd("Unknown Optimizer "+t)}(t.optimizer),this.isOptimizerOwned=!0;else{if(!(t.optimizer instanceof Kr))throw new Nd("User-defined optimizer must be an instance of tf.Optimizer.");this.optimizer_=t.optimizer,this.isOptimizerOwned=!1}let e=[];if(Array.isArray(t.loss)||"string"==typeof t.loss||"function"==typeof t.loss)if(Array.isArray(t.loss)){if(t.loss.length!==this.outputs.length)throw new Nd(`When passing an Array as loss, it should have one entry per model output. The model has ${this.outputs.length} output(s), but you passed loss=${t.loss}.`);const n=t.loss;e=n.map((t=>jm(t)))}else{const n=jm(t.loss);this.outputs.forEach((t=>{e.push(n)}))}else{t.loss=t.loss;for(const e in t.loss)if(-1===this.outputNames.indexOf(e))throw new Nd(`Unknown entry in loss dictionary: "${e}". Only expected the following keys: `+this.outputNames);for(const n of this.outputNames)null==t.loss[n]&&console.warn(`Output "${n}" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ${n} during training`),e.push(jm(t.loss[n]))}this.lossFunctions=e,this.feedOutputNames=[],this.feedOutputShapes=[],this.feedLossFns=[];for(let t=0;t<this.outputs.length;++t){const e=this.internalOutputShapes[t],n=this.outputNames[t];this.feedOutputNames.push(n),this.feedOutputShapes.push(e),this.feedLossFns.push(this.lossFunctions[t])}const n=[];this.metrics=t.metrics,this.metricsNames=["loss"],this.metricsTensors=[],hf("loss",(()=>{for(let t=0;t<this.outputs.length;++t){if(-1!==n.indexOf(t))continue;const e=this.lossFunctions[t];this.outputs.length>1&&(this.metricsTensors.push([e,t]),this.metricsNames.push(this.outputNames[t]+"_loss"))}}));const s=function(t,e){if(null==t||Array.isArray(t)&&0===t.length)return e.map((t=>[]));let n;if("string"==typeof t||"function"==typeof t)n=[t];else{if(!Array.isArray(t)&&"object"!=typeof t)throw new TypeError("Type of metrics argument not understood. Expected an string,function, Array, or Object, found: "+t);n=t}if(Array.isArray(n))return e.map((t=>n));{const t=[];for(const s of e){let e=n.hasOwnProperty(s)?n[s]:[];Array.isArray(e)||(e=[e]),t.push(e)}return t}}(t.metrics,this.outputNames),r=(t,e,n)=>{this.outputNames.length>1&&(e=this.outputNames[t]+"_"+e),this.metricsNames.push(e),this.metricsTensors.push([n,t])};hf("metric",(()=>{for(let t=0;t<this.outputs.length;++t)-1===n.indexOf(t)&&(e=>{let n,s,a;for(const i of e){if("string"==typeof i&&-1!==["accuracy","acc","crossentropy","ce"].indexOf(i)){const e=this.internalOutputShapes[t];let r;1===e[e.length-1]||this.lossFunctions[t]===Um?-1!==["accuracy","acc"].indexOf(i)?s=qm:-1!==["crossentropy","ce"].indexOf(i)&&(s=Xm):this.lossFunctions[t]===Vm?-1!==["accuracy","acc"].indexOf(i)?s=Ym:-1!==["crossentropy","ce"].indexOf(i)&&(s=Zm):-1!==["accuracy","acc"].indexOf(i)?s=Km:-1!==["crossentropy","ce"].indexOf(i)&&(s=Jm),-1!==["accuracy","acc"].indexOf(i)?r="acc":-1!==["crossentropy","ce"].indexOf(i)&&(r="ce"),a=s,n=""+r}else{const t=tg(i);a=t,n=""+eg(i)}let e;hf(n,(()=>{e=a})),r(t,n,e)}})(s[t])})),this.collectedTrainableWeights=this.trainableWeights}checkTrainableWeightsConsistency(){null!=this.collectedTrainableWeights&&this.trainableWeights.length!==this.collectedTrainableWeights.length&&console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?")}evaluate(t,e,n={}){const s=null==n.batchSize?32:n.batchSize;Ig(s);const r=this.standardizeUserDataXY(t,e,!0,s);try{const a=r[0].concat(r[1]);this.makeTestFunction();const i=this.testFunction;return Ed(this.testLoop(i,a,s,n.verbose,n.steps))}finally{Eg(r[0],t),Eg(r[1],e)}}async evaluateDataset(t,e){return this.makeTestFunction(),async function(t,e,n){const s=null!=(n=n||{}).batches,r=t.testFunction;let a=[];if(n.verbose>0)throw new Id("Verbose mode is not implemented yet.");A(!s||n.batches>0&&Number.isInteger(n.batches),(()=>"Test loop expects `batches` to be a positive integer, but received "+JSON.stringify(n.batches)));const i="function"==typeof e.next?e:await e.iterator();let o=0,l=0;for(;!s||l<n.batches;){const e=await i.next();if(a=Wr((()=>{if(e.value){const{xs:n,ys:s}=vg(t,e.value),i=n.concat(s),u=Wr((()=>r(i)));if(Vr(i),0===l)for(let t=0;t<u.length;++t)a.push(qr(0));const c=i[0].shape[0];for(let t=0;t<u.length;++t){const e=u[t],n=a[t];a[t]=Wr((()=>Yr(a[t],pi(c,e)))),l>0&&Vr(n)}Vr(u),o+=c,++l}return a})),e.done){s&&console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${n.batches} batches). You may need to use the repeat() function when building your dataset.`);break}}for(let t=0;t<a.length;++t){const e=a[t];a[t]=Ha(a[t],o),Vr(e)}return Ed(a)}(this,t,e)}checkNumSamples(t,e,n,s="steps"){let r;if(null!=n){if(r=null,null!=e)throw new Nd(`If ${s} is set, batchSize must be null or undefined.Got batchSize = `+e)}else{if(null==t)throw new Nd("Either the input data should have a defined shape, or "+s+" shoud be specified.");r=Array.isArray(t)?t[0].shape[0]:t.shape[0]}return r}execute(t,e){if(Array.isArray(e)&&0===e.length)throw new Nd("`outputs` is an empty Array, which is not allowed.");const n=Array.isArray(e),s=n?e:[e],r=this.retrieveSymbolicTensors(s),a=new cg;if(t instanceof Jn&&(t=[t]),Array.isArray(t)){if(t.length!==this.inputs.length)throw new Nd(`The number of inputs provided (${t.length}) does not match the number of inputs of this model (${this.inputs.length}).`);for(let e=0;e<this.inputs.length;++e)a.add(this.inputs[e],t[e])}else for(const e of this.inputs){const n=t[e.name];if(null==n)throw new Nd("No value is provided for the model's input "+e.name);a.add(e,n)}const i=dg(r,a);return n?i:i[0]}retrieveSymbolicTensors(t){const e=Sd(null,t.length);let n=t.length;for(const s of this.layers){const r=Array.isArray(s.output)?s.output:[s.output],a=r.map((t=>t.name));for(let s=0;s<t.length;++s){const i=a.indexOf(t[s]);if(-1!==i&&(e[s]=r[i],n--),0===n)break}if(0===n)break}if(n>0){const n=[];throw e.forEach(((e,s)=>{null==e&&n.push(t[s])})),new Nd("Cannot find SymbolicTensors for output name(s): "+JSON.stringify(n))}return e}predictLoop(t,e=32,n=!1){return Wr((()=>{const s=this.checkNumSamples(t);if(n)throw new Id("Verbose predictLoop() is not implemented yet.");const r=Tg(s,e),a=this.outputs.map((t=>[]));for(let e=0;e<r.length;++e)Wr((()=>{const n=r[e][0],s=r[e][1],a=Cg(t,n,s),i=[];if(Array.isArray(a))for(let t=0;t<a.length;++t)i.push({key:this.inputs[t],value:a[t]});else i.push({key:this.inputs[0],value:a});const o=new cg(i);return dg(this.outputs,o)})).forEach(((t,e)=>a[e].push(t)));return Ed(a.map((t=>Fa(t,0))))}))}predict(t,e={}){const n=$g(t);Fg(n,this.inputNames,this.feedInputShapes,!1);try{const s=null==e.batchSize?32:e.batchSize;return Ig(s),this.predictLoop(n,s)}finally{Eg(n,t)}}predictOnBatch(t){Fg(t,this.inputNames,this.feedInputShapes,!0);const e=(Array.isArray(t)?t[0]:t).shape[0];return this.predictLoop(t,e)}standardizeUserDataXY(t,e,n=!0,s){if(null==this.optimizer_)throw new kd("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");const r=[];for(let t=0;t<this.feedOutputShapes.length;++t){const e=this.feedOutputShapes[t];this.feedLossFns[t]===Vm?r.push(e.slice(0,e.length-1).concat([1])):r.push(e)}if(function(t,e,n){const s=zd(t.map((t=>t.shape[0])));s.sort();const r=zd(e.map((t=>t.shape[0])));if(r.sort(),s.length>1)throw new Nd("All input Tensors (x) should have the same number of samples. Got array shapes: "+JSON.stringify(t.map((t=>t.shape))));if(r.length>1)throw new Nd("All target Tensors (y) should have the same number of samples. Got array shapes: "+JSON.stringify(e.map((t=>t.shape))));if(s.length>0&&r.length>0&&!O(s,r))throw new Nd(`Input Tensors should have the same number of samples as target Tensors. Found ${s[0]} input sample(s) and ${r[0]} target sample(s).`)}(t=Dg(t,this.feedInputNames,this.feedInputShapes,!1,"input"),e=Dg(e,this.feedOutputNames,r,!1,"target")),function(t,e,n){const s=[zm,Um,Wm];for(let r=0;r<t.length;++r){const a=t[r],i=e[r],o=n[r];if(null!=i){if(i===Wm&&1===a.shape[a.shape.length-1])throw new Nd(`You are passing a target array of shape ${a.shape} while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].`);if(-1!==s.indexOf(i)){const t=a.shape.slice(1),e=o.slice(1);for(let n=0;n<t.length;++n){const s=t[n],r=e[n];if(null!=r&&s!==r)throw new Nd(`A target Tensor with shape ${a.shape} was passed for an output of shape ${o}, while using a loss function that expects targets to have the same shape as the output.`)}}}}}(e,this.feedLossFns,this.feedOutputShapes),this.stateful&&null!=s&&s>0&&t[0].shape[0]%s!=0)throw new Nd(`In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ${s}. Found: ${t[0].shape[0]} sample(s).`);return[t,e]}async standardizeUserData(t,e,n,s,r=!0,a){const[i,o]=this.standardizeUserDataXY(t,e,r,a);if(null!=n)throw new Error("sample weight is not supported yet.");let l=null;if(null!=s){const t=bg(s,this.outputNames);l=[];for(let e=0;e<t.length;++e)l.push(await xg(o[e],null,t[e]))}return[i,o,l]}testLoop(t,e,n,s=0,r){return Wr((()=>{const a=this.checkNumSamples(e,n,r,"steps"),i=[];if(s>0)throw new Id("Verbose mode is not implemented yet.");if(null!=r)throw new Id("steps mode in testLoop() is not implemented yet");{const s=Tg(a,n),r=Ui(wf(0,a));for(let n=0;n<s.length;++n){const a=s[n][0],o=s[n][1],l=Nf(r,a,o-a),u=Sg(e,l),c=t(u);if(0===n)for(let t=0;t<c.length;++t)i.push(qr(0));for(let t=0;t<c.length;++t){const e=c[t];i[t]=Yr(i[t],pi(o-a,e))}}for(let t=0;t<i.length;++t)i[t]=Ha(i[t],a)}return i}))}getDedupedMetricsNames(){const t=this.metricsNames,e=[];for(let n=0;n<t.length;++n){const s=t[n];let r=s;$d(t,s)>1&&(r+="_"+$d(t.slice(0,n),s)),e.push(r)}return e}makeTrainFunction(){return t=>{const e=[],n=t.slice(0,this.inputs.length),s=t.slice(this.inputs.length,this.inputs.length+this.outputs.length),r=t.slice(this.inputs.length+this.outputs.length,this.inputs.length+2*this.outputs.length),a=[],i=this.collectedTrainableWeights.map((t=>t.read()));return[this.optimizer_.minimize((()=>{const t=[];for(let e=0;e<this.inputs.length;++e)t.push({key:this.inputs[e],value:n[e]});const i=new cg(t),o=dg(this.outputs,i,{training:!0});let l;for(let t=0;t<this.lossFunctions.length;++t){let n=(0,this.lossFunctions[t])(s[t],o[t]);null!=r[t]&&(n=wg(n,r[t]));const a=Ii(n);e.push(a),l=0===t?n:Yr(l,n)}for(let t=0;t<this.metricsTensors.length;++t){let n;if(this.outputs.length>1&&t<this.outputs.length)n=e[t];else{const e=this.metricsTensors[t][0],r=this.metricsTensors[t][1];n=Ii(e(s[r],o[r]))}Ur(n),a.push(n)}return l=Ii(l),this.calculateLosses().forEach((t=>{l=Yr(l,t)})),l}),!0,i)].concat(a)}}makeTestFunction(){this.testFunction=t=>Wr((()=>{const e=[];let n;const s=t.slice(0,this.inputs.length),r=t.slice(this.inputs.length,this.inputs.length+this.outputs.length),a=[];for(let t=0;t<this.inputs.length;++t)a.push({key:this.inputs[t],value:s[t]});const i=new cg(a),o=dg(this.outputs,i);for(let t=0;t<this.lossFunctions.length;++t){const s=this.lossFunctions[t],a=Ii(s(r[t],o[t]));n=0===t?a:Yr(n,a),e.push(n)}for(let t=0;t<this.metricsTensors.length;++t){const n=this.metricsTensors[t][0],s=this.metricsTensors[t][1],a=Ii(n(r[s],o[s]));e.push(a)}return e}))}async fit(t,e,n={}){return async function(t,e,n,s={}){if(t.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");let r,a,i,o,l,u,c;t.isTraining=!0;try{const h=null==s.batchSize?32:s.batchSize;Ig(h);const p=!1,d=await t.standardizeUserData(e,n,s.sampleWeight,s.classWeight,p,h);r=d[0],a=d[1],c=d[2];let f,m=!1;if(null!=s.validationData&&s.validationData.length>0){if(m=!0,2!==s.validationData.length)throw 3===s.validationData.length?new Id("validationData including sample weights is not supported yet."):new Nd("When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; "+s.validationData+" is invalid.");i=s.validationData[0],o=s.validationData[1];const e=!0,n=await t.standardizeUserData(i,o,null,null,e,h);l=n[0],u=n[1],f=l.concat(u)}else if(null!=s.validationSplit&&s.validationSplit>0&&s.validationSplit<1){m=!0;const t=Math.floor(r[0].shape[0]*(1-s.validationSplit)),e=r[0].shape[0];l=Cg(r,t,e),r=Cg(r,0,t),u=Cg(a,t,e),a=Cg(a,0,t),f=l.concat(u)}else null!=s.validationSteps&&(m=!0);const g=r.concat(a).concat(c);t.checkTrainableWeightsConsistency();const y=t.makeTrainFunction(),b=t.getDedupedMetricsNames();let x,w;m?(t.makeTestFunction(),x=t.testFunction,w=b.slice().concat(b.map((t=>"val_"+t)))):(x=null,f=[],w=b.slice());const v=Fm(s.callbacks,s.yieldEvery);return await async function(t,e,n,s,r,a,i,o,l,u,c,h,p,d,f){null==r&&(r=32),null==a&&(a=1),null==c&&(c=!0),null==p&&(p=0);let m=!1;null!=l&&null!=u&&(m=!0);const g=t.checkNumSamples(n,r,d,"steps_per_epoch");let y;null!=g&&(y=wf(0,g)),null==i&&(i=1);const{callbackList:b,history:x}=Om(o,i,a,p,g,d,r,m,h);b.setModel(t),t.history=x,await b.onTrainBegin(),t.stopTraining_=!1;for(let i=p;i<a;++i){await b.onEpochBegin(i);const a={};{if("batch"===c)throw new Id("batch shuffling is not implemneted yet");c&&T(y);const i=Ui(y),o=Tg(g,r);for(let c=0;c<o.length;++c){const h={};if(await b.onBatchBegin(c,h),Wr((()=>{const p=o[c][0],d=o[c][1],f=Nf(i,p,d-p);h.batch=c,h.size=d-p;const g=Sg(n,f),y=e(g);for(let t=0;t<s.length;++t){const e=s[t],n=y[t];h[e]=n,Ur(n)}if(c===o.length-1&&m){const e=t.testLoop(l,u,r);for(let t=0;t<s.length;++t){const n=s[t],r=e[t];Ur(r),a["val_"+n]=r}}})),await b.onBatchEnd(c,h),Sm(h),t.stopTraining_)break}i.dispose()}if(await b.onEpochEnd(i,a),t.stopTraining_)break}return await b.onTrainEnd(),await t.history.syncData(),t.history}(t,y,g,b,h,s.epochs,s.verbose,v,x,f,s.shuffle,w,s.initialEpoch,null)}finally{t.isTraining=!1,Eg(r,e),Eg(a,n),Eg(l,i),Eg(u,o),null!=c&&Vr(c)}}(this,t,e,n)}async fitDataset(t,e){return async function(t,e,n){const s=null!=n.batchesPerEpoch;if(A(null!=t.optimizer,(()=>"You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig).")),A(null!=n,(()=>"For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call.")),A(null!=n.epochs&&n.epochs>0&&Number.isInteger(n.epochs),(()=>"For fitDataset(), config.epochs is expected to be a positive integer, but got "+n.epochs)),A(!s||n.batchesPerEpoch>0&&Number.isInteger(n.batchesPerEpoch),(()=>"For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got "+n.batchesPerEpoch)),A(null==n.validationSplit,(()=>"`validationSplit` is not supported by `fitDataset()`. Use validationData instead.")),t.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");t.isTraining=!0;try{const r=null!=n.validationData;let a,i;if(r)if(Ng(n.validationData))A(null==n.validationBatches||n.validationBatches>0&&Number.isInteger(n.validationBatches),(()=>"For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got "+n.validationBatches));else{const t=function(t){if(3===t.length)throw new Id("Validation with sample weights is not implemented yet.");return{xs:t[0],ys:t[1]}}(n.validationData);a=t.xs,i=t.ys}const o=t.makeTrainFunction(),l=t.getDedupedMetricsNames();let u;u=r?l.slice().concat(l.map((t=>"val_"+t))):l.slice();const c=Fm(n.callbacks,n.yieldEvery),h=null==n.verbose?1:n.verbose,{callbackList:p,history:d}=Om(c,h,n.epochs,null,null,function(t,e){let n=null;return null!=e.batchesPerEpoch?n=e.batchesPerEpoch:Number.isFinite(t.size)&&(n=t.size),n}(e,n),null,r,u);p.setModel(t),t.history=d,await p.onTrainBegin(),t.stopTraining_=!1;let f=null==n.initialEpoch?0:n.initialEpoch,m=await e.iterator();for(;f<n.epochs;){const u={};await p.onEpochBegin(f);let c=0,h=0;for(s||(m=await e.iterator());!s||c<n.batchesPerEpoch;){const e=await m.next();if(s&&e.done){console.warn("You provided `batchesPerEpoch` as "+n.batchesPerEpoch+", but your dataset iterator ran out of data after "+c+" batches; interrupting training. Make sure that your dataset can generate at least `batchesPerEpoch * epochs` batches (in this case, "+n.batchesPerEpoch*n.epochs+" batches). You may need to use the repeat() function when building your dataset.");break}if(null!=e.value){const{xs:s,ys:r}=vg(t,e.value),a={};a.batch=h,a.size=s[0].shape[0],await p.onBatchBegin(h,a);const i=[];if(null!=n.classWeight){const e=bg(n.classWeight,t.outputNames);for(let t=0;t<e.length;++t)i.push(await xg(r[t],null,e[t]))}const u=s.concat(r).concat(i),d=o(u);Vr(u);for(let t=0;t<l.length;++t){const e=l[t],n=d[t];a[e]=n,Ur(n)}await p.onBatchEnd(h,a),Sm(a),h++,c++}if(s?c>=n.batchesPerEpoch:e.done){if(r){let e;e=Ng(n.validationData)?Ad(await t.evaluateDataset(n.validationData,{batches:n.validationBatches})):Ad(t.evaluate(a,i,{batchSize:null==n.validationBatchSize?32:n.validationBatchSize,verbose:0}));for(let n=0;n<t.metricsNames.length;++n)u["val_"+t.metricsNames[n]]=e[n]}break}if(t.stopTraining_)break}if(await p.onEpochEnd(f,u),f++,t.stopTraining_)break}return await p.onTrainEnd(),await t.history.syncData(),t.history}finally{t.isTraining=!1}}(this,t,e)}async trainOnBatch(t,e){const n=await this.standardizeUserData(t,e),s=n[0],r=n[1],a=this.makeTrainFunction()(s.concat(r)),i=[];for(const t of a){const e=await t.data();i.push(e[0])}return Vr(a),Ed(i)}getNamedWeights(t){const e=[],n=null!=t&&t.trainableOnly,s=n?this.trainableWeights:this.weights,r=this.getWeights(n);for(let t=0;t<s.length;++t)n&&!s[t].trainable||e.push({name:s[t].originalName,tensor:r[t]});return e}set stopTraining(t){this.stopTraining_=t}get stopTraining(){return this.stopTraining_}get optimizer(){return this.optimizer_}set optimizer(t){this.optimizer_!==t&&(this.optimizer_=t,this.isOptimizerOwned=!1)}dispose(){const t=super.dispose();if(0===t.refCountAfterDispose&&null!=this.optimizer&&this.isOptimizerOwned){const e=Pr().numTensors;this.optimizer_.dispose(),t.numDisposedVariables+=e-Pr().numTensors}return t}getLossIdentifiers(){let t;if("string"==typeof this.loss)t=Rd(this.loss);else if(Array.isArray(this.loss)){for(const t of this.loss)if("string"!=typeof t)throw new Error("Serialization of non-string loss is not supported.");t=this.loss.map((t=>Rd(t)))}else{const e=Object.keys(this.loss);t={};const n=this.loss;for(const s of e){if("string"!=typeof n[s])throw new Error("Serialization of non-string loss is not supported.");t[s]=Rd(n[s])}}return t}getMetricIdentifiers(){if("string"==typeof this.metrics||"function"==typeof this.metrics)return[Rd(eg(this.metrics))];if(Array.isArray(this.metrics))return this.metrics.map((t=>Rd(eg(t))));{const t={};for(const e in this.metrics)t[e]=Rd(eg(this.metrics[e]));return t}}getTrainingConfig(){return{loss:this.getLossIdentifiers(),metrics:this.getMetricIdentifiers(),optimizer_config:{class_name:this.optimizer.getClassName(),config:this.optimizer.getConfig()}}}loadTrainingConfig(t){if(null!=t.weighted_metrics)throw new Error("Loading weight_metrics is not supported yet.");if(null!=t.loss_weights)throw new Error("Loading loss_weights is not supported yet.");if(null!=t.sample_weight_mode)throw new Error("Loading sample_weight_mode is not supported yet.");const e=Mm(lg(t.optimizer_config));let n,s;if("string"==typeof t.loss)n=Dd(t.loss);else if(Array.isArray(t.loss))n=t.loss.map((t=>Dd(t)));else if(null!=t.loss){n={};for(const e in t.loss)n[e]=Dd(t.loss[e])}if(Array.isArray(t.metrics))s=t.metrics.map((t=>Dd(t)));else if(null!=t.metrics){s={};for(const e in t.metrics)s[e]=Dd(t.metrics[e])}this.compile({loss:n,metrics:s,optimizer:e})}async save(t,e){if("string"==typeof t){const e=Ms(t);if(0===e.length)throw new Nd(`Cannot find any save handlers for URL '${t}'`);if(e.length>1)throw new Nd(`Found more than one (${e.length}) save handlers for URL '${t}'`);t=e[0]}if(null==t.save)throw new Nd("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");const n=await $s(this.getNamedWeights(e)),s={modelTopology:this.toJSON(null,!1),format:"layers-model",generatedBy:"TensorFlow.js tfjs-layers v2.7.0",convertedBy:null};if(null!=e&&e.includeOptimizer&&null!=this.optimizer){s.trainingConfig=this.getTrainingConfig();const t="optimizer",{data:e,specs:r}=await $s(await this.optimizer.getWeights(),t);n.specs.push(...r),n.data=Ds([n.data,e])}if(null!=this.userDefinedMetadata){const t=!0;ng(this.userDefinedMetadata,this.name,t),s.userDefinedMetadata=this.userDefinedMetadata}return s.weightData=n.data,s.weightSpecs=n.specs,t.save(s)}setUserDefinedMetadata(t){ng(t,this.name),this.userDefinedMetadata=t}getUserDefinedMetadata(){return this.userDefinedMetadata}}_g.className="Model",Lr(_g);class Og extends _g{}Og.className="Functional",Lr(Og);class Mg extends _g{constructor(t){if(super({inputs:[],outputs:[]}),t=t||{},this.trainable=!0,this.built=!1,this.name=null!=t.name?t.name:lm("sequential_"),null!=t.layers)for(const e of t.layers)this.add(e)}checkShape(t){if(t.inboundNodes[0].outputTensors[0].shape.some((t=>t<0)))throw new Nd("Negative dimension size caused by adding layer "+t.name+" with input shape ["+t.inboundNodes[0].inputTensors[0].shape+"]")}add(t){const e=t instanceof Mg||t instanceof _g;let n;if(e){if(n=t,1!==n.outputs.length)throw new Nd("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");if(1!==n.inputs.length)throw new Nd("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.")}if(0===this.outputs.length){if(0===t.inboundNodes.length){if(null==t.batchInputShape)throw new Nd("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");const e=function(t){if(null==t.batchShape&&null==t.shape)throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");if(null!=t.batchShape&&null!=t.shape)throw new Nd("Please provide either a `shape` or `batchShape` argument to Input, but not both.");let e=t.batchShape;null!=t.shape&&null==e&&(e=[null].concat(t.shape));let n=t.dtype;return null==n&&(n="float32"),new Im({batchInputShape:e,name:t.name,dtype:n,sparse:t.sparse}).inboundNodes[0].outputTensors[0]}({batchShape:t.batchInputShape,dtype:t.dtype,name:t.name+"_input"});t.apply(e)}if(e)this.outputs=n.outputs,this.inputs=n.inputs;else{if(1!==t.inboundNodes.length)throw new Nd(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${t.name} which has ${t.inboundNodes.length} pre-existing inbound connections.`);if(1!==t.inboundNodes[0].outputTensors.length)throw new Nd("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(t),this.outputs=[t.inboundNodes[0].outputTensors[0]],this.inputs=Nm(this.outputs[0])}this.inboundNodes=[],new wm({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:Sd(null,this.inputs.length),outputMasks:[null],inputShapes:this.inputs.map((t=>t.shape)),outputShapes:this.outputs[0].shape})}else{const e=t.apply(this.outputs[0]);if(Array.isArray(e))throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(t),this.outputs=[e],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}this.layers.push(t),this.built=!1}pop(){if(0===this.layers.length)throw new TypeError("There are no layers in the model.");if(this.layers.pop(),0===this.layers.length)this.outputs=[],this.inboundNodes=[],this.outboundNodes=[];else{const t=this.layers.length-1;this.layers[t].outboundNodes=[],this.outputs=[this.layers[t].output],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}}call(t,e){return null==this.model&&this.build(),this.model.call(t,e)}build(t){if(pm(t),0===this.inputs.length||0===this.outputs.length)throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");this.model=new _g({inputs:this.inputs,outputs:this.outputs[0],name:this.name+"_model"}),this.model.trainable=this.trainable,this.supportsMasking=this.model.supportsMasking,this.inputLayers=this.model.inputLayers,this.inputLayersNodeIndices=this.model.inputLayersNodeIndices,this.inputLayersTensorIndices=this.model.inputLayersTensorIndices,this.outputLayers=this.model.outputLayers,this.outputLayersNodeIndices=this.model.outputLayersNodeIndices,this.outputLayersTensorIndices=this.model.outputLayersTensorIndices,this.nodesByDepth=this.model.nodesByDepth,this.containerNodes=this.model.containerNodes,this.outputNames=this.model.outputNames,this.inputNames=this.model.inputNames,this.built=!0}countParams(){return this.built||this.build(),super.countParams()}summary(t,e,n=console.log){this.built||this.build(),super.summary(t,e,n)}setWeights(t){null==this.model&&this.build(),this.model.setWeights(t)}evaluate(t,e,n={}){if(!this.built)throw new kd("The model needs to be compiled before being used.");return this.model.evaluate(t,e,n)}async evaluateDataset(t,e){if(!this.built)throw new kd("The model needs to be compiled before being used.");return this.model.evaluateDataset(t,e)}predict(t,e={}){return null==this.model&&this.build(),this.model.predict(t,e)}predictOnBatch(t){return null==this.model&&this.build(),this.model.predictOnBatch(t)}compile(t){this.build(),this.model.compile(t),this.optimizer_=this.model.optimizer,this.isOptimizerOwned=this.model.isOptimizerOwned,this.loss=this.model.loss,this.metrics=this.model.metrics,this.metricsTensors=this.model.metricsTensors,this.metricsNames=this.model.metricsNames}get optimizer(){return null==this.model?void 0:this.model.optimizer}set optimizer(t){this.model.optimizer=t}async fit(t,e,n={}){if(!this.built)throw new kd("The model needs to be compiled before being used.");return this.model.fit(t,e,n)}async fitDataset(t,e){if(!this.built)throw new kd("The model needs to be compiled before being used.");return this.model.fitDataset(t,e)}async trainOnBatch(t,e){return this.model.trainOnBatch(t,e)}static fromConfig(t,e,n={},s=!1){let r,a={};if(e instanceof Array){if(null==e[0].className||"Merge"===e[0].className)throw new Nd("Legacy serialization format not supported yet.");r=e}else A(null!=e.layers,(()=>"When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field.")),r=e.layers,delete e.layers,a=e;const i=new t(a);if(!(i instanceof Mg))throw new Id("Sequential.fromConfig called on non-Sequential input: "+i);for(const t of r){const e=Mm(t,void 0,s);s&&e.setFastWeightInitDuringBuild(!0),i.add(e)}return i}set stopTraining(t){if(null==this.model)throw new Nd("Cannot set the stopTraining property of a sequential model before it is compiled.");this.model.stopTraining=t}get stopTraining(){if(null==this.model)throw new Nd("Cannot get the stopTraining property of a sequential model before it is compiled.");return this.model.stopTraining}getConfig(){const t=[];for(const e of this.layers){const n={};n.className=e.getClassName(),n.config=e.getConfig(),t.push(n)}return{name:this.name,layers:t}}}Mg.className="Sequential",Lr(Mg);class Lg extends Or{getConfig(){return{}}}class zg extends Lg{apply(t,e=1){return function(t,e=1){if(1!==e)throw new Id(`Support for alpha values other than 1 (${e}) is not implemented yet.`);return ja(t)}(t,e)}}zg.className="elu",Lr(zg);class Bg extends Lg{apply(t){return qi(t)}}Bg.className="selu",Lr(Bg);class Pg extends Lg{apply(t){return Hi(t)}}Pg.className="relu",Lr(Pg);class Wg extends Lg{apply(t){return Wr((()=>Si(6,Hi(t))))}}Wg.className="relu6",Lr(Wg);class Vg extends Lg{apply(t){return t}}Vg.className="linear",Lr(Vg);class Ug extends Lg{apply(t){return Xi(t)}}Ug.className="sigmoid",Lr(Ug);class Gg extends Lg{apply(t){return function(t){return Wr((()=>{const e=Yr(.5,pi(.2,t));return Aa(e,0,1)}))}(t)}}Gg.className="hardSigmoid",Lr(Gg);class Hg extends Lg{apply(t){return no(t)}}Hg.className="softplus",Lr(Hg);class jg extends Lg{apply(t){return function(t){return Wr((()=>Ha(t,Xr(t).add(1))))}(t)}}jg.className="softsign",Lr(jg);class qg extends Lg{apply(t){return lo(t)}}qg.className="tanh",Lr(qg);class Kg extends Lg{apply(t,e=-1){return eo(t,e)}}Kg.className="softmax",Lr(Kg);class Xg extends Lg{apply(t,e=-1){return bi(t,e)}}Xg.className="logSoftmax",Lr(Xg);class Yg extends Lg{apply(t,e=1){return Wr((()=>Xi(t.mul(e)).mul(t)))}}function Jg(t){return t.getClassName()}function Zg(t,e={}){return Md(t,Mr.getMap().classNameMap,e,"activation")}function Qg(t){if(null==t){return Zg({className:"linear",config:{}})}if("string"==typeof t){const e={};return e.className=t,e.config={},Zg(e)}return t instanceof Lg?t:Zg(t)}Yg.className="swish",Lr(Yg);class ty extends Or{}class ey extends ty{constructor(t){super(),function(t){if(null!=t&&"object"!=typeof t)throw new Error("Argument to L1L2 regularizer's constructor is expected to be an object, but received: "+t)}(t),this.l1=null==t||null==t.l1?.01:t.l1,this.l2=null==t||null==t.l2?.01:t.l2,this.hasL1=0!==this.l1,this.hasL2=0!==this.l2}apply(t){return Wr((()=>{let e=ki([1]);return this.hasL1&&(e=Yr(e,yi(pi(this.l1,Xr(t))))),this.hasL2&&(e=Yr(e,yi(pi(this.l2,Df(t))))),e.asScalar()}))}getConfig(){return{l1:this.l1,l2:this.l2}}static fromConfig(t,e){return new t({l1:e.l1,l2:e.l2})}}ey.className="L1L2",Lr(ey);const ny={l1l2:"L1L2"};function sy(t){return _d(t)}function ry(t,e={}){return Md(t,Mr.getMap().classNameMap,e,"regularizer")}function ay(t){return null==t?null:"string"==typeof t?ry({className:t in ny?ny[t]:t,config:{}}):t instanceof ty?t:ry(t)}class iy extends km{constructor(t){super(null==t?{}:t),this.supportsMasking=!0,null!=t&&(this.maxValue=t.maxValue)}call(t,e){t=hm(t);let n=Hi(t);return null!=this.maxValue&&(n=Aa(n,0,this.maxValue)),n}computeOutputShape(t){return t}getConfig(){const t={maxValue:this.maxValue},e=super.getConfig();return Object.assign(t,e),t}}iy.className="ReLU",Lr(iy);class oy extends km{constructor(t){super(null==t?{}:t),this.DEFAULT_ALPHA=.3,null==t&&(t={}),this.alpha=null==t.alpha?this.DEFAULT_ALPHA:t.alpha}call(t,e){const n=hm(t);return di(n,this.alpha)}computeOutputShape(t){return t}getConfig(){const t={alpha:this.alpha},e=super.getConfig();return Object.assign(t,e),t}}oy.className="LeakyReLU",Lr(oy);class ly extends km{constructor(t){if(super(null==t?{}:t),this.DEFAULT_ALPHA_INITIALIZER="zeros",null==t&&(t={}),this.supportsMasking=!0,this.alphaInitializer=rm(t.alphaInitializer||this.DEFAULT_ALPHA_INITIALIZER),this.alphaRegularizer=ay(t.alphaRegularizer),this.alphaConstraint=tf(t.alphaConstraint),null==t.sharedAxes)this.sharedAxes=null;else if(Array.isArray(t.sharedAxes))this.sharedAxes=t.sharedAxes;else{if("number"!=typeof t.sharedAxes)throw new Nd("Expected sharedAxes to be a number or an array of numbers, but got "+t.sharedAxes);this.sharedAxes=[t.sharedAxes]}}build(t){const e=(t=pm(t)).slice(1);if(null!=this.sharedAxes)for(const t of this.sharedAxes)e[t-1]=1;this.alpha=this.addWeight("alpha",e,"float32",this.alphaInitializer,this.alphaRegularizer,!0,this.alphaConstraint);const n={};if(null!=this.sharedAxes)for(let e=1;e<t.length;++e)n[e]=t[e];this.inputSpec=[new ym({ndim:t.length,axes:n})],this.built=!0}call(t,e){return t=hm(t),Li(t,this.alpha.read())}getConfig(){const t={alphaInitializer:sm(this.alphaInitializer),alphaRegularizer:sy(this.alphaRegularizer),alphaConstraint:Zd(this.alphaConstraint),sharedAxes:this.sharedAxes},e=super.getConfig();return Object.assign(t,e),t}}ly.className="PReLU",Lr(ly);class uy extends km{constructor(t){if(super(null==t?{}:t),this.DEFAULT_ALPHA=1,null==t&&(t={}),null!=t.alpha&&t.alpha!==this.DEFAULT_ALPHA)throw new Id(`Non-default alpha value (${t.alpha}) is not supported by the ELU layer yet.`);this.alpha=null==t.alpha?this.DEFAULT_ALPHA:t.alpha}call(t,e){const n=hm(t);return ja(n)}computeOutputShape(t){return t}getConfig(){const t={alpha:this.alpha},e=super.getConfig();return Object.assign(t,e),t}}uy.className="ELU",Lr(uy);class cy extends km{constructor(t){super(null==t?{}:t),this.DEFAULT_THETA=1,null==t&&(t={}),this.theta=null==t.theta?this.DEFAULT_THETA:t.theta}call(t,e){const n=hm(t);return n.mul(vf(n.greater(this.theta),"float32"))}computeOutputShape(t){return t}getConfig(){const t={theta:this.theta},e=super.getConfig();return Object.assign(t,e),t}}cy.className="ThresholdedReLU",Lr(cy);class hy extends km{constructor(t){super(null==t?{}:t),this.DEFAULT_AXIS=1,null==t&&(t={}),this.softmax=(new Kg).apply,this.axis=null==t.axis?this.DEFAULT_AXIS:t.axis}call(t,e){const n=hm(t);return this.softmax(n,this.axis)}computeOutputShape(t){return t}getConfig(){const t={axis:this.axis},e=super.getConfig();return Object.assign(t,e),t}}function py(t,e,n){if("number"==typeof t)return Sd(t,e);if(t.length!==e)throw new Nd(`The ${n} argument must be an integer or tuple of ${e} integers. Received: ${t.length} elements.`);for(let r=0;r<e;++r){const a=t[r];if((s=a)!==parseInt(s.toString(),10))throw new Nd(`The ${n} argument must be an integer or tuple of ${e} integers. Received: ${JSON.stringify(t)} including a non-integer number `+a)}return t;var s}function dy(t,e,n,s,r=1){if(null==t)return t;let a;return a="same"===n?t:t-(e+(e-1)*(r-1))+1,Math.floor((a+s-1)/s)}function fy(t,e,n,s){if(null==t)return null;if("valid"===s)t=t*e+xf([n-e,0]);else{if("same"!==s)throw new Nd(`Unsupport padding mode: ${s}.`);t*=e}return t}function my(t,e){return Wr((()=>(of(e),"channelsFirst"===e?ia(t,[0,2,3,1]):t)))}function gy(t,e){return Wr((()=>(of(e),"channelsFirst"===e?ia(t,[0,2,3,4,1]):t)))}function yy(t,e,n,s=[1,1],r="valid",a,i,o=null){return Wr((()=>{if(null==a&&(a="channelsLast"),of(a),3!==t.rank&&4!==t.rank)throw new Nd(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${t.rank}.`);if(3!==e.rank&&4!==e.rank)throw new Nd(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${t.rank}.`);let l=my(t,a);if("causal"===r)throw new Id("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");return l=$o({x:l,filter:e,strides:s,pad:"same"===r?"same":"valid",dilations:i,dataFormat:"NHWC",bias:n,activation:o}),"channelsFirst"===a&&(l=ia(l,[0,3,1,2])),l}))}hy.className="Softmax",Lr(hy);class by extends km{constructor(t,e){if(super(e),this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",by.verifyArgs(e),this.rank=t,Vd(this.rank,"rank"),1!==this.rank&&2!==this.rank&&3!==this.rank)throw new Id(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);if(this.kernelSize=py(e.kernelSize,t,"kernelSize"),this.strides=py(null==e.strides?1:e.strides,t,"strides"),this.padding=null==e.padding?"valid":e.padding,lf(this.padding),this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,of(this.dataFormat),this.activation=Qg(e.activation),this.useBias=null==e.useBias||e.useBias,this.biasInitializer=rm(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.biasConstraint=tf(e.biasConstraint),this.biasRegularizer=ay(e.biasRegularizer),this.activityRegularizer=ay(e.activityRegularizer),this.dilationRate=py(null==e.dilationRate?1:e.dilationRate,t,"dilationRate"),1===this.rank&&Array.isArray(this.dilationRate)&&1!==this.dilationRate.length)throw new Nd("dilationRate must be a number or an array of a single number for 1D convolution, but received "+JSON.stringify(this.dilationRate));if(2===this.rank){if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate];else if(2!==this.dilationRate.length)throw new Nd("dilationRate must be a number or array of two numbers for 2D convolution, but received "+JSON.stringify(this.dilationRate))}else if(3===this.rank)if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate,this.dilationRate];else if(3!==this.dilationRate.length)throw new Nd("dilationRate must be a number or array of three numbers for 3D convolution, but received "+JSON.stringify(this.dilationRate))}static verifyArgs(t){if(Td("kernelSize"in t,"required key 'kernelSize' not in config"),"number"!=typeof t.kernelSize&&!Wd(t.kernelSize,"number",1,3))throw new Nd(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(t.kernelSize)}.`)}getConfig(){const t={kernelSize:this.kernelSize,strides:this.strides,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,activation:Jg(this.activation),useBias:this.useBias,biasInitializer:sm(this.biasInitializer),biasRegularizer:sy(this.biasRegularizer),activityRegularizer:sy(this.activityRegularizer),biasConstraint:Zd(this.biasConstraint)},e=super.getConfig();return Object.assign(t,e),t}}class xy extends by{constructor(t,e){super(t,e),this.kernel=null,xy.verifyArgs(e),this.filters=e.filters,Vd(this.filters,"filters"),this.kernelInitializer=rm(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.kernelConstraint=tf(e.kernelConstraint),this.kernelRegularizer=ay(e.kernelRegularizer)}build(t){t=pm(t);const e="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[e])throw new Nd("The channel dimension of the input should be defined. Found "+t[e]);const n=t[e],s=this.kernelSize.concat([n,this.filters]);this.kernel=this.addWeight("kernel",s,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[{ndim:this.rank+2,axes:{[e]:n}}],this.built=!0}call(t,e){return Wr((()=>{let e;t=hm(t);const n=null==this.bias?null:this.bias.read(),s=Gd(this.activation.getClassName());if(null!=s&&2===this.rank)e=yy(t,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate,s);else{if(1===this.rank)e=function(t,e,n,s=1,r="valid",a,i=1){return Wr((()=>{if(null==a&&(a="channelsLast"),of(a),3!==t.shape.length)throw new Nd("The input of a conv1dWithBias operation should be 3, but is "+t.shape.length+" instead.");if(3!==e.shape.length)throw new Nd("The kernel for a conv1dWithBias operation should be 3, but is "+e.shape.length+" instead");if(null!=n&&1!==n.shape.length)throw new Nd("The bias for a conv1dWithBias operation should be 1, but is "+e.shape.length+" instead");if("channelsFirst"===a&&(t=ia(t,[0,2,1])),"causal"===r)throw new Id("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");let o=Ba(t,e,s,"same"===r?"same":"valid","NWC",i);return null!=n&&(o=_f(o,n)),o}))}(t,this.kernel.read(),n,this.strides[0],this.padding,this.dataFormat,this.dilationRate[0]);else if(2===this.rank)e=yy(t,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate);else{if(3!==this.rank)throw new Id("convolutions greater than 3D are not implemented yet.");e=function(t,e,n,s=[1,1,1],r="valid",a,i){return Wr((()=>{if(null==a&&(a="channelsLast"),of(a),4!==t.rank&&5!==t.rank)throw new Nd("conv3dWithBias expects input to be of rank 4 or 5, but received "+t.rank+".");if(4!==e.rank&&5!==e.rank)throw new Nd("conv3dWithBias expects kernel to be of rank 4 or 5, but received "+t.rank+".");let o=gy(t,a);if("causal"===r)throw new Id("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");return o=Va(o,e,s,"same"===r?"same":"valid","NDHWC",i),null!=n&&(o=_f(o,n)),"channelsFirst"===a&&(o=ia(o,[0,4,1,2,3])),o}))}(t,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate)}null!=this.activation&&(e=this.activation.apply(e))}return e}))}computeOutputShape(t){t=pm(t);const e=[],n="channelsLast"===this.dataFormat?t.slice(1,t.length-1):t.slice(2);for(let t=0;t<n.length;++t){const s=dy(n[t],this.kernelSize[t],this.padding,this.strides[t],"number"==typeof this.dilationRate?this.dilationRate:this.dilationRate[t]);e.push(s)}let s=[t[0]];return"channelsLast"===this.dataFormat?(s=s.concat(e),s.push(this.filters)):(s.push(this.filters),s=s.concat(e)),s}getConfig(){const t={filters:this.filters,kernelInitializer:sm(this.kernelInitializer),kernelRegularizer:sy(this.kernelRegularizer),kernelConstraint:Zd(this.kernelConstraint)},e=super.getConfig();return Object.assign(t,e),t}static verifyArgs(t){if(!("filters"in t)||"number"!=typeof t.filters||t.filters<1)throw new Nd("Convolution layer expected config.filters to be a 'number' > 0 but got "+JSON.stringify(t.filters))}}class wy extends xy{constructor(t){super(2,t),wy.verifyArgs(t)}getConfig(){const t=super.getConfig();return delete t.rank,t}static verifyArgs(t){if("number"!=typeof t.kernelSize&&!Wd(t.kernelSize,"number",1,2))throw new Nd(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(t.kernelSize)}.`)}}wy.className="Conv2D",Lr(wy);class vy extends xy{constructor(t){super(3,t),vy.verifyArgs(t)}getConfig(){const t=super.getConfig();return delete t.rank,t}static verifyArgs(t){if("number"!=typeof t.kernelSize&&(!Array.isArray(t.kernelSize)||1!==t.kernelSize.length&&3!==t.kernelSize.length))throw new Nd(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(t.kernelSize)}.`)}}vy.className="Conv3D",Lr(vy);class ky extends wy{constructor(t){if(super(t),this.inputSpec=[new ym({ndim:4})],"same"!==this.padding&&"valid"!==this.padding)throw new Nd("Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode "+this.padding)}build(t){if(4!==(t=pm(t)).length)throw new Nd("Input should have rank 4; Received input shape: "+JSON.stringify(t));const e="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[e])throw new Nd("The channel dimension of the inputs should be defined. Found `None`.");const n=t[e],s=this.kernelSize.concat([this.filters,n]);this.kernel=this.addWeight("kernel",s,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new ym({ndim:4,axes:{[e]:n}})],this.built=!0}call(t,e){return Wr((()=>{let e=hm(t);if(4!==e.shape.length)throw new Nd("Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-"+e.shape.length);const n=e.shape,s=n[0];let r,a;"channelsFirst"===this.dataFormat?(r=2,a=3):(r=1,a=2);const i=n[r],o=n[a],l=this.kernelSize[0],u=this.kernelSize[1],c=this.strides[0],h=this.strides[1],p=[s,fy(i,c,l,this.padding),fy(o,h,u,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(e=ia(e,[0,2,3,1]));let d=Wa(e,this.kernel.read(),p,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(d=ia(d,[0,3,1,2])),null!=this.bias&&(d=_f(d,this.bias.read(),this.dataFormat)),null!=this.activation&&(d=this.activation.apply(d)),d}))}computeOutputShape(t){const e=(t=pm(t)).slice();let n,s,r;"channelsFirst"===this.dataFormat?(n=1,s=2,r=3):(n=3,s=1,r=2);const a=this.kernelSize[0],i=this.kernelSize[1],o=this.strides[0],l=this.strides[1];return e[n]=this.filters,e[s]=fy(e[s],o,a,this.padding),e[r]=fy(e[r],l,i,this.padding),e}getConfig(){const t=super.getConfig();return delete t.dilationRate,t}}ky.className="Conv2DTranspose",Lr(ky);class Ny extends xy{constructor(t,e){if(super(t,e),this.DEFAULT_DEPTHWISE_INITIALIZER="glorotUniform",this.DEFAULT_POINTWISE_INITIALIZER="glorotUniform",this.depthwiseKernel=null,this.pointwiseKernel=null,null==e.filters)throw new Nd("The `filters` configuration field is required by SeparableConv, but is unspecified.");if(null!=e.kernelInitializer||null!=e.kernelRegularizer||null!=e.kernelConstraint)throw new Nd("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");if(null!=e.padding&&"same"!==e.padding&&"valid"!==e.padding)throw new Nd(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received `+JSON.stringify(e.padding));this.depthMultiplier=null==e.depthMultiplier?1:e.depthMultiplier,this.depthwiseInitializer=rm(e.depthwiseInitializer||this.DEFAULT_DEPTHWISE_INITIALIZER),this.depthwiseRegularizer=ay(e.depthwiseRegularizer),this.depthwiseConstraint=tf(e.depthwiseConstraint),this.pointwiseInitializer=rm(e.depthwiseInitializer||this.DEFAULT_POINTWISE_INITIALIZER),this.pointwiseRegularizer=ay(e.pointwiseRegularizer),this.pointwiseConstraint=tf(e.pointwiseConstraint)}build(t){if((t=pm(t)).length<this.rank+2)throw new Nd(`Inputs to SeparableConv${this.rank}D should have rank `+(this.rank+2)+", but received input shape: "+JSON.stringify(t));const e="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[e]||t[e]<0)throw new Nd("The channel dimension of the inputs should be defined, but found "+JSON.stringify(t[e]));const n=t[e],s=this.kernelSize.concat([n,this.depthMultiplier]),r=[];for(let t=0;t<this.rank;++t)r.push(1);r.push(n*this.depthMultiplier,this.filters);const a=!0;this.depthwiseKernel=this.addWeight("depthwise_kernel",s,"float32",this.depthwiseInitializer,this.depthwiseRegularizer,a,this.depthwiseConstraint),this.pointwiseKernel=this.addWeight("pointwise_kernel",r,"float32",this.pointwiseInitializer,this.pointwiseRegularizer,a,this.pointwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,a,this.biasConstraint):this.bias=null,this.inputSpec=[new ym({ndim:this.rank+2,axes:{[e]:n}})],this.built=!0}call(t,e){return Wr((()=>{let e;if(t=hm(t),1===this.rank)throw new Id("1D separable convolution is not implemented yet.");return 2===this.rank&&("channelsFirst"===this.dataFormat&&(t=ia(t,[0,2,3,1])),e=Ki(t,this.depthwiseKernel.read(),this.pointwiseKernel.read(),this.strides,this.padding,this.dilationRate,"NHWC")),this.useBias&&(e=_f(e,this.bias.read(),this.dataFormat)),null!=this.activation&&(e=this.activation.apply(e)),"channelsFirst"===this.dataFormat&&(e=ia(e,[0,3,1,2])),e}))}getConfig(){const t=super.getConfig();return delete t.rank,delete t.kernelInitializer,delete t.kernelRegularizer,delete t.kernelConstraint,t.depthwiseInitializer=sm(this.depthwiseInitializer),t.pointwiseInitializer=sm(this.pointwiseInitializer),t.depthwiseRegularizer=sy(this.depthwiseRegularizer),t.pointwiseRegularizer=sy(this.pointwiseRegularizer),t.depthwiseConstraint=Zd(this.depthwiseConstraint),t.pointwiseConstraint=Zd(this.pointwiseConstraint),t}}Ny.className="SeparableConv";class Iy extends Ny{constructor(t){super(2,t)}}Iy.className="SeparableConv2D",Lr(Iy);class Cy extends xy{constructor(t){super(1,t),Cy.verifyArgs(t),this.inputSpec=[{ndim:3}]}getConfig(){const t=super.getConfig();return delete t.rank,delete t.dataFormat,t}static verifyArgs(t){if("number"!=typeof t.kernelSize&&!Wd(t.kernelSize,"number",1,1))throw new Nd(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(t.kernelSize)}.`)}}Cy.className="Conv1D",Lr(Cy);class Sy extends km{constructor(t){super(t),"number"==typeof t.cropping?this.cropping=[[t.cropping,t.cropping],[t.cropping,t.cropping]]:"number"==typeof t.cropping[0]?this.cropping=[[t.cropping[0],t.cropping[0]],[t.cropping[1],t.cropping[1]]]:this.cropping=t.cropping,this.dataFormat=void 0===t.dataFormat?"channelsLast":t.dataFormat,this.inputSpec=[{ndim:4}]}computeOutputShape(t){return"channelsFirst"===this.dataFormat?[t[0],t[1],t[2]-this.cropping[0][0]-this.cropping[0][1],t[3]-this.cropping[1][0]-this.cropping[1][1]]:[t[0],t[1]-this.cropping[0][0]-this.cropping[0][1],t[2]-this.cropping[1][0]-this.cropping[1][1],t[3]]}call(t,e){return Wr((()=>{if(t=hm(t),"channelsLast"===this.dataFormat){const e=Cf(t,this.cropping[0][0],t.shape[1]-this.cropping[0][0]-this.cropping[0][1],2);return Cf(e,this.cropping[1][0],t.shape[2]-this.cropping[1][1]-this.cropping[1][0],3)}{const e=Cf(t,this.cropping[0][0],t.shape[2]-this.cropping[0][0]-this.cropping[0][1],3);return Cf(e,this.cropping[1][0],t.shape[3]-this.cropping[1][1]-this.cropping[1][0],4)}}))}getConfig(){const t={cropping:this.cropping,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}Sy.className="Cropping2D",Lr(Sy);class Ty extends km{constructor(t){super(t),this.DEFAULT_SIZE=[2,2],this.inputSpec=[{ndim:4}],this.size=null==t.size?this.DEFAULT_SIZE:t.size,this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat}computeOutputShape(t){if("channelsFirst"===this.dataFormat){const e=null==t[2]?null:this.size[0]*t[2],n=null==t[3]?null:this.size[1]*t[3];return[t[0],t[1],e,n]}{const e=null==t[1]?null:this.size[0]*t[1],n=null==t[2]?null:this.size[1]*t[2];return[t[0],e,n,t[3]]}}call(t,e){return Wr((()=>{let e=hm(t);const n=e.shape;if("channelsFirst"===this.dataFormat){e=ia(e,[0,2,3,1]);const t=this.size[0]*n[2],s=this.size[1]*n[3],r=e.resizeNearestNeighbor([t,s]);return ia(r,[0,3,1,2])}{const t=this.size[0]*n[1],s=this.size[1]*n[2];return e.resizeNearestNeighbor([t,s])}}))}getConfig(){const t={size:this.size,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}Ty.className="UpSampling2D",Lr(Ty);class $y extends by{constructor(t){super(2,t),this.depthwiseKernel=null,this.depthMultiplier=null==t.depthMultiplier?1:t.depthMultiplier,this.depthwiseInitializer=rm(t.depthwiseInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.depthwiseConstraint=tf(t.depthwiseConstraint),this.depthwiseRegularizer=ay(t.depthwiseRegularizer)}build(t){if((t=pm(t)).length<4)throw new Nd(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(t)}.`);const e="channelsFirst"===this.dataFormat?1:3;if(null==t[e]||t[e]<0)throw new Nd(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${t[e]}).`);const n=t[e],s=[this.kernelSize[0],this.kernelSize[1],n,this.depthMultiplier];this.depthwiseKernel=this.addWeight("depthwise_kernel",s,null,this.depthwiseInitializer,this.depthwiseRegularizer,!0,this.depthwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[n*this.depthMultiplier],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,e){return Wr((()=>{let e=function(t,e,n=[1,1],s="valid",r,a){return Wr((()=>{null==r&&(r="channelsLast"),of(r);let i=my(t,r);if(4!==t.rank)throw new Nd("Input for depthwiseConv2d is required to be 4-D, but is instead "+t.rank+"-D");if(4!==e.rank)throw new Nd("depthwiseKernel is required to be 4-D, but is instead "+e.rank+"-D");return i=Ua(i,e,n,"same"===s?"same":"valid","NHWC",a),"channelsFirst"===r&&(i=ia(i,[0,3,1,2])),i}))}(t=hm(t),this.depthwiseKernel.read(),this.strides,this.padding,this.dataFormat,null);return this.useBias&&(e=_f(e,this.bias.read(),this.dataFormat)),null!=this.activation&&(e=this.activation.apply(e)),e}))}computeOutputShape(t){t=pm(t);const e="channelsFirst"===this.dataFormat?t[2]:t[1],n="channelsFirst"===this.dataFormat?t[3]:t[2],s="channelsFirst"===this.dataFormat?t[1]*this.depthMultiplier:t[3]*this.depthMultiplier,r=dy(e,this.kernelSize[0],this.padding,this.strides[0]),a=dy(n,this.kernelSize[1],this.padding,this.strides[1]);return"channelsFirst"===this.dataFormat?[t[0],s,r,a]:[t[0],r,a,s]}getConfig(){const t=super.getConfig();return t.depthMultiplier=this.depthMultiplier,t.depthwiseInitializer=sm(this.depthwiseInitializer),t.depthwiseRegularizer=sy(this.depthwiseRegularizer),t.depthwiseConstraint=Zd(this.depthwiseRegularizer),t}}function Ey(t,e,n,s){if(Array.isArray(t)){if(null!=e||null!=n)throw new Nd("When inputs is an array, neither initialState or constants should be provided");null!=s&&(n=t.slice(t.length-s,t.length),t=t.slice(0,t.length-s)),t.length>1&&(e=t.slice(1,t.length)),t=t[0]}function r(t){return null==t||Array.isArray(t)?t:[t]}return{inputs:t,initialState:e=r(e),constants:n=r(n)}}function Ay(t,e,n,s=!1,r,a,i=!1,o=!1){return Wr((()=>{const l=e.shape.length;if(l<3)throw new Nd(`Input should be at least 3D, but is ${l}D.`);const u=[1,0].concat(wf(2,l));if(e=ia(e,u),null!=a)throw new Id("The rnn() functoin of the deeplearn.js backend does not support constants yet.");i&&console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend."),null!=r&&((r=r.asType("bool").asType("float32")).rank===l-1&&(r=Za(r,-1)),r=ia(r,u)),s&&(e=ji(e,0),null!=r&&(r=ji(r,0)));const c=[];let h,p=n;const d=e.shape[0],f=po(e);let m,g;null!=r&&(m=po(r));for(let e=0;e<d;++e){const n=f[e],s=Wr((()=>t(n,p)));if(null==r)h=s[0],p=s[1];else{const t=Wr((()=>{const t=m[e],n=Oi(t).sub(t);return{output:s[0].mul(t).add(p[0].mul(n)),newStates:p.map(((e,r)=>s[1][r].mul(t).add(e.mul(n))))}}));h=t.output,p=t.newStates}o&&c.push(h)}return o&&(g=oo(c,1)),[h,g,p]}))}$y.className="DepthwiseConv2D",Lr($y);class Ry extends km{constructor(t){let e;if(super(t),null==t.cell)throw new Nd("cell property is missing for the constructor of RNN.");if(e=Array.isArray(t.cell)?new By({cells:t.cell}):t.cell,null==e.stateSize)throw new Nd("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");this.cell=e,this.returnSequences=null!=t.returnSequences&&t.returnSequences,this.returnState=null!=t.returnState&&t.returnState,this.goBackwards=null!=t.goBackwards&&t.goBackwards,this._stateful=null!=t.stateful&&t.stateful,this.unroll=null!=t.unroll&&t.unroll,this.supportsMasking=!0,this.inputSpec=[new ym({ndim:3})],this.stateSpec=null,this.states_=null,this.numConstants=null,this.keptStates=[]}getStates(){return null==this.states_?wf(0,Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1).map((t=>null)):this.states_}setStates(t){this.states_=t}computeOutputShape(t){um(t)&&(t=t[0]),t=t;let e=this.cell.stateSize;Array.isArray(e)||(e=[e]);const n=e[0];let s;if(s=this.returnSequences?[t[0],t[1],n]:[t[0],n],this.returnState){const n=[];for(const s of e)n.push([t[0],s]);return[s].concat(n)}return s}computeMask(t,e){return Wr((()=>{Array.isArray(e)&&(e=e[0]);const t=this.returnSequences?e:null;if(this.returnState){const e=this.states.map((t=>null));return[t].concat(e)}return t}))}get states(){if(null==this.states_){const t=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1,e=[];for(let n=0;n<t;++n)e.push(null);return e}return this.states_}set states(t){this.states_=t}build(t){if(null!=this.numConstants)throw new Id("Constants support is not implemented in RNN yet.");um(t)&&(t=t[0]),t=t;const e=this.stateful?t[0]:null,n=t.slice(2);this.inputSpec[0]=new ym({shape:[e,null,...n]});const s=[t[0]].concat(t.slice(2));let r;if(this.cell.build(s),r=Array.isArray(this.cell.stateSize)?this.cell.stateSize:[this.cell.stateSize],null!=this.stateSpec){if(!O(this.stateSpec.map((t=>t.shape[t.shape.length-1])),r))throw new Nd(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is `+this.cell.stateSize)}else this.stateSpec=r.map((t=>new ym({shape:[null,t]})));this.stateful&&this.resetStates()}resetStates(t,e=!1){Wr((()=>{if(!this.stateful)throw new vd("Cannot call resetStates() on an RNN Layer that is not stateful.");const n=this.inputSpec[0].shape[0];if(null==n)throw new Nd("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.states_)Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((t=>ki([n,t]))):this.states_=[ki([n,this.cell.stateSize])];else if(null==t)Vr(this.states_),null!=this.keptStates&&(Vr(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((t=>ki([n,t]))):this.states_[0]=ki([n,this.cell.stateSize]);else{if(Array.isArray(t)||(t=[t]),t.length!==this.states_.length)throw new Nd(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: `+t);!0===e?this.keptStates.push(this.states_.slice()):Vr(this.states_);for(let e=0;e<this.states_.length;++e){const s=t[e],r=Array.isArray(this.cell.stateSize)?this.cell.stateSize[e]:this.cell.stateSize,a=[n,r];if(!O(s.shape,a))throw new Nd(`State ${e} is incompatible with layer ${this.name}: expected shape=${a}, received shape=${s.shape}`);this.states_[e]=s}}this.states_=this.states_.map((t=>Ur(t.clone())))}))}apply(t,e){let n=null==e?null:e.initialState,s=null==e?null:e.constants;null==e&&(e={});const r=Ey(t,n,s,this.numConstants);t=r.inputs,n=r.initialState,s=r.constants;let a=[],i=[];if(null!=n){e.initialState=n,a=a.concat(n),this.stateSpec=[];for(const t of n)this.stateSpec.push(new ym({shape:t.shape}));i=i.concat(this.stateSpec)}if(null!=s&&(e.constants=s,a=a.concat(s),this.numConstants=s.length),a[0]instanceof bm){const n=[t].concat(a),s=this.inputSpec.concat(i),r=this.inputSpec;this.inputSpec=s;const o=super.apply(n,e);return this.inputSpec=r,o}return super.apply(t,e)}call(t,e){return Wr((()=>{const n=null==e?null:e.mask,s=null==e?null:e.training;let r=null==e?null:e.initialState;t=hm(t),null==r&&(r=this.stateful?this.states_:this.getInitialState(t));const a=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1;if(r.length!==a)throw new Nd(`RNN Layer has ${a} state(s) but was passed `+r.length+" initial state(s).");this.unroll&&console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");const i={training:s},o=Ay(((t,e)=>{const n=this.cell.call([t].concat(e),i);return[n[0],n.slice(1)]}),t,r,this.goBackwards,n,null,this.unroll,this.returnSequences),l=o[0],u=o[1],c=o[2];this.stateful&&this.resetStates(c,s);const h=this.returnSequences?u:l;return this.returnState?[h].concat(c):h}))}getInitialState(t){return Wr((()=>{let e=ki(t.shape);return e=yi(e,[1,2]),e=kf(e),Array.isArray(this.cell.stateSize)?this.cell.stateSize.map((t=>t>1?$f(e,[1,t]):e)):this.cell.stateSize>1?[$f(e,[1,this.cell.stateSize])]:[e]}))}get trainableWeights(){return this.trainable?this.cell.trainableWeights:[]}get nonTrainableWeights(){return this.trainable?this.cell.nonTrainableWeights:this.cell.weights}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),null!=this.cell&&this.cell.setFastWeightInitDuringBuild(t)}getConfig(){const t=super.getConfig(),e={returnSequences:this.returnSequences,returnState:this.returnState,goBackwards:this.goBackwards,stateful:this.stateful,unroll:this.unroll};null!=this.numConstants&&(e.numConstants=this.numConstants);const n=this.cell.getConfig();return this.getClassName()===Ry.className&&(e.cell={className:this.cell.getClassName(),config:n}),Object.assign({},n,t,e)}static fromConfig(t,e,n={}){const s=Mm(e.cell,n);return new t(Object.assign(e,{cell:s}))}}Ry.className="RNN",Lr(Ry);class Dy extends km{}class Fy extends Dy{constructor(t){super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=t.units,Vd(this.units,"units"),this.activation=Qg(null==t.activation?this.DEFAULT_ACTIVATION:t.activation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=rm(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=rm(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=rm(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=ay(t.kernelRegularizer),this.recurrentRegularizer=ay(t.recurrentRegularizer),this.biasRegularizer=ay(t.biasRegularizer),this.kernelConstraint=tf(t.kernelConstraint),this.recurrentConstraint=tf(t.recurrentConstraint),this.biasConstraint=tf(t.biasConstraint),this.dropout=bf([1,xf([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=bf([1,xf([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){t=pm(t),this.kernel=this.addWeight("kernel",[t[t.length-1],this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias?this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,e){return Wr((()=>{if(2!==(t=t).length)throw new Nd(`SimpleRNNCell expects 2 input Tensors, got ${t.length}.`);let n=t[1];t=t[0];const s=null!=e.training&&e.training;let r;0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=Py({ones:()=>Oi(t),rate:this.dropout,training:s})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=Py({ones:()=>Oi(n),rate:this.recurrentDropout,training:s}));const a=this.dropoutMask,i=this.recurrentDropoutMask;r=Af(null!=a?pi(t,a):t,this.kernel.read()),null!=this.bias&&(r=_f(r,this.bias.read())),null!=i&&(n=pi(n,i));let o=Yr(r,Af(n,this.recurrentKernel.read()));return null!=this.activation&&(o=this.activation.apply(o)),[o,o]}))}getConfig(){const t=super.getConfig(),e={units:this.units,activation:Jg(this.activation),useBias:this.useBias,kernelInitializer:sm(this.kernelInitializer),recurrentInitializer:sm(this.recurrentInitializer),biasInitializer:sm(this.biasInitializer),kernelRegularizer:sy(this.kernelRegularizer),recurrentRegularizer:sy(this.recurrentRegularizer),biasRegularizer:sy(this.biasRegularizer),activityRegularizer:sy(this.activityRegularizer),kernelConstraint:Zd(this.kernelConstraint),recurrentConstraint:Zd(this.recurrentConstraint),biasConstraint:Zd(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout};return Object.assign({},t,e)}}Fy.className="SimpleRNNCell",Lr(Fy);class _y extends Ry{constructor(t){t.cell=new Fy(t),super(t)}call(t,e){return Wr((()=>{null!=this.cell.dropoutMask&&(Vr(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(Vr(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const n=null==e?null:e.mask,s=null==e?null:e.training,r=null==e?null:e.initialState;return super.call(t,{mask:n,training:s,initialState:r})}))}static fromConfig(t,e){return new t(e)}}_y.className="SimpleRNN",Lr(_y);class Oy extends Dy{constructor(t){if(super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",t.resetAfter)throw new Nd("GRUCell does not support reset_after parameter set to true.");this.units=t.units,Vd(this.units,"units"),this.activation=Qg(void 0===t.activation?this.DEFAULT_ACTIVATION:t.activation),this.recurrentActivation=Qg(void 0===t.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:t.recurrentActivation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=rm(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=rm(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=rm(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=ay(t.kernelRegularizer),this.recurrentRegularizer=ay(t.recurrentRegularizer),this.biasRegularizer=ay(t.biasRegularizer),this.kernelConstraint=tf(t.kernelConstraint),this.recurrentConstraint=tf(t.recurrentConstraint),this.biasConstraint=tf(t.biasConstraint),this.dropout=bf([1,xf([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=bf([1,xf([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.implementation=t.implementation,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){const e=(t=pm(t))[t.length-1];this.kernel=this.addWeight("kernel",[e,3*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,3*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias?this.bias=this.addWeight("bias",[3*this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,e){return Wr((()=>{if(2!==(t=t).length)throw new Nd("GRUCell expects 2 input Tensors (inputs, h, c), got "+t.length+".");const n=null!=e.training&&e.training;let s=t[1];t=t[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=Py({ones:()=>Oi(t),rate:this.dropout,training:n,count:3})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=Py({ones:()=>Oi(s),rate:this.recurrentDropout,training:n,count:3}));const r=this.dropoutMask,a=this.recurrentDropoutMask;let i,o,l;0<this.dropout&&this.dropout<1&&(t=pi(t,r[0]));let u=Af(t,this.kernel.read());this.useBias&&(u=_f(u,this.bias.read())),0<this.recurrentDropout&&this.recurrentDropout<1&&(s=pi(s,a[0]));const c=this.recurrentKernel.read(),[h,p]=ro(c,[2*this.units,this.units],c.rank-1),d=Af(s,h),[f,m,g]=ro(u,3,u.rank-1),[y,b]=ro(d,2,d.rank-1);i=this.recurrentActivation.apply(Yr(f,y)),o=this.recurrentActivation.apply(Yr(m,b));const x=Af(pi(o,s),p);l=this.activation.apply(Yr(g,x));const w=Yr(pi(i,s),pi(Yr(1,Ei(i)),l));return[w,w]}))}getConfig(){const t=super.getConfig(),e={units:this.units,activation:Jg(this.activation),recurrentActivation:Jg(this.recurrentActivation),useBias:this.useBias,kernelInitializer:sm(this.kernelInitializer),recurrentInitializer:sm(this.recurrentInitializer),biasInitializer:sm(this.biasInitializer),kernelRegularizer:sy(this.kernelRegularizer),recurrentRegularizer:sy(this.recurrentRegularizer),biasRegularizer:sy(this.biasRegularizer),activityRegularizer:sy(this.activityRegularizer),kernelConstraint:Zd(this.kernelConstraint),recurrentConstraint:Zd(this.recurrentConstraint),biasConstraint:Zd(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation,resetAfter:!1};return Object.assign({},t,e)}}Oy.className="GRUCell",Lr(Oy);class My extends Ry{constructor(t){0===t.implementation&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),t.cell=new Oy(t),super(t)}call(t,e){return Wr((()=>{null!=this.cell.dropoutMask&&(Vr(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(Vr(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const n=null==e?null:e.mask,s=null==e?null:e.training,r=null==e?null:e.initialState;return super.call(t,{mask:n,training:s,initialState:r})}))}static fromConfig(t,e){return 0===e.implmentation&&(e.implementation=1),new t(e)}}My.className="GRU",Lr(My);class Ly extends Dy{constructor(t){super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=t.units,Vd(this.units,"units"),this.activation=Qg(void 0===t.activation?this.DEFAULT_ACTIVATION:t.activation),this.recurrentActivation=Qg(void 0===t.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:t.recurrentActivation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=rm(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=rm(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=rm(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.unitForgetBias=t.unitForgetBias,this.kernelRegularizer=ay(t.kernelRegularizer),this.recurrentRegularizer=ay(t.recurrentRegularizer),this.biasRegularizer=ay(t.biasRegularizer),this.kernelConstraint=tf(t.kernelConstraint),this.recurrentConstraint=tf(t.recurrentConstraint),this.biasConstraint=tf(t.biasConstraint),this.dropout=bf([1,xf([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=bf([1,xf([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.implementation=t.implementation,this.stateSize=[this.units,this.units],this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){var e;const n=(t=pm(t))[t.length-1];let s;if(this.kernel=this.addWeight("kernel",[n,4*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,4*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){if(this.unitForgetBias){const t=this.biasInitializer,n=this.units;s=new((e=class extends Bf{apply(e,s){const r=t.apply([n]),a=(new Wf).apply([n]),i=t.apply([2*n]);return Tf(Tf(r,a),i)}}).className="CustomInit",e)}else s=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.units],null,s,this.biasRegularizer,!0,this.biasConstraint)}else this.bias=null;this.built=!0}call(t,e){return Wr((()=>{const n=null!=e.training&&e.training;if(3!==(t=t).length)throw new Nd("LSTMCell expects 3 input Tensors (inputs, h, c), got "+t.length+".");let s=t[1];const r=t[2];t=t[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=Py({ones:()=>Oi(t),rate:this.dropout,training:n,count:4})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=Py({ones:()=>Oi(s),rate:this.recurrentDropout,training:n,count:4}));const a=this.dropoutMask,i=this.recurrentDropoutMask;let o,l,u,c;0<this.dropout&&this.dropout<1&&(t=pi(t,a[0]));let h=Af(t,this.kernel.read());0<this.recurrentDropout&&this.recurrentDropout<1&&(s=pi(s,i[0])),h=Yr(h,Af(s,this.recurrentKernel.read())),this.useBias&&(h=_f(h,this.bias.read()));const[p,d,f,m]=ro(h,4,h.rank-1);o=this.recurrentActivation.apply(p),l=this.recurrentActivation.apply(d),u=Yr(pi(l,r),pi(o,this.activation.apply(f))),c=this.recurrentActivation.apply(m);const g=pi(c,this.activation.apply(u));return[g,g,u]}))}getConfig(){const t=super.getConfig(),e={units:this.units,activation:Jg(this.activation),recurrentActivation:Jg(this.recurrentActivation),useBias:this.useBias,kernelInitializer:sm(this.kernelInitializer),recurrentInitializer:sm(this.recurrentInitializer),biasInitializer:sm(this.biasInitializer),unitForgetBias:this.unitForgetBias,kernelRegularizer:sy(this.kernelRegularizer),recurrentRegularizer:sy(this.recurrentRegularizer),biasRegularizer:sy(this.biasRegularizer),activityRegularizer:sy(this.activityRegularizer),kernelConstraint:Zd(this.kernelConstraint),recurrentConstraint:Zd(this.recurrentConstraint),biasConstraint:Zd(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation};return Object.assign({},t,e)}}Ly.className="LSTMCell",Lr(Ly);class zy extends Ry{constructor(t){0===t.implementation&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),t.cell=new Ly(t),super(t)}call(t,e){return Wr((()=>{null!=this.cell.dropoutMask&&(Vr(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(Vr(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const n=null==e?null:e.mask,s=null==e?null:e.training,r=null==e?null:e.initialState;return super.call(t,{mask:n,training:s,initialState:r})}))}static fromConfig(t,e){return 0===e.implmentation&&(e.implementation=1),new t(e)}}zy.className="LSTM",Lr(zy);class By extends Dy{constructor(t){super(t),this.cells=t.cells}get stateSize(){const t=[];for(const e of this.cells.slice().reverse())Array.isArray(e.stateSize)?t.push(...e.stateSize):t.push(e.stateSize);return t}call(t,e){return Wr((()=>{let n=(t=t).slice(1);const s=[];for(const t of this.cells.slice().reverse())Array.isArray(t.stateSize)?s.push(n.splice(0,t.stateSize.length)):s.push(n.splice(0,1));s.reverse();const r=[];let a;for(let i=0;i<this.cells.length;++i){const o=this.cells[i];n=s[i],a=0===i?[t[0]].concat(n):[a[0]].concat(n),a=o.call(a,e),r.push(a.slice(1))}n=[];for(const t of r.slice().reverse())n.push(...t);return[a[0]].concat(n)}))}build(t){let e;um(t)&&(t=t[0]),t=t,this.cells.forEach(((n,s)=>{hf("RNNCell_"+s,(()=>{n.build(t),e=Array.isArray(n.stateSize)?n.stateSize[0]:n.stateSize,t=[t[0],e]}))})),this.built=!0}getConfig(){const t=super.getConfig(),e={cells:this.cells.map((t=>({className:t.getClassName(),config:t.getConfig()})))};return Object.assign({},t,e)}static fromConfig(t,e,n={}){const s=[];for(const t of e.cells)s.push(Mm(t,n));return new t({cells:s})}get trainableWeights(){if(!this.trainable)return[];const t=[];for(const e of this.cells)t.push(...e.trainableWeights);return t}get nonTrainableWeights(){const t=[];for(const e of this.cells)t.push(...e.nonTrainableWeights);if(!this.trainable){const e=[];for(const t of this.cells)e.push(...t.trainableWeights);return e.concat(t)}return t}getWeights(){const t=[];for(const e of this.cells)t.push(...e.weights);return mm(t)}setWeights(t){const e=[];for(const n of this.cells){const s=n.weights.length,r=t.splice(s);for(let t=0;t<n.weights.length;++t)e.push([n.weights[t],r[t]])}gm(e)}}function Py(t){const{ones:e,rate:n,training:s=!1,count:r=1}=t,a=()=>Of(e(),n),i=()=>Mf(a,e,s);return!r||r<=1?Ur(i().clone()):Array(r).fill(void 0).map(i).map((t=>Ur(t.clone())))}By.className="StackedRNNCells",Lr(By);var Wy,Vy;class Uy extends Ry{constructor(t){if(t.unroll)throw new Id("Unrolling is not possible with convolutional RNNs.");if(Array.isArray(t.cell))throw new Id("It is not possible at the moment to stack convolutional cells.");super(t),this.inputSpec=[new ym({ndim:5})]}call(t,e){return Wr((()=>{if(null!=this.cell.dropoutMask&&(Vr(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(Vr(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),e&&e.constants)throw new Nd("ConvRNN2D cell does not support constants");const n=null==e?null:e.mask,s=null==e?null:e.training,r=null==e?null:e.initialState;return super.call(t,{mask:n,training:s,initialState:r})}))}computeOutputShape(t){let e=this.computeSingleOutputShape(t);return this.returnSequences||(e=[e[0],...e.slice(2)]),this.returnState&&(e=[e,...Array(2).fill([t[0],...e.slice(-3)])]),e}getInitialState(t){return Wr((()=>{const{stateSize:e}=this.cell,n=t.shape,s=this.computeSingleOutputShape(n),r=ki([s[0],...s.slice(2)]);return Array.isArray(e)?Array(e.length).fill(r):[r]}))}resetStates(t,e=!1){Wr((()=>{if(!this.stateful)throw new vd("Cannot call resetStates() on an RNN Layer that is not stateful.");const n=this.inputSpec[0].shape,s=this.computeSingleOutputShape(n),r=[s[0],...s.slice(2)];if(null==n[0])throw new Nd("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.getStates())Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((()=>ki(r))):this.states_=[ki(r)];else if(null==t)Vr(this.states_),null!=this.keptStates&&(Vr(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((()=>ki(r))):this.states_[0]=ki(r);else{if(Array.isArray(t)||(t=[t]),t.length!==this.states_.length)throw new Nd(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: `+t);e?this.keptStates.push(this.states_.slice()):Vr(this.states_);for(let e=0;e<this.states_.length;++e){const n=t[e],s=r;if(!O(n.shape,s))throw new Nd(`State ${e} is incompatible with layer ${this.name}: expected shape=${s}, received shape=${n.shape}`);this.states_[e]=n}}this.states_=this.states_.map((t=>Ur(t.clone())))}))}computeSingleOutputShape(t){const{dataFormat:e,filters:n,kernelSize:s,padding:r,strides:a,dilationRate:i}=this.cell,o="channelsFirst"===e,l=t[o?3:2],u=t[o?4:3],c=dy(l,s[0],r,a[0],i[0]),h=dy(u,s[1],r,a[1],i[1]);return[...t.slice(0,2),...o?[n,c,h]:[c,h,n]]}}Uy.className="ConvRNN2D";class Gy extends Ly{constructor(t){const{filters:e,kernelSize:n,strides:s,padding:r,dataFormat:a,dilationRate:i}=t;super(Object.assign({},t,{units:e})),this.filters=e,Vd(this.filters,"filters"),this.kernelSize=py(n,2,"kernelSize"),this.kernelSize.forEach((t=>Vd(t,"kernelSize"))),this.strides=py(s||1,2,"strides"),this.strides.forEach((t=>Vd(t,"strides"))),this.padding=r||"valid",lf(this.padding),this.dataFormat=a||"channelsLast",of(this.dataFormat),this.dilationRate=py(i||1,2,"dilationRate"),this.dilationRate.forEach((t=>Vd(t,"dilationRate")))}build(t){var e;t=pm(t);const n="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[n])throw new Nd("The channel dimension of the input should be defined. Found "+t[n]);const s=t[n],r=this.kernelSize.concat([s,4*this.filters]);this.kernel=this.addWeight("kernel",r,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint);const a=this.kernelSize.concat([this.filters,4*this.filters]);if(this.recurrentKernel=this.addWeight("recurrent_kernel",a,null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){let t;if(this.unitForgetBias){const n=this.biasInitializer,s=this.filters;t=new((e=class extends Bf{apply(t,e){return Sf([n.apply([s]),Ni([s]),n.apply([2*s])])}}).className="CustomInit",e)}else t=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.filters],null,t,this.biasRegularizer,!0,this.biasConstraint)}this.built=!0}call(t,e){return Wr((()=>{if(3!==t.length)throw new Nd("ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got "+t.length+".");const n=e.training||!1,s=t[0],r=t[1],a=t[2];0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=Py({ones:()=>Oi(s),rate:this.dropout,training:n,count:4}));const i=this.dropoutMask,o=(t,e,n)=>e&&e[n]?pi(e[n],t):t;let l=o(s,i,0),u=o(s,i,1),c=o(s,i,2),h=o(s,i,3);0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=Py({ones:()=>Oi(r),rate:this.recurrentDropout,training:n,count:4}));const p=this.recurrentDropoutMask;let d=o(r,p,0),f=o(r,p,1),m=o(r,p,2),g=o(r,p,3);const[y,b,x,w]=ro(this.kernel.read(),4,3),[v,k,N,I]=this.useBias?ro(this.bias.read(),4):[null,null,null,null];l=this.inputConv(l,y,v,this.padding),u=this.inputConv(u,b,k,this.padding),c=this.inputConv(c,x,N,this.padding),h=this.inputConv(h,w,I,this.padding);const[C,S,T,$]=ro(this.recurrentKernel.read(),4,3);d=this.recurrentConv(d,C),f=this.recurrentConv(f,S),m=this.recurrentConv(m,T),g=this.recurrentConv(g,$);const E=this.recurrentActivation.apply(Yr(l,d)),A=this.recurrentActivation.apply(Yr(u,f)),R=Yr(pi(A,a),pi(E,this.activation.apply(Yr(c,m)))),D=pi(this.recurrentActivation.apply(Yr(h,g)),this.activation.apply(R));return[D,D,R]}))}getConfig(){const t=super.getConfig(),{units:e}=t,n=function(t,e){var n={};for(var s in t)Object.prototype.hasOwnProperty.call(t,s)&&e.indexOf(s)<0&&(n[s]=t[s]);if(null!=t&&"function"==typeof Object.getOwnPropertySymbols){var r=0;for(s=Object.getOwnPropertySymbols(t);r<s.length;r++)e.indexOf(s[r])<0&&Object.prototype.propertyIsEnumerable.call(t,s[r])&&(n[s[r]]=t[s[r]])}return n}(t,["units"]),s={filters:this.filters,kernelSize:this.kernelSize,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,strides:this.strides};return Object.assign({},n,s)}inputConv(t,e,n,s){const r=za(t,e,this.strides,s||"valid","channelsFirst"===this.dataFormat?"NCHW":"NHWC",this.dilationRate);return n?_f(r,n,this.dataFormat):r}recurrentConv(t,e){return za(t,e,1,"same","channelsFirst"===this.dataFormat?"NCHW":"NHWC")}}Gy.className="ConvLSTM2DCell",Lr(Gy);class Hy extends Uy{constructor(t){const e=new Gy(t);super(Object.assign({},t,{cell:e}))}static fromConfig(t,e){return new t(e)}}Hy.className="ConvLSTM2D",Lr(Hy);class jy extends km{constructor(t){super(t),this.rate=Math.max(Math.min(t.rate,1),0),this.noiseShape=t.noiseShape,this.seed=t.seed,this.supportsMasking=!0}getNoiseShape(t){if(null==this.noiseShape)return this.noiseShape;const e=t.shape,n=[];for(let t=0;t<this.noiseShape.length;++t)n.push(null==this.noiseShape[t]?e[t]:this.noiseShape[t]);return n}call(t,e){return Wr((()=>{this.invokeCallHook(t,e);const n=hm(t);if(0<this.rate&&this.rate<1){const t=null!=e.training&&e.training,s=this.getNoiseShape(n);return Mf((()=>Of(n,this.rate,s,this.seed)),(()=>n),t)}return t}))}getConfig(){const t={rate:this.rate,noiseShape:this.noiseShape,seed:this.seed},e=super.getConfig();return Object.assign(t,e),t}dispose(){return super.dispose()}}jy.className="Dropout",Lr(jy);class qy extends jy{constructor(t){super(t),this.inputSpec=[{ndim:3}]}getNoiseShape(t){const e=t.shape;return[e[0],1,e[2]]}}qy.className="SpatialDropout1D",Lr(qy);class Ky extends km{constructor(t){if(super(t),this.activation=null,this.useBias=!0,this.kernel=null,this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",null==t.batchInputShape&&null==t.inputShape&&null!=t.inputDim){let e=null;null!=t.batchSize&&(e=t.batchSize),this.batchInputShape=[e,t.inputDim]}this.units=t.units,Vd(this.units,"units"),this.activation=Qg(t.activation),null!=t.useBias&&(this.useBias=t.useBias),this.kernelInitializer=rm(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.biasInitializer=rm(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelConstraint=tf(t.kernelConstraint),this.biasConstraint=tf(t.biasConstraint),this.kernelRegularizer=ay(t.kernelRegularizer),this.biasRegularizer=ay(t.biasRegularizer),this.activityRegularizer=ay(t.activityRegularizer),this.supportsMasking=!0,this.inputSpec=[{minNDim:2}]}build(t){const e=(t=pm(t))[t.length-1];null==this.kernel&&(this.kernel=this.addWeight("kernel",[e,this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint))),this.inputSpec=[{minNDim:2,axes:{[-1]:e}}],this.built=!0}computeOutputShape(t){const e=(t=pm(t)).slice();return e[e.length-1]=this.units,e}call(t,e){return Wr((()=>{this.invokeCallHook(t,e);const n=hm(t),s=Gd(this.activation.getClassName());let r;return null!=s?r=Af(n,this.kernel.read(),s,this.bias?this.bias.read():null):(r=Af(n,this.kernel.read()),null!=this.bias&&(r=_f(r,this.bias.read())),null!=this.activation&&(r=this.activation.apply(r))),r}))}getConfig(){const t={units:this.units,activation:Jg(this.activation),useBias:this.useBias,kernelInitializer:sm(this.kernelInitializer),biasInitializer:sm(this.biasInitializer),kernelRegularizer:sy(this.kernelRegularizer),biasRegularizer:sy(this.biasRegularizer),activityRegularizer:sy(this.activityRegularizer),kernelConstraint:Zd(this.kernelConstraint),biasConstraint:Zd(this.biasConstraint)},e=super.getConfig();return Object.assign(t,e),t}}Ky.className="Dense",Lr(Ky);class Xy extends km{constructor(t){super(t=t||{}),this.inputSpec=[{minNDim:3}],this.dataFormat=t.dataFormat}computeOutputShape(t){t=pm(t);for(const e of t.slice(1))if(null==e)throw new Nd(`The shape of the input to "Flatten" is not fully defined (got ${t.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);return[t[0],gf(t,1)]}call(t,e){return Wr((()=>{this.invokeCallHook(t,e);let n=hm(t);if("channelsFirst"===this.dataFormat&&n.rank>1){const t=[0];for(let e=2;e<n.rank;++e)t.push(e);t.push(1),n=n.transpose(t)}return function(t){if(t.rank<=1)throw new Nd(`batchFlatten requires a minimum rank of 2. Got rank: ${t.rank}.`);const e=[t.shape[0],gf(t.shape,1)];return t.reshape(e)}(n)}))}getConfig(){const t={};null!=this.dataFormat&&(t.dataFormat=this.dataFormat);const e=super.getConfig();return Object.assign(t,e),t}}Xy.className="Flatten",Lr(Xy);class Yy extends km{constructor(t){super(t),this.supportsMasking=!0,this.activation=Qg(t.activation)}call(t,e){return Wr((()=>{this.invokeCallHook(t,e);const n=hm(t);return this.activation.apply(n)}))}getConfig(){const t={activation:Jg(this.activation)},e=super.getConfig();return Object.assign(t,e),t}}Yy.className="Activation",Lr(Yy);class Jy extends km{constructor(t){super(t),this.n=t.n,this.inputSpec=[{ndim:2}]}computeOutputShape(t){return[t[0],this.n,t[1]]}call(t,e){return Wr((()=>{return t=hm(t),e=t,n=this.n,Wr((()=>{if(2!==e.shape.length)throw new Nd(`repeat() expects a rank-2 tensor, but received a rank-${e.shape.length} tensor.`);return $f(kf(e,1),[1,n,1])}));var e,n}))}getConfig(){const t={n:this.n},e=super.getConfig();return Object.assign(t,e),t}}Jy.className="RepeatVector",Lr(Jy);class Zy extends km{constructor(t){super(t),this.targetShape=t.targetShape;for(let t=0;t<this.targetShape.length;++t)this.isUnknown(this.targetShape[t])&&(this.targetShape[t]=null)}isUnknown(t){return t<0||null==t}fixUnknownDimension(t,e){const n="Total size of new array must be unchanged.",s=e.slice();let r=1,a=null;for(let t=0;t<s.length;++t){const e=s[t];if(this.isUnknown(e)){if(null!==a)throw new Nd("Can only specifiy one unknown dimension.");a=t}else r*=e}const i=gf(t);if(null!==a){if(0===r||i%r!=0)throw new Nd(n);s[a]=i/r}else if(i!==r)throw new Nd(n);return s}computeOutputShape(t){let e=!1;for(let n=0;n<t.length;++n)if(this.isUnknown(t[n])){e=!0;break}return e?t.slice(0,1).concat(this.targetShape):t.slice(0,1).concat(this.fixUnknownDimension(t.slice(1),this.targetShape))}call(t,e){return Wr((()=>{this.invokeCallHook(t,e);const n=hm(t),s=n.shape,r=s.slice(0,1).concat(this.fixUnknownDimension(s.slice(1),this.targetShape));return n.reshape(r)}))}getConfig(){const t={targetShape:this.targetShape},e=super.getConfig();return Object.assign(t,e),t}}Zy.className="Reshape",Lr(Zy);class Qy extends km{constructor(t){if(super(t),null==t.dims)throw new Error("Required configuration field `dims` is missing during Permute constructor call.");if(!Array.isArray(t.dims))throw new Error("Permute constructor requires `dims` to be an Array, but received "+t.dims+" instead.");const e=wf(1,t.dims.length+1);if(!O(t.dims.slice().sort(),e))throw new Error("Invalid permutation `dims`: "+JSON.stringify(t.dims)+" `dims` must contain consecutive integers starting from 1.");this.dims=t.dims,this.dimsIncludingBatch=[0].concat(this.dims),this.inputSpec=[new ym({ndim:this.dims.length+1})]}computeOutputShape(t){const e=(t=pm(t)).slice();return this.dims.forEach(((n,s)=>{e[s+1]=t[n]})),e}call(t,e){return ia(hm(t),this.dimsIncludingBatch)}getConfig(){const t={dims:this.dims},e=super.getConfig();return Object.assign(t,e),t}}Qy.className="Permute",Lr(Qy);class tb extends km{constructor(t){super(null==t?{}:t),this.supportsMasking=!0,this.maskValue=null!=t?null==t.maskValue?0:t.maskValue:0}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={maskValue:this.maskValue};return Object.assign(e,t),e}computeMask(t,e){const n=hm(t);return la(Ai(n,this.maskValue),-1)}call(t,e){return Wr((()=>{this.invokeCallHook(t,e);const n=hm(t),s=la(Ai(n,this.maskValue),-1,!0);return n.mul(s.asType(n.dtype))}))}}tb.className="Masking",Lr(tb);class eb extends km{constructor(t){if(super(t),this.embeddings=null,this.DEFAULT_EMBEDDINGS_INITIALIZER="randomUniform",null==t.batchInputShape&&null==t.inputShape){let e=null;null!=t.batchSize&&(e=t.batchSize),null==t.inputLength?this.batchInputShape=[e,null]:this.batchInputShape=[e].concat(Ad(t.inputLength))}this.inputDim=t.inputDim,Vd(this.inputDim,"inputDim"),this.outputDim=t.outputDim,Vd(this.outputDim,"outputDim"),this.embeddingsInitializer=rm(t.embeddingsInitializer||this.DEFAULT_EMBEDDINGS_INITIALIZER),this.embeddingsRegularizer=ay(t.embeddingsRegularizer),this.activityRegularizer=ay(t.activityRegularizer),this.embeddingsConstraint=tf(t.embeddingsConstraint),this.maskZero=t.maskZero,this.supportsMasking=t.maskZero,this.inputLength=t.inputLength}build(t){this.embeddings=this.addWeight("embeddings",[this.inputDim,this.outputDim],this.dtype,this.embeddingsInitializer,this.embeddingsRegularizer,!0,this.embeddingsConstraint),this.built=!0}warnOnIncompatibleInputShape(t){}computeMask(t,e){return Wr((()=>this.maskZero?(t=hm(t),Ai(t,_i(t))):null))}computeOutputShape(t){if(t=pm(t),null==this.inputLength)return[...t,this.outputDim];const e=Ad(this.inputLength);if(e.length!==t.length-1)throw new Nd(`"inputLength" is ${this.inputLength}, but received input shape has shape `+t);{let n=0;for(let s=0;s<e.length;++s){const r=e[s],a=t[s+1];if(null!=r&&null!=a&&r!==a)throw new Nd(`"inputLength" is ${this.inputLength}, but received input shape has shape `+t);null==r&&(e[n]=a),n++}}return[t[0],...e,this.outputDim]}call(t,e){return Wr((()=>{this.invokeCallHook(t,e);let n=hm(t);return"int32"!==n.dtype&&(n=vf(n,"int32")),Rf(this.embeddings.read(),n.as1D()).reshape(pm(this.computeOutputShape(n.shape)))}))}getConfig(){const t={inputDim:this.inputDim,outputDim:this.outputDim,embeddingsInitializer:sm(this.embeddingsInitializer),embeddingsRegularizer:sy(this.embeddingsRegularizer),activityRegularizer:sy(this.activityRegularizer),embeddingsConstraint:Zd(this.embeddingsConstraint),maskZero:this.maskZero,inputLength:this.inputLength},e=super.getConfig();return Object.assign(t,e),t}}eb.className="Embedding",Lr(eb);class nb extends km{constructor(t){super(t||{}),this.supportsMasking=!0}mergeFunction(t){throw new Id}computeElementwiseOpOutputShape(t,e){if(null==t||null==e)return null;if(t.length<e.length)return this.computeElementwiseOpOutputShape(e,t);if(0===e.length)return t;const n=t.slice(0,t.length-e.length);for(let s=0;s<e.length;++s){const r=t[t.length-e.length+s],a=e[s];if(null==r||null==a||r<0||a<0)n.push(null);else if(1===r)n.push(a);else if(1===a)n.push(r);else{if(r!==a)throw new Nd("Operands could not be broadcast together with shapes "+JSON.stringify(t)+" "+JSON.stringify(e));n.push(r)}}return n}build(t){if(Array.isArray(t)&&!Array.isArray(t[0])&&(t=[pm(t)]),(t=t).length<2)throw new Nd(`A merge layer should be called on an Array of at least 2 inputs. Got ${t.length} input(s).`);let e=[];for(const n of t)null!=n&&null!==n[0]&&e.push(n[0]);if(e=zd(e),e.length>1)throw new Nd(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(t)}.`);let n=null==t[0]?null:t[0].slice(1);for(let e=1;e<t.length;++e){const s=null==t[e]?null:t[e].slice(1);n=this.computeElementwiseOpOutputShape(n,s)}const s=t.map((t=>t.length));-1===t.indexOf(null)&&1===zd(s).length?this.reshapeRequired=!1:this.reshapeRequired=!0}call(t,e){return Wr((()=>{if(t=t,this.reshapeRequired){const e=[],n=t.map((t=>t.rank));if(-1===n.indexOf(null)){const s=xf(n);for(let n of t){const t=n.rank;for(let e=0;e<s-t;++e)n=kf(n,1);e.push(n)}return this.mergeFunction(e)}{let n=!1;for(const s of t){const t=s.rank;if(null==t){const t=s.shape,r=t[0],a=t.slice(1).concat([r]);let i=s.reshape([r].concat(gf(t.slice(1))));i=ia(i,[1,0]),i=i.reshape(a),e.push(i),n=!0}else if(t>1){const r=wf(1,t).concat([0]);e.push(ia(s,r)),n=!0}else e.push(s)}let s=this.mergeFunction(e);const r=s.rank;if(n)if(null==r){const t=s.shape,e=t[t.length-1],n=[e].concat(t.slice(0,t.length-1));s=ia(s.reshape([-1,e]),[1,0]).reshape(n)}else if(r>1){const t=[r-1].concat(wf(0,r-1));s=ia(s,t)}return s}}return this.mergeFunction(t)}))}computeOutputShape(t){let e;e=null==(t=t)[0]?null:t[0].slice(1);for(let n=1;n<t.length;++n){const s=null==t[n]?null:t[n].slice(1);e=this.computeElementwiseOpOutputShape(e,s)}let n=[];for(const e of t)null!=e&&null!==e[0]&&n.push(e[0]);return n=zd(n),e=1===n.length?n.concat(e):[null].concat(e),e}computeMask(t,e){return Wr((()=>{if(null==e)return null;if(!Array.isArray(e))throw new Nd("`mask` should be an Array");if(!Array.isArray(t))throw new Nd("`inputs` should be an Array");if(e.length!==t.length)throw new Nd(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${t.length} vs ${e.length})`);if(e.every((t=>null==t)))return null;let n=(e=e.map((t=>null==t?t:Za(t,0))))[0];for(let t=1;t<e.length-1;++t)n=xi(n,e[t]);return n}))}}class sb extends nb{constructor(t){super(t)}mergeFunction(t){return Wr((()=>{let e=t[0].clone();for(let n=1;n<t.length;++n)e=Yr(e,t[n]);return e}))}}sb.className="Add",Lr(sb);class rb extends nb{constructor(t){super(t)}mergeFunction(t){return Wr((()=>{let e=t[0].clone();for(let n=1;n<t.length;++n)e=pi(e,t[n]);return e}))}}rb.className="Multiply",Lr(rb);class ab extends nb{constructor(t){super(t)}mergeFunction(t){return Wr((()=>{let e=t[0].clone();for(let n=1;n<t.length;++n)e=Yr(e,t[n]);return pi(1/t.length,e)}))}}ab.className="Average",Lr(ab);class ib extends nb{constructor(t){super(t)}mergeFunction(t){return Wr((()=>{let e=t[0];for(let n=1;n<t.length;++n)e=hi(e,t[n]);return e}))}}ib.className="Maximum",Lr(ib);class ob extends nb{constructor(t){super(t)}mergeFunction(t){return Wr((()=>{let e=t[0];for(let n=1;n<t.length;++n)e=Si(e,t[n]);return e}))}}ob.className="Minimum",Lr(ob);class lb extends nb{constructor(t){super(t),this.DEFAULT_AXIS=-1,null==t&&(t={}),this.axis=null==t.axis?this.DEFAULT_AXIS:t.axis,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){if(!Array.isArray(t)||!Array.isArray(t[0])||1===t.length)throw new Nd("A `Concatenate` layer should be called on a list of at least 2 inputs");t=t;let e=!0;for(const n of t)if(null!=n){e=!1;break}if(e)return;const n=[];for(let e=0;e<t.length;++e){const s=t[e].slice();s.splice(this.axis,1);let r=!1;for(const t of n)if(O(t,s)){r=!0;break}r||n.push(s)}if(n.length>1)throw new Nd("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: "+JSON.stringify(t))}mergeFunction(t){return Wr((()=>Sf(t,this.axis)))}computeOutputShape(t){if(!Array.isArray(t)||!Array.isArray(t[0]))throw new Nd("A `Concatenate` layer should be called on a list of inputs.");const e=t,n=e[0].slice(),s=this.axis<0?n.length+this.axis:this.axis;for(const t of e.slice(1)){if(null==n[s]||null==t[s]){n[s]=null;break}n[s]+=t[s]}return n}computeMask(t,e){if(null==e)return null;if(!Array.isArray(e))throw new Nd("`mask` should be an array for Concatenate");if(!Array.isArray(t))throw new Nd("`inputs` should be an array for Concatenate");if(e.length!==t.length)throw new Nd(`Mismatch in the length of mask (${e.length}) and the legnth of inputs (${t.length})`);return Wr((()=>{let n=!0;if(e.forEach((t=>{null==t||(n=!1)})),n)return null;const s=[];for(let n=0;n<t.length;++n)null==e[n]?s.push(Oi(t[n]).asType("bool")):e[n].rank<t[n].rank?s.push(Za(e[n],-1)):s.push(e[n]);const r=Fa(s,this.axis);return oa(r,-1,!1)}))}getConfig(){const t={axis:this.axis},e=super.getConfig();return Object.assign(t,e),t}}function ub(t,e){for(;t<0;)t+=e;return t}lb.className="Concatenate",Lr(lb);class cb extends nb{constructor(t){super(t),this.axes=t.axes,this.normalize=null!=t.normalize&&t.normalize,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){A(Array.isArray(t)&&2===t.length&&Array.isArray(t[0])&&Array.isArray(t[1]),(()=>"A `Dot` layer should be called on a list of exactly 2 inputs."));const e=t[0],n=t[1];if(e.length>3||n.length>3)throw new Id("Dot layer does not support tensors of 4D or higher rank yet.");const s=this.interpretAxes(e,n);if(e[s[0]]!==n[s[1]])throw new Nd(`Dimension incompatibility: ${e[s[0]]} !== ${n[s[1]]}`)}mergeFunction(t){if(2!==t.length)throw new Nd(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${t.length} input(s).`);let e,n=t[0],s=t[1];return e=Array.isArray(this.axes)?this.axes.map(((e,n)=>ub(e,t[n].shape.length))):[ub(this.axes,n.shape.length),ub(this.axes,s.shape.length)],this.normalize&&(n=Lm(n,e[0]),s=Lm(s,e[1])),function(t,e,n){if(t.shape.length>3||e.shape.length>3)throw new Id("batchDot is not implemented for tensors of 4D or higher rank yet");if(A(t.shape.length>=2,(()=>"batchDot requires the rank of x to be >= 2, but got "+t.shape.length)),A(t.shape.length>=2,(()=>"batchDot requires the rank of y to be >= 2, but got "+e.shape.length)),"number"==typeof n&&(n=[n,n]),"complex64"===t.dtype||"complex64"===e.dtype)throw new Id("batchDot is not implemented for complex64-type Tensors yet.");const s=t.shape.length,r=e.shape.length;null==n&&(n=[s-1,r-2]);const a=n;return Wr((()=>{let n,i;if(s>r){n=s-r;const t=[];for(let e=0;e<n;++e)t.push(1);e=e.reshape(e.shape.concat(t))}else if(r>s){n=r-s;const e=[];for(let t=0;t<n;++t)e.push(1);t=t.reshape(t.shape.concat(e))}else n=0;if(2===t.shape.length&&2===e.shape.length)i=a[0]===a[1]?t.mul(e).sum(a[0]):t.transpose([1,0]).mul(e).sum(a[1]);else{const n=a[0]!==t.shape.length-1,s=a[1]===e.shape.length-1;i=t.matMul(e,n,s)}if(n>0){let t;t=s>r?s+r-3:s-1;const e=[];for(let s=t;s<t+n;++s)e.push(s);i=i.squeeze(e)}return 1===i.shape.length&&(i=i.expandDims(1)),i}))}(n,s,e)}interpretAxes(t,e){let n;return n=Array.isArray(this.axes)?this.axes:[ub(this.axes,t.length),ub(this.axes,e.length)],n}computeOutputShape(t){A(Array.isArray(t)&&2===t.length&&Array.isArray(t[0])&&Array.isArray(t[1]),(()=>"A `Dot` layer should be called on a list of exactly 2 inputs."));const e=t[0].slice(),n=t[1].slice();if(e.length>3||n.length>3)throw new Id("Dot layer does not support tensors of 4D or higher rank yet.");const s=this.interpretAxes(e,n);e.splice(s[0],1),n.splice(s[1],1),n.splice(0,1);const r=e.concat(n);return 1===r.length&&r.push(1),r}computeMask(t,e){return null}getConfig(){const t={axes:this.axes,normalize:this.normalize},e=super.getConfig();return Object.assign(t,e),t}}cb.className="Dot",Lr(cb);class hb extends km{constructor(t){super(t),this.supportsMasking=!0,this.stddev=t.stddev}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={stddev:this.stddev};return Object.assign(e,t),e}call(t,e){return Wr((()=>{this.invokeCallHook(t,e);const n=hm(t);return Mf((()=>Ef(n.shape,0,this.stddev).add(n)),(()=>n),e.training||!1)}))}}hb.className="GaussianNoise",Lr(hb);class pb extends km{constructor(t){super(t),this.supportsMasking=!0,this.rate=t.rate}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={rate:this.rate};return Object.assign(e,t),e}call(t,e){return Wr((()=>{this.invokeCallHook(t,e);const n=hm(t);return this.rate>0&&this.rate<1?Mf((()=>{const t=Math.sqrt(this.rate/(1-this.rate));return n.mul(Ef(n.shape,1,t))}),(()=>n),e.training||!1):n}))}}pb.className="GaussianDropout",Lr(pb);class db extends km{constructor(t){super(t),this.supportsMasking=!0,this.rate=t.rate,this.noiseShape=t.noiseShape}_getNoiseShape(t){return this.noiseShape||hm(t).shape}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={rate:this.rate};return Object.assign(e,t),e}call(t,e){return Wr((()=>{if(this.rate<1&&this.rate>0){const n=this._getNoiseShape(t);return Mf((()=>{const e=hm(t),s=-1.7580993408473766;let r=ci(Vi(n),this.rate);r=vf(r,"float32");const a=((1-this.rate)*(1+this.rate*s**2))**-.5,i=-a*s*this.rate;return e.mul(r).add(r.add(-1).mul(s)).mul(a).add(i)}),(()=>hm(t)),e.training||!1)}return t}))}}function fb(t,e,n,s,r,a=.001){let i;if(2===t.rank)i=Ta(t,e,n,s,r,a);else if(3===t.rank)i=$a(t,e,n,s,r,a);else{if(4!==t.rank)throw new Id(`batchNormalization is not implemented for array of rank ${t.rank} yet`);i=Ea(t,e,n,s,r,a)}return i}db.className="AlphaDropout",Lr(db);class mb extends km{constructor(t){null==t&&(t={}),super(t),this.supportsMasking=!0,this.axis=null==t.axis?-1:t.axis,this.momentum=null==t.momentum?.99:t.momentum,this.epsilon=null==t.epsilon?.001:t.epsilon,this.center=null==t.center||t.center,this.scale=null==t.scale||t.scale,this.betaInitializer=rm(t.betaInitializer||"zeros"),this.gammaInitializer=rm(t.gammaInitializer||"ones"),this.movingMeanInitializer=rm(t.movingMeanInitializer||"zeros"),this.movingVarianceInitializer=rm(t.movingVarianceInitializer||"ones"),this.betaConstraint=tf(t.betaConstraint),this.gammaConstraint=tf(t.gammaConstraint),this.betaRegularizer=ay(t.betaRegularizer),this.gammaRegularizer=ay(t.gammaRegularizer)}build(t){t=pm(t);const e=this.axis>=0?this.axis:this.axis+t.length,n=t[e];if(null==n)throw new Nd(`Axis ${e} of input tensor should have a defined dimension but the layer received an input with shape `+JSON.stringify(t)+".");this.inputSpec=[new ym({ndim:t.length,axes:{[e]:n}})];const s=[n];this.scale&&(this.gamma=this.addWeight("gamma",s,null,this.gammaInitializer,this.gammaRegularizer,!0,this.gammaConstraint)),this.center&&(this.beta=this.addWeight("beta",s,null,this.betaInitializer,this.betaRegularizer,!0,this.betaConstraint)),this.movingMean=this.addWeight("moving_mean",s,null,this.movingMeanInitializer,null,!1),this.movingVariance=this.addWeight("moving_variance",s,null,this.movingVarianceInitializer,null,!1),this.built=!0}call(t,e){return Wr((()=>{const n=null!=e.training&&e.training,s=hm(t),r=s.shape,a=r.length,i=wf(0,a),o=this.axis>=0?this.axis:this.axis+a;i.splice(o,1);const l=Sd(1,a);l[o]=r[o];const u=i.slice();u.sort();const c=!O(u,wf(0,a).slice(0,a-1));if(!n)return(()=>{if(c){const t=this.movingMean.read().reshape(l),e=this.movingVariance.read().reshape(l),n=this.center?this.beta.read().reshape(l):null,r=this.scale?this.gamma.read().reshape(l):null;return fb(s,t,e,n,r,this.epsilon)}return fb(s,this.movingMean.read(),this.movingVariance.read(),null==this.beta?null:this.beta.read(),null==this.gamma?null:this.gamma.read(),this.epsilon)})();const[h,p,d]=function(t,e,n,s,r=.001){return O(s.slice().sort(),wf(0,t.rank-1))?function(t,e,n,s,r=.001){return Wr((()=>{const a=$i(t,s),i=a.mean,o=a.variance;return[fb(t,i,o,n,e,r),i,o]}))}(t,e,n,s,r):function(t,e,n,s,r=.001){return Wr((()=>{const a=$i(t,s),i=a.mean,o=a.variance,l=[];for(const e of wf(0,t.rank))-1!==s.indexOf(e)?l.push(1):l.push(t.shape[e]);const u=i.reshape(l),c=o.reshape(l),h=null==e?null:e.reshape(l),p=null==n?null:n.reshape(l);return[fb(t,u,c,p,h,r),i,o]}))}(t,e,n,s,r)}(s,this.gamma.read(),this.beta.read(),i,this.epsilon),f=(t,e,n)=>{Wr((()=>{const s=1-n,r=t.read(),a=r.sub(e).mul(s);t.write(r.sub(a))}))};return(()=>{f(this.movingMean,p,this.momentum),f(this.movingVariance,d,this.momentum)})(),h}))}getConfig(){const t={axis:this.axis,momentum:this.momentum,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:sm(this.betaInitializer),gammaInitializer:sm(this.gammaInitializer),movingMeanInitializer:sm(this.movingMeanInitializer),movingVarianceInitializer:sm(this.movingVarianceInitializer),betaRegularizer:sy(this.betaRegularizer),gammaRegularizer:sy(this.gammaRegularizer),betaConstraint:Zd(this.betaConstraint),gammaConstraint:Zd(this.gammaConstraint)},e=super.getConfig();return Object.assign(t,e),t}}mb.className="BatchNormalization",Lr(mb);class gb extends km{constructor(t){if(null==t&&(t={}),super(t),this.axis=null==t.axis?-1:t.axis,"number"==typeof this.axis){if(!Number.isInteger(this.axis))throw new Error("Expected axis to be an integer, but received "+this.axis)}else{if(!Array.isArray(this.axis))throw new Error("Expected axis to be an integer or an array of integers, but received "+JSON.stringify(this.axis));for(const t of this.axis)if(!Number.isInteger(t))throw new Error("Expected axis to be an array of integers, but received "+JSON.stringify(this.axis))}this.epsilon=null==t.epsilon?.001:t.epsilon,this.center=null==t.center||t.center,this.scale=null==t.scale||t.scale,this.betaInitializer=rm(t.betaInitializer||"zeros"),this.gammaInitializer=rm(t.gammaInitializer||"ones"),this.betaRegularizer=ay(t.betaRegularizer),this.gammaRegularizer=ay(t.gammaRegularizer),this.supportsMasking=!0}build(t){const e=(t=pm(t)).length;"number"==typeof this.axis&&(this.axis=[this.axis]);for(let t=0;t<this.axis.length;++t)this.axis[t]<0&&(this.axis[t]+=e);for(const t of this.axis)if(t<0||t>=e)throw new Error("Invalid axis: "+t);if(this.axis.length!==zd(this.axis).length)throw new Error("Found duplicate axes in: "+this.axis);const n=this.axis.map((e=>t[e]));this.scale?this.gamma=this.addWeight("gamma",n,"float32",this.gammaInitializer,this.gammaRegularizer,!0):this.gamma=null,this.center?this.beta=this.addWeight("beta",n,"float32",this.betaInitializer,this.betaRegularizer,!0):this.beta=null,this.built=!0}call(t,e){const n=hm(t),s=n.shape,r=s.length;return Wr((()=>{let{mean:t,variance:e}=$i(n,this.axis,!0);const a=Sd(1,r);for(const t of this.axis)a[t]=s[t];const i=t=>null!=t&&t.shape.length!==r&&this.axis!==[r-1]?t.reshape(a):t;let o=i(this.gamma.read()),l=i(this.beta.read());const u=[],c=[];for(let t=0;t<r;++t)-1!==this.axis.indexOf(t)?(u.push(s[t]),c.push(1)):(u.push(1),c.push(s[t]));return t=t.tile(u),e=e.tile(u),o=o.tile(c),l=l.tile(c),fb(n,t,e,l,o,this.epsilon)}))}getConfig(){const t={axis:this.axis,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:sm(this.betaInitializer),gammaInitializer:sm(this.gammaInitializer),betaRegularizer:sy(this.betaRegularizer),gammaRegularizer:sy(this.gammaRegularizer)},e=super.getConfig();return Object.assign(t,e),t}}gb.className="LayerNormalization",Lr(gb);class yb extends km{constructor(t){if(null==t&&(t={}),super(t),this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,null==t.padding)this.padding=[[1,1],[1,1]];else if("number"==typeof t.padding)this.padding=[[t.padding,t.padding],[t.padding,t.padding]];else{if(t.padding=t.padding,2!==t.padding.length)throw new Nd(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${t.padding.length} array.`);let e,n;if("number"==typeof t.padding[0])e=[t.padding[0],t.padding[0]],n=[t.padding[1],t.padding[1]];else{if(t.padding=t.padding,2!==t.padding[0].length)throw new Nd(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${t.padding[0].length} array.`);if(e=t.padding[0],2!==t.padding[1].length)throw new Nd(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${t.padding[1].length} array.`);n=t.padding[1]}this.padding=[e,n]}this.inputSpec=[new ym({ndim:4})]}computeOutputShape(t){let e,n;return t=pm(t),"channelsFirst"===this.dataFormat?(e=null!=t[2]&&t[2]>=0?t[2]+this.padding[0][0]+this.padding[0][1]:null,n=null!=t[3]&&t[3]>=0?t[3]+this.padding[1][0]+this.padding[1][1]:null,[t[0],t[1],e,n]):(e=null!=t[1]&&t[1]>=0?t[1]+this.padding[0][0]+this.padding[0][1]:null,n=null!=t[2]&&t[2]>=0?t[2]+this.padding[1][0]+this.padding[1][1]:null,[t[0],e,n,t[3]])}call(t,e){return Wr((()=>{return e=hm(t),n=this.padding,s=this.dataFormat,Wr((()=>{if(4!==e.rank)throw new Nd("temporalPadding expects input tensor to be 4-D, but received a "+e.rank+"-D tensor.");if(null==n&&(n=[[1,1],[1,1]]),2!==n.length||2!==n[0].length||2!==n[1].length)throw new Nd("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");if(null==s&&(s="channelsLast"),"channelsLast"!==s&&"channelsFirst"!==s)throw new Nd(`Unknown data format: ${s}. Supported data formats are 'channelsLast' and 'channelsFirst.`);let t;return t="channelsFirst"===s?[[0,0],[0,0],n[0],n[1]]:[[0,0],n[0],n[1],[0,0]],Mi(e,t)}));var e,n,s}))}getConfig(){const t={padding:this.padding,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}function bb(t,e,n,s,r,a){return Wr((()=>{let i;of(r),uf(a),lf(s),null==n&&(n=[1,1]),null==s&&(s="valid"),null==r&&(r="channelsLast"),null==a&&(a="max"),t=my(t,r);const o="same"===s?"same":"valid";return i="max"===a?wi(t,e,n,o):Na(t,e,n,o),"channelsFirst"===r&&(i=ia(i,[0,3,1,2])),i}))}function xb(t,e,n,s,r,a){return Wr((()=>{let i;of(r),uf(a),lf(s),null==n&&(n=[1,1,1]),null==s&&(s="valid"),null==r&&(r="channelsLast"),null==a&&(a="max"),t=gy(t,r);const o="same"===s?"same":"valid";return i="max"===a?vi(t,e,n,o):Ia(t,e,n,o),"channelsFirst"===r&&(i=ia(i,[0,4,1,2,3])),i}))}yb.className="ZeroPadding2D",Lr(yb);class wb extends km{constructor(t){if(null==t.poolSize&&(t.poolSize=2),super(t),"number"==typeof t.poolSize)this.poolSize=[t.poolSize];else{if(!Array.isArray(t.poolSize)||1!==t.poolSize.length||"number"!=typeof t.poolSize[0])throw new Nd("poolSize for 1D convolutional layer must be a number or an Array of a single number, but received "+JSON.stringify(t.poolSize));this.poolSize=t.poolSize}if(Vd(this.poolSize,"poolSize"),null==t.strides)this.strides=this.poolSize;else if("number"==typeof t.strides)this.strides=[t.strides];else{if(!Array.isArray(t.strides)||1!==t.strides.length||"number"!=typeof t.strides[0])throw new Nd("strides for 1D convolutional layer must be a number or an Array of a single number, but received "+JSON.stringify(t.strides));this.strides=t.strides}Vd(this.strides,"strides"),this.padding=null==t.padding?"valid":t.padding,lf(this.padding),this.inputSpec=[new ym({ndim:3})]}computeOutputShape(t){const e=dy((t=pm(t))[1],this.poolSize[0],this.padding,this.strides[0]);return[t[0],e,t[2]]}call(t,e){return Wr((()=>{this.invokeCallHook(t,e),t=kf(hm(t),2);const n=this.poolingFunction(hm(t),[this.poolSize[0],1],[this.strides[0],1],this.padding,"channelsLast");return io(n,[2])}))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides},e=super.getConfig();return Object.assign(t,e),t}}class vb extends wb{constructor(t){super(t)}poolingFunction(t,e,n,s,r){return of(r),lf(s),bb(t,e,n,s,r,"max")}}vb.className="MaxPooling1D",Lr(vb);class kb extends wb{constructor(t){super(t)}poolingFunction(t,e,n,s,r){return of(r),lf(s),bb(t,e,n,s,r,"avg")}}kb.className="AveragePooling1D",Lr(kb);class Nb extends km{constructor(t){if(null==t.poolSize&&(t.poolSize=[2,2]),super(t),this.poolSize=Array.isArray(t.poolSize)?t.poolSize:[t.poolSize,t.poolSize],null==t.strides)this.strides=this.poolSize;else if(Array.isArray(t.strides)){if(2!==t.strides.length)throw new Nd("If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length "+t.strides.length+".");this.strides=t.strides}else this.strides=[t.strides,t.strides];Vd(this.poolSize,"poolSize"),Vd(this.strides,"strides"),this.padding=null==t.padding?"valid":t.padding,this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,of(this.dataFormat),lf(this.padding),this.inputSpec=[new ym({ndim:4})]}computeOutputShape(t){t=pm(t);let e="channelsFirst"===this.dataFormat?t[2]:t[1],n="channelsFirst"===this.dataFormat?t[3]:t[2];return e=dy(e,this.poolSize[0],this.padding,this.strides[0]),n=dy(n,this.poolSize[1],this.padding,this.strides[1]),"channelsFirst"===this.dataFormat?[t[0],t[1],e,n]:[t[0],e,n,t[3]]}call(t,e){return Wr((()=>(this.invokeCallHook(t,e),this.poolingFunction(hm(t),this.poolSize,this.strides,this.padding,this.dataFormat))))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class Ib extends Nb{constructor(t){super(t)}poolingFunction(t,e,n,s,r){return of(r),lf(s),bb(t,e,n,s,r,"max")}}Ib.className="MaxPooling2D",Lr(Ib);class Cb extends Nb{constructor(t){super(t)}poolingFunction(t,e,n,s,r){return of(r),lf(s),bb(t,e,n,s,r,"avg")}}Cb.className="AveragePooling2D",Lr(Cb);class Sb extends km{constructor(t){if(null==t.poolSize&&(t.poolSize=[2,2,2]),super(t),this.poolSize=Array.isArray(t.poolSize)?t.poolSize:[t.poolSize,t.poolSize,t.poolSize],null==t.strides)this.strides=this.poolSize;else if(Array.isArray(t.strides)){if(3!==t.strides.length)throw new Nd("If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length "+t.strides.length+".");this.strides=t.strides}else this.strides=[t.strides,t.strides,t.strides];Vd(this.poolSize,"poolSize"),Vd(this.strides,"strides"),this.padding=null==t.padding?"valid":t.padding,this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,of(this.dataFormat),lf(this.padding),this.inputSpec=[new ym({ndim:5})]}computeOutputShape(t){t=pm(t);let e="channelsFirst"===this.dataFormat?t[2]:t[1],n="channelsFirst"===this.dataFormat?t[3]:t[2],s="channelsFirst"===this.dataFormat?t[4]:t[3];return e=dy(e,this.poolSize[0],this.padding,this.strides[0]),n=dy(n,this.poolSize[1],this.padding,this.strides[1]),s=dy(s,this.poolSize[2],this.padding,this.strides[2]),"channelsFirst"===this.dataFormat?[t[0],t[1],e,n,s]:[t[0],e,n,s,t[4]]}call(t,e){return Wr((()=>(this.invokeCallHook(t,e),this.poolingFunction(hm(t),this.poolSize,this.strides,this.padding,this.dataFormat))))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class Tb extends Sb{constructor(t){super(t)}poolingFunction(t,e,n,s,r){return of(r),lf(s),xb(t,e,n,s,r,"max")}}Tb.className="MaxPooling3D",Lr(Tb);class $b extends Sb{constructor(t){super(t)}poolingFunction(t,e,n,s,r){return of(r),lf(s),xb(t,e,n,s,r,"avg")}}$b.className="AveragePooling3D",Lr($b);class Eb extends km{constructor(t){super(t),this.inputSpec=[new ym({ndim:3})]}computeOutputShape(t){return[t[0],t[2]]}call(t,e){throw new Id}}class Ab extends Eb{constructor(t){super(t||{})}call(t,e){return Wr((()=>{const e=hm(t);return Ii(e,1)}))}}Ab.className="GlobalAveragePooling1D",Lr(Ab);class Rb extends Eb{constructor(t){super(t||{})}call(t,e){return Wr((()=>{const e=hm(t);return mi(e,1)}))}}Rb.className="GlobalMaxPooling1D",Lr(Rb);class Db extends km{constructor(t){super(t),this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,of(this.dataFormat),this.inputSpec=[new ym({ndim:4})]}computeOutputShape(t){return t=t,"channelsLast"===this.dataFormat?[t[0],t[3]]:[t[0],t[1]]}call(t,e){throw new Id}getConfig(){const t={dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class Fb extends Db{call(t,e){return Wr((()=>{const e=hm(t);return"channelsLast"===this.dataFormat?Ii(e,[1,2]):Ii(e,[2,3])}))}}Fb.className="GlobalAveragePooling2D",Lr(Fb);class _b extends Db{call(t,e){return Wr((()=>{const e=hm(t);return"channelsLast"===this.dataFormat?mi(e,[1,2]):mi(e,[2,3])}))}}_b.className="GlobalMaxPooling2D",Lr(_b);class Ob extends km{constructor(t){super(t),this.layer=t.layer}build(t){this.built=!0}get trainable(){return null!=this.layer&&this.layer.trainable}set trainable(t){null!=this.layer&&(this.layer.trainable=t)}get trainableWeights(){return this.layer.trainableWeights}get nonTrainableWeights(){return this.layer.nonTrainableWeights}get updates(){return this.layer._updates}get losses(){return this.layer.losses}getWeights(){return this.layer.getWeights()}setWeights(t){this.layer.setWeights(t)}getConfig(){const t={layer:{className:this.layer.getClassName(),config:this.layer.getConfig()}},e=super.getConfig();return Object.assign(t,e),t}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),null!=this.layer&&this.layer.setFastWeightInitDuringBuild(t)}static fromConfig(t,e,n={}){const s=Mm(e.layer,n);delete e.layer;const r={layer:s};return Object.assign(r,e),new t(r)}}class Mb extends Ob{constructor(t){super(t),this.supportsMasking=!0}build(t){if((t=pm(t)).length<3)throw new Nd("TimeDistributed layer expects an input shape >= 3D, but received input shape "+JSON.stringify(t));this.inputSpec=[{shape:t}];const e=[t[0]].concat(t.slice(2));this.layer.built||(this.layer.build(e),this.layer.built=!0),super.build(t)}computeOutputShape(t){const e=[(t=pm(t))[0]].concat(t.slice(2)),n=this.layer.computeOutputShape(e),s=t[1];return[n[0],s].concat(n.slice(1))}call(t,e){return Wr((()=>Ay(((t,n)=>[hm(this.layer.call(t,e)),[]]),t=hm(t),[],!1,null,null,!1,!0)[1]))}}Mb.className="TimeDistributed",Lr(Mb);class Lb extends Ob{constructor(t){super(t);const e=t.layer.getConfig(),n={};n.className=t.layer.getClassName(),n.config=e,this.forwardLayer=Mm(n),e.goBackwards=!0!==e.goBackwards;const s={};var r;if(s.className=t.layer.getClassName(),s.config=e,this.backwardLayer=Mm(s),this.forwardLayer.name="forward_"+this.forwardLayer.name,this.backwardLayer.name="backward_"+this.backwardLayer.name,this.mergeMode=void 0===t.mergeMode?"concat":t.mergeMode,r=this.mergeMode,Pd(rf,"BidirectionalMergeMode",r),t.weights)throw new Id("weights support is not implemented for Bidirectional layer yet.");this._stateful=t.layer.stateful,this.returnSequences=t.layer.returnSequences,this.returnState=t.layer.returnState,this.supportsMasking=!0,this._trainable=!0,this.inputSpec=t.layer.inputSpec,this.numConstants=null}get trainable(){return this._trainable}set trainable(t){this._trainable=t,null!=this.forwardLayer&&(this.forwardLayer.trainable=t),null!=this.backwardLayer&&(this.backwardLayer.trainable=t)}getWeights(){return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights())}setWeights(t){const e=t.length,n=Math.floor(e/2);this.forwardLayer.setWeights(t.slice(0,n)),this.backwardLayer.setWeights(t.slice(n))}computeOutputShape(t){let e,n,s,r=this.forwardLayer.computeOutputShape(t);return Array.isArray(r)&&Array.isArray(r[0])||(r=[r]),r=r,this.returnState?(s=r.slice(1),e=r[0]):e=r[0],e=e,"concat"===this.mergeMode?(e[e.length-1]*=2,n=[e]):n=null==this.mergeMode?[e,e.slice()]:[e],this.returnState?null==this.mergeMode?n.concat(s).concat(s.slice()):[e].concat(s).concat(s.slice()):Ed(n)}apply(t,e){let n=null==e?null:e.initialState,s=null==e?null:e.constants;null==e&&(e={});const r=Ey(t,n,s,this.numConstants);if(t=r.inputs,n=r.initialState,s=r.constants,Array.isArray(t)&&(n=t.slice(1),t=t[0]),(null==n||0===n.length)&&null==s)return super.apply(t,e);const a=[],i=[];if(null!=n){const t=n.length;if(t%2>0)throw new Nd("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");e.initialState=n,a.push(...n);const s=n.map((t=>new ym({shape:t.shape})));this.forwardLayer.stateSpec=s.slice(0,t/2),this.backwardLayer.stateSpec=s.slice(t/2),i.push(...s)}if(null!=s)throw new Id("Support for constants in Bidirectional layers is not implemented yet.");const o=a[0]instanceof bm;for(const t of a)if(t instanceof bm!==o)throw new Nd("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");if(o){const n=[t].concat(a),s=this.inputSpec.concat(i),r=this.inputSpec;this.inputSpec=s;const o=super.apply(n,e);return this.inputSpec=r,o}return super.apply(t,e)}call(t,e){return Wr((()=>{const n=e.initialState;let s,r,a,i;if(null==n)s=this.forwardLayer.call(t,e),r=this.backwardLayer.call(t,e);else{const a=n.slice(0,n.length/2),i=n.slice(n.length/2);s=this.forwardLayer.call(t,Object.assign(e,{initialState:a})),r=this.backwardLayer.call(t,Object.assign(e,{initialState:i}))}return this.returnState&&(Array.isArray(s)&&(a=s.slice(1).concat(r.slice(1))),s=s[0],r=r[0]),this.returnSequences&&(r=ji(r,1)),"concat"===this.mergeMode?i=Sf([s,r]):"sum"===this.mergeMode?i=Yr(s,r):"ave"===this.mergeMode?i=pi(.5,Yr(s,r)):"mul"===this.mergeMode?i=pi(s,r):null==this.mergeMode&&(i=[s,r]),this.returnState?null==this.mergeMode?i.concat(a):[i].concat(a):i}))}resetStates(t){this.forwardLayer.resetStates(),this.backwardLayer.resetStates()}build(t){hf(this.forwardLayer.name,(()=>{this.forwardLayer.build(t)})),hf(this.backwardLayer.name,(()=>{this.backwardLayer.build(t)})),this.built=!0}computeMask(t,e){let n;if(Array.isArray(e)&&(e=e[0]),n=this.returnSequences?null==this.mergeMode?[e,e]:e:null==this.mergeMode?[null,null]:null,this.returnState){const t=this.forwardLayer.states.map((t=>null));return Array.isArray(n)?n.concat(t).concat(t):[n].concat(t).concat(t)}return n}get trainableWeights(){return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights)}get nonTrainableWeights(){return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights)}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),null!=this.forwardLayer&&this.forwardLayer.setFastWeightInitDuringBuild(t),null!=this.backwardLayer&&this.backwardLayer.setFastWeightInitDuringBuild(t)}getConfig(){const t={mergeMode:this.mergeMode},e=super.getConfig();return Object.assign(t,e),t}static fromConfig(t,e){const n=Mm(e.layer);if(delete e.layer,null!=e.numConstants)throw new Id("Deserialization of a Bidirectional layer with numConstants present is not supported yet.");const s=e;return s.layer=n,new t(s)}}function zb(t,e,n=new Map,s=new Set){if(null==t)return null;if(s.has(t))throw new Error("Circular references are not supported.");if(n.has(t))return n.get(t);const r=e(t);if(r.recurse&&null!==r.value)throw new Error("A deep map function may not return both a value and recurse=true.");if(r.recurse){if(Vb(t)){const r=Array.isArray(t)?[]:{};s.add(t);for(const a in t){const i=zb(t[a],e,n,s);r[a]=i}return s.delete(t),r}throw new Error("Can't recurse into non-iterable type: "+t)}return n.set(t,r.value),r.value}function Bb(t,e=Wb){return Pb(t,e)}function Pb(t,e,n=new Set){const s=t[0];if(n.has(s))throw new Error("Circular references are not supported.");const r=e(t);if(r.recurse&&null!==r.value)throw new Error("A deep zip function may not return both a value and recurse=true.");if(r.recurse){if(Vb(s)){const r=Array.isArray(s)?[]:{};n.add(s);for(const a in s){const s=Pb(t.map((t=>t[a])),e,n);r[a]=s}return n.delete(s),r}throw new Error("Can't recurse into non-iterable type: "+s)}return r.value}function Wb(t){return null===t?null:Vb(t[0])?{value:null,recurse:!0}:{value:t,recurse:!1}}function Vb(t){return null!=t&&!ArrayBuffer.isView(t)&&(Array.isArray(t)||"object"==typeof t&&!(t instanceof Jn))}function Ub(t){return zb(t,Gb)}function Gb(t){return t instanceof Jn?{value:t.clone(),recurse:!1}:Vb(t)?{value:null,recurse:!0}:{value:t,recurse:!1}}Lb.className="Bidirectional",Lr(Lb);class Hb{constructor(t){if(this.capacity=t,this.begin=0,this.end=0,null==t)throw new RangeError("Can't create a ring buffer of unknown capacity.");if(t<1)throw new RangeError("Can't create ring buffer of capacity < 1.");this.data=new Array(t),this.doubledCapacity=2*t}wrap(t){for(;t<0;)t+=this.doubledCapacity;return t%this.doubledCapacity}get(t){if(t<0)throw new RangeError("Can't get item at a negative index.");return this.data[t%this.capacity]}set(t,e){if(t<0)throw new RangeError("Can't set item at a negative index.");this.data[t%this.capacity]=e}length(){let t=this.end-this.begin;return t<0&&(t=this.doubledCapacity+t),t}isFull(){return this.length()===this.capacity}isEmpty(){return 0===this.length()}push(t){if(this.isFull())throw new RangeError("Ring buffer is full.");this.set(this.end,t),this.end=this.wrap(this.end+1)}pushAll(t){for(const e of t)this.push(e)}pop(){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");this.end=this.wrap(this.end-1);const t=this.get(this.end);return this.set(this.end,void 0),t}unshift(t){if(this.isFull())throw new RangeError("Ring buffer is full.");this.begin=this.wrap(this.begin-1),this.set(this.begin,t)}shift(){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");const t=this.get(this.begin);return this.set(this.begin,void 0),this.begin=this.wrap(this.begin+1),t}shuffleExcise(t){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");const e=this.wrap(this.begin+t),n=this.get(e);return this.set(e,this.pop()),n}}class jb extends Hb{constructor(){super(jb.INITIAL_CAPACITY)}isFull(){return!1}push(t){super.isFull()&&this.expand(),super.push(t)}unshift(t){super.isFull()&&this.expand(),super.unshift(t)}expand(){const t=2*this.capacity,e=new Array(t),n=this.length();for(let t=0;t<n;t++)e[t]=this.get(this.wrap(this.begin+t));this.data=e,this.capacity=t,this.doubledCapacity=2*this.capacity,this.begin=0,this.end=n}}jb.INITIAL_CAPACITY=32;class qb{async toArray(){const t=[];let e=await this.next();for(;!e.done;)t.push(e.value),e=await this.next();return t}async toArrayForTest(){const t=this.prefetch(100),e=[];let n=await t.next();for(;!n.done;)e.push(n.value),n=await t.next();return e}async resolveFully(){let t=await this.next();for(;!t.done;)t=await this.next()}async resolveWhile(t){let e=await this.next(),n=t(e.value);for(;!e.done&&n;)e=await this.next(),n=t(e.value)}handleErrors(t){return new nx(this,t)}filter(t){return new tx(this,t)}map(t){return new ex(this,t)}mapAsync(t){return new sx(this,t)}serialMapAsync(t){return new sx(this,t).serial()}flatmap(t){return new ax(this,t)}async forEachAsync(t){return this.map(t).resolveFully()}async serialForEach(t){return this.serialMapAsync(t).resolveWhile((t=>!0===t))}rowMajorBatch(t,e=!0){return new Qb(this,t,e)}columnMajorBatch(t,e=!0,n=Wb){return this.rowMajorBatch(t,e).map((t=>Bb(t,n)))}concatenate(t,e){return new ix(new Kb([this,t]),e)}take(t){return t<0||null==t?this:new Zb(this,t)}skip(t){return t<0||null==t?this:new Jb(this,t)}prefetch(t){return new ox(this,t)}shuffle(t,e){return new lx(this,t,e)}serial(){return new Yb(this)}}class Kb extends qb{constructor(t){super(),this.items=t,this.trav=0}summary(){return`Array of ${this.items.length} items`}async next(){if(this.trav>=this.items.length)return{value:null,done:!0};const t=this.items[this.trav];return this.trav++,{value:Ub(t),done:!1}}}class Xb extends qb{constructor(t){super(),this.nextFn=t}summary(){return"Function call"}async next(){try{return this.nextFn()}catch(t){throw t.message="Error thrown while iterating through a dataset: "+t.message,t}}}class Yb extends qb{constructor(t){super(),this.upstream=t,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return this.upstream.summary()+" -> Serial"}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){return this.upstream.next()}}class Jb extends qb{constructor(t,e){super(),this.upstream=t,this.maxCount=e,this.count=0,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return this.upstream.summary()+" -> Skip"}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){for(;this.count++<this.maxCount;){const t=await this.upstream.next();if(t.done)return t;Vr(t.value)}return this.upstream.next()}}class Zb extends qb{constructor(t,e){super(),this.upstream=t,this.maxCount=e,this.count=0}summary(){return this.upstream.summary()+" -> Take"}async next(){return this.count++>=this.maxCount?{value:null,done:!0}:this.upstream.next()}}class Qb extends qb{constructor(t,e,n=!0){super(),this.upstream=t,this.batchSize=e,this.enableSmallLastBatch=n,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return this.upstream.summary()+" -> RowMajorBatch"}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){const t=[];for(;t.length<this.batchSize;){const e=await this.upstream.next();if(e.done)return this.enableSmallLastBatch&&t.length>0?{value:t,done:!1}:{value:null,done:!0};t.push(e.value)}return{value:t,done:!1}}}class tx extends qb{constructor(t,e){super(),this.upstream=t,this.predicate=e,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return this.upstream.summary()+" -> Filter"}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){for(;;){const t=await this.upstream.next();if(t.done||this.predicate(t.value))return t;Vr(t.value)}}}class ex extends qb{constructor(t,e){super(),this.upstream=t,this.transform=e}summary(){return this.upstream.summary()+" -> Map"}async next(){const t=await this.upstream.next();if(t.done)return{value:null,done:!0};const e=us(t.value),n=this.transform(t.value),s=us(n);for(const t of e)ls(t,s)||t.dispose();return{value:n,done:!1}}}class nx extends qb{constructor(t,e){super(),this.upstream=t,this.handler=e,this.count=0,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return this.upstream.summary()+" -> handleErrors"}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){for(;;)try{return await this.upstream.next()}catch(t){if(!this.handler(t))return{value:null,done:!0}}}}class sx extends qb{constructor(t,e){super(),this.upstream=t,this.transform=e}summary(){return this.upstream.summary()+" -> AsyncMap"}async next(){const t=await this.upstream.next();if(t.done)return{value:null,done:!0};const e=us(t.value),n=await this.transform(t.value),s=us(n);for(const t of e)ls(t,s)||t.dispose();return{value:n,done:!1}}}class rx extends qb{constructor(){super(),this.outputQueue=new jb,this.lastRead=Promise.resolve({value:null,done:!1})}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){for(;0===this.outputQueue.length();)if(!await this.pump())return{value:null,done:!0};return{value:this.outputQueue.shift(),done:!1}}}class ax extends rx{constructor(t,e){super(),this.upstream=t,this.transform=e}summary(){return this.upstream.summary()+" -> Flatmap"}async pump(){const t=await this.upstream.next();if(t.done)return!1;const e=us(t.value),n=this.transform(t.value),s=us(n);this.outputQueue.pushAll(n);for(const t of e)ls(t,s)||t.dispose();return!0}}class ix extends qb{constructor(t,e){super(),this.baseErrorHandler=e,this.lastRead=null,this.iterator=null,this.moreIterators=t}summary(){return"TODO: fill in upstream of chained summaries -> Chained"}async next(){return this.lastRead=this.readFromChain(this.lastRead),this.lastRead}async readFromChain(t){if(await t,null==this.iterator){const t=await this.moreIterators.next();if(t.done)return{value:null,done:!0};this.iterator=t.value,null!=this.baseErrorHandler&&(this.iterator=this.iterator.handleErrors(this.baseErrorHandler))}const e=await this.iterator.next();return e.done?(this.iterator=null,this.readFromChain(t)):e}}(Vy=Wy||(Wy={}))[Vy.FAIL=0]="FAIL",Vy[Vy.SHORTEST=1]="SHORTEST",Vy[Vy.LONGEST=2]="LONGEST";class ox extends qb{constructor(t,e){super(),this.upstream=t,this.bufferSize=e,this.buffer=new Hb(e)}summary(){return this.upstream.summary()+" -> Prefetch"}refill(){for(;!this.buffer.isFull();){const t=this.upstream.next();this.buffer.push(t)}}next(){return this.refill(),this.buffer.shift()}}class lx extends ox{constructor(t,e,n){super(t,e),this.upstream=t,this.windowSize=e,this.upstreamExhausted=!1,this.random=zi.alea(n||Gn().toString()),this.lastRead=Promise.resolve({value:null,done:!1})}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}randomInt(t){return Math.floor(this.random()*t)}chooseIndex(){return this.randomInt(this.buffer.length())}async serialNext(){for(this.upstreamExhausted||this.refill();!this.buffer.isEmpty();){const t=this.chooseIndex(),e=await this.buffer.shuffleExcise(t);if(!e.done)return this.refill(),e;this.upstreamExhausted=!0}return{value:null,done:!0}}}class ux{constructor(){this.size=null}batch(t,e=!0){const n=this;let s;return A(t>0,(()=>"batchSize needs to be positive, but it is\n      "+t)),s=this.size===1/0||null==this.size?this.size:e?Math.ceil(this.size/t):Math.floor(this.size/t),cx((async()=>(await n.iterator()).columnMajorBatch(t,e,hx)),s)}concatenate(t){const e=this;let n;return n=this.size===1/0||t.size===1/0?1/0:null!=this.size&&null!=t.size?this.size+t.size:null,cx((async()=>(await e.iterator()).concatenate(await t.iterator())),n)}filter(t){const e=this;let n;return n=this.size===1/0?1/0:null,cx((async()=>(await e.iterator()).filter((e=>Wr((()=>t(e)))))),n)}async forEachAsync(t){return(await this.iterator()).forEachAsync(t)}map(t){const e=this;return cx((async()=>(await e.iterator()).map((e=>Wr((()=>t(e)))))),this.size)}mapAsync(t){const e=this;return cx((async()=>(await e.iterator()).mapAsync(t)),this.size)}prefetch(t){if(null==t)throw new RangeError("`Dataset.prefetch()` requires bufferSize to be specified.");const e=this;return cx((async()=>(await e.iterator()).prefetch(t)),this.size)}repeat(t){const e=this;let n;return n=null!=this.size&&t>0?this.size*t:0===t?0:null!=this.size&&(void 0===t||t<0)?1/0:null,cx((async()=>{return n=(r=async()=>({value:await e.iterator(),done:!1}),new Xb(r)).take(t),new ix(n,s);var n,s,r}),n)}skip(t){const e=this;let n;return n=null!=this.size&&t>=0&&this.size>=t?this.size-t:null!=this.size&&(this.size<t||void 0===t||t<0)?0:null,cx((async()=>(await e.iterator()).skip(t)),n)}shuffle(t,e,n=!0){if(null==t||t<0)throw null==this.size?new RangeError("`Dataset.shuffle()` requires bufferSize to be specified."):new RangeError(`\`Dataset.shuffle()\` requires bufferSize to be specified.  If your data fits in main memory (for regular JS objects), and/or GPU memory (for \`tf.Tensor\`s), consider setting bufferSize to the dataset size (${this.size} elements)`);const s=this,r=zi.alea(e||Gn().toString());return cx((async()=>{let e=r.int32();return n&&(e+=r.int32()),(await s.iterator()).shuffle(t,e.toString())}),this.size)}take(t){const e=this;let n;return n=null!=this.size&&this.size>t?t:null!=this.size&&this.size<=t?this.size:null,cx((async()=>(await e.iterator()).take(t)),n)}async toArray(){if(this.size===1/0)throw new Error("Can not convert infinite data stream to array.");return(await this.iterator()).toArray()}async toArrayForTest(){if(this.size===1/0)throw new Error("Can not convert infinite data stream to array.");return(await this.iterator()).toArrayForTest()}}function cx(t,e=null){return new class extends ux{constructor(){super(...arguments),this.size=e}async iterator(){return t()}}}function hx(t){if(null===t)return null;return null==(e=t[0])||null===(n=e)||"object"!=typeof n&&"function"!=typeof n||Array.isArray(e)||"object"==typeof e&&e instanceof Jn||j(e)?{value:function(t){if(0===t.length)throw new Error("Can't make a batch of zero elements.");return t[0]instanceof Jn?oo(t):Ss(t)}(t),recurse:!1}:{value:null,recurse:!0};var e,n}function px(t,e){Array.isArray(t)||(t=[t]),t.forEach((t=>{null!=t&&A("complex64"!==t.dtype,(()=>e+" does not support complex64 tensors in the CPU backend."))}))}ux.MAX_BUFFER_SIZE=1e4,Symbol("out"),Symbol("field"),Symbol("quote"),Symbol("quoteafterquote"),Symbol("quoteinquote");const dx=Go,fx=ru,mx=au,gx=iu,yx=ou;class bx extends C{constructor(){super(),this.blockSize=48,this.firstUse=!0,this.data=new I(this,Br())}write(t,e,n){this.firstUse&&(this.firstUse=!1,ct().get("IS_NODE")&&Hl("\n============================\nHi there 👋. Looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, which binds to TensorFlow C++, by running npm i @tensorflow/tfjs-node, or npm i @tensorflow/tfjs-node-gpu if you have CUDA. Then call require('@tensorflow/tfjs-node'); (-gpu suffix for CUDA) at the start of your program. Visit https://github.com/tensorflow/tfjs-node for more details.\n============================"));const s={};return this.data.set(s,{values:t,dtype:n,refCount:1}),s}makeTensorInfo(t,e,n){let s;if("string"===e&&null!=n&&n.length>0&&K(n[0])){const r=n.map((t=>Hn(t)));s=this.write(r,t,e)}else s=this.write(n,t,e);return{dataId:s,shape:t,dtype:e}}incRef(t){this.data.get(t).refCount++}decRef(t){this.data.has(t)&&this.data.get(t).refCount--}move(t,e,n,s){this.data.set(t,{values:e,dtype:s,refCount:1})}numDataIds(){return this.data.numDataIds()}async read(t){return this.readSync(t)}readSync(t){const{dtype:e,complexTensorInfos:n}=this.data.get(t);return"complex64"===e?ql(this.readSync(n.real.dataId),this.readSync(n.imag.dataId)):this.data.get(t).values}bufferSync(t){const e=this.readSync(t.dataId);let n=e;if("string"===t.dtype)try{n=e.map((t=>jn(t)))}catch(t){throw new Error("Failed to decode encoded string bytes into utf-8")}return ir(t.shape,t.dtype,n)}makeOutput(t,e,n){const s=this.write(t,e,n);return Br().makeTensorFromDataId(s,e,n,this)}disposeData(t){if(this.data.has(t)){const{complexTensorInfos:e}=this.data.get(t);null!=e&&(this.disposeData(e.real.dataId),this.disposeData(e.imag.dataId)),this.data.delete(t)}}disposeIntermediateTensorInfo(t){const e=t.dataId;if(this.data.has(e)){const t=this.data.get(e);t.refCount--,t.refCount<1&&this.disposeData(e)}}async time(t){const e=Gn();return t(),{kernelMs:Gn()-e}}memory(){return{unreliable:!0,reasons:["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]}}stridedSlice(t,e,n,s){px(t,"stridedSlice");const r=kr(e,n,s);if(r.some((t=>0===t)))return Ss([],r);const a=ir(r,t.dtype),i=this.bufferSync(t);for(let t=0;t<a.size;t++){const n=a.indexToLoc(t),r=new Array(n.length);for(let t=0;t<r.length;t++)r[t]=n[t]*s[t]+e[t];a.set(i.get(...r),...n)}return a.toTensor()}diag(t){const e=this.readSync(t.dataId),n=ir([t.size,t.size],t.dtype),s=n.values;for(let n=0;n<e.length;n++)s[n*t.size+n]=e[n];return n.toTensor()}unstack(t,e){const n=t.shape[e],s=new Array(t.rank-1);let r=0;for(let n=0;n<t.rank;n++)n!==e&&(s[r++]=t.shape[n]);const a=new Array(t.rank).fill(0),i=t.shape.slice();i[e]=1;const o=new Array(n);for(let n=0;n<o.length;n++)a[e]=n,o[n]=Yi(t,a,i).reshape(s);return o}reverse(t,e){px(t,"reverse");const n=ir(t.shape,t.dtype),s=this.bufferSync(t);for(let r=0;r<n.size;r++){const a=n.indexToLoc(r),i=a.slice();e.forEach((e=>i[e]=t.shape[e]-1-i[e])),n.set(s.get(...i),...a)}return n.toTensor()}neg(t){return px(t,"neg"),pi(qr(-1),t)}addN(t){px(t,"addN");const e=t.map((t=>this.readSync(t.dataId))),n=ir(t[0].shape,t[0].dtype),s=n.values;for(let n=0;n<t.length;n++){const t=e[n];for(let e=0;e<s.length;e++)s[e]+=t[e]}return n.toTensor()}softmax(t,e){const n=W([e],t.shape),s=mi(t,n),r=ta(s.shape,n),a=gi(t,s.reshape(r)),i=Ja(a),o=this.sum(i,n).reshape(r);return Ha(i,o)}pow(t,e){return px([t,e],"pow"),this.broadcastedBinaryOp(t,e,t.dtype,((t,e)=>Math.pow(t,e)))}floorDiv(t,e){return px([t,e],"floorDiv"),this.broadcastedBinaryOp(t,e,"int32",((t,e)=>Math.floor(t/e)))}sum(t,e){px(t,"sum"),ea("sum",e,t.rank);const[n,s]=Qr(t.shape,e),r=ki(n,as(t.dtype,"int32")),a=_(s),i=this.readSync(r.dataId),o=this.readSync(t.dataId);for(let t=0;t<i.length;++t){const e=t*a;let n=0;for(let t=0;t<a;++t)n+=o[e+t];i[t]=n}return r}prod(t,e){px(t,"sum");const[n,s]=Qr(t.shape,e),r=ki(n,as(t.dtype,"int32")),a=_(s),i=this.readSync(r.dataId),o=this.readSync(t.dataId);for(let t=0;t<i.length;++t){const e=t*a;let n=1;for(let t=0;t<a;++t)n*=o[e+t];i[t]=n}return r}unsortedSegmentSum(t,e,n){px(t,"unsortedSegmentSum");const s=[],r=t.rank-e.rank;for(let t=0;t<r;++t)e=e.expandDims(t+1);for(let r=0;r<n;++r){const n=qr(r,"int32"),a=Ya(n,e).asType("float32").mul(t).sum(0);s.push(a)}return oo(s)}argMin(t,e){px(t,"argMin");const n=[e];ea("argMin",n,t.rank);const[s,r]=Qr(t.shape,n),a=ki(s,"int32"),i=_(r),o=this.readSync(a.dataId),l=this.readSync(t.dataId);for(let t=0;t<o.length;++t){const e=t*i;let n=l[e],s=0;for(let t=0;t<i;++t){const r=l[e+t];r<n&&(n=r,s=t)}o[t]=s}return a}argMax(t,e){px(t,"argMax");const n=[e];ea("argMax",n,t.rank);const[s,r]=Qr(t.shape,n),a=ki(s,"int32"),i=_(r),o=this.readSync(a.dataId),l=this.readSync(t.dataId);for(let t=0;t<o.length;++t){const e=t*i;let n=l[e],s=0;for(let t=0;t<i;++t){const r=l[e+t];r>n&&(n=r,s=t)}o[t]=s}return a}cumsum(t,e,n,s){if(px(t,"cumsum"),e!==t.rank-1)throw new Error(`backend.cumsum in CPU expects an inner-most axis=${t.rank-1} but got axis=`+e);const r=as(t.dtype,"int32"),a=ki(t.shape,r),i=this.readSync(a.dataId),o=this.readSync(t.dataId),l=t.shape[t.rank-1],u=s?(t,e)=>t+l-e-1:(t,e)=>t+e;for(let t=0;t<o.length;t+=l)for(let e=0;e<l;e++){const s=u(t,e);if(0===e)i[s]=n?0:o[s];else{const r=u(t,e-1);i[s]=n?o[r]+i[r]:o[s]+i[r]}}return a}equal(t,e){return px([t,e],"equal"),this.broadcastedBinaryOp(t,e,"bool",((t,e)=>t===e?1:0))}notEqual(t,e){return px([t,e],"notEqual"),this.broadcastedBinaryOp(t,e,"bool",((t,e)=>t!==e?1:0))}less(t,e){return px([t,e],"less"),this.broadcastedBinaryOp(t,e,"bool",((t,e)=>t<e?1:0))}lessEqual(t,e){return px([t,e],"lessEqual"),this.broadcastedBinaryOp(t,e,"bool",((t,e)=>t<=e?1:0))}greater(t,e){return px([t,e],"greater"),this.broadcastedBinaryOp(t,e,"bool",((t,e)=>t>e?1:0))}greaterEqual(t,e){return px([t,e],"greaterEqual"),this.broadcastedBinaryOp(t,e,"bool",((t,e)=>t>=e?1:0))}logicalAnd(t,e){return px([t,e],"logicalAnd"),this.broadcastedBinaryOp(t,e,"bool",((t,e)=>t&&e))}logicalOr(t,e){return px([t,e],"logicalOr"),this.broadcastedBinaryOp(t,e,"bool",((t,e)=>t||e))}select(t,e,n){px([t,e,n],"select");const s=this.readSync(t.dataId),r=this.readSync(e.dataId),a=this.readSync(n.dataId),i=ki(e.shape,as(e.dtype,n.dtype)),o=this.readSync(i.dataId);let l=0;const u=0===t.rank||t.rank>1||1===e.rank?1:_(e.shape.slice(1));for(let t=0;t<s.length;t++)for(let e=0;e<u;e++)1===s[t]?o[l++]=r[t]:o[l++]=a[t];return i}where(t){px([t],"where");const e=this.readSync(t.dataId);return yx(t.shape,e)}topk(t,e,n){px(t,"topk");const s=this.readSync(t.dataId);return gx(s,t.shape,t.dtype,e,n)}min(t,e){px(t,"min"),ea("min",e,t.rank);const[n,s]=Qr(t.shape,e),r=ki(n,t.dtype),a=_(s),i=this.readSync(r.dataId),o=this.readSync(t.dataId);for(let t=0;t<i.length;++t){const e=t*a;let n=o[e];for(let t=0;t<a;++t){const s=o[e+t];s<n&&(n=s)}i[t]=n}return r}minimum(t,e){return px([t,e],"minimum"),this.broadcastedBinaryOp(t,e,t.dtype,((t,e)=>Math.min(t,e)))}mod(t,e){return px([t,e],"mod"),this.broadcastedBinaryOp(t,e,t.dtype,((t,e)=>{const n=t%e;return t<0&&e<0||t>=0&&e>=0?n:(n+e)%e}))}maximum(t,e){return px([t,e],"maximum"),this.broadcastedBinaryOp(t,e,t.dtype,((t,e)=>Math.max(t,e)))}all(t,e){px(t,"all"),ea("all",e,t.rank);const[n,s]=Qr(t.shape,e),r=ki(n,t.dtype),a=_(s),i=this.readSync(r.dataId),o=this.readSync(t.dataId);for(let t=0;t<i.length;++t){const e=t*a;let n=o[e];for(let t=0;t<a;++t){const s=o[e+t];n=n&&s}i[t]=n}return r}any(t,e){px(t,"any"),ea("any",e,t.rank);const[n,s]=Qr(t.shape,e),r=ki(n,t.dtype),a=_(s),i=this.readSync(r.dataId),o=this.readSync(t.dataId);for(let t=0;t<i.length;++t){const e=t*a;let n=o[e];for(let t=0;t<a;++t){const s=o[e+t];n=n||s}i[t]=n}return r}squaredDifference(t,e){return px([t,e],"squaredDifference"),this.broadcastedBinaryOp(t,e,t.dtype,((t,e)=>{const n=t-e;return n*n}))}eluDer(t,e){px([t,e],"eluDer");const n=new Float32Array(e.size),s=this.readSync(e.dataId),r=this.readSync(t.dataId);for(let t=0;t<s.length;++t){const e=s[t];n[t]=e>=1?r[t]:r[t]*(e+1)}return this.makeOutput(n,e.shape,"float32")}atan2(t,e){return px([t,e],"atan2"),this.broadcastedBinaryOp(t,e,t.dtype,((t,e)=>Math.atan2(t,e)))}tile(t,e){return px(t,"tile"),mx(this.bufferSync(t),e)}gather(t,e,n){px([t,e],"gather");const s=t.shape.slice(),r=this.readSync(e.dataId);s[n]=r.length;const a=ir(s,t.dtype),i=this.bufferSync(t);for(let t=0;t<a.size;++t){const e=a.indexToLoc(t),s=e.slice();s[n]=r[e[n]];const o=i.locToIndex(s);a.values[t]=i.values[o]}return a.toTensor()}batchToSpaceND(t,e,n){px([t],"batchToSpaceND");const s=e.reduce(((t,e)=>t*e)),r=$l(t.shape,e,s),a=El(r.length,e.length),i=Al(t.shape,e,s),o=Rl(n,e.length),l=Dl(i,n,e.length);return ia(t.reshape(r),a).reshape(i).slice(o,l)}pool3d(t,e,n){px(t,"pool3d");const s=e.strideDepth,r=e.strideHeight,a=e.strideWidth,i=e.dilationDepth,o=e.dilationHeight,l=e.dilationWidth,u=e.effectiveFilterDepth,c=e.effectiveFilterHeight,h=e.effectiveFilterWidth,p=e.padInfo.front,d=e.padInfo.top,f=e.padInfo.left,m="max"===n?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,g=this.readSync(t.dataId),y=ir(e.outShape,t.dtype),b=y.values,x=e.outShape[1]*e.outShape[2]*e.outShape[3]*e.outShape[4],w=e.outShape[2]*e.outShape[3]*e.outShape[4],v=e.outShape[3]*e.outShape[4],k=e.outShape[4];for(let y=0;y<e.batchSize;++y){const N=y*x,I=y*t.strides[0];for(let y=0;y<e.inChannels;++y)for(let x=0;x<e.outDepth;++x){const C=x*s-p;let S=C;for(;S<0;)S+=i;const T=Math.min(e.inDepth,u+C),$=N+x*w;for(let s=0;s<e.outHeight;++s){const u=s*r-d;let p=u;for(;p<0;)p+=o;const x=Math.min(e.inHeight,c+u),w=$+s*v;for(let s=0;s<e.outWidth;++s){const r=s*a-f;let u=r;for(;u<0;)u+=l;const c=Math.min(e.inWidth,h+r),d=w+s*k;let v=m,N=0,C=0;for(let e=S;e<T;e+=i){const s=I+e*t.strides[1];for(let e=p;e<x;e+=o){const r=s+e*t.strides[2];for(let e=u;e<c;e+=l){const s=g[r+e*t.strides[3]+y];if("max"===n&&s>v?v=s:"avg"===n&&(N+=s,C++),isNaN(v))break}if(isNaN(v))break}if(isNaN(v))break}b[d+y]="avg"===n?N/C:v}}}}return y.toTensor()}avgPool3d(t,e){return px(t,"avgPool3d"),this.pool3d(t,e,"avg").toFloat()}avgPool3dBackprop(t,e,n){px([t,e],"avgPool3dBackprop");const s=n.strideDepth,r=n.strideHeight,a=n.strideWidth,i=n.filterDepth,o=n.filterHeight,l=n.filterWidth,u=n.dilationDepth,c=n.dilationHeight,h=n.dilationWidth,p=n.effectiveFilterDepth,d=n.effectiveFilterHeight,f=n.effectiveFilterWidth,m=p-1-n.padInfo.front,g=f-1-n.padInfo.left,y=d-1-n.padInfo.top,b=ir(e.shape,"float32"),x=1/(i*o*l),w=this.bufferSync(t);for(let t=0;t<n.batchSize;++t)for(let e=0;e<n.inChannels;++e)for(let i=0;i<n.inDepth;++i)for(let o=0;o<n.inHeight;++o)for(let l=0;l<n.inWidth;++l){const v=i-m,k=o-y,N=l-g;let I=0;for(let i=0;i<p;i+=u){const o=(v+i)/s;if(!(o<0||o>=n.outDepth||Math.floor(o)!==o))for(let s=0;s<d;s+=c){const i=(k+s)/r;if(!(i<0||i>=n.outHeight||Math.floor(i)!==i))for(let s=0;s<f;s+=h){const r=(N+s)/a;r<0||r>=n.outWidth||Math.floor(r)!==r||(I+=w.get(t,o,i,r,e))}}}b.set(I*x,t,i,o,l,e)}return b.toTensor()}maxPool3d(t,e){return px(t,"maxPool3d"),this.pool3d(t,e,"max").toFloat()}maxPool3dPositions(t,e){const n=ir(e.outShape,"int32"),s=e.strideDepth,r=e.strideHeight,a=e.strideWidth,i=e.dilationDepth,o=e.dilationHeight,l=e.dilationWidth,u=e.effectiveFilterDepth,c=e.effectiveFilterHeight,h=e.effectiveFilterWidth,p=e.padInfo.front,d=e.padInfo.top,f=e.padInfo.left,m=this.bufferSync(t);for(let t=0;t<e.batchSize;++t)for(let g=0;g<e.inChannels;++g)for(let y=0;y<e.outDepth;++y){const b=y*s-p;let x=b;for(;x<0;)x+=i;const w=Math.min(e.inDepth,u+b);for(let s=0;s<e.outHeight;++s){const u=s*r-d;let p=u;for(;p<0;)p+=o;const v=Math.min(e.inHeight,c+u);for(let r=0;r<e.outWidth;++r){const d=r*a-f;let k=d;for(;k<0;)k+=l;const N=Math.min(e.inWidth,h+d);let I=Number.NEGATIVE_INFINITY,C=-1;for(let e=x;e<w;e+=i){const n=e-b;for(let s=p;s<v;s+=o){const r=s-u;for(let a=k;a<N;a+=l){const i=a-d,o=m.get(t,e,s,a,g);o>=I&&(I=o,C=n*c*h+r*c+i)}}}n.set(C,t,y,s,r,g)}}}return n.toTensor()}maxPool3dBackprop(t,e,n,s){px([e,n],"maxPool3dBackprop");const r=this.maxPool3dPositions(e,s),a=s.strideDepth,i=s.strideHeight,o=s.strideWidth,l=s.dilationDepth,u=s.dilationHeight,c=s.dilationWidth,h=s.effectiveFilterDepth,p=s.effectiveFilterHeight,d=s.effectiveFilterWidth,f=h-1-s.padInfo.front,m=d-1-s.padInfo.left,g=p-1-s.padInfo.top,y=ir(e.shape,"float32"),b=this.bufferSync(r),x=this.bufferSync(t);for(let t=0;t<s.batchSize;++t)for(let e=0;e<s.inChannels;++e)for(let n=0;n<s.inDepth;++n)for(let r=0;r<s.inHeight;++r)for(let w=0;w<s.inWidth;++w){const v=n-f,k=r-g,N=w-m;let I=0;for(let n=0;n<h;n+=l){const r=(v+n)/a;if(!(r<0||r>=s.outDepth||Math.floor(r)!==r))for(let a=0;a<p;a+=u){const l=(k+a)/i;if(!(l<0||l>=s.outHeight||Math.floor(l)!==l))for(let i=0;i<d;i+=c){const u=(N+i)/o;if(u<0||u>=s.outWidth||Math.floor(u)!==u)continue;const c=h*p*d-1-b.get(t,r,l,u,e)===n*p*d+a*d+i?1:0;0!==c&&(I+=x.get(t,r,l,u,e)*c)}}}y.set(I,t,n,r,w,e)}return y.toTensor()}resizeBilinear(t,e,n,s){px(t,"resizeBilinear");const[r,a,i,o]=t.shape,l=this.readSync(t.dataId),u=new Float32Array(_([r,e,n,o])),c=[s&&e>1?a-1:a,s&&n>1?i-1:i],h=[s&&e>1?e-1:e,s&&n>1?n-1:n];let p=0;const d=c[0]/h[0],f=c[1]/h[1];for(let s=0;s<r;s++)for(let r=0;r<e;r++){const e=d*r,c=Math.floor(e),h=e-c,m=Math.min(a-1,Math.ceil(e)),g=s*t.strides[0]+c*t.strides[1],y=s*t.strides[0]+m*t.strides[1];for(let e=0;e<n;e++){const n=f*e,s=Math.floor(n),r=n-s,a=Math.min(i-1,Math.ceil(n)),c=g+s*t.strides[2],d=y+s*t.strides[2],m=g+a*t.strides[2],b=y+a*t.strides[2];for(let t=0;t<o;t++){const e=l[c+t],n=l[d+t],s=e+(l[m+t]-e)*r,a=s+(n+(l[b+t]-n)*r-s)*h;u[p++]=a}}}return Ss(u,[r,e,n,o])}resizeBilinearBackprop(t,e,n){px([t,e],"resizeBilinearBackprop");const[s,r,a,i]=e.shape,[,o,l]=t.shape,u=new Float32Array(s*r*a*i),c=[n&&o>1?r-1:r,n&&l>1?a-1:a],h=[n&&o>1?o-1:o,n&&l>1?l-1:l],p=c[0]/h[0],d=c[1]/h[1],f=this.readSync(t.dataId);let m=0;for(let t=0;t<s;t++){const n=t*e.strides[0];for(let t=0;t<o;t++){const s=t*p,o=Math.floor(s),c=Math.min(Math.ceil(s),r-1),h=n+o*e.strides[1],g=n+c*e.strides[1],y=s-o,b=1-y;for(let t=0;t<l;t++){const n=t*d,s=Math.floor(n),r=Math.min(Math.ceil(n),a-1),o=n-s,l=1-o,c=h+s*e.strides[2],p=h+r*e.strides[2],x=g+s*e.strides[2],w=g+r*e.strides[2],v=b*l,k=b*o,N=y*l,I=y*o;for(let t=0;t<i;t++){const e=f[m++];u[c+t]+=e*v,u[p+t]+=e*k,u[x+t]+=e*N,u[w+t]+=e*I}}}}return co(u,[s,a,r,i],e.dtype)}resizeNearestNeighbor(t,e,n,s){px(t,"resizeNearestNeighbor");const[r,a,i,o]=t.shape,l=this.readSync(t.dataId),u=new Float32Array(r*e*n*o),c=[s&&e>1?a-1:a,s&&n>1?i-1:i],h=[s&&e>1?e-1:e,s&&n>1?n-1:n],p=c[0]/h[0],d=c[1]/h[1];let f=0;for(let c=0;c<r;c++){const r=c*t.strides[0];for(let c=0;c<e;c++){const e=p*c,h=r+Math.min(a-1,s?Math.round(e):Math.floor(e))*t.strides[1];for(let e=0;e<n;e++){const n=d*e,r=h+Math.min(i-1,s?Math.round(n):Math.floor(n))*t.strides[2];for(let t=0;t<o;t++){const e=l[r+t];u[f++]=e}}}}return Ss(u,[r,e,n,o],t.dtype)}resizeNearestNeighborBackprop(t,e,n){px([t,e],"resizeNearestNeighborBackprop");const[s,r,a,i]=e.shape,[,o,l]=t.shape,u=new Float32Array(s*r*a*i),c=this.readSync(t.dataId),h=[n&&o>1?r-1:r,n&&l>1?a-1:a],p=[n&&o>1?o-1:o,n&&l>1?l-1:l],d=h[0]/p[0],f=h[1]/p[1],m=1/d,g=1/f,y=2*Math.ceil(m)+2,b=2*Math.ceil(g)+2;for(let h=0;h<s;h++){const s=h*e.strides[0];for(let h=0;h<r;h++){const p=s+h*e.strides[1],x=Math.floor(h*m),w=Math.floor(x-y/2);for(let m=0;m<a;m++){const x=p+m*e.strides[2],v=Math.floor(m*g),k=Math.floor(v-b/2);for(let e=0;e<i;e++){let i=0;for(let u=0;u<y;u++){const p=u+w;if(p<0||p>=o)continue;const g=s+p*t.strides[1],y=p*d;if(h===Math.min(r-1,n?Math.round(y):Math.floor(y)))for(let s=0;s<b;s++){const r=s+k;if(r<0||r>=l)continue;const o=g+r*t.strides[2],u=r*f;m===Math.min(a-1,n?Math.round(u):Math.floor(u))&&(i+=c[o+e])}}u[x+e]=i}}}}return co(u,e.shape,e.dtype)}localResponseNormalization4D(t,e,n,s,r){px(t,"localResponseNormalization4D");const a=t.shape[3],i=a-1,o=this.readSync(t.dataId),l=t.size,u=new Float32Array(l);function c(t){const n=t%a;let s=t-n+Math.max(0,n-e);const r=t-n+Math.min(n+e,i);let l=0;for(;s<=r;s++){const t=o[s];l+=t*t}return l}for(let t=0;t<l;t++){const e=c(t),a=o[t]*Math.pow(n+s*e,-r);u[t]=a}return co(u,t.shape)}LRNGrad(t,e,n,s,r,a,i){px(t,"LRNGrad");const o=t.shape[3],l=this.readSync(t.dataId),u=this.readSync(e.dataId),c=this.readSync(n.dataId),h=new Float32Array(t.size),p=t.size;for(let t=0;t<p;t++){const e=t%o,n=t-e+Math.max(0,e-s),p=t-e+Math.min(o,e+s+1);let d=0;for(let t=n;t<p;t++)d+=Math.pow(u[t],2);d=a*d+r;for(let e=n;e<p;e++){let n=-2*a*i*u[e]*c[t]/d;t===e&&(n+=Math.pow(d,-i)),n*=l[t],h[e]+=n}}return co(h,t.shape)}multinomial(t,e,n,s){px(t,"multinomial");const r=e?t:eo(t),a=r.shape[0],i=r.shape[1],o=ki([a,n],"int32"),l=this.readSync(o.dataId),u=this.readSync(r.dataId);for(let t=0;t<a;++t){const e=t*i,r=new Float32Array(i-1);r[0]=u[e];for(let t=1;t<r.length;++t)r[t]=r[t-1]+u[e+t];const a=zi.alea(s.toString()),o=t*n;for(let t=0;t<n;++t){const e=a();l[o+t]=r.length;for(let n=0;n<r.length;n++)if(e<r[n]){l[o+t]=n;break}}}return o}oneHot(t,e,n,s){px(t,"oneHot");const r=new Float32Array(t.size*e);r.fill(s);const a=this.readSync(t.dataId);for(let s=0;s<t.size;++s)a[s]>=0&&a[s]<e&&(r[s*e+a[s]]=n);return uo(r,[t.size,e],"int32")}nonMaxSuppression(t,e,n,s,r){px(t,"nonMaxSuppression");const a=this.readSync(t.dataId),i=this.readSync(e.dataId);return dx(a,i,n,s,r)}depthToSpace(t,e,n){A("NHWC"===n,(()=>"Only NHWC dataFormat supported on CPU for depthToSpace. Got "+n)),A(e>1,(()=>"blockSize should be > 1 for depthToSpace, but was: "+e));const s=t.shape[0],r=t.shape[1],a=t.shape[2],i=t.shape[3],o=r*e,l=a*e,u=i/(e*e),c=this.readSync(t.dataId),h=new Float32Array(s*o*l*u);let p=0;for(let t=0;t<s;++t)for(let n=0;n<o;++n){const s=Math.floor(n/e),o=n%e;for(let n=0;n<l;++n){const l=Math.floor(n/e),d=(o*e+n%e)*u;for(let e=0;e<u;++e){const n=e+d+i*(l+a*(s+r*t));h[p++]=c[n]}}}return co(h,[s,o,l,u])}broadcastedBinaryOp(t,e,n,s){const r=Xa(t.shape,e.shape),a=ir(r,n),i=this.readSync(t.dataId),o=this.readSync(e.dataId),l=qa(t.shape,r),u=qa(e.shape,r),c=a.values;if(l.length+u.length===0)for(let t=0;t<c.length;++t)c[t]=s(i[t%i.length],o[t%o.length]);else{const n=this.bufferSync(t),r=this.bufferSync(e);for(let h=0;h<c.length;++h){const p=a.indexToLoc(h),d=p.slice(-t.rank);l.forEach((t=>d[t]=0));const f=n.locToIndex(d),m=p.slice(-e.rank);u.forEach((t=>m[t]=0));const g=r.locToIndex(m);c[h]=s(i[f],o[g])}}return a.toTensor()}split(t,e,n){return fx(t,e,n)}dispose(){}floatPrecision(){return 32}epsilon(){return super.epsilon()}cropAndResize(t,e,n,s,r,a){const[i,o,l,u]=t.shape,c=e.shape[0],[h,p]=s,d=ir([c,h,p,u],"float32"),f=this.readSync(e.dataId),m=this.readSync(n.dataId),g=this.readSync(t.dataId),y=t.strides,b=d.strides;for(let t=0;t<c;t++){const e=4*t,n=f[e],s=f[e+1],c=f[e+2],x=f[e+3],w=m[t];if(w>=i)continue;const v=h>1?(c-n)*(o-1)/(h-1):0,k=p>1?(x-s)*(l-1)/(p-1):0;for(let e=0;e<h;e++){const i=h>1?n*(o-1)+e*v:.5*(n+c)*(o-1);if(i<0||i>o-1)for(let n=0;n<p;n++)for(let s=0;s<u;s++){const r=s+n*b[2]+e*b[1]+t*b[0];d.values[r]=a}else if("bilinear"===r){const n=Math.floor(i),r=Math.ceil(i),o=i-n;for(let i=0;i<p;i++){const c=p>1?s*(l-1)+i*k:.5*(s+x)*(l-1);if(c<0||c>l-1){for(let n=0;n<u;n++){const s=n+i*b[2]+e*b[1]+t*b[0];d.values[s]=a}continue}const h=Math.floor(c),f=Math.ceil(c),m=c-h;for(let s=0;s<u;s++){let a=s+h*y[2]+n*y[1]+w*y[0];const l=g[a];a=s+f*y[2]+n*y[1]+w*y[0];const u=g[a];a=s+h*y[2]+r*y[1]+w*y[0];const c=g[a];a=s+f*y[2]+r*y[1]+w*y[0];const p=l+(u-l)*m,x=c+(g[a]-c)*m;a=s+i*b[2]+e*b[1]+t*b[0],d.values[a]=p+(x-p)*o}}}else for(let n=0;n<p;++n){const r=p>1?s*(l-1)+n*k:.5*(s+x)*(l-1);if(r<0||r>l-1){for(let s=0;s<u;s++){const r=s+n*b[2]+e*b[1]+t*b[0];d.values[r]=a}continue}const o=Math.round(r),c=Math.round(i);for(let s=0;s<u;s++){const r=s+o*y[2]+c*y[1]+w*y[0],a=s+n*b[2]+e*b[1]+t*b[0];d.values[a]=g[r]}}}}return d.toTensor()}sparseToDense(t,e,n,s){const{sliceRank:r,numUpdates:a,sliceSize:i,strides:o,outputSize:l}=Ml(0,t,n);return this.scatter(t,e,n,l,i,a,r,o,s,!1)}gatherND(t,e){const n=e.shape,s=n[n.length-1],[r,a,i,o]=Fl(t,e);if(0===a)return Ss([],r,t.dtype);const l=new qn([a,i],t.dtype),u=this.readSync(e.dataId),c=this.readSync(t.dataId);for(let e=0;e<a;e++){const n=[];let r=0;for(let t=0;t<s;t++){const a=u[e*s+t];r+=a*o[t],n.push(a)}if(r<0||r>=t.size/i)throw new Error(`Invalid indices: ${n} does not index into ${t.shape}`);for(let t=0;t<i;t++)l.values[e*i+t]=c[r*i+t]}return l.toTensor().reshape(r)}scatterND(t,e,n){const{sliceRank:s,numUpdates:r,sliceSize:a,strides:i,outputSize:o}=Ml(0,t,n),l=qr(0);return this.scatter(t,e,n,o,a,r,s,i,l,!0)}onesLike(t){if("string"===t.dtype)throw new Error("onesLike is not supported for string tensors");return ei(t.shape,1,t.dtype)}zerosLike(t){const e=G(t.dtype,_(t.shape));return this.makeOutput(e,t.shape,t.dtype)}linspace(t,e,n){return su(t,e,n)}scatter(t,e,n,s,r,a,i,o,l,u){const c=[s/r,r],h=this.readSync(t.dataId),p=this.readSync(e.dataId);if(0===s)return Ss([],n,e.dtype);const d=new qn(c,e.dtype);d.values.fill(this.readSync(l.dataId)[0]);for(let t=0;t<a;t++){const a=[];let l=0;for(let e=0;e<i;e++){const n=h[t*i+e];a.push(n),l+=n*o[e]}if(l<0||l>=s/r)throw new Error(`Invalid indices: ${a} does not index into ${n}`);for(let n=0;n<r;n++)u?d.values[l*r+n]+=p[t*r+n]:d.values[l*r+n]=0===e.rank?p[0]:p[t*r+n]}return d.toTensor().reshape(n)}}function xx(t,e,n){return({inputs:s,attrs:r,backend:a})=>{const{x:i}=s;if(px(i,t),"string"===i.dtype||"string"===n)throw new Error("unaryKernelFunc does not support string input/output");const o=a,l=o.data.get(i.dataId).values,u=_(i.shape),c=n||i.dtype,h=G(c,u);for(let t=0;t<u;++t)h[t]=e(l[t],r);return o.makeTensorInfo(i.shape,c,h)}}function wx(t,e,n){return({inputs:s,attrs:r,backend:a})=>{const{x:i}=s;if(px(i,t),"string"===i.dtype||"string"===n)throw new Error("unaryKernelFunc does not support string input/output");const o=a,l=o.data.get(i.dataId).values,u=n||i.dtype,c=e(l,u,r);return o.makeTensorInfo(i.shape,u,c)}}Hr("cpu",(()=>new bx),1);const vx=xx(te,(t=>t>=0?t:Math.exp(t)-1)),kx={kernelName:te,backendName:"cpu",kernelFunc:vx};function Nx(t){const{inputs:e,backend:n}=t,{x:s}=e;return n.incRef(s.dataId),{dataId:s.dataId,shape:s.shape,dtype:s.dtype}}const Ix={kernelName:pe,backendName:"cpu",kernelFunc:Nx};function Cx(t){return(e,n,s,r,a)=>{const i=Xa(e,n),o=i.length,l=Q(i),u=U(a,_(i)),c=e.length,h=n.length,p=Q(e),d=Q(n),f=qa(e,i),m=qa(n,i);if(f.length+m.length===0)for(let e=0;e<u.length;++e)u[e]=t(s[e%s.length],r[e%r.length]);else for(let e=0;e<u.length;++e){const n=ot(e,o,l),a=n.slice(-c);f.forEach((t=>a[t]=0));const i=it(a,c,p),g=n.slice(-h);m.forEach((t=>g[t]=0));const y=it(g,h,d);u[e]=t(s[i],r[y])}return[u,i]}}const Sx=Cx(((t,e)=>t<0?e*t:t));function Tx(t){const{inputs:e,backend:n}=t,{x:s,alpha:r}=e;px([s,r],"prelu");const a=n.data.get(s.dataId).values,i=n.data.get(r.dataId).values,[o,l]=Sx(s.shape,r.shape,a,i,s.dtype);return n.makeTensorInfo(l,s.dtype,o)}const $x={kernelName:Pe,backendName:"cpu",kernelFunc:Tx},Ex=xx(Ue,(t=>Math.max(0,t))),Ax={kernelName:Ue,backendName:"cpu",kernelFunc:Ex},Rx=xx(qe,(t=>Math.min(Math.max(0,t),6))),Dx={kernelName:qe,backendName:"cpu",kernelFunc:Rx};function Fx(t,e,n,s){if("linear"===n)return Nx({inputs:{x:e},backend:t});if("relu"===n)return Ex({inputs:{x:e},backend:t});if("elu"===n)return vx({inputs:{x:e},backend:t});if("relu6"===n)return Rx({inputs:{x:e},backend:t});if("prelu"===n)return Tx({inputs:{x:e,alpha:s},backend:t});throw new Error(`Activation ${n} has not been implemented for the CPU backend.`)}function _x(t){const{inputs:e,backend:n}=t,{real:s,imag:r}=e,a=n.data.get(s.dataId).values,i=n.data.get(r.dataId).values,o=n.makeTensorInfo(s.shape,"complex64");return n.data.get(o.dataId).complexTensorInfos={real:n.makeTensorInfo(s.shape,"float32",a),imag:n.makeTensorInfo(r.shape,"float32",i)},o}const Ox={kernelName:Mt,backendName:"cpu",kernelFunc:_x};function Mx(t){const{inputs:e,backend:n}=t,{input:s}=e,r=n.data.get(s.dataId).complexTensorInfos.real,a=n.data.get(r.dataId).values;return n.makeTensorInfo(r.shape,r.dtype,a)}const Lx={kernelName:We,backendName:"cpu",kernelFunc:Mx};function zx(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{dtype:a}=s;if("complex64"===a){if("complex64"===r.dtype)return Nx({inputs:{x:r},backend:n});const t=ki(r.shape),e=zx({inputs:{x:r},backend:n,attrs:{dtype:"float32"}}),s=_x({inputs:{real:e,imag:t},backend:n});return t.dispose(),n.disposeIntermediateTensorInfo(e),s}if("complex64"===r.dtype){const t=Mx({inputs:{input:r},backend:n}),e=zx({inputs:{x:t},backend:n,attrs:{dtype:a}});return n.disposeIntermediateTensorInfo(t),e}if(!H(r.dtype,a)){const t=Nx({inputs:{x:r},backend:n});return{dataId:t.dataId,shape:t.shape,dtype:a}}if("int32"===a){const t=n.data.get(r.dataId).values,e=Int32Array.from(t);return n.makeTensorInfo(r.shape,"int32",e)}if("bool"===a){const t=n.data.get(r.dataId).values,e=Un([0],r.dtype),[s,a]=Cx(((t,e)=>t!==e?1:0))(r.shape,[],t,e,"bool");return n.makeTensorInfo(a,"bool",s)}throw new Error(`Error in Cast: failed to cast ${r.dtype} to ${a}`)}const Bx={kernelName:Ft,backendName:"cpu",kernelFunc:zx};function Px(t,e,n,s){return null==n?({inputs:n,backend:r})=>{const{a,b:i}=n,o=r;px([a,i],t);const l=o.data.get(a.dataId).values,u=o.data.get(i.dataId).values,c=s||a.dtype,[h,p]=e(a.shape,i.shape,l,u,c);return o.makeTensorInfo(p,c,h)}:({inputs:t,backend:r})=>{const{a,b:i}=t,o=r;if("complex64"===a.dtype||"complex64"===i.dtype){const t=zx({inputs:{x:a},backend:o,attrs:{dtype:"complex64"}}),e=o.data.get(t.dataId),s=e.complexTensorInfos.real,r=e.complexTensorInfos.imag,l=o.data.get(s.dataId).values,u=o.data.get(r.dataId).values,c=zx({inputs:{x:i},backend:o,attrs:{dtype:"complex64"}}),h=o.data.get(c.dataId),p=h.complexTensorInfos.real,d=h.complexTensorInfos.imag,f=o.data.get(p.dataId).values,m=o.data.get(d.dataId).values,[g,y,b]=n(a.shape,i.shape,l,u,f,m),x=o.makeTensorInfo(b,"float32",g),w=o.makeTensorInfo(b,"float32",y),v=_x({inputs:{real:x,imag:w},backend:o});return o.disposeIntermediateTensorInfo(t),o.disposeIntermediateTensorInfo(c),o.disposeIntermediateTensorInfo(x),o.disposeIntermediateTensorInfo(w),v}{const t=o.data.get(a.dataId).values,n=o.data.get(i.dataId).values,r=s||a.dtype,[l,u]=e(a.shape,i.shape,t,n,r);return o.makeTensorInfo(u,r,l)}}}function Wx(t){return(e,n,s,r,a,i)=>{const o=Xa(e,n),l=_(o),u=o.length,c=Q(o),h=U("float32",l),p=U("float32",l),d=qa(e,o),f=qa(n,o),m=ql(s,r),g=ql(a,i),y=e.length,b=Q(e),x=n.length,w=Q(n);if(d.length+f.length===0)for(let e=0;e<h.length;e++){const n=e%m.length,s=e%g.length,r=t(m[2*n],m[2*n+1],g[2*s],g[2*s+1]);h[e]=r.real,p[e]=r.imag}else for(let e=0;e<h.length;e++){const n=ot(e,u,c),s=n.slice(-y);d.forEach((t=>s[t]=0));const r=it(s,y,b),a=n.slice(-x);f.forEach((t=>a[t]=0));const i=it(a,x,w),o=t(m[2*r],m[2*r+1],g[2*i],g[2*i+1]);h[e]=o.real,p[e]=o.imag}return[h,p,o]}}const Vx=Cx(((t,e)=>t+e)),Ux=Wx(((t,e,n,s)=>({real:t+n,imag:e+s}))),Gx=Px(bt,Vx,Ux),Hx={kernelName:bt,backendName:"cpu",kernelFunc:Gx};function jx(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{shape:a}=s,i=_(r.shape),o=P(a,i),l=_(o);A(i===l,(()=>`The new shape (${o}) has ${l} elements and the old shape (${r.shape}) has ${i} elements. The new shape and old shape must have the same number of elements.`)),n.incRef(r.dataId);const u=n.data.get(r.dataId);if(null!=u.complexTensorInfos){const t=u.complexTensorInfos.real,e=u.complexTensorInfos.imag;t.shape=o,e.shape=o}return{dataId:r.dataId,shape:o,dtype:r.dtype}}const qx={kernelName:Ge,backendName:"cpu",kernelFunc:jx};function Kx(t){const{inputs:e,backend:n,attrs:s}=t,{a:r,b:a}=e,{transposeA:i,transposeB:o}=s;px([r,a],"matMul");const l=r.shape.length,u=a.shape.length,c=i?r.shape[l-2]:r.shape[l-1],h=o?a.shape[u-1]:a.shape[u-2],p=i?r.shape[l-1]:r.shape[l-2],d=o?a.shape[u-2]:a.shape[u-1],f=r.shape.slice(0,-2),m=a.shape.slice(0,-2),g=_(f),y=_(m);A(l>=2&&u>=2&&(g===y||1===g||1===y),(()=>`Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (${f}) and (${m}).`));const b=(g>y?r.shape.slice(0,-2):a.shape.slice(0,-2)).concat([p,d]);A(c===h,(()=>`Error in matMul: inner shapes (${c}) and (${h}) of Tensors with shapes ${r.shape} and ${a.shape} and transposeA=${i} and transposeB=${o} must match.`));const x=o?[y,d,h]:[y,h,d],w=jx({inputs:{x:r},backend:n,attrs:{shape:i?[g,c,p]:[g,p,c]}}),v=jx({inputs:{x:a},backend:n,attrs:{shape:x}}),k=i?w.shape[1]:w.shape[2],N=i?w.shape[2]:w.shape[1],I=o?v.shape[1]:v.shape[2],C=Math.max(g,y),S=n.data.get(w.dataId).values,T=n.data.get(v.dataId).values,$=Q(w.shape),E=Q(v.shape),[R,D,F]=i?[$[0],1,$[1]]:[$[0],$[1],1],[O,M,L]=o?[1,E[1],E[0]]:[E[1],1,E[0]],z=N*I,B=ir([C,N,I],w.dtype),P=B.values,W=n.blockSize;for(let t=0;t<C;t++)for(let e=0;e<N;e+=W)for(let n=0;n<I;n+=W)for(let s=0;s<k;s+=W){const r=Math.min(e+W,N),a=Math.min(n+W,I),i=Math.min(s+W,k);for(let o=e;o<r;o++)for(let e=n;e<a;e++){let n=0;for(let r=s;r<i;r++){const s=Math.min(t,g-1)*R,a=Math.min(t,y-1)*L;n+=S[s+o*D+r*F]*T[r*O+e*M+a]}P[t*z+(o*I+e)]+=n}}return n.disposeIntermediateTensorInfo(w),n.disposeIntermediateTensorInfo(v),n.makeTensorInfo(b,B.dtype,B.values)}const Xx={kernelName:At,backendName:"cpu",kernelFunc:Kx},Yx={kernelName:In,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{a:r,b:a,bias:i,preluActivationWeights:o}=e,{transposeA:l,transposeB:u,activation:c}=s;let h,p,d;const f=[];h=Kx({inputs:{a:r,b:a},attrs:{transposeA:l,transposeB:u},backend:n}),i&&(p=Gx({inputs:{a:h,b:i},backend:n}),f.push(h),h=p),c&&(d=Fx(n,h,c,o),f.push(h),h=d);for(const t of f)n.disposeIntermediateTensorInfo(t);return h}};function Jx(t){const e=new Float32Array(t.length);for(let n=0;n<t.length;++n)e[n]=Math.abs(t[n]);return e}const Zx={kernelName:mt,backendName:"cpu",kernelFunc:t=>{const{x:e}=t.inputs,n=t.backend;let s=new Float32Array(_(e.shape));if("complex64"!==e.dtype)s=Jx(n.data.get(e.dataId).values);else{const t=n.data.get(e.dataId),r=t.complexTensorInfos.real,a=t.complexTensorInfos.imag,i=n.data.get(r.dataId).values,o=n.data.get(a.dataId).values;for(let t=0;t<i.length;t++){const e=i[t],n=o[t];s[t]=Math.hypot(e,n)}}return n.makeOutput(s,e.shape,"float32")}},Qx=xx(gt,(t=>Math.acos(t))),tw={kernelName:gt,backendName:"cpu",kernelFunc:Qx},ew=xx(yt,(t=>Math.acosh(t))),nw={kernelName:yt,backendName:"cpu",kernelFunc:ew},sw=xx(kt,(t=>Math.asin(t))),rw={kernelName:kt,backendName:"cpu",kernelFunc:sw},aw=xx(Nt,(t=>Math.asinh(t))),iw={kernelName:Nt,backendName:"cpu",kernelFunc:aw},ow=xx(It,(t=>Math.atan(t))),lw={kernelName:It,backendName:"cpu",kernelFunc:ow},uw=xx(Ct,(t=>Math.atanh(t))),cw={kernelName:Ct,backendName:"cpu",kernelFunc:uw};function hw(t,e,n,s,r,a){const i=r.strideHeight,o=r.strideWidth,l=r.dilationHeight,u=r.dilationWidth,c=r.effectiveFilterHeight,h=r.effectiveFilterWidth,p=r.padInfo.top,d=r.padInfo.left,f="max"===a?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,m=ir(r.outShape,n),g=m.values,y=r.outShape[1]*r.outShape[2]*r.outShape[3],b=r.outShape[2]*r.outShape[3],x=r.outShape[3];for(let e=0;e<r.batchSize;++e){const n=e*y,m=e*s[0];for(let e=0;e<r.inChannels;++e)for(let y=0;y<r.outHeight;++y){const w=y*i-p,v=Math.max(0,w),k=Math.min(r.inHeight,c+w),N=n+y*b;for(let n=0;n<r.outWidth;++n){const i=n*o-d,c=Math.max(0,i),p=Math.min(r.inWidth,h+i);let y=f,b=0,w=0;for(let n=v;n<k;n+=l){const r=m+n*s[1];for(let n=c;n<p;n+=u){const i=t[r+n*s[2]+e];"max"===a&&i>y?y=i:"avg"===a&&(b+=i,w++)}if(isNaN(y))break}g[N+n*x+e]="avg"===a?b/w:y}}}return m}function pw(t,e,n,s,r=!1,a=!1){const i=ir(s.outShape,"int32"),o=s.strideHeight,l=s.strideWidth,u=s.dilationHeight,c=s.dilationWidth,h=s.effectiveFilterHeight,p=s.effectiveFilterWidth,d=s.padInfo.top,f=s.padInfo.left,m=ir(e,n,t);for(let t=0;t<s.batchSize;++t)for(let e=0;e<s.inChannels;++e)for(let n=0;n<s.outHeight;++n){const g=n*o-d;let y=g;for(;y<0;)y+=u;const b=Math.min(s.inHeight,h+g);for(let o=0;o<s.outWidth;++o){const h=o*l-f;let d=h;for(;d<0;)d+=c;const x=Math.min(s.inWidth,p+h);let w=Number.NEGATIVE_INFINITY,v=-1;for(let n=y;n<b;n+=u){const i=n-g;for(let o=d;o<x;o+=c){const l=o-h,u=m.get(t,n,o,e);u>w&&(w=u,v=r?a?((t*s.inHeight+n)*s.inWidth+o)*s.inChannels+e:(n*s.inWidth+o)*s.inChannels+e:i*p+l)}}i.set(v,t,n,o,e)}}return i}const dw={kernelName:Tt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e;px(r,"avgPool");const{filterSize:a,strides:i,pad:o,dimRoundingMode:l}=s;A(va(i,1),(()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`));const u=ha(r.shape,a,i,1,o,l);let c;if(1===u.filterWidth&&1===u.filterHeight&&O(u.inShape,u.outShape))c=Nx({inputs:{x:r},backend:n});else{const t=n.data.get(r.dataId).values,e=Q(r.shape),s=hw(t,r.shape,r.dtype,e,u,"avg");c=n.makeTensorInfo(u.outShape,r.dtype,s.values)}return c}},fw={kernelName:$t,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{dy:r,input:a}=e,i=a;px([r,a],"avgPoolBackprop");const{filterSize:o,strides:l,pad:u}=s,c=ha(i.shape,o,l,1,u),h=c.strideHeight,p=c.strideWidth,d=c.filterHeight,f=c.filterWidth,m=c.dilationHeight,g=c.dilationWidth,y=c.effectiveFilterHeight,b=c.effectiveFilterWidth,x=b-1-c.padInfo.left,w=y-1-c.padInfo.top,v=ir(i.shape,"float32"),k=1/(d*f),N=n.data.get(r.dataId).values,I=ir(r.shape,"float32",N);for(let t=0;t<c.batchSize;++t)for(let e=0;e<c.inChannels;++e)for(let n=0;n<c.inHeight;++n)for(let s=0;s<c.inWidth;++s){const r=n-w,a=s-x;let i=0;for(let n=0;n<y;n+=m){const s=(r+n)/h;if(!(s<0||s>=c.outHeight||Math.floor(s)!==s))for(let n=0;n<b;n+=g){const r=(a+n)/p;r<0||r>=c.outWidth||Math.floor(r)!==r||(i+=I.get(t,s,r,e))}}v.set(i*k,t,n,s,e)}return n.makeTensorInfo(v.shape,v.dtype,v.values)}},mw={kernelName:ue,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,scale:a,offset:i,mean:o,variance:l}=e;A(o.shape.length===l.shape.length,(()=>"Batch normalization gradient requires mean and variance to have equal ranks.")),A(null==i||o.shape.length===i.shape.length,(()=>"Batch normalization gradient requires mean and offset to have equal ranks.")),A(null==a||o.shape.length===a.shape.length,(()=>"Batch normalization gradient requires mean and scale to have equal ranks.")),px([r,o,l,a,i],"batchNorm");let{varianceEpsilon:u}=s;null==u&&(u=.001);const c=n.data.get(r.dataId).values,h=n.data.get(o.dataId).values,p=n.data.get(l.dataId).values,d=a?n.data.get(a.dataId).values:new Float32Array([1]),f=i?n.data.get(i.dataId).values:new Float32Array([0]),m=new Float32Array(c.length),g=f.length,y=d.length,b=p.length,x=h.length;let w=0,v=0,k=0,N=0;for(let t=0;t<c.length;++t)m[t]=f[w++]+(c[t]-h[v++])*d[k++]/Math.sqrt(p[N++]+u),w>=g&&(w=0),v>=x&&(v=0),k>=y&&(k=0),N>=b&&(N=0);return n.makeTensorInfo(r.shape,r.dtype,m)}};function gw(t){return(e,n,s)=>{const r=U(n,e.length);for(let n=0;n<e.length;++n)r[n]=t(e[n],s);return r}}const yw=gw((t=>Math.ceil(t))),bw=wx(_t,yw),xw={kernelName:_t,backendName:"cpu",kernelFunc:bw},ww=xx(Ot,((t,e)=>{const n=e;return t>n.clipValueMax?n.clipValueMax:t<n.clipValueMin?n.clipValueMin:t})),vw={kernelName:Ot,backendName:"cpu",kernelFunc:ww};function kw(t){const{inputs:e,backend:n}=t,{input:s}=e,r=n.data.get(s.dataId).complexTensorInfos.imag,a=n.data.get(r.dataId).values;return n.makeTensorInfo(r.shape,r.dtype,a)}const Nw={kernelName:fe,backendName:"cpu",kernelFunc:kw};function Iw(t){const{inputs:e,backend:n,attrs:s}=t,{axis:r}=s,a=W(r,e[0].shape)[0];let i=Da(e.map((t=>t.shape)),a);if(0===_(i))return n.makeTensorInfo(i,e[0].dtype,[]);const o=e.filter((t=>_(t.shape)>0));if(1===o.length)return o[0];if(Ra(o.map((t=>t.shape)),a),"complex64"===o[0].dtype){const t=o.map((t=>Mx({inputs:{input:t},backend:n}))),e=o.map((t=>kw({inputs:{input:t},backend:n}))),s=Iw({inputs:t,backend:n,attrs:{axis:a}}),r=Iw({inputs:e,backend:n,attrs:{axis:a}}),i=_x({inputs:{real:s,imag:r},backend:n});return t.forEach((t=>n.disposeIntermediateTensorInfo(t))),e.forEach((t=>n.disposeIntermediateTensorInfo(t))),n.disposeIntermediateTensorInfo(s),n.disposeIntermediateTensorInfo(r),i}const l=o.map((t=>{const e=_(t.shape.slice(a));return jx({inputs:{x:t},backend:n,attrs:{shape:[-1,e]}})}));i=Da(l.map((t=>t.shape)),1);const u=U(o[0].dtype,_(i));if(1===l[0].shape[0]){let t=0;l.forEach((e=>{const s=n.data.get(e.dataId).values,r=_(e.shape);u.set(s,t),t+=r}))}else{let t=0;l.forEach((e=>{const s=n.data.get(e.dataId).values;let r=0;for(let n=0;n<e.shape[0];++n){const a=n*i[1]+t;for(let t=0;t<e.shape[1];++t)u[a+t]=s[r++]}t+=e.shape[1]}))}const c=Da(o.map((t=>t.shape)),a),h=n.makeTensorInfo(c,e[0].dtype,u);return l.forEach((t=>n.disposeIntermediateTensorInfo(t))),h}const Cw={kernelName:Lt,backendName:"cpu",kernelFunc:Iw};function Sw(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,filter:a}=e,{strides:i,pad:o,dataFormat:l,dilations:u,dimRoundingMode:c}=s;px([r,a],"conv2d");const h=ka(l),p=da(r.shape,a.shape,i,u,o,c,!1,h),d=p.filterHeight,f=p.filterWidth,m=p.dilationHeight,g=p.dilationWidth,y=p.padInfo.left,b=p.padInfo.top,x="channelsLast"===p.dataFormat,w=new qn(p.outShape,r.dtype),v=Q(r.shape),k=Q(a.shape),N=v[0],I=x?v[1]:v[2],C=x?v[2]:1,S=x?1:v[1],T=w.strides[0],$=x?w.strides[1]:w.strides[2],E=x?w.strides[2]:1,A=x?1:w.strides[1],R=n.data.get(r.dataId).values,D=n.data.get(a.dataId).values,F=w.values;for(let t=0;t<p.batchSize;++t){const e=t*N,n=t*T;for(let t=0;t<p.outHeight;++t){const s=n+t*$,r=t*p.strideHeight-b;for(let t=0;t<d;++t){const n=r+t*m;if(n<0||n>=p.inHeight)continue;const a=t*k[0],i=e+n*I;for(let t=0;t<p.outWidth;++t){const e=s+t*E,n=t*p.strideWidth-y;for(let t=0;t<f;++t){const s=n+t*g;if(s<0||s>=p.inWidth)continue;const r=i+s*C;let o=a+t*k[1];for(let t=0;t<p.inChannels;++t){const n=R[r+t*S];for(let t=0;t<p.outChannels;++t)F[e+t*A]+=n*D[o+t];o+=p.outChannels}}}}}}return n.makeTensorInfo(w.shape,w.dtype,F)}const Tw={kernelName:zt,backendName:"cpu",kernelFunc:Sw},$w={kernelName:Bt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,dy:a}=e,{strides:i,pad:o,dataFormat:l,dimRoundingMode:u,filterShape:c}=s;px([r,a],"conv2dBackpropFilter");const h=ka(l),p=da(r.shape,c,i,1,o,u,!1,h),{strideHeight:d,strideWidth:f,filterHeight:m,filterWidth:g}=p,y="channelsLast"===p.dataFormat,b=new qn(p.filterShape,"float32"),x=p.padInfo.left,w=p.padInfo.top,v=n.data.get(r.dataId).values,k=n.data.get(a.dataId).values,N=new qn(r.shape,r.dtype,v),I=new qn(a.shape,a.dtype,k);for(let t=0;t<m;++t){const e=Math.max(0,Math.ceil((w-t)/d)),n=Math.min(p.outHeight,(p.inHeight+w-t)/d);for(let s=0;s<g;++s){const r=Math.max(0,Math.ceil((x-s)/f)),a=Math.min(p.outWidth,(p.inWidth+x-s)/f);for(let i=0;i<p.inChannels;++i)for(let o=0;o<p.outChannels;++o){let l=0;for(let u=0;u<p.batchSize;++u)for(let c=e;c<n;++c){const e=t+c*d-w;for(let t=r;t<a;++t){const n=s+t*f-x;l+=y?N.get(u,e,n,i)*I.get(u,c,t,o):N.get(u,i,e,n)*I.get(u,o,c,t)}}b.set(l,t,s,i,o)}}}return n.makeTensorInfo(b.shape,b.dtype,b.values)}},Ew={kernelName:Pt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{dy:r,filter:a}=e,{inputShape:i,strides:o,pad:l,dataFormat:u,dimRoundingMode:c}=s;px([r,a],"conv2dBackpropInput");const h=Q(a.shape),p=Q(r.shape);let d=ka(u);const f=da(i,a.shape,o,1,l,c,!1,d),m=new qn(f.inShape,"float32"),g=m.values,y=n.data.get(r.dataId).values,b=n.data.get(a.dataId).values,[x,w,v]=h,{batchSize:k,filterHeight:N,filterWidth:I,inChannels:C,inHeight:S,inWidth:T,outChannels:$,outHeight:E,outWidth:A,strideHeight:R,strideWidth:D}=f;d=f.dataFormat;const F=N-1-f.padInfo.top,_=I-1-f.padInfo.left,O="channelsLast"===d,M=m.strides[0],L=O?m.strides[1]:m.strides[2],z=O?m.strides[2]:1,B=O?1:m.strides[1],P=p[0],W=O?p[1]:p[2],V=O?p[2]:1,U=O?1:p[1];for(let t=0;t<k;++t)for(let e=0;e<C;++e)for(let n=0;n<S;++n){const s=n-F,r=Math.max(0,Math.ceil(s/R)),a=Math.min(E,(N+s)/R);for(let i=0;i<T;++i){const o=i-_,l=Math.max(0,Math.ceil(o/D)),u=Math.min(A,(I+o)/D);let c=0;for(let n=r;n<a;++n){const r=n*R-s;for(let s=l;s<u;++s){const a=P*t+W*n+V*s,i=x*(N-1-r)+w*(I-1-(s*D-o))+v*e;for(let t=0;t<$;++t)c+=y[a+U*t]*b[i+t]}}g[M*t+L*n+z*i+B*e]=c}}return n.makeTensorInfo(m.shape,m.dtype,m.values)}},Aw={kernelName:Wt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,filter:a}=e,{strides:i,pad:o,dilations:l}=s;px([r,a],"conv3d");const u=fa(r.shape,a.shape,i,l,o),{filterDepth:c,filterHeight:h,filterWidth:p,dilationDepth:d,dilationHeight:f,dilationWidth:m,padInfo:g}=u,y=g.front,b=g.left,x=g.top,w=new qn(u.outShape,r.dtype),v=n.data.get(r.dataId).values,k=n.data.get(a.dataId).values,N=w.values,I=Q(r.shape),C=Q(a.shape);for(let t=0;t<u.batchSize;++t){const e=t*I[0],n=t*w.strides[0];for(let t=0;t<u.outDepth;++t){const s=n+t*w.strides[1],r=t*u.strideDepth-y;for(let t=0;t<c;++t){const n=r+t*d;if(n<0||n>=u.inDepth)continue;const a=t*C[0],i=e+n*I[1];for(let t=0;t<u.outHeight;++t){const e=s+t*w.strides[2],n=t*u.strideHeight-x;for(let t=0;t<h;++t){const s=n+t*f;if(s<0||s>=u.inHeight)continue;const r=a+t*C[1],o=i+s*I[2];for(let t=0;t<u.outWidth;++t){const n=e+t*u.outChannels,s=t*u.strideWidth-b;for(let t=0;t<p;++t){const e=s+t*m;if(e<0||e>=u.inWidth)continue;const a=r+t*C[2],i=o+e*u.inChannels;let l=a;for(let t=0;t<u.inChannels;++t){const e=v[i+t];for(let t=0;t<u.outChannels;++t)N[n+t]+=e*k[l+t];l+=u.outChannels}}}}}}}}return n.makeTensorInfo(w.shape,w.dtype,w.values)}},Rw={kernelName:Vt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,dy:a}=e,{strides:i,pad:o,filterShape:l}=s;px([r,a],"conv3dBackpropFilterV2");const u=Q(r.shape),c=Q(a.shape),h=fa(r.shape,l,i,1,o),p=h.strideDepth,d=h.strideHeight,f=h.strideWidth,m=h.filterDepth,g=h.filterHeight,y=h.filterWidth,b=new qn(h.filterShape,"float32"),x=b.values,[w,v,k,N]=b.strides,I=n.data.get(a.dataId).values,[C,S,T,$]=c,E=n.data.get(r.dataId).values,[A,R,D,F]=u,_=h.padInfo.front,O=h.padInfo.left,M=h.padInfo.top;for(let t=0;t<m;++t){const e=Math.max(0,Math.ceil((_-t)/p)),n=Math.min(h.outDepth,(h.inDepth+_-t)/p),s=t*w;for(let r=0;r<g;++r){const a=Math.max(0,Math.ceil((M-r)/d)),i=Math.min(h.outHeight,(h.inHeight+M-r)/d),o=r*v+s;for(let s=0;s<y;++s){const l=Math.max(0,Math.ceil((O-s)/f)),u=Math.min(h.outWidth,(h.inWidth+O-s)/f),c=s*k+o;for(let o=0;o<h.inChannels;++o){const m=o*N+c;for(let c=0;c<h.outChannels;++c){let g=0;for(let m=0;m<h.batchSize;++m){const h=m*A,y=m*C;for(let m=e;m<n;++m){const e=(t+m*p-_)*R+h,n=m*S+y;for(let t=a;t<i;++t){const a=(r+t*d-M)*D+e,i=t*T+n;for(let t=l;t<u;++t){const e=t*$+i;g+=E[(s+t*f-O)*F+a+o]*I[e+c]}}}}x[m+c]=g}}}}}return n.makeTensorInfo(b.shape,b.dtype,b.values)}},Dw={kernelName:Ut,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{dy:r,filter:a}=e,{pad:i,strides:o,inputShape:l}=s;px([r],"conv3dBackpropInputV2");const u=Q(r.shape),c=Q(a.shape),h=fa(l,a.shape,o,1,i),p=new qn(h.inShape,"float32"),d=p.values,[f,m,g,y]=p.strides,b=n.data.get(r.dataId).values,[x,w,v,k]=u,N=n.data.get(a.dataId).values,[I,C,S,T]=c,{batchSize:$,filterDepth:E,filterHeight:A,filterWidth:R,inChannels:D,inDepth:F,inHeight:_,inWidth:O,outChannels:M,outDepth:L,outHeight:z,outWidth:B,strideDepth:P,strideHeight:W,strideWidth:V}=h,U=E-1-h.padInfo.front,G=A-1-h.padInfo.top,H=R-1-h.padInfo.left;for(let t=0;t<$;++t)for(let e=0;e<D;++e)for(let n=0;n<F;++n){const s=n-U,r=Math.max(0,Math.ceil(s/P)),a=Math.min(L,(E+s)/P);for(let i=0;i<_;++i){const o=i-G,l=Math.max(0,Math.ceil(o/W)),u=Math.min(z,(A+o)/W);for(let c=0;c<O;++c){const h=c-H,p=Math.max(0,Math.ceil(h/V)),$=Math.min(B,(R+h)/V);let D=0;for(let n=r;n<a;++n){const r=n*P-s;for(let s=l;s<u;++s){const a=s*W-o;for(let i=p;i<$;++i){const o=x*t+w*n+v*s+k*i,l=I*(E-1-r)+C*(A-1-a)+S*(R-1-(i*V-h))+T*e;for(let t=0;t<M;++t)D+=b[o+t]*N[l+t]}}}d[f*t+m*n+g*i+y*c+e]=D}}}return n.makeTensorInfo(p.shape,p.dtype,p.values)}},Fw=xx(Gt,(t=>Math.cos(t))),_w={kernelName:Gt,backendName:"cpu",kernelFunc:Fw},Ow=xx(Ht,(t=>Math.cosh(t))),Mw={kernelName:Ht,backendName:"cpu",kernelFunc:Ow};function Lw(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,filter:a}=e,{strides:i,pad:o,dilations:l,dimRoundingMode:u}=s;px([r,a],"depthwiseConv2DNative");const c=Q(r.shape),h=Q(a.shape);let p=l;null==p&&(p=[1,1]),A(va(i,p),(()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${i} and dilations '${p}'`));const d=da(r.shape,a.shape,i,p,o,u,!0),{filterHeight:f,filterWidth:m,dilationHeight:g,dilationWidth:y,padInfo:b}=d,x=b.left,w=b.top,v=d.outChannels/d.inChannels,k=new qn(d.outShape,r.dtype),N=n.data.get(r.dataId).values,I=n.data.get(a.dataId).values,C=k.values;for(let t=0;t<d.batchSize;++t){const e=t*c[0],n=t*k.strides[0];for(let t=0;t<d.outHeight;++t){const s=n+t*k.strides[1],r=t*d.strideHeight-x;for(let t=0;t<f;++t){const n=r+t*g;if(n<0||n>=d.inHeight)continue;const a=t*h[0],i=e+n*c[1];for(let t=0;t<d.outWidth;++t){const e=s+t*k.strides[2],n=t*d.strideWidth-w;for(let t=0;t<m;++t){const s=n+t*y;if(s<0||s>=d.inWidth)continue;const r=a+t*h[1],o=i+s*d.inChannels;let l=e,u=r;for(let t=0;t<d.inChannels;++t){const e=N[o+t];for(let t=0;t<v;++t)C[l+t]+=e*I[u+t];l+=v,u+=v}}}}}}return n.makeTensorInfo(k.shape,k.dtype,k.values)}const zw={kernelName:qt,backendName:"cpu",kernelFunc:Lw},Bw={kernelName:Kt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,dy:a}=e,{strides:i,dilations:o,pad:l,dimRoundingMode:u,filterShape:c}=s;px([r,a],"depthwiseConv2dNativeBackpropFilter");const h=da(r.shape,c,i,o,l,u,!0),{strideHeight:p,strideWidth:d,filterHeight:f,filterWidth:m}=h,g=new qn(h.filterShape,"float32"),y=h.padInfo.left,b=h.padInfo.top,x=h.outChannels/h.inChannels,w=n.data.get(r.dataId).values,v=new qn(r.shape,r.dtype,w),k=n.data.get(a.dataId).values,N=new qn(a.shape,a.dtype,k);for(let t=0;t<f;++t){const e=Math.max(0,Math.ceil((b-t)/p)),n=Math.min(h.outHeight,(h.inHeight+b-t)/p);for(let s=0;s<m;++s){const r=Math.max(0,Math.ceil((y-s)/d)),a=Math.min(h.outWidth,(h.inWidth+y-s)/d);for(let i=0;i<h.outChannels;++i){const o=Math.trunc(i/x),l=i%x;let u=0;for(let l=0;l<h.batchSize;++l)for(let c=e;c<n;++c){const e=t+c*p-b;for(let t=r;t<a;++t){const n=s+t*d-y;u+=v.get(l,e,n,o)*N.get(l,c,t,i)}}g.set(u,t,s,o,l)}}}return n.makeTensorInfo(g.shape,g.dtype,g.values)}},Pw={kernelName:Xt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{dy:r,filter:a}=e,{strides:i,dilations:o,pad:l,dimRoundingMode:u,inputShape:c}=s;px([r,a],"depthwiseConv2DNativeBackpropInput");const h=Q(r.shape),p=Q(a.shape),d=da(c,a.shape,i,o,l,u,!0),f=new qn(d.inShape,"float32"),m=f.values,[g,y,b]=f.strides,x=n.data.get(r.dataId).values,[w,v,k]=h,N=n.data.get(a.dataId).values,[I,C,S]=p,{batchSize:T,filterHeight:$,filterWidth:E,inChannels:A,inHeight:R,inWidth:D,outChannels:F,outHeight:_,outWidth:O,strideHeight:M,strideWidth:L}=d,z=$-1-d.padInfo.top,B=E-1-d.padInfo.left,P=F/A;for(let t=0;t<T;++t)for(let e=0;e<A;++e)for(let n=0;n<R;++n){const s=n-z,r=Math.max(0,Math.ceil(s/M)),a=Math.min(_,($+s)/M);for(let i=0;i<D;++i){const o=i-B,l=Math.max(0,Math.ceil(o/L)),u=Math.min(O,(E+o)/L);let c=0;for(let n=r;n<a;++n){const r=n*M-s;for(let s=l;s<u;++s){const a=w*t+v*n+k*s,i=I*($-1-r)+C*(E-1-(s*L-o))+S*e;for(let t=0;t<P;++t)c+=x[a+(e*P+t)]*N[i+t]}}m[g*t+y*n+b*i+e]=c}}return n.makeTensorInfo(f.shape,f.dtype,f.values)}},Ww={kernelName:Yt,backendName:"cpu",kernelFunc:({inputs:t,backend:e,attrs:n})=>{const{x:s,filter:r}=t,{strides:a,pad:i,dilations:o}=n,l=e,u=l.data.get(s.dataId).values,c=s.shape.length,h=l.data.get(r.dataId).values,p=r.shape.length,{batchSize:d,inHeight:f,inWidth:m,inChannels:g,outHeight:y,outWidth:b,padInfo:x,strideHeight:w,strideWidth:v,filterHeight:k,filterWidth:N,dilationHeight:I,dilationWidth:C,outShape:S}=ca(s.shape,r.shape,a,i,"NHWC",o),T=_(S),$=S.length,E=G(s.dtype,T);for(let t=0;t<d;++t)for(let e=0;e<y;++e){const n=e*w-x.top;for(let a=0;a<b;++a){const i=a*v-x.left;for(let o=0;o<g;++o){let l=Number.MIN_SAFE_INTEGER;for(let e=0;e<k;++e){const a=n+e*I;if(a>=0&&a<f)for(let n=0;n<N;++n){const d=i+n*C;if(d>=0&&d<m){const i=it([t,a,d,o],c,Q(s.shape)),f=it([e,n,o],p,Q(r.shape)),m=u[i]+h[f];m>l&&(l=m)}}}E[it([t,e,a,o],$,Q(S))]=l}}}return{dataId:l.write(Un(E,s.dtype),S,s.dtype),shape:S,dtype:s.dtype}}},Vw={kernelName:Zt,backendName:"cpu",kernelFunc:({inputs:t,backend:e,attrs:n})=>{const{x:s,filter:r,dy:a}=t,{strides:i,pad:o,dilations:l}=n,u=e,c=et(s.shape,u.data.get(s.dataId).values),h=et(r.shape,u.data.get(r.dataId).values),{batchSize:p,inHeight:d,inWidth:f,inChannels:m,outHeight:g,outWidth:y,padInfo:b,strideHeight:x,strideWidth:w,filterHeight:v,filterWidth:k,dilationHeight:N,dilationWidth:I,outShape:C}=ca(s.shape,r.shape,i,o,"NHWC",l);A(a.rank===C.length,(()=>`Error in Dilation2DBackpropFilter, dy must have the same rank as output ${C.length}, but got `+a.rank));const S=et(C,u.data.get(a.dataId).values),T=rt(r.shape,r.dtype);for(let t=0;t<p;++t)for(let e=0;e<g;++e){const n=e*x-b.top;for(let s=0;s<y;++s){const r=s*w-b.left;for(let a=0;a<m;++a){let i=Number.MIN_SAFE_INTEGER,o=0,l=0;for(let e=0;e<v;++e){const s=n+e*N;if(s>=0&&s<d)for(let n=0;n<k;++n){const u=r+n*I;if(u>=0&&u<f){const r=c[t][s][u][a]+h[e][n][a];r>i&&(i=r,o=e,l=n)}}}T[o][l][a]+=S[t][e][s][a]}}}return{dataId:u.write(Un(T,s.dtype),r.shape,r.dtype),shape:r.shape,dtype:r.dtype}}},Uw={kernelName:Jt,backendName:"cpu",kernelFunc:({inputs:t,backend:e,attrs:n})=>{const{x:s,filter:r,dy:a}=t,{strides:i,pad:o,dilations:l}=n,u=e,c=et(s.shape,u.data.get(s.dataId).values),h=et(r.shape,u.data.get(r.dataId).values),{batchSize:p,inHeight:d,inWidth:f,inChannels:m,outHeight:g,outWidth:y,padInfo:b,strideHeight:x,strideWidth:w,filterHeight:v,filterWidth:k,dilationHeight:N,dilationWidth:I,outShape:C}=ca(s.shape,r.shape,i,o,"NHWC",l);A(a.rank===C.length,(()=>`Error in Dilation2DBackpropInput, dy must have the same rank as output ${C.length}, but got `+a.rank));const S=et(C,u.data.get(a.dataId).values),T=rt(s.shape,s.dtype);for(let t=0;t<p;++t)for(let e=0;e<g;++e){const n=e*x-b.top;for(let s=0;s<y;++s){const r=s*w-b.left;for(let a=0;a<m;++a){let i=Number.MIN_SAFE_INTEGER,o=n<0?0:n,l=r<0?0:r;for(let e=0;e<v;++e){const s=n+e*N;if(s>=0&&s<d)for(let n=0;n<k;++n){const u=r+n*I;if(u>=0&&u<f){const r=c[t][s][u][a]+h[e][n][a];r>i&&(i=r,o=s,l=u)}}}T[t][o][l][a]+=S[t][e][s][a]}}}return{dataId:u.write(Un(T,s.dtype),s.shape,s.dtype),shape:s.shape,dtype:s.dtype}}},Gw=Cx(((t,e)=>t/e)),Hw=Px(Qt,Gw),jw={kernelName:Qt,backendName:"cpu",kernelFunc:Hw},qw=Bl,Kw=Pl,Xw=Wl,Yw=Vl,Jw=Ul,Zw=Gl,Qw=xx(ee,(t=>{const e=Math.sign(t),n=Math.abs(t),s=1/(1+qw*n);return e*(1-((((Zw*s+Jw)*s+Yw)*s+Xw)*s+Kw)*s*Math.exp(-n*n))})),tv={kernelName:ee,backendName:"cpu",kernelFunc:Qw},ev=gw((t=>Math.exp(t))),nv=wx(ne,ev),sv={kernelName:ne,backendName:"cpu",kernelFunc:nv},rv=gw((t=>Math.expm1(t))),av=wx(se,rv),iv={kernelName:se,backendName:"cpu",kernelFunc:av},ov=Cx(((t,e)=>t*e)),lv=Wx(((t,e,n,s)=>({real:t*n-e*s,imag:t*s+e*n}))),uv=Px(Re,ov,lv),cv={kernelName:Re,backendName:"cpu",kernelFunc:uv};function hv(t,e,n,s,r){const a=Dr(s,e,n),i=_(n),o=Q(s);if(a){const n=Fr(e,o);return t.subarray(n,n+i)}const l=U(r,i);for(let r=0;r<i;++r){const a=it(ot(r,n.length,Q(n)).map(((t,n)=>t+e[n])),s.length,o);l[r]=t[a]}return l}function pv(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{begin:a,size:i}=s;px(r,"slice");const[o,l]=_r(r,a,i);wr(r,o,l);const u=hv(n.data.get(r.dataId).values,o,l,r.shape,r.dtype);return n.makeTensorInfo(l,r.dtype,u)}const dv={kernelName:Qe,backendName:"cpu",kernelFunc:pv},fv=Cx(((t,e)=>t-e)),mv=Wx(((t,e,n,s)=>({real:t-n,imag:e-s}))),gv=Px(pn,fv,mv),yv={kernelName:pn,backendName:"cpu",kernelFunc:gv};function bv(t,e,n){const s=t.shape,r=s[0],a=s[1],i=n.data.get(t.dataId),o=i.complexTensorInfos.real,l=i.complexTensorInfos.imag,u=[r,a],c=_(u),h=U("float32",c),p=U("float32",c);for(let t=0;t<r;t++){const s=pv({inputs:{x:o},backend:n,attrs:{begin:[t,0],size:[1,a]}}),r=pv({inputs:{x:l},backend:n,attrs:{begin:[t,0],size:[1,a]}}),i=_x({inputs:{real:s,imag:r},backend:n}),{real:u,imag:c}=xv(i,e,n),d=ql(u,c);for(let e=0;e<a;e++){const n=Jl(d,e);h[t*a+e]=n.real,p[t*a+e]=n.imag}n.disposeIntermediateTensorInfo(s),n.disposeIntermediateTensorInfo(r),n.disposeIntermediateTensorInfo(i)}const d=n.makeTensorInfo(u,"float32",h),f=n.makeTensorInfo(u,"float32",p),m=_x({inputs:{real:d,imag:f},backend:n});return n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(f),m}function xv(t,e,n){const s=_(t.shape),r=n.data.get(t.dataId),a=n.data.get(r.complexTensorInfos.real.dataId).values,i=n.data.get(r.complexTensorInfos.imag.dataId).values;if(0==((l=s)&l-1)){const r=wv(a,i,s,e,n),l=[t.shape[0],t.shape[1]];if(e){const t=n.makeTensorInfo(l,"float32",r.real),e=n.makeTensorInfo(l,"float32",r.imag),a=n.makeTensorInfo([],"float32",(o=s,"string"=="float32"?Hn(o):Un([o],"float32"))),i=Nx({inputs:{x:a},backend:n}),u=jw.kernelFunc({inputs:{a:t,b:a},backend:n}),c=jw.kernelFunc({inputs:{a:e,b:i},backend:n}),h=n.data.get(u.dataId).values,p=n.data.get(c.dataId).values;return n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(u),n.disposeIntermediateTensorInfo(c),{real:h,imag:p}}return r}return Kl(function(t,e,n){const s=new Float32Array(2*e);for(let r=0;r<e;r++){let a=0,i=0;for(let s=0;s<e;s++){const o=tu(r*s,e,n),l=Jl(t,s);a+=l.real*o.real-l.imag*o.imag,i+=l.real*o.imag+l.imag*o.real}n&&(a/=e,i/=e),Zl(s,a,i,r)}return s}(ql(a,i),s,e));var o,l}function wv(t,e,n,s,r){if(1===n)return{real:t,imag:e};const a=ql(t,e),i=n/2,o=Xl(a),l=o.real,u=o.imag,c=[l.length],h=r.makeTensorInfo(c,"float32",l),p=r.makeTensorInfo(c,"float32",u),d=_x({inputs:{real:h,imag:p},backend:r}),f=Yl(a),m=f.real,g=f.imag,y=[m.length],b=r.makeTensorInfo(y,"float32",m),x=r.makeTensorInfo(y,"float32",g),w=_x({inputs:{real:b,imag:x},backend:r}),v=wv(l,u,i,s,r),k=v.real,N=v.imag,I=[k.length],C=r.makeTensorInfo(I,"float32",k),S=r.makeTensorInfo(I,"float32",N),T=_x({inputs:{real:C,imag:S},backend:r}),$=wv(m,g,i,s,r),E=$.real,A=$.imag,R=[E.length],D=r.makeTensorInfo(R,"float32",E),F=r.makeTensorInfo(R,"float32",A),_=_x({inputs:{real:D,imag:F},backend:r}),O=Ql(n,s),M=[O.real.length],L=r.makeTensorInfo(M,"float32",O.real),z=r.makeTensorInfo(M,"float32",O.imag),B=_x({inputs:{real:L,imag:z},backend:r}),P=uv({inputs:{a:B,b:_},backend:r}),W=Gx({inputs:{a:T,b:P},backend:r}),V=gv({inputs:{a:T,b:P},backend:r}),U=Mx({inputs:{input:W},backend:r}),G=Mx({inputs:{input:V},backend:r}),H=kw({inputs:{input:W},backend:r}),j=kw({inputs:{input:V},backend:r}),q=Iw({inputs:[U,G],backend:r,attrs:{axis:0}}),K=Iw({inputs:[H,j],backend:r,attrs:{axis:0}}),X=r.data.get(q.dataId).values,Y=r.data.get(K.dataId).values;return r.disposeIntermediateTensorInfo(h),r.disposeIntermediateTensorInfo(p),r.disposeIntermediateTensorInfo(d),r.disposeIntermediateTensorInfo(b),r.disposeIntermediateTensorInfo(x),r.disposeIntermediateTensorInfo(w),r.disposeIntermediateTensorInfo(C),r.disposeIntermediateTensorInfo(S),r.disposeIntermediateTensorInfo(T),r.disposeIntermediateTensorInfo(D),r.disposeIntermediateTensorInfo(F),r.disposeIntermediateTensorInfo(_),r.disposeIntermediateTensorInfo(L),r.disposeIntermediateTensorInfo(z),r.disposeIntermediateTensorInfo(B),r.disposeIntermediateTensorInfo(P),r.disposeIntermediateTensorInfo(W),r.disposeIntermediateTensorInfo(V),r.disposeIntermediateTensorInfo(U),r.disposeIntermediateTensorInfo(H),r.disposeIntermediateTensorInfo(G),r.disposeIntermediateTensorInfo(j),r.disposeIntermediateTensorInfo(q),r.disposeIntermediateTensorInfo(K),{real:X,imag:Y}}const vv={kernelName:re,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n}=t,{input:s}=e,r=_(s.shape),a=s.shape[s.shape.length-1],i=jx({inputs:{x:s},backend:n,attrs:{shape:[r/a,a]}}),o=bv(i,!1,n),l=jx({inputs:{x:o},backend:n,attrs:{shape:s.shape}});return n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(o),l}},kv={kernelName:ae,backendName:"cpu",kernelFunc:function(t){const{backend:e,attrs:n}=t,{shape:s,value:r,dtype:a}=n,i=a||Y(r),o=G(i,_(s));return function(t,e,n){t.fill(e)}(o,r),e.makeTensorInfo(s,i,o)}},Nv={kernelName:ie,backendName:"cpu",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{image:s}=t,r=n,a=U(s.dtype,_(s.shape)),[i,o,l,u]=s.shape,c=r.data.get(s.dataId).values;for(let t=0;t<i;t++){const e=t*l*o*u;for(let t=0;t<o;t++){const n=t*(l*u);for(let s=0;s<l;s++){const r=s*u;for(let o=0;o<u;o++){const h=[i,t,s,o][2],p=Math.round(l-h),d=e+n+r+o;let f=c[d];p>=0&&p<l&&(f=c[e+n+p*u+o]),a[d]=f}}}}return{dataId:r.write(a,s.shape,s.dtype),shape:s.shape,dtype:s.dtype}}},Iv=gw((t=>Math.floor(t))),Cv=wx(oe,Iv),Sv={kernelName:oe,backendName:"cpu",kernelFunc:Cv},Tv={kernelName:Cn,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,filter:a,bias:i,preluActivationWeights:o}=e,{strides:l,pad:u,dataFormat:c,dilations:h,dimRoundingMode:p,activation:d}=s;let f=Sw({inputs:{x:r,filter:a},backend:n,attrs:{strides:l,pad:u,dataFormat:c,dilations:h,dimRoundingMode:p}});if(i){const t=f;f=Gx({inputs:{a:f,b:i},backend:n}),n.disposeIntermediateTensorInfo(t)}if(d){const t=f;f=Fx(n,f,d,o),n.disposeIntermediateTensorInfo(t)}return f}},$v={kernelName:Sn,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,filter:a,bias:i,preluActivationWeights:o}=e,{strides:l,pad:u,dataFormat:c,dilations:h,dimRoundingMode:p,activation:d}=s;let f=Lw({inputs:{x:r,filter:a},backend:n,attrs:{strides:l,pad:u,dataFormat:c,dilations:h,dimRoundingMode:p}});if(i){const t=f;f=Gx({inputs:{a:f,b:i},backend:n}),n.disposeIntermediateTensorInfo(t)}if(d){const t=f;f=Fx(n,f,d,o),n.disposeIntermediateTensorInfo(t)}return f}},Ev={kernelName:de,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n}=t,{input:s}=e,r=_(s.shape),a=s.shape[s.shape.length-1],i=jx({inputs:{x:s},backend:n,attrs:{shape:[r/a,a]}}),o=bv(i,!0,n),l=jx({inputs:{x:o},backend:n,attrs:{shape:s.shape}});return n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(o),l}},Av=xx(me,(t=>Number.isFinite(t)?1:0),"bool"),Rv={kernelName:me,backendName:"cpu",kernelFunc:Av},Dv=xx(ge,(t=>Math.abs(t)===1/0?1:0),"bool"),Fv={kernelName:ge,backendName:"cpu",kernelFunc:Dv},_v=xx(ye,(t=>Number.isNaN(t)?1:0),"bool"),Ov={kernelName:ye,backendName:"cpu",kernelFunc:_v},Mv=gw((t=>Math.log(t))),Lv=wx(be,Mv),zv={kernelName:be,backendName:"cpu",kernelFunc:Lv},Bv=xx(xe,(t=>Math.log1p(t))),Pv={kernelName:xe,backendName:"cpu",kernelFunc:Bv},Wv=xx(we,(t=>t?0:1),"bool"),Vv={kernelName:we,backendName:"cpu",kernelFunc:Wv};function Uv(t,e,n,s){const r=U(s,_(n));for(let n=0;n<r.length;++n){const s=n*e;let a=t[s];for(let n=0;n<e;++n){const e=t[s+n];e>a&&(a=e)}r[n]=a}return r}function Gv(t,e,n,s,r){const a=e.length,i=_(e),o=Q(e),l=Q(r),u=U(n,_(r));for(let e=0;e<i;++e){const n=ot(e,a,o),r=new Array(n.length);for(let t=0;t<r.length;t++)r[t]=n[s[t]];u[it(r,a,l)]=t[e]}return u}const Hv={kernelName:ke,backendName:"cpu",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{x:s}=t,{reductionIndices:r,keepDims:a}=e,i=n;let o=s.shape;const l=o.length,u=W(r,o);let c=u;const h=na(c,l);let p=i.data.get(s.dataId).values;if(null!=h){const t=new Array(l);for(let e=0;e<t.length;e++)t[e]=o[h[e]];p=Gv(p,o,s.dtype,h,t),c=ra(c.length,l),o=t}px(s,"max"),ea("max",c,l);const[d,f]=Qr(o,c),m=Uv(p,_(f),d,s.dtype),g=i.write(m,d,s.dtype);let y=d;return a&&(y=ta(d,u)),{dataId:g,shape:y,dtype:s.dtype}}},jv={kernelName:Ie,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e;px(r,"maxPool");const{filterSize:a,strides:i,pad:o,dimRoundingMode:l}=s;A(va(i,1),(()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`));const u=ha(r.shape,a,i,1,o,l);let c;if(1===u.filterWidth&&1===u.filterHeight&&O(u.inShape,u.outShape))c=Nx({inputs:{x:r},backend:n});else{const t=n.data.get(r.dataId).values,e=Q(r.shape),s=hw(t,r.shape,r.dtype,e,u,"max");c=n.makeTensorInfo(u.outShape,r.dtype,s.values)}return c}},qv={kernelName:Ce,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{dy:r,input:a,output:i}=e,o=a;px([a,i],"maxPoolBackprop");const{filterSize:l,strides:u,pad:c,dimRoundingMode:h}=s,p=ha(o.shape,l,u,1,c,h),d=n.data.get(o.dataId).values,f=ir(p.outShape,o.dtype,pw(d,o.shape,o.dtype,p).values),m=p.strideHeight,g=p.strideWidth,y=p.dilationHeight,b=p.dilationWidth,x=p.effectiveFilterHeight,w=p.effectiveFilterWidth,v=w-1-p.padInfo.left,k=x-1-p.padInfo.top,N=ir(o.shape,"float32"),I=n.data.get(r.dataId).values,C=ir(r.shape,"float32",I);for(let t=0;t<p.batchSize;++t)for(let e=0;e<p.inChannels;++e)for(let n=0;n<p.inHeight;++n)for(let s=0;s<p.inWidth;++s){const r=n-k,a=s-v;let i=0;for(let n=0;n<x;n+=y){const s=(r+n)/m;if(!(s<0||s>=p.outHeight||Math.floor(s)!==s))for(let r=0;r<w;r+=b){const o=(a+r)/g;if(o<0||o>=p.outWidth||Math.floor(o)!==o)continue;const l=x*w-1-f.get(t,s,o,e)===n*w+r?1:0;0!==l&&(i+=C.get(t,s,o,e)*l)}}N.set(i,t,n,s,e)}return n.makeTensorInfo(N.shape,N.dtype,N.values)}},Kv={kernelName:Te,backendName:"cpu",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{x:s}=t,{filterSize:r,strides:a,pad:i,includeBatchInIndex:o}=e,l=n;px(s,"MaxPoolWithArgmax");const u=l.data.get(s.dataId).values,c=ha(s.shape,r,a,[1,1],i),[h,p]=function(t,e,n,s,r){const a=hw(t,0,n,Q(e),r,"max"),i=pw(t,e,n,r,!0,s);return[a.values,i.values]}(u,s.shape,s.dtype,o,c),d=l.write(h,c.outShape,s.dtype),f=l.write(p,c.outShape,s.dtype);return[{dataId:d,shape:c.outShape,dtype:s.dtype},{dataId:f,shape:c.outShape,dtype:"int32"}]}},Xv={kernelName:Ae,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{paddings:a,mode:i}=s;px(r,"mirrorPad");const o=a.map(((t,e)=>t[0]+r.shape[e]+t[1])),l=a.map((t=>t[0])),u=a.map(((t,e)=>t[0]+r.shape[e])),c="reflect"===i?0:1,h=n.data.get(r.dataId).values,p=r.shape.length,d=Q(r.shape),f=_(o),m=o.length,g=Q(o),y=U(r.dtype,f);for(let t=0;t<f;t++){let e=ot(t,m,g);for(let t=0;t<m;t++)e[t]<l[t]?e[t]=2*l[t]-e[t]-c:e[t]>=u[t]&&(e[t]=2*(u[t]-1)-e[t]+c);e=e.map(((t,e)=>t-l[e]));const n=it(e,p,d);y[t]=h[n]}return{dataId:n.write(y,o,r.dtype),shape:o,dtype:r.dtype}}},Yv=Ho,Jv={kernelName:Oe,backendName:"cpu",kernelFunc:({inputs:t,backend:e,attrs:n})=>{const{boxes:s,scores:r}=t,{maxOutputSize:a,iouThreshold:i,scoreThreshold:o,padToMaxOutputSize:l}=n,u=e;px(s,"NonMaxSuppressionPadded");const c=u.data.get(s.dataId).values,h=u.data.get(r.dataId).values,{selectedIndices:p,validOutputs:d}=Yv(c,h,a,i,o,l);return[p,d]}},Zv=jo,Qv={kernelName:Me,backendName:"cpu",kernelFunc:({inputs:t,backend:e,attrs:n})=>{const{boxes:s,scores:r}=t,{maxOutputSize:a,iouThreshold:i,scoreThreshold:o,softNmsSigma:l}=n,u=e;px(s,"NonMaxSuppressionWithScore");const c=u.data.get(s.dataId).values,h=u.data.get(r.dataId).values,p=a,d=i,f=o,m=l,{selectedIndices:g,selectedScores:y}=Zv(c,h,p,d,f,m);return[g,y]}},tk=Cx(((t,e)=>t!==e?1:0)),ek=Px(Fe,tk,null,"bool"),nk={kernelName:Fe,backendName:"cpu",kernelFunc:ek},sk={kernelName:Be,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{paddings:a,constantValue:i}=s;px(r,"pad");const o=a.map(((t,e)=>t[0]+r.shape[e]+t[1])),l=a.map((t=>t[0])),u=n.data.get(r.dataId).values,c=_(r.shape),h=r.shape.length,p=Q(r.shape),d=_(o),f=o.length,m=Q(o),g=U(r.dtype,d);0!==i&&g.fill(i);for(let t=0;t<c;t++)g[it(ot(t,h,p).map(((t,e)=>t+l[e])),f,m)]=u[t];return{dataId:n.write(g,o,r.dtype),shape:o,dtype:r.dtype}}},rk=xx(Ve,(t=>1/t)),ak={kernelName:Ve,backendName:"cpu",kernelFunc:rk},ik={kernelName:Nn,backendName:"cpu",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{image:s}=t,{radians:r,fillValue:a,center:i}=e,o=n,l=U(s.dtype,_(s.shape)),[u,c,h,p]=s.shape,[d,f]=Tl(i,c,h),m=Math.sin(r),g=Math.cos(r),y=o.data.get(s.dataId).values;for(let t=0;t<u;t++){const e=t*h*c*p;for(let t=0;t<c;t++){const n=t*(h*p);for(let s=0;s<h;s++){const r=s*p;for(let i=0;i<p;i++){const o=[u,t,s,i],b=o[2],x=o[1];let w=(b-d)*g-(x-f)*m,v=(b-d)*m+(x-f)*g;w=Math.round(w+d),v=Math.round(v+f);let k=a;"number"!=typeof a&&(k=3===i?255:a[i]),w>=0&&w<h&&v>=0&&v<c&&(k=y[e+v*(h*p)+w*p+i]),l[e+n+r+i]=k}}}}return{dataId:o.write(l,s.shape,s.dtype),shape:s.shape,dtype:s.dtype}}},ok=xx(Xe,(t=>{const e=Math.floor(t);return t-e<.5?Math.floor(t):t-e>.5?Math.ceil(t):e%2==0?e:e+1})),lk={kernelName:Xe,backendName:"cpu",kernelFunc:ok},uk=gw((t=>1/Math.sqrt(t))),ck=wx(Ye,uk),hk={kernelName:Ye,backendName:"cpu",kernelFunc:ck},pk=Ll,dk=zl,fk=xx(Ze,(t=>t>=0?dk*t:pk*(Math.exp(t)-1))),mk={kernelName:Ze,backendName:"cpu",kernelFunc:fk},gk=xx(sn,(t=>1/(1+Math.exp(-t)))),yk={kernelName:sn,backendName:"cpu",kernelFunc:gk},bk=xx(nn,(t=>t<0?-1:t>0?1:0)),xk={kernelName:nn,backendName:"cpu",kernelFunc:bk},wk=xx(tn,(t=>Math.sin(t))),vk={kernelName:tn,backendName:"cpu",kernelFunc:wk},kk=xx(en,(t=>Math.sinh(t))),Nk={kernelName:en,backendName:"cpu",kernelFunc:kk},Ik=Math.log(1.1920928955078125e-7)+2,Ck=xx(rn,(t=>{const e=t>-Ik,n=t<Ik,s=Math.exp(t);let r;return r=n?s:e?t:Math.log(1+s),r})),Sk={kernelName:rn,backendName:"cpu",kernelFunc:Ck};function Tk(t){const{inputs:e,attrs:n,backend:s}=t,{x:r}=e,{perm:a}=n;px(r,"transpose");const i=r.shape.length,o=new Array(i);for(let t=0;t<o.length;t++)o[t]=r.shape[a[t]];const l=Gv(s.data.get(r.dataId).values,r.shape,r.dtype,a,o);return{dataId:s.write(l,o,r.dtype),shape:o,dtype:r.dtype}}const $k={kernelName:gn,backendName:"cpu",kernelFunc:Tk},Ek={kernelName:on,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{blockShape:a,paddings:i}=s;px([r],"spaceToBatchND");const o=_(a),l=[[0,0]];l.push(...i);for(let t=1+a.length;t<r.shape.length;++t)l.push([0,0]);const u=sk.kernelFunc({inputs:{x:r},backend:n,attrs:{paddings:l,constantValue:0}}),c=$l(u.shape,a,o,!1),h=El(c.length,a.length,!1),p=Al(u.shape,a,o,!1),d=jx({inputs:{x:u},backend:n,attrs:{shape:c}}),f=Tk({inputs:{x:d},backend:n,attrs:{perm:h}}),m=jx({inputs:{x:f},backend:n,attrs:{shape:p}});return n.disposeIntermediateTensorInfo(u),n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(f),m}},Ak=xx(an,(t=>Math.sqrt(t))),Rk={kernelName:an,backendName:"cpu",kernelFunc:Ak},Dk={kernelName:hn,backendName:"cpu",kernelFunc:({inputs:t,backend:e})=>{const{x:n}=t,s=e;px(n,"square");const r=s.data.get(n.dataId).values,a=new Float32Array(r.length);for(let t=0;t<r.length;++t){const e=r[t];a[t]=e*e}return{dataId:s.write(a,n.shape,n.dtype),shape:n.shape,dtype:n.dtype}}},Fk=Cx(((t,e)=>{const n=t-e;return n*n})),_k=Px(cn,Fk),Ok={kernelName:cn,backendName:"cpu",kernelFunc:_k},Mk=xx(vn,((t,e)=>{const n=e;return isNaN(t)?NaN:t>0?1:n.alpha})),Lk={kernelName:vn,backendName:"cpu",kernelFunc:Mk},zk=xx(dn,(t=>Math.tan(t))),Bk={kernelName:dn,backendName:"cpu",kernelFunc:zk},Pk=xx(fn,(t=>Math.tanh(t)));function Wk(t,e,n,s){const r=W(e,n)[0],a=[1,n[0],1];for(let t=0;t<r;t++)a[0]*=n[t];a[1]=n[r];for(let t=r+1;t<n.length;t++)a[2]*=n[t];const i={},o=new Int32Array(n[r]),l=new qn(a,s,t),u=[],c=1===a[0]&&1===a[2];for(let e=0;e<n[r];e++){let n;if(c)n=t[e].toString();else{const t=[];for(let n=0;n<a[0];n++)for(let s=0;s<a[2];s++)t.push(l.get(n,e,s));n=t.join(",")}if(void 0!==i[n])o[e]=i[n];else{const t=Object.keys(i).length;i[n]=t,o[e]=t,u.push(e)}}const h=a.slice();h[1]=Object.keys(i).length;const p=new qn(h,s);u.forEach(((t,e)=>{for(let n=0;n<a[0];n++)for(let s=0;s<a[2];s++)p.set(l.get(n,t,s),n,e,s)}));const d=n.slice();return d[r]=h[1],{outputValues:p.values,outputShape:d,indices:o}}const Vk=[Yx,Zx,tw,nw,Hx,rw,iw,lw,cw,dw,fw,Xx,mw,Bx,xw,vw,Ox,Cw,$w,Ew,Tw,Rw,Dw,Aw,_w,Mw,zw,Bw,Pw,Ww,Uw,Vw,jw,kx,tv,sv,iv,vv,kv,Nv,Sv,Tv,$v,Ix,Ev,Nw,Rv,Fv,Ov,zv,Pv,Vv,jv,qv,Kv,Hv,Xv,cv,Jv,Qv,nk,sk,$x,Lx,ak,Ax,Dx,qx,ik,lk,hk,mk,yk,xk,vk,Nk,dv,Sk,Ek,Rk,Dk,Ok,Lk,yv,Bk,{kernelName:fn,backendName:"cpu",kernelFunc:Pk},$k,{kernelName:yn,backendName:"cpu",kernelFunc:function(t){const{inputs:e,attrs:n,backend:s}=t,{axis:r}=n,{x:a}=e;px(a,"unique");const i=s.data.get(a.dataId).values,{outputValues:o,outputShape:l,indices:u}=Wk(i,r,a.shape,a.dtype);return[s.makeTensorInfo(l,a.dtype,o),s.makeTensorInfo([u.length],"int32",u)]}}];for(const t of Vk)Dn(t);const Uk={},Gk={alpha:!1,antialias:!1,premultipliedAlpha:!1,preserveDrawingBuffer:!1,depth:!1,stencil:!1,failIfMajorPerformanceCaveat:!0};function Hk(t){if(!(t in Uk)){const e=function(t){if(1!==t&&2!==t)throw new Error("Cannot get WebGL rendering context, WebGL is disabled.");const e=function(t){if("undefined"!=typeof OffscreenCanvas&&2===t)return new OffscreenCanvas(300,150);if("undefined"!=typeof document)return document.createElement("canvas");throw new Error("Cannot create a canvas in this context")}(t);return e.addEventListener("webglcontextlost",(e=>{e.preventDefault(),delete Uk[t]}),!1),1===t?e.getContext("webgl",Gk)||e.getContext("experimental-webgl",Gk):e.getContext("webgl2",Gk)}(t);if(null===e)return console.log("Could not get context for WebGL version",t),null;Uk[t]=e}const e=Uk[t];return e.isContextLost()?(delete Uk[t],Hk(t)):(e.disable(e.DEPTH_TEST),e.disable(e.STENCIL_TEST),e.disable(e.BLEND),e.disable(e.DITHER),e.disable(e.POLYGON_OFFSET_FILL),e.disable(e.SAMPLE_COVERAGE),e.enable(e.SCISSOR_TEST),e.enable(e.CULL_FACE),e.cullFace(e.BACK),Uk[t])}var jk,qk,Kk;function Xk(t,e){return[e,t]}function Yk(t){const e=_(t);return L(Math.ceil(e/4))}function Jk(t,e){return[Math.max(1,Math.ceil(e/2)),Math.max(1,Math.ceil(t/2))]}function Zk(t,e){const n=t;let s,r,a,i,o,l,u,c,h,p;return 2===ct().getNumber("WEBGL_VERSION")?(s=n.R32F,r=n.R16F,a=n.RGBA16F,i=n.RGBA32F,o=n.RED,u=4,c=1,h=n.HALF_FLOAT,p=n.FLOAT):(s=t.RGBA,r=t.RGBA,a=t.RGBA,i=n.RGBA,o=t.RGBA,u=4,c=4,h=null!=e?e.HALF_FLOAT_OES:null,p=t.FLOAT),l=t.RGBA,{internalFormatFloat:s,internalFormatHalfFloat:r,internalFormatPackedHalfFloat:a,internalFormatPackedFloat:i,textureFormatFloat:o,downloadTextureFormat:l,downloadUnpackNumChannels:u,defaultNumChannels:c,textureTypeHalfFloat:h,textureTypeFloat:p}}function Qk(t,e){const n=e();return ct().getBool("DEBUG")&&function(t){const e=t.getError();if(e!==t.NO_ERROR)throw new Error("WebGL Error: "+function(t,e){switch(e){case t.NO_ERROR:return"NO_ERROR";case t.INVALID_ENUM:return"INVALID_ENUM";case t.INVALID_VALUE:return"INVALID_VALUE";case t.INVALID_OPERATION:return"INVALID_OPERATION";case t.INVALID_FRAMEBUFFER_OPERATION:return"INVALID_FRAMEBUFFER_OPERATION";case t.OUT_OF_MEMORY:return"OUT_OF_MEMORY";case t.CONTEXT_LOST_WEBGL:return"CONTEXT_LOST_WEBGL";default:return"Unknown error code "+e}}(t,e))}(t),n}function tN(t){return!!(ct().getBool("WEBGL_RENDER_FLOAT32_ENABLED")||0===t||5.96e-8<Math.abs(t)&&Math.abs(t)<65504)}function eN(t,e){return uN(t,(()=>t.getExtension(e)),'Extension "'+e+'" not supported on this browser.')}!function(t){t[t.DENSE=0]="DENSE",t[t.SHARED_BATCH=1]="SHARED_BATCH"}(jk||(jk={})),function(t){t[t.RENDER=0]="RENDER",t[t.UPLOAD=1]="UPLOAD",t[t.PIXELS=2]="PIXELS",t[t.DOWNLOAD=3]="DOWNLOAD"}(qk||(qk={})),function(t){t[t.UNPACKED_FLOAT16=0]="UNPACKED_FLOAT16",t[t.UNPACKED_FLOAT32=1]="UNPACKED_FLOAT32",t[t.PACKED_4X1_UNSIGNED_BYTE=2]="PACKED_4X1_UNSIGNED_BYTE",t[t.PACKED_2X2_FLOAT32=3]="PACKED_2X2_FLOAT32",t[t.PACKED_2X2_FLOAT16=4]="PACKED_2X2_FLOAT16"}(Kk||(Kk={}));const nN=/ERROR: [0-9]+:([0-9]+):/g;function sN(t,e){if(Qk(t,(()=>t.validateProgram(e))),!1===t.getProgramParameter(e,t.VALIDATE_STATUS))throw console.log(t.getProgramInfoLog(e)),new Error("Shader program validation failed.")}function rN(t,e,n,s,r,a,i){const o=t.getAttribLocation(e,n);return-1!==o&&(Qk(t,(()=>t.bindBuffer(t.ARRAY_BUFFER,s))),Qk(t,(()=>t.vertexAttribPointer(o,r,t.FLOAT,!1,a,i))),Qk(t,(()=>t.enableVertexAttribArray(o))),!0)}function aN(t,e,n,s){Qk(t,(()=>function(t,e,n){(function(t,e){const n=t.MAX_COMBINED_TEXTURE_IMAGE_UNITS-1,s=e+t.TEXTURE0;if(s<t.TEXTURE0||s>n)throw new Error(`textureUnit must be in [gl.TEXTURE0, gl.TEXTURE${n}].`)})(t,n),Qk(t,(()=>t.activeTexture(t.TEXTURE0+n))),Qk(t,(()=>t.bindTexture(t.TEXTURE_2D,e)))}(t,e,s))),Qk(t,(()=>t.uniform1i(n,s)))}function iN(t,e,n){Qk(t,(()=>t.bindFramebuffer(t.FRAMEBUFFER,n))),Qk(t,(()=>t.framebufferTexture2D(t.FRAMEBUFFER,t.COLOR_ATTACHMENT0,t.TEXTURE_2D,e,0)))}function oN(t,e){Qk(t,(()=>t.bindFramebuffer(t.FRAMEBUFFER,e))),Qk(t,(()=>t.framebufferTexture2D(t.FRAMEBUFFER,t.COLOR_ATTACHMENT0,t.TEXTURE_2D,null,0)))}function lN(t){const e=t.checkFramebufferStatus(t.FRAMEBUFFER);if(e!==t.FRAMEBUFFER_COMPLETE)throw new Error("Error binding framebuffer: "+function(t,e){switch(e){case t.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:return"FRAMEBUFFER_INCOMPLETE_ATTACHMENT";case t.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:return"FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";case t.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:return"FRAMEBUFFER_INCOMPLETE_DIMENSIONS";case t.FRAMEBUFFER_UNSUPPORTED:return"FRAMEBUFFER_UNSUPPORTED";default:return"unknown error "+e}}(t,e))}function uN(t,e,n){const s=Qk(t,(()=>e()));if(null==s)throw new Error(n);return s}function cN(t,e=2){return _(t.slice(0,t.length-e))}function hN(t){if(0===t.length)throw Error("Cannot get rows and columns of an empty shape array.");return[t.length>1?t[t.length-2]:1,t[t.length-1]]}function pN(t){let e=[1,1,1];return 0===t.length||1===t.length&&1===t[0]||(e=[cN(t),...hN(t)]),e}function dN(t){return t%2==0}function fN(t,e){if(O(t=t.slice(-2),e=e.slice(-2)))return!0;if(!t.length||!e.length)return!0;if(0===t[0]||0===t[1]||0===e[0]||0===e[1])return!0;if(t.length!==e.length){const n=t.slice(-1)[0],s=e.slice(-1)[0];if(n===s)return!0;if(dN(n)&&dN(s)&&(1===t[0]||1===e[0]))return!0}return t[1]===e[1]&&dN(t[0])&&dN(e[0])}let mN,gN;function yN(t,e){return null!=t.getExtension(e)}function bN(t){try{if(null!=Hk(t))return!0}catch(t){return console.log("Error when getting WebGL context: ",t),!1}return!1}function xN(t){const e=Zk(t),n=t.createTexture();t.bindTexture(t.TEXTURE_2D,n),t.texImage2D(t.TEXTURE_2D,0,e.internalFormatFloat,1,1,0,e.textureFormatFloat,e.textureTypeFloat,null);const s=t.createFramebuffer();t.bindFramebuffer(t.FRAMEBUFFER,s),t.framebufferTexture2D(t.FRAMEBUFFER,t.COLOR_ATTACHMENT0,t.TEXTURE_2D,n,0);const r=t.checkFramebufferStatus(t.FRAMEBUFFER)===t.FRAMEBUFFER_COMPLETE;return t.bindTexture(t.TEXTURE_2D,null),t.bindFramebuffer(t.FRAMEBUFFER,null),t.deleteTexture(n),t.deleteFramebuffer(s),r}function wN(t,e){Array.isArray(t)||(t=[t]),t.forEach((t=>{null!=t&&A("complex64"!==t.dtype,(()=>e+" does not support complex64 tensors in the WebGL backend."))}))}const vN=ct();vN.registerFlag("HAS_WEBGL",(()=>vN.getNumber("WEBGL_VERSION")>0)),vN.registerFlag("WEBGL_VERSION",(()=>bN(2)?2:bN(1)?1:0)),vN.registerFlag("WEBGL_CHECK_NUMERICAL_PROBLEMS",(()=>!1)),vN.registerFlag("WEBGL_BUFFER_SUPPORTED",(()=>2===vN.get("WEBGL_VERSION"))),vN.registerFlag("WEBGL_CPU_FORWARD",(()=>!0)),vN.registerFlag("WEBGL_FORCE_F16_TEXTURES",(()=>!1)),vN.registerFlag("WEBGL_PACK",(()=>vN.getBool("HAS_WEBGL"))),vN.registerFlag("WEBGL_PACK_NORMALIZATION",(()=>vN.getBool("WEBGL_PACK"))),vN.registerFlag("WEBGL_PACK_CLIP",(()=>vN.getBool("WEBGL_PACK"))),vN.registerFlag("WEBGL_PACK_DEPTHWISECONV",(()=>!1)),vN.registerFlag("WEBGL_PACK_BINARY_OPERATIONS",(()=>vN.getBool("WEBGL_PACK"))),vN.registerFlag("WEBGL_PACK_UNARY_OPERATIONS",(()=>vN.getBool("WEBGL_PACK"))),vN.registerFlag("WEBGL_PACK_ARRAY_OPERATIONS",(()=>vN.getBool("WEBGL_PACK"))),vN.registerFlag("WEBGL_PACK_IMAGE_OPERATIONS",(()=>vN.getBool("WEBGL_PACK"))),vN.registerFlag("WEBGL_PACK_REDUCE",(()=>vN.getBool("WEBGL_PACK"))),vN.registerFlag("WEBGL_LAZILY_UNPACK",(()=>vN.getBool("WEBGL_PACK"))),vN.registerFlag("WEBGL_CONV_IM2COL",(()=>vN.getBool("WEBGL_PACK"))),vN.registerFlag("WEBGL_MAX_TEXTURE_SIZE",(()=>function(t){if(null==mN){const e=Hk(t);mN=e.getParameter(e.MAX_TEXTURE_SIZE)}return mN}(vN.getNumber("WEBGL_VERSION")))),vN.registerFlag("WEBGL_MAX_TEXTURES_IN_SHADER",(()=>function(t){if(null==gN){const e=Hk(t);gN=e.getParameter(e.MAX_TEXTURE_IMAGE_UNITS)}return Math.min(16,gN)}(vN.getNumber("WEBGL_VERSION")))),vN.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION",(()=>{const t=vN.getNumber("WEBGL_VERSION");return 0===t?0:function(t){if(0===t)return 0;let e;const n=Hk(t);return e=yN(n,"EXT_disjoint_timer_query_webgl2")&&2===t?2:yN(n,"EXT_disjoint_timer_query")?1:0,e}(t)})),vN.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE",(()=>vN.getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")>0&&!function(){if("undefined"!=typeof navigator&&null!=navigator){const t=navigator.userAgent||navigator.vendor||window.opera;return/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(t)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(t.substr(0,4))}return!1}())),vN.registerFlag("WEBGL_RENDER_FLOAT32_CAPABLE",(()=>function(t){if(0===t)return!1;const e=Hk(t);if(1===t){if(!yN(e,"OES_texture_float"))return!1}else if(!yN(e,"EXT_color_buffer_float"))return!1;return xN(e)}(vN.getNumber("WEBGL_VERSION")))),vN.registerFlag("WEBGL_RENDER_FLOAT32_ENABLED",(()=>!vN.getBool("WEBGL_FORCE_F16_TEXTURES")&&vN.getBool("WEBGL_RENDER_FLOAT32_CAPABLE"))),vN.registerFlag("WEBGL_DOWNLOAD_FLOAT_ENABLED",(()=>function(t){if(0===t)return!1;const e=Hk(t);if(1!==t){if(yN(e,"EXT_color_buffer_float"))return xN(e);const t="EXT_color_buffer_half_float";if(yN(e,t)){const n=e.getExtension(t);return function(t,e){const n=Zk(t,e),s=t.createTexture();t.bindTexture(t.TEXTURE_2D,s),t.texImage2D(t.TEXTURE_2D,0,n.internalFormatHalfFloat,1,1,0,n.textureFormatFloat,n.textureTypeHalfFloat,null);const r=t.createFramebuffer();t.bindFramebuffer(t.FRAMEBUFFER,r),t.framebufferTexture2D(t.FRAMEBUFFER,t.COLOR_ATTACHMENT0,t.TEXTURE_2D,s,0);const a=t.checkFramebufferStatus(t.FRAMEBUFFER)===t.FRAMEBUFFER_COMPLETE;return t.bindTexture(t.TEXTURE_2D,null),t.bindFramebuffer(t.FRAMEBUFFER,null),t.deleteTexture(s),t.deleteFramebuffer(r),a}(e,n)}return!1}return!!yN(e,"OES_texture_float")&&!!yN(e,"WEBGL_color_buffer_float")&&xN(e)}(vN.getNumber("WEBGL_VERSION")))),vN.registerFlag("WEBGL_FENCE_API_ENABLED",(()=>{return 2===(t=vN.getNumber("WEBGL_VERSION"))&&null!=Hk(t).fenceSync;var t})),vN.registerFlag("WEBGL_SIZE_UPLOAD_UNIFORM",(()=>vN.getBool("WEBGL_RENDER_FLOAT32_ENABLED")?4:0)),vN.registerFlag("WEBGL_DELETE_TEXTURE_THRESHOLD",(()=>-1),(t=>{if(t<0&&-1!==t)throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never delete) or at least 0, but got ${t}.`)}));const{simpleAbsImpl:kN,addImpl:NN,ceilImpl:IN,expImpl:CN,expm1Impl:SN,floorImpl:TN,logImpl:$N,maxImpl:EN,multiplyImpl:AN,rsqrtImpl:RN,sliceImpl:DN,subImpl:FN,transposeImpl:_N,uniqueImpl:ON}=v;class MN{constructor(t,e){this.outputShape=[],this.outputShape=t,this.variableNames=e.map(((t,e)=>"T"+e));const n=[];this.variableNames.forEach((t=>{n.push(`float v${t} = get${t}AtOutCoords();`)}));const s=this.variableNames.map((t=>"v"+t)).join(" + ");this.userCode=`\n      void main() {\n        ${n.join("\n        ")}\n\n        float result = ${s};\n        setOutput(result);\n      }\n    `}}class LN{constructor(t,e){this.outputShape=[],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=t,this.variableNames=e.map(((t,e)=>"T"+e));const n=[];this.variableNames.forEach((t=>{n.push(`vec4 v${t} = get${t}AtOutCoords();`)}));const s=this.variableNames.map((t=>"v"+t)).join(" + ");this.userCode=`\n      void main() {\n        ${n.join("\n        ")}\n\n        vec4 result = ${s};\n        setOutput(result);\n      }\n    `}}class zN{constructor(t,e,n){this.variableNames=["A"];const{windowSize:s,batchSize:r,outSize:a}=t;n||this.variableNames.push("bestIndicesA"),this.outputShape=[r,a];const i="max"===e?">":"<",o=n?"inOffset + i;":"round(getBestIndicesA(batch, inOffset + i));";this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${s};\n\n        int bestIndex = inOffset;\n        float bestValue = getA(batch, bestIndex);\n\n        for (int i = 0; i < ${s}; i++) {\n          int inIdx = ${o};\n          float candidate = getA(batch, inIdx);\n          if (candidate ${i} bestValue) {\n            bestValue = candidate;\n            bestIndex = inIdx;\n          }\n        }\n        setOutput(float(bestIndex));\n      }\n    `}}function BN(t,e){return["x","y","z","w","u","v"].slice(0,e).map((e=>`${t}.${e}`))}function PN(t,e){return 1===e?[t]:BN(t,e)}function WN(){let t,e,n,s,r,a,i,o,l,u;return 2===ct().getNumber("WEBGL_VERSION")?(t="#version 300 es",e="in",n="out",s="in",r="texture",a="outputColor",i="out vec4 outputColor;",o="\n      bool isnan_custom(float val) {\n        return (val > 0.0 || val < 0.0) ? false : val != 0.0;\n      }\n\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan_custom(val.x),\n          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));\n      }\n\n      #define isnan(value) isnan_custom(value)\n    ",l="",u="\n      #define round(value) newRound(value)\n      int newRound(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 newRound(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    "):(t="",e="attribute",n="varying",s="varying",r="texture2D",a="gl_FragColor",i="",o="\n      #define isnan(value) isnan_custom(value)\n      bool isnan_custom(float val) {\n        return (val > 0. || val < 1. || val == 0.) ? false : true;\n      }\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));\n      }\n    ",l="\n      uniform float INFINITY;\n\n      bool isinf(float val) {\n        return abs(val) == INFINITY;\n      }\n      bvec4 isinf(vec4 val) {\n        return equal(abs(val), vec4(INFINITY));\n      }\n    ",u="\n      int round(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 round(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    "),{version:t,attribute:e,varyingVs:n,varyingFs:s,texture2D:r,output:a,defineOutput:i,defineSpecialNaN:o,defineSpecialInf:l,defineRound:u}}function VN(t,e,n="index"){const s=Q(e);return s.map(((e,r)=>`int ${t[r]} = ${n} / ${e}; ${r===s.length-1?`int ${t[r+1]} = ${n} - ${t[r]} * ${e}`:`index -= ${t[r]} * ${e}`};`)).join("")}function UN(t){const e=Q(t).map((t=>t.toString()));return`\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * ${e[0]} + coords.y * ${e[1]} + coords.z;\n  }\n`}const GN="\n  const float FLOAT_MAX = 1.70141184e38;\n  const float FLOAT_MIN = 1.17549435e-38;\n\n  lowp vec4 encode_float(highp float v) {\n    if (isnan(v)) {\n      return vec4(255, 255, 255, 255);\n    }\n\n    highp float av = abs(v);\n\n    if(av < FLOAT_MIN) {\n      return vec4(0.0, 0.0, 0.0, 0.0);\n    } else if(v > FLOAT_MAX) {\n      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;\n    } else if(v < -FLOAT_MAX) {\n      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;\n    }\n\n    highp vec4 c = vec4(0,0,0,0);\n\n    highp float e = floor(log2(av));\n    highp float m = exp2(fract(log2(av))) - 1.0;\n\n    c[2] = floor(128.0 * m);\n    m -= c[2] / 128.0;\n    c[1] = floor(32768.0 * m);\n    m -= c[1] / 32768.0;\n    c[0] = floor(8388608.0 * m);\n\n    highp float ebias = e + 127.0;\n    c[3] = floor(ebias / 2.0);\n    ebias -= c[3] * 2.0;\n    c[2] += floor(ebias) * 128.0;\n\n    c[3] += 128.0 * step(0.0, -v);\n\n    return c / 255.0;\n  }\n",{getBroadcastDims:HN}=s;function jN(t,e,n,s){const r=[];t.forEach((t=>{const e=_(t.shapeInfo.logicalShape);t.shapeInfo.isUniform?r.push(`uniform float ${t.name}${e>1?`[${e}]`:""};`):(r.push(`uniform sampler2D ${t.name};`),r.push(`uniform int offset${t.name};`))}));const a=r.join("\n"),i=t.map((t=>function(t,e,n=!1){let s="";s+=n?KN(t):qN(t);const r=t.shapeInfo.logicalShape,a=e.logicalShape;return r.length<=a.length&&(s+=n?function(t,e){const n=t.name,s=n.charAt(0).toUpperCase()+n.slice(1),r="get"+s+"AtOutCoords",a=t.shapeInfo.logicalShape.length,i=e.logicalShape.length,o=HN(t.shapeInfo.logicalShape,e.logicalShape),l=eI(i),u=i-a;let c;const h=["x","y","z","w","u","v"];c=0===a?"":i<2&&o.length>=1?"coords = 0;":o.map((t=>`coords.${h[t+u]} = 0;`)).join("\n");let p="";p=i<2&&a>0?"coords":t.shapeInfo.logicalShape.map(((t,e)=>"coords."+h[e+u])).join(", ");let d="return outputValue;";const f=1===_(t.shapeInfo.logicalShape),m=1===_(e.logicalShape);if(1!==a||f||m){if(f&&!m)d=1===i?"\n        return vec4(outputValue.x, outputValue.x, 0., 0.);\n      ":"\n        return vec4(outputValue.x);\n      ";else if(o.length){const t=a-2,e=a-1;o.indexOf(t)>-1&&o.indexOf(e)>-1?d="return vec4(outputValue.x);":o.indexOf(t)>-1?d="return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);":o.indexOf(e)>-1&&(d="return vec4(outputValue.xx, outputValue.zz);")}}else d="\n      return vec4(outputValue.xy, outputValue.xy);\n    ";return`\n    vec4 ${r}() {\n      ${l} coords = getOutputCoords();\n      ${c}\n      vec4 outputValue = get${s}(${p});\n      ${d}\n    }\n  `}(t,e):function(t,e){const n=t.name,s=n.charAt(0).toUpperCase()+n.slice(1),r="get"+s+"AtOutCoords",a=e.texShape,i=t.shapeInfo.texShape,o=t.shapeInfo.logicalShape.length,l=e.logicalShape.length;if(!t.shapeInfo.isUniform&&o===l&&null==t.shapeInfo.flatOffset&&O(i,a))return`\n      float ${r}() {\n        return sampleTexture(${n}, resultUV);\n      }\n    `;const u=eI(l),c=HN(t.shapeInfo.logicalShape,e.logicalShape),h=l-o;let p;const d=["x","y","z","w","u","v"];p=0===o?"":l<2&&c.length>=1?"coords = 0;":c.map((t=>`coords.${d[t+h]} = 0;`)).join("\n");let f="";return f=l<2&&o>0?"coords":t.shapeInfo.logicalShape.map(((t,e)=>"coords."+d[e+h])).join(", "),`\n    float ${r}() {\n      ${u} coords = getOutputCoords();\n      ${p}\n      return get${s}(${f});\n    }\n  `}(t,e)),s}(t,e,s))).join("\n"),o=e.texShape,l=WN(),u=function(t){return`\n    float sampleTexture(sampler2D textureSampler, vec2 uv) {\n      return ${t.texture2D}(textureSampler, uv).r;\n    }\n  `}(l);let c,h,p=function(t){return`${t.version}\n    precision highp float;\n    precision highp int;\n    precision highp sampler2D;\n    ${t.varyingFs} vec2 resultUV;\n    ${t.defineOutput}\n    const vec2 halfCR = vec2(0.5, 0.5);\n\n    struct ivec5\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n    };\n\n    struct ivec6\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n      int v;\n    };\n\n    uniform float NAN;\n    ${t.defineSpecialNaN}\n    ${t.defineSpecialInf}\n    ${t.defineRound}\n\n    int imod(int x, int y) {\n      return x - y * (x / y);\n    }\n\n    int idiv(int a, int b, float sign) {\n      int res = a / b;\n      int mod = imod(a, b);\n      if (sign < 0. && mod != 0) {\n        res -= 1;\n      }\n      return res;\n    }\n\n    //Based on the work of Dave Hoskins\n    //https://www.shadertoy.com/view/4djSRW\n    #define HASHSCALE1 443.8975\n    float random(float seed){\n      vec2 p = resultUV * seed;\n      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);\n      p3 += dot(p3, p3.yzx + 19.19);\n      return fract((p3.x + p3.y) * p3.z);\n    }\n\n    ${XN}\n    ${YN}\n    ${JN}\n  `}(l);return e.isPacked?(c=function(t,e){switch(t.length){case 0:return"\n    int getOutputCoords() {\n      return 0;\n    }\n  ";case 1:return function(t,e){const n=[Math.ceil(e[0]/2),Math.ceil(e[1]/2)];return 1===n[0]?`\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ${n[1]}.0);\n      }\n    `:1===n[1]?`\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ${n[0]}.0);\n      }\n    `:`\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${n[0]}, ${n[1]}));\n      return 2 * (resTexRC.x * ${n[1]} + resTexRC.y);\n    }\n  `}(0,e);case 2:return function(t,e){const n=[Math.ceil(e[0]/2),Math.ceil(e[1]/2)];if(O(t,e))return`\n      ivec2 getOutputCoords() {\n        return 2 * ivec2(resultUV.yx * vec2(${n[0]}, ${n[1]}));\n      }\n    `;const s=Math.ceil(t[1]/2);return`\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${n[0]}, ${n[1]}));\n\n      int index = resTexRC.x * ${n[1]} + resTexRC.y;\n      int r = 2 * (index / ${s});\n      int c = imod(index, ${s}) * 2;\n\n      return ivec2(r, c);\n    }\n  `}(t,e);case 3:return function(t,e){const n=[Math.ceil(e[0]/2),Math.ceil(e[1]/2)],s=Math.ceil(t[2]/2),r=s*Math.ceil(t[1]/2);return`\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${n[0]}, ${n[1]}));\n      int index = resTexRC.x * ${n[1]} + resTexRC.y;\n\n      int b = index / ${r};\n      index -= b * ${r};\n\n      int r = 2 * (index / ${s});\n      int c = imod(index, ${s}) * 2;\n\n      return ivec3(b, r, c);\n    }\n  `}(t,e);default:return function(t,e){const n=[Math.ceil(e[0]/2),Math.ceil(e[1]/2)],s=Math.ceil(t[t.length-1]/2),r=s*Math.ceil(t[t.length-2]/2);let a=r,i="",o="b, r, c";for(let e=2;e<t.length-1;e++)a*=t[t.length-e-1],i=`\n      int b${e} = index / ${a};\n      index -= b${e} * ${a};\n    `+i,o=`b${e}, `+o;return`\n    ivec${t.length} getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${n[0]}, ${n[1]}));\n      int index = resTexRC.x * ${n[1]} + resTexRC.y;\n\n      ${i}\n\n      int b = index / ${r};\n      index -= b * ${r};\n\n      int r = 2 * (index / ${s});\n      int c = imod(index, ${s}) * 2;\n\n      return ivec${t.length}(${o});\n    }\n  `}(t,e)}}(e.logicalShape,o),h=function(t){return`\n    void setOutput(vec4 val) {\n      ${t.output} = val;\n    }\n  `}(l)):(c=function(t,e){switch(t.length){case 0:return"\n    int getOutputCoords() {\n      return 0;\n    }\n  ";case 1:return 1===(n=e)[0]?`\n      int getOutputCoords() {\n        return int(resultUV.x * ${n[1]}.0);\n      }\n    `:1===n[1]?`\n      int getOutputCoords() {\n        return int(resultUV.y * ${n[0]}.0);\n      }\n    `:`\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${n[0]}, ${n[1]}));\n      return resTexRC.x * ${n[1]} + resTexRC.y;\n    }\n  `;case 2:return function(t,e){return O(t,e)?`\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(${e[0]}, ${e[1]}));\n      }\n    `:1===t[1]?`\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(${e[0]}, ${e[1]}));\n        int index = resTexRC.x * ${e[1]} + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    `:1===t[0]?`\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(${e[0]}, ${e[1]}));\n        int index = resTexRC.x * ${e[1]} + resTexRC.y;\n        return ivec2(0, index);\n      }\n    `:`\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${e[0]}, ${e[1]}));\n      int index = resTexRC.x * ${e[1]} + resTexRC.y;\n      int r = index / ${t[1]};\n      int c = index - r * ${t[1]};\n      return ivec2(r, c);\n    }\n  `}(t,e);case 3:return function(t,e){const n=VN(["r","c","d"],t);return`\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${e[0]}, ${e[1]}));\n      int index = resTexRC.x * ${e[1]} + resTexRC.y;\n      ${n}\n      return ivec3(r, c, d);\n    }\n  `}(t,e);case 4:return function(t,e){const n=VN(["r","c","d","d2"],t);return`\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(${e[0]}, ${e[1]}));\n      int index = resTexRC.x * ${e[1]} + resTexRC.y;\n      ${n}\n      return ivec4(r, c, d, d2);\n    }\n  `}(t,e);case 5:return function(t,e){const n=VN(["r","c","d","d2","d3"],t);return`\n    ivec5 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx * vec2(${e[0]},\n                             ${e[1]}));\n\n      int index = resTexRC.x * ${e[1]} + resTexRC.y;\n\n      ${n}\n\n      ivec5 outShape = ivec5(r, c, d, d2, d3);\n      return outShape;\n    }\n  `}(t,e);case 6:return function(t,e){const n=VN(["r","c","d","d2","d3","d4"],t);return`\n    ivec6 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(${e[0]}, ${e[1]}));\n      int index = resTexRC.x * ${e[1]} + resTexRC.y;\n\n      ${n}\n\n      ivec6 result = ivec6(r, c, d, d2, d3, d4);\n      return result;\n    }\n  `}(t,e);default:throw new Error(t.length+"-D output sampling is not yet supported")}var n}(e.logicalShape,o),h=function(t){return`\n    void setOutput(float val) {\n      ${t.output} = vec4(val, 0, 0, 0);\n    }\n  `}(l)),s&&(p+=ZN),[p,u,h,a,c,i,n].join("\n")}function qN(t){const e=t.shapeInfo.logicalShape;switch(e.length){case 0:return function(t){const e=t.name,n="get"+e.charAt(0).toUpperCase()+e.slice(1);if(t.shapeInfo.isUniform)return`float ${n}() {return ${e};}`;const[s,r]=t.shapeInfo.texShape;if(1===s&&1===r)return`\n      float ${n}() {\n        return sampleTexture(${e}, halfCR);\n      }\n    `;const[a,i]=t.shapeInfo.texShape;return`\n    float ${n}() {\n      vec2 uv = uvFromFlat(${a}, ${i}, ${QN(e)});\n      return sampleTexture(${e}, uv);\n    }\n  `}(t);case 1:return function(t){const e=t.name,n="get"+e.charAt(0).toUpperCase()+e.slice(1);if(t.shapeInfo.isUniform)return`\n      float ${n}(int index) {\n        ${tI(t)}\n      }\n    `;const s=t.shapeInfo.texShape,r=s[0],a=s[1];if(1===a&&1===r)return`\n      float ${n}(int index) {\n        return sampleTexture(${e}, halfCR);\n      }\n    `;const i=QN(e);return 1===a?`\n      float ${n}(int index) {\n        vec2 uv = vec2(0.5, (float(index + ${i}) + 0.5) / ${r}.0);\n        return sampleTexture(${e}, uv);\n      }\n    `:1===r?`\n      float ${n}(int index) {\n        vec2 uv = vec2((float(index + ${i}) + 0.5) / ${a}.0, 0.5);\n        return sampleTexture(${e}, uv);\n      }\n    `:`\n    float ${n}(int index) {\n      vec2 uv = uvFromFlat(${r}, ${a}, index + ${i});\n      return sampleTexture(${e}, uv);\n    }\n  `}(t);case 2:return function(t){const e=t.shapeInfo.logicalShape,n=t.name,s="get"+n.charAt(0).toUpperCase()+n.slice(1),r=t.shapeInfo.texShape;if(null!=r&&O(e,r)){const t=r[0];return`\n    float ${s}(int row, int col) {\n      vec2 uv = (vec2(col, row) + halfCR) / vec2(${r[1]}.0, ${t}.0);\n      return sampleTexture(${n}, uv);\n    }\n  `}const{newShape:a,keptDims:i}=V(e),o=a;if(o.length<e.length){const e=["row","col"];return`\n      ${qN(nI(t,o))}\n      float ${s}(int row, int col) {\n        return ${s}(${sI(e,i)});\n      }\n    `}if(t.shapeInfo.isUniform)return`\n      float ${s}(int row, int col) {\n        int index = round(dot(vec2(row, col), vec2(${e[1]}, 1)));\n        ${tI(t)}\n      }\n    `;const l=r[0],u=r[1],c=QN(n);return 1===u?`\n    float ${s}(int row, int col) {\n      float index = dot(vec3(row, col, ${c}), vec3(${e[1]}, 1, 1));\n      vec2 uv = vec2(0.5, (index + 0.5) / ${l}.0);\n      return sampleTexture(${n}, uv);\n    }\n  `:1===l?`\n    float ${s}(int row, int col) {\n      float index = dot(vec3(row, col, ${c}), vec3(${e[1]}, 1, 1));\n      vec2 uv = vec2((index + 0.5) / ${u}.0, 0.5);\n      return sampleTexture(${n}, uv);\n    }\n  `:`\n  float ${s}(int row, int col) {\n    // Explicitly use integer operations as dot() only works on floats.\n    int index = row * ${e[1]} + col + ${c};\n    vec2 uv = uvFromFlat(${l}, ${u}, index);\n    return sampleTexture(${n}, uv);\n  }\n`}(t);case 3:return function(t){const e=t.shapeInfo.logicalShape,n=t.name,s="get"+n.charAt(0).toUpperCase()+n.slice(1),r=e[1]*e[2],a=e[2],{newShape:i,keptDims:o}=V(e),l=i;if(l.length<e.length){const e=["row","col","depth"];return`\n        ${qN(nI(t,l))}\n        float ${s}(int row, int col, int depth) {\n          return ${s}(${sI(e,o)});\n        }\n      `}if(t.shapeInfo.isUniform)return`\n      float ${s}(int row, int col, int depth) {\n        int index = round(dot(vec3(row, col, depth),\n                          vec3(${r}, ${a}, 1)));\n        ${tI(t)}\n      }\n    `;const u=t.shapeInfo.texShape,c=u[0],h=u[1],p=t.shapeInfo.flatOffset;if(h===r&&null==p)return`\n        float ${s}(int row, int col, int depth) {\n          float texR = float(row);\n          float texC = dot(vec2(col, depth), vec2(${a}, 1));\n          vec2 uv = (vec2(texC, texR) + halfCR) /\n                     vec2(${h}.0, ${c}.0);\n          return sampleTexture(${n}, uv);\n        }\n      `;if(h===a&&null==p)return`\n    float ${s}(int row, int col, int depth) {\n      float texR = dot(vec2(row, col), vec2(${e[1]}, 1));\n      float texC = float(depth);\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${h}.0, ${c}.0);\n      return sampleTexture(${n}, uv);\n    }\n  `;return`\n      float ${s}(int row, int col, int depth) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ${r} + col * ${a} + depth + ${QN(n)};\n        vec2 uv = uvFromFlat(${c}, ${h}, index);\n        return sampleTexture(${n}, uv);\n      }\n  `}(t);case 4:return function(t){const e=t.shapeInfo.logicalShape,n=t.name,s="get"+n.charAt(0).toUpperCase()+n.slice(1),r=e[3],a=e[2]*r,i=e[1]*a,{newShape:o,keptDims:l}=V(e);if(o.length<e.length){const e=["row","col","depth","depth2"];return`\n      ${qN(nI(t,o))}\n      float ${s}(int row, int col, int depth, int depth2) {\n        return ${s}(${sI(e,l)});\n      }\n    `}if(t.shapeInfo.isUniform)return`\n      float ${s}(int row, int col, int depth, int depth2) {\n        int index = round(dot(vec4(row, col, depth, depth2),\n                          vec4(${i}, ${a}, ${r}, 1)));\n        ${tI(t)}\n      }\n    `;const u=t.shapeInfo.flatOffset,c=t.shapeInfo.texShape,h=c[0],p=c[1];if(p===i&&null==u)return`\n      float ${s}(int row, int col, int depth, int depth2) {\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(${a}, ${r}, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${p}.0, ${h}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;if(p===r&&null==u)return`\n      float ${s}(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(${e[1]*e[2]}, ${e[2]}, 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${p}.0, ${h}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;return`\n    float ${s}(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${i} + col * ${a} +\n          depth * ${r} + depth2;\n      vec2 uv = uvFromFlat(${h}, ${p}, index + ${QN(n)});\n      return sampleTexture(${n}, uv);\n    }\n  `}(t);case 5:return function(t){const e=t.shapeInfo.logicalShape,n=t.name,s="get"+n.charAt(0).toUpperCase()+n.slice(1),r=e[4],a=e[3]*r,i=e[2]*a,o=e[1]*i,{newShape:l,keptDims:u}=V(e);if(l.length<e.length){const e=["row","col","depth","depth2","depth3"];return`\n      ${qN(nI(t,l))}\n      float ${s}(int row, int col, int depth, int depth2, int depth3) {\n        return ${s}(${sI(e,u)});\n      }\n    `}if(t.shapeInfo.isUniform)return`\n      float ${s}(int row, int col, int depth, int depth2, int depth3) {\n        float index = dot(\n          vec4(row, col, depth, depth2),\n          vec4(${o}, ${i}, ${a}, ${r})) +\n          depth3;\n        ${tI(t)}\n      }\n    `;const c=t.shapeInfo.flatOffset,h=t.shapeInfo.texShape,p=h[0],d=h[1];if(d===o&&null==c)return`\n      float ${s}(int row, int col, int depth, int depth2, int depth3) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n                         vec4(${i}, ${a}, ${r}, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${d}.0, ${p}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;if(d===r&&null==c)return`\n      float ${s}(int row, int col, int depth, int depth2, int depth3) {\n        float texR = dot(\n          vec4(row, col, depth, depth2),\n          vec4(${e[1]*e[2]*e[3]},\n               ${e[2]*e[3]}, ${e[3]}, 1));\n        int texC = depth3;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${d}.0, ${p}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;return`\n    float ${s}(int row, int col, int depth, int depth2, int depth3) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${o} + col * ${i} + depth * ${a} +\n          depth2 * ${r} + depth3 + ${QN(n)};\n      vec2 uv = uvFromFlat(${p}, ${d}, index);\n      return sampleTexture(${n}, uv);\n    }\n  `}(t);case 6:return function(t){const e=t.shapeInfo.logicalShape,n=t.name,s="get"+n.charAt(0).toUpperCase()+n.slice(1),{newShape:r,keptDims:a}=V(e);if(r.length<e.length){const e=["row","col","depth","depth2","depth3","depth4"];return`\n      ${qN(nI(t,r))}\n      float ${s}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        return ${s}(${sI(e,a)});\n      }\n    `}const i=e[5],o=e[4]*i,l=e[3]*o,u=e[2]*l,c=e[1]*u;if(t.shapeInfo.isUniform)return`\n      float ${s}(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n        int index = round(dot(\n          vec4(row, col, depth, depth2),\n          vec4(${c}, ${u}, ${l}, ${o})) +\n          dot(\n            vec2(depth3, depth4),\n            vec2(${i}, 1)));\n        ${tI(t)}\n      }\n    `;const h=t.shapeInfo.flatOffset,p=t.shapeInfo.texShape,d=p[0],f=p[1];if(f===c&&null==h)return`\n      float ${s}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n          vec4(${u}, ${l}, ${o}, ${i})) +\n               float(depth4);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${f}.0, ${d}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;if(f===i&&null==h)return`\n      float ${s}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        float texR = dot(vec4(row, col, depth, depth2),\n          vec4(${e[1]*e[2]*e[3]*e[4]},\n               ${e[2]*e[3]*e[4]},\n               ${e[3]*e[4]},\n               ${e[4]})) + float(depth3);\n        int texC = depth4;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${f}.0, ${d}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;return`\n    float ${s}(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${c} + col * ${u} + depth * ${l} +\n          depth2 * ${o} + depth3 * ${i} + depth4 + ${QN(n)};\n      vec2 uv = uvFromFlat(${d}, ${f}, index);\n      return sampleTexture(${n}, uv);\n    }\n  `}(t);default:throw new Error(e.length+"-D input sampling is not yet supported")}}function KN(t){switch(t.shapeInfo.logicalShape.length){case 0:return function(t){const e=t.name;return`\n    vec4 ${"get"+e.charAt(0).toUpperCase()+e.slice(1)}() {\n      return ${WN().texture2D}(${e}, halfCR);\n    }\n  `}(t);case 1:return function(t){const e=t.name,n="get"+e.charAt(0).toUpperCase()+e.slice(1),s=t.shapeInfo.texShape,r=[Math.ceil(s[0]/2),Math.ceil(s[1]/2)],a=WN();return`\n    vec4 ${n}(int index) {\n      vec2 uv = packedUVfrom1D(\n        ${r[0]}, ${r[1]}, index);\n      return ${a.texture2D}(${e}, uv);\n    }\n  `}(t);case 2:return function(t){const e=t.shapeInfo.logicalShape,n=t.name,s="get"+n.charAt(0).toUpperCase()+n.slice(1),r=t.shapeInfo.texShape,a=r[0],i=r[1],o=WN();if(null!=r&&O(e,r))return`\n      vec4 ${s}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${i}.0, ${a}.0);\n\n        return ${o.texture2D}(${n}, uv);\n      }\n    `;const l=[Math.ceil(r[0]/2),Math.ceil(r[1]/2)];return`\n    vec4 ${s}(int row, int col) {\n      vec2 uv = packedUVfrom2D(${Math.ceil(e[1]/2)}, ${l[0]}, ${l[1]}, row, col);\n      return ${o.texture2D}(${n}, uv);\n    }\n  `}(t);case 3:return function(t){const e=t.shapeInfo.logicalShape,n=t.name,s="get"+n.charAt(0).toUpperCase()+n.slice(1),r=t.shapeInfo.texShape,a=[Math.ceil(r[0]/2),Math.ceil(r[1]/2)];if(1===e[0]){const n=[1,2],r=["b","row","col"];return`\n        ${KN(nI(t,e.slice(1)))}\n        vec4 ${s}(int b, int row, int col) {\n          return ${s}(${sI(r,n)});\n        }\n      `}const i=a[0],o=a[1],l=Math.ceil(e[2]/2);return`\n    vec4 ${s}(int b, int row, int col) {\n      vec2 uv = packedUVfrom3D(\n        ${i}, ${o}, ${l*Math.ceil(e[1]/2)}, ${l}, b, row, col);\n      return ${WN().texture2D}(${n}, uv);\n    }\n  `}(t);default:return function(t){const e=t.shapeInfo.logicalShape,n=e.length,s=t.name,r="get"+s.charAt(0).toUpperCase()+s.slice(1),a=t.shapeInfo.texShape,i=[Math.ceil(a[0]/2),Math.ceil(a[1]/2)],o=i[0],l=i[1],u=Math.ceil(e[n-1]/2);let c=u*Math.ceil(e[n-2]/2),h="int b, int row, int col",p=`b * ${c} + (row / 2) * ${u} + (col / 2)`;for(let t=2;t<n-1;t++)h=`int b${t}, `+h,c*=e[n-t-1],p=`b${t} * ${c} + `+p;return`\n    vec4 ${r}(${h}) {\n      int index = ${p};\n      int texR = index / ${l};\n      int texC = index - texR * ${l};\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${l}, ${o});\n      return ${WN().texture2D}(${s}, uv);\n    }\n  `}(t)}}const XN="\nvec2 uvFromFlat(int texNumR, int texNumC, int index) {\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\nvec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\n  int texelIndex = index / 2;\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",YN="\nvec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,\n  int texNumC, int row, int col) {\n  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",JN="\nvec2 packedUVfrom3D(int texNumR, int texNumC,\n    int texelsInBatch, int texelsInLogicalRow, int b,\n    int row, int col) {\n  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",ZN="\n  float getChannel(vec4 frag, vec2 innerDims) {\n    vec2 modCoord = mod(innerDims, 2.);\n    return modCoord.x == 0. ?\n      (modCoord.y == 0. ? frag.r : frag.g) :\n      (modCoord.y == 0. ? frag.b : frag.a);\n  }\n  float getChannel(vec4 frag, int dim) {\n    float modCoord = mod(float(dim), 2.);\n    return modCoord == 0. ? frag.r : frag.g;\n  }\n";function QN(t){return"offset"+t}function tI(t){const e=t.name,n=_(t.shapeInfo.logicalShape);return n<2?`return ${e};`:`\n    for (int i = 0; i < ${n}; i++) {\n      if (i == index) {\n        return ${e}[i];\n      }\n    }\n  `}function eI(t){if(t<=1)return"int";if(2===t)return"ivec2";if(3===t)return"ivec3";if(4===t)return"ivec4";if(5===t)return"ivec5";if(6===t)return"ivec6";throw Error(`GPU for rank ${t} is not yet supported`)}function nI(t,e){const n=JSON.parse(JSON.stringify(t));return n.shapeInfo.logicalShape=e,n}function sI(t,e){return e.map((e=>t[e])).join(", ")}class rI{constructor(t,e,n,s){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,A(t.length>2,(()=>`Packed arg${n.charAt(0).toUpperCase()+n.slice(1)} supports only inputs with rank above 2.`));const r=t[t.length-1],a=Math.ceil(r/e);this.outputShape=t.slice(0,-1),a>1&&this.outputShape.push(a),s||this.variableNames.push("bestIndicesA");const i=this.outputShape,o=i.length,l=eI(o),u=PN("coords",o);let c,h;if(1===a){h=o+1;const t=eI(h);c=`\n        ${t} sourceLocR = ${t}(${u.join()}, 0);\n        ++${u[o-1]};\n        ${t} sourceLocG = ${t}(${u.join()}, 0);\n        ++${u[o-2]};\n        ${t} sourceLocA = ${t}(${u.join()}, 0);\n        --${u[o-1]};\n        ${t} sourceLocB = ${t}(${u.join()}, 0);\n        --${u[o-2]};`}else h=o,c=`\n        ${l} sourceLocR = coords;\n        ++${u[o-1]};\n        ${l} sourceLocG = coords;\n        ++${u[o-2]};\n        ${l} sourceLocA = coords;\n        --${u[o-1]};\n        ${l} sourceLocB = coords;\n        --${u[o-2]};`;const p=["x","y","z","w","u","v"].slice(0,h),d="."+p[h-1],f=p.map((t=>"int "+t)),m=PN("sourceLocR",h-1).concat("inIdx.r"),g=PN("sourceLocG",h-1).concat("inIdx.g"),y=PN("sourceLocB",h-1).concat("inIdx.b"),b=PN("sourceLocA",h-1).concat("inIdx.a"),x="max"===n?"greaterThan":"lessThan",w=s?"":`\n          inIdx = round(vec4(getBestIndicesAChannel(${m.join()}),\n                             getBestIndicesAChannel(${g.join()}),\n                             getBestIndicesAChannel(${y.join()}),\n                             getBestIndicesAChannel(${b.join()})));`,v=`vec4(\n            getAChannel(${m.join()}),\n            hasNextCol ? getAChannel(${g.join()}) : 0.,\n            hasNextRow ? getAChannel(${y.join()}) : 0.,\n            hasNextRow && hasNextCol ? getAChannel(${b.join()}) : 0.)`,k=s?"":`\n      float getBestIndicesAChannel(${f.join()}) {\n        return getChannel(getBestIndicesA(${p.join()}),\n                                          vec2(${p.slice(-2).join()}));\n      }`;this.userCode=`\n      float getAChannel(${f.join()}) {\n        return getChannel(getA(${p.join()}),\n                               vec2(${p.slice(-2).join()}));\n      }\n      ${k}\n      void main() {\n        ${l} coords = getOutputCoords();\n        bool hasNextCol = ${u[o-1]} < ${i[o-1]-1};\n        bool hasNextRow = ${u[o-2]} < ${i[o-2]-1};\n        ${c}\n        ivec4 srcIdx = ivec4(sourceLocR${d}, sourceLocG${d},\n          sourceLocB${d}, sourceLocA${d}) * ${e};\n        ivec4 inIdx = srcIdx;\n        vec4 bestIndex = vec4(inIdx);\n        vec4 bestValue = ${v};\n\n        for (int i = 0; i < ${e}; i++) {\n          inIdx = srcIdx;\n          ${w}\n          vec4 candidate = ${v};\n          bvec4 nan = isnan(candidate);\n          bvec4 replace = bvec4(\n            vec4(${x}(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));\n\n          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,\n                           replace.y  ? candidate.y : bestValue.y,\n                           replace.z  ? candidate.z : bestValue.z,\n                           replace.w  ? candidate.w : bestValue.w);\n          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));\n          srcIdx++;\n        }\n        setOutput(bestIndex);\n      }\n    `}}class aI{constructor(t){this.variableNames=["dy"],this.outputShape=t.inShape;const e=t.filterHeight,n=t.filterWidth,s=t.strideHeight,r=t.strideWidth,a=t.dilationHeight,i=t.dilationWidth,o=t.effectiveFilterHeight,l=t.effectiveFilterWidth,u=o-1-t.padInfo.top,c=l-1-t.padInfo.left,h=1/(e*n);this.userCode=`\n      const ivec2 pads = ivec2(${u}, ${c});\n      const float avgMultiplier = float(${h});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${o};\n            wR += ${a}) {\n          float dyR = float(dyRCorner + wR) / ${s}.0;\n\n          if (dyR < 0.0 || dyR >= ${t.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ${l};\n            wC+= ${i}) {\n            float dyC = float(dyCCorner + wC) / ${r}.0;\n\n            if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n\n            dotProd += dyValue * avgMultiplier;\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class iI{constructor(t){this.variableNames=["dy"],this.outputShape=t.inShape;const e=t.filterDepth,n=t.filterHeight,s=t.filterWidth,r=t.strideDepth,a=t.strideHeight,i=t.strideWidth,o=t.dilationDepth,l=t.dilationHeight,u=t.dilationWidth,c=t.effectiveFilterDepth,h=t.effectiveFilterHeight,p=t.effectiveFilterWidth,d=c-1-t.padInfo.front,f=h-1-t.padInfo.top,m=p-1-t.padInfo.left,g=1/(e*n*s);this.userCode=`\n      const ivec3 pads = ivec3(${d}, ${f}, ${m});\n      const float avgMultiplier = float(${g});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ${c};\n            wD += ${o}) {\n          float dyD = float(dyDCorner + wD) / ${r}.0;\n\n          if (dyD < 0.0 || dyD >= ${t.outDepth}.0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ${h};\n              wR += ${l}) {\n            float dyR = float(dyRCorner + wR) / ${a}.0;\n\n            if (dyR < 0.0 || dyR >= ${t.outHeight}.0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ${p};\n                wC += ${u}) {\n              float dyC = float(dyCCorner + wC) / ${i}.0;\n\n              if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n\n              dotProd += dyValue * avgMultiplier;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}const oI="return (a < 0.) ? b * a : a;";class lI{constructor(t,e,n){this.variableNames=["A","B"],this.outputShape=Xa(e,n),this.userCode=`\n      float binaryOperation(float a, float b) {\n        ${t}\n      }\n\n      void main() {\n        float a = getAAtOutCoords();\n        float b = getBAtOutCoords();\n        setOutput(binaryOperation(a, b));\n      }\n    `}}const uI="\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n";class cI{constructor(t,e,n,s=!1){this.variableNames=["A","B"],this.supportsBroadcasting=!0,this.packedInputs=!0,this.packedOutput=!0,this.outputShape=Xa(e,n);const r=this.outputShape.length;let a="";if(s)if(0===r||1===_(this.outputShape))a="\n          result.y = 0.;\n          result.z = 0.;\n          result.w = 0.;\n        ";else if(a=`\n          ${eI(r)} coords = getOutputCoords();\n        `,1===r)a+=`\n            result.y = (coords + 1) >= ${this.outputShape[0]} ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          `;else{const t=PN("coords",r);a+=`\n            bool nextRowOutOfBounds =\n              (${t[r-2]} + 1) >= ${this.outputShape[r-2]};\n            bool nextColOutOfBounds =\n              (${t[r-1]} + 1) >= ${this.outputShape[r-1]};\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          `}this.userCode=`\n      vec4 binaryOperation(vec4 a, vec4 b) {\n        ${t}\n      }\n\n      void main() {\n        vec4 a = getAAtOutCoords();\n        vec4 b = getBAtOutCoords();\n\n        vec4 result = binaryOperation(a, b);\n        ${a}\n\n        setOutput(result);\n      }\n    `}}class hI{constructor(t){this.variableNames=["A"],this.outputShape=t,this.userCode="\n      uniform float minVal;\n      uniform float maxVal;\n\n      void main() {\n        float value = getAAtOutCoords();\n        if (isnan(value)) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, minVal, maxVal));\n      }\n    "}getCustomSetupFunc(t,e){return(n,s)=>{null==this.minLoc&&(this.minLoc=n.getUniformLocationNoThrow(s,"minVal"),this.maxLoc=n.getUniformLocationNoThrow(s,"maxVal")),n.gl.uniform1f(this.minLoc,t),n.gl.uniform1f(this.maxLoc,e)}}}class pI{constructor(t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=t,this.userCode="\n      uniform float minVal;\n      uniform float maxVal;\n\n      void main() {\n        vec4 value = getAAtOutCoords();\n\n        if (any(isnan(value))) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));\n      }\n    "}getCustomSetupFunc(t,e){return(n,s)=>{null==this.minLoc&&(this.minLoc=n.getUniformLocationNoThrow(s,"minVal"),this.maxLoc=n.getUniformLocationNoThrow(s,"maxVal")),n.gl.uniform1f(this.minLoc,t),n.gl.uniform1f(this.maxLoc,e)}}}class dI{constructor(t){this.variableNames=["real","imag"],this.outputShape=t,this.userCode="\n      void main() {\n        float re = abs(getRealAtOutCoords());\n        float im = abs(getImagAtOutCoords());\n        float mx = max(re, im);\n\n        // sadly the length function in glsl is not underflow-safe\n        // (at least not on Intel GPUs). So the safe solution is\n        // to ensure underflow-safety in all cases.\n        setOutput(\n          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))\n        );\n      }\n    "}}class fI{constructor(t){this.variableNames=["x","dy"],this.outputShape=t.filterShape;const e=t.strideHeight,n=t.strideWidth,s=t.padInfo.top,r=t.padInfo.left,a="channelsLast"===t.dataFormat;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int d2 = coords.w;\n\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ${t.batchSize}; b++) {\n          for (int yR = 0; yR < ${t.outHeight}; yR++) {\n            int xR = wR + yR * ${e} - ${s};\n\n            if (xR < 0 || xR >= ${t.inHeight}) {\n              continue;\n            }\n\n            for (int yC = 0; yC < ${t.outWidth}; yC++) {\n              int xC = wC + yC * ${n} - ${r};\n\n              if (xC < 0 || xC >= ${t.inWidth}) {\n                continue;\n              }\n\n              if (${a}) {\n                float dyValue = getDy(b, yR, yC, d2);\n                float xValue = getX(b, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              } else {\n                float dyValue = getDy(b, d2, yR, yC);\n                float xValue = getX(b, d1, xR, xC);\n                dotProd += (xValue * dyValue);\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class mI{constructor(t){this.variableNames=["dy","W"],this.outputShape=t.inShape;const e=t.filterHeight,n=t.filterWidth,s=t.strideHeight,r=t.strideWidth,a="channelsLast"===t.dataFormat,i=e-1-t.padInfo.top,o=n-1-t.padInfo.left,l=a?1:2,u=a?2:3,c=a?3:1;this.userCode=`\n      const ivec2 pads = ivec2(${i}, ${o});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[${c}];\n\n        ivec2 dyCorner = ivec2(coords[${l}], coords[${u}]) - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${e}; wR++) {\n          float dyR = float(dyRCorner + wR) / ${s}.0;\n\n          if (dyR < 0.0 || dyR >= ${t.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ${e} - 1 - wR;\n\n          for (int wC = 0; wC < ${n}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${r}.0;\n\n            if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ${n} - 1 - wC;\n\n            for (int d2 = 0; d2 < ${t.outChannels}; d2++) {\n\n              if (${a}) {\n                float xValue = getDy(batch, idyR, idyC, d2);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              } else {\n                float xValue = getDy(batch, d2, idyR, idyC);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class gI{constructor(t){this.variableNames=["x","dy"],this.outputShape=t.filterShape;const e=t.strideDepth,n=t.strideHeight,s=t.strideWidth,r=t.padInfo.front,a=t.padInfo.top,i=t.padInfo.left;this.userCode=`\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int wF = coords.x;\n        int wR = coords.y;\n        int wC = coords.z;\n        int d1 = coords.w;\n        int d2 = coords.u;\n\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ${t.batchSize}; b++) {\n          for (int yF = 0; yF < ${t.outDepth}; yF++) {\n            int xF = wF + yF * ${e} - ${r};\n\n            if (xF < 0 || xF >= ${t.inDepth}) {\n              continue;\n            }\n\n            for (int yR = 0; yR < ${t.outHeight}; yR++) {\n              int xR = wR + yR * ${n} - ${a};\n\n              if (xR < 0 || xR >= ${t.inHeight}) {\n                continue;\n              }\n\n              for (int yC = 0; yC < ${t.outWidth}; yC++) {\n                int xC = wC + yC * ${s} - ${i};\n\n                if (xC < 0 || xC >= ${t.inWidth}) {\n                  continue;\n                }\n\n                float dyValue = getDy(b, yF, yR, yC, d2);\n                float xValue = getX(b, xF, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class yI{constructor(t){this.variableNames=["dy","W"],this.outputShape=t.inShape;const e=t.filterDepth,n=t.filterHeight,s=t.filterWidth,r=t.strideDepth,a=t.strideHeight,i=t.strideWidth,o=e-1-t.padInfo.front,l=n-1-t.padInfo.top,u=s-1-t.padInfo.left;this.userCode=`\n      const ivec3 pads = ivec3(${o}, ${l}, ${u});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.u;\n\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyFCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ${e}; wF++) {\n          float dyF = float(dyFCorner + wF) / ${r}.0;\n\n          if (dyF < 0.0 || dyF >= ${t.outDepth}.0 || fract(dyF) > 0.0) {\n            continue;\n          }\n          int idyF = int(dyF);\n\n          int wFPerm = ${e} - 1 - wF;\n\n          for (int wR = 0; wR < ${n}; wR++) {\n            float dyR = float(dyRCorner + wR) / ${a}.0;\n\n            if (dyR < 0.0 || dyR >= ${t.outHeight}.0 ||\n              fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            int wRPerm = ${n} - 1 - wR;\n\n            for (int wC = 0; wC < ${s}; wC++) {\n              float dyC = float(dyCCorner + wC) / ${i}.0;\n\n              if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              int wCPerm = ${s} - 1 - wC;\n\n              for (int d2 = 0; d2 < ${t.outChannels}; d2++) {\n                float xValue = getDy(batch, idyF, idyR, idyC, d2);\n                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class bI{constructor(t){this.variableNames=["x","dy"],this.outputShape=t.filterShape;const e=t.strideHeight,n=t.strideWidth,s=t.padInfo.top,r=t.padInfo.left,a=t.outChannels/t.inChannels;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int dm = coords.w;\n        int d2 = d1 * ${a} + dm;\n\n        float dotProd = 0.0;\n\n        // TO DO: Vec4 over the batch size\n        for (int b = 0; b < ${t.batchSize}; b++) {\n          for (int yR = 0; yR < ${t.outHeight}; yR++) {\n            int xR = wR + yR * ${e} - ${s};\n\n            if (xR < 0 || xR >= ${t.inHeight}) {\n              continue;\n            }\n\n            for (int yC = 0; yC < ${t.outWidth}; yC++) {\n              int xC = wC + yC * ${n} - ${r};\n\n              if (xC < 0 || xC >= ${t.inWidth}) {\n                continue;\n              }\n\n              float dyValue = getDy(b, yR, yC, d2);\n              float xValue = getX(b, xR, xC, d1);\n              dotProd += (xValue * dyValue);\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class xI{constructor(t){this.variableNames=["dy","W"],this.outputShape=t.inShape;const e=t.filterHeight,n=t.filterWidth,s=t.strideHeight,r=t.strideWidth,a=e-1-t.padInfo.top,i=n-1-t.padInfo.left,o=t.outChannels/t.inChannels;this.userCode=`\n      const ivec2 pads = ivec2(${a}, ${i});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[3];\n        ivec2 dyCorner = coords.yz - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        float dotProd = 0.0;\n\n        for (int wR = 0; wR < ${e}; wR++) {\n          float dyR = float(dyRCorner + wR) / ${s}.0;\n\n          if (dyR < 0.0 || dyR >= ${t.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ${e} - 1 - wR;\n\n          for (int wC = 0; wC < ${n}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${r}.0;\n\n            if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ${n} - 1 - wC;\n\n            // TO DO: Vec4 over the channelMul\n            for (int dm = 0; dm < ${o}; dm++) {\n              int d2 = d1 * ${o} + dm;\n              float xValue = getDy(batch, idyR, idyC, d2);\n              float wValue = getW(wRPerm, wCPerm, d1, dm);\n              dotProd += xValue * wValue;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class wI{constructor(t,e=!1,n=null,s=!1){this.variableNames=["x","W"],this.outputShape=t.outShape;const r=t.padInfo.top,a=t.padInfo.left,i=t.strideHeight,o=t.strideWidth,l=t.dilationHeight,u=t.dilationWidth,c=t.filterHeight,h=t.filterWidth,p=4*Math.floor(t.inChannels/4),d=t.inChannels%4,f="channelsLast"===t.dataFormat,m=f?1:2,g=f?2:3,y=f?3:1;let b="",x="";n&&(b=s?`float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }`:`\n          float activation(float x) {\n            ${n}\n          }\n        `,x="result = activation(result);");const w=e?"result += getBiasAtOutCoords();":"";e&&this.variableNames.push("bias"),s&&this.variableNames.push("preluActivationWeights"),this.userCode=`\n      ${b}\n\n      const ivec2 strides = ivec2(${i}, ${o});\n      const ivec2 pads = ivec2(${r}, ${a});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d2 = coords[${y}];\n\n        ivec2 xRCCorner =\n            ivec2(coords[${m}], coords[${g}]) * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${c}; wR++) {\n          int xR = xRCorner + wR * ${l};\n\n          if (xR < 0 || xR >= ${t.inHeight}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${h}; wC++) {\n            int xC = xCCorner + wC * ${u};\n\n            if (xC < 0 || xC >= ${t.inWidth}) {\n              continue;\n            }\n\n            for (int d1 = 0; d1 < ${p}; d1 += 4) {\n              vec4 wValues = vec4(\n                getW(wR, wC, d1, d2),\n                getW(wR, wC, d1 + 1, d2),\n                getW(wR, wC, d1 + 2, d2),\n                getW(wR, wC, d1 + 3, d2)\n              );\n\n              if (${f}) {\n                vec4 xValues = vec4(\n                  getX(batch, xR, xC, d1),\n                  getX(batch, xR, xC, d1 + 1),\n                  getX(batch, xR, xC, d1 + 2),\n                  getX(batch, xR, xC, d1 + 3)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec4 xValues = vec4(\n                  getX(batch, d1, xR, xC),\n                  getX(batch, d1 + 1, xR, xC),\n                  getX(batch, d1 + 2, xR, xC),\n                  getX(batch, d1 + 3, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n\n            if (${1===d}) {\n\n              if (${f}) {\n                dotProd +=\n                    getX(batch, xR, xC, ${p}) *\n                    getW(wR, wC, ${p}, d2);\n              } else {\n                dotProd +=\n                    getX(batch, ${p}, xR, xC) *\n                    getW(wR, wC, ${p}, d2);\n              }\n\n            } else if (${2===d}) {\n              vec2 wValues = vec2(\n                getW(wR, wC, ${p}, d2),\n                getW(wR, wC, ${p} + 1, d2)\n              );\n\n              if (${f}) {\n                vec2 xValues = vec2(\n                  getX(batch, xR, xC, ${p}),\n                  getX(batch, xR, xC, ${p} + 1)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec2 xValues = vec2(\n                  getX(batch, ${p}, xR, xC),\n                  getX(batch, ${p} + 1, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            } else if (${3===d}) {\n              vec3 wValues = vec3(\n                getW(wR, wC, ${p}, d2),\n                getW(wR, wC, ${p} + 1, d2),\n                getW(wR, wC, ${p} + 2, d2)\n              );\n\n              if (${f}) {\n                vec3 xValues = vec3(\n                  getX(batch, xR, xC, ${p}),\n                  getX(batch, xR, xC, ${p} + 1),\n                  getX(batch, xR, xC, ${p} + 2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec3 xValues = vec3(\n                  getX(batch, ${p}, xR, xC),\n                  getX(batch, ${p} + 1, xR, xC),\n                  getX(batch, ${p} + 2, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            }\n          }\n        }\n\n        float result = dotProd;\n        ${w}\n        ${x}\n        setOutput(result);\n      }\n    `}}class vI{constructor(t){this.variableNames=["x","W"],this.outputShape=t.outShape;const e=t.padInfo.front,n=t.padInfo.top,s=t.padInfo.left,r=t.strideDepth,a=t.strideHeight,i=t.strideWidth,o=t.dilationDepth,l=t.dilationHeight,u=t.dilationWidth,c=t.filterDepth,h=t.filterHeight,p=t.filterWidth,d=4*Math.floor(t.inChannels/4),f=t.inChannels%4;this.userCode=`\n      const ivec3 strides = ivec3(${r}, ${a}, ${i});\n      const ivec3 pads = ivec3(${e}, ${n}, ${s});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d2 = coords.u;\n\n        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xFCorner = xFRCCorner.x;\n        int xRCorner = xFRCCorner.y;\n        int xCCorner = xFRCCorner.z;\n\n        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get\n        // y(yF, yR, yC, d2). ? = to be determined. : = across all\n        // values in that axis.\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ${c}; wF++) {\n          int xF = xFCorner + wF * ${o};\n\n          if (xF < 0 || xF >= ${t.inDepth}) {\n            continue;\n          }\n\n          for (int wR = 0; wR < ${h}; wR++) {\n            int xR = xRCorner + wR * ${l};\n\n            if (xR < 0 || xR >= ${t.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${p}; wC++) {\n              int xC = xCCorner + wC * ${u};\n\n              if (xC < 0 || xC >= ${t.inWidth}) {\n                continue;\n              }\n\n              for (int d1 = 0; d1 < ${d}; d1 += 4) {\n                vec4 xValues = vec4(\n                  getX(batch, xF, xR, xC, d1),\n                  getX(batch, xF, xR, xC, d1 + 1),\n                  getX(batch, xF, xR, xC, d1 + 2),\n                  getX(batch, xF, xR, xC, d1 + 3)\n                );\n                vec4 wValues = vec4(\n                  getW(wF, wR, wC, d1, d2),\n                  getW(wF, wR, wC, d1 + 1, d2),\n                  getW(wF, wR, wC, d1 + 2, d2),\n                  getW(wF, wR, wC, d1 + 3, d2)\n                );\n\n                dotProd += dot(xValues, wValues);\n              }\n\n              if (${1===f}) {\n                dotProd +=\n                  getX(batch, xF, xR, xC, ${d}) *\n                  getW(wF, wR, wC, ${d}, d2);\n              } else if (${2===f}) {\n                vec2 xValues = vec2(\n                  getX(batch, xF, xR, xC, ${d}),\n                  getX(batch, xF, xR, xC, ${d} + 1)\n                );\n                vec2 wValues = vec2(\n                  getW(wF, wR, wC, ${d}, d2),\n                  getW(wF, wR, wC, ${d} + 1, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else if (${3===f}) {\n                vec3 xValues = vec3(\n                  getX(batch, xF, xR, xC, ${d}),\n                  getX(batch, xF, xR, xC, ${d} + 1),\n                  getX(batch, xF, xR, xC, ${d} + 2)\n                );\n                vec3 wValues = vec3(\n                  getW(wF, wR, wC, ${d}, d2),\n                  getW(wF, wR, wC, ${d} + 1, d2),\n                  getW(wF, wR, wC, ${d} + 2, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class kI{constructor(t,e=!1,n=null,s=!1){this.variableNames=["x","W"],this.outputShape=t.outShape;const r=t.inHeight,a=t.inWidth,i=t.padInfo.top,o=t.padInfo.left,l=t.strideHeight,u=t.strideWidth,c=t.dilationHeight,h=t.dilationWidth,p=t.filterHeight,d=t.filterWidth,f=t.outChannels/t.inChannels;let m="",g="";n&&(m=s?`float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }`:`\n          float activation(float x) {\n            ${n}\n          }\n        `,g="result = activation(result);");const y=e?"result += getBiasAtOutCoords();":"";e&&this.variableNames.push("bias"),s&&this.variableNames.push("preluActivationWeights"),this.userCode=`\n      ${m}\n\n      const ivec2 strides = ivec2(${l}, ${u});\n      const ivec2 pads = ivec2(${i}, ${o});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${f};\n        int q = d2 - d1 * ${f};\n\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.\n        for (int wR = 0; wR < ${p}; wR++) {\n          int xR = xRCorner + wR * ${c};\n\n          if (xR < 0 || xR >= ${r}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${d}; wC++) {\n            int xC = xCCorner + wC * ${h};\n\n            if (xC < 0 || xC >= ${a}) {\n              continue;\n            }\n\n            float xVal = getX(batch, xR, xC, d1);\n            float wVal = getW(wR, wC, d1, q);\n            dotProd += xVal * wVal;\n          }\n        }\n\n        float result = dotProd;\n        ${y}\n        ${g}\n        setOutput(result);\n      }\n    `}}class NI{constructor(t,e=!1,n=null,s=!1){this.variableNames=["x","W"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=t.outShape;const r=t.inHeight,a=t.inWidth,i=t.padInfo.top,o=t.padInfo.left,l=t.strideHeight,u=t.strideWidth,c=t.dilationHeight,h=t.dilationWidth,p=t.filterHeight,d=t.filterWidth,f=d;let m="int xR; int xC; int xCOffset;";for(let t=0;t<p;t++)for(let e=0;e<d;e++)m+=`\n          vec4 xTexelR${t}C${2*e} = vec4(0.);\n          vec4 wR${t}C${e} = vec4(0.);\n          vec4 xR${t}C${e} = vec4(0.);`;for(let t=0;t<p;t++)for(let e=0;e<f;e++){const n=2*e;if(m+=`\n          xR = xRCorner + ${t*c};\n          xC = xCCorner + ${n*h};\n        `,1===u){if(n<d&&(m+=o%2==1?`\n                xCOffset = xC + 1;\n                if(xR >= 0 && xR < ${r} && xCOffset >= 0 && xCOffset < ${a}) {\n                  xTexelR${t}C${n} = getX(batch, xR, xCOffset, d1);\n\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if(xCOffset + 1 >= ${a}) {\n                    xTexelR${t}C${n}.zw = vec2(0.);\n                  }\n                } else {\n                  xTexelR${t}C${n} = vec4(0.);\n                }\n\n                xCOffset = xC + 1 - 2;\n                if(xR >= 0 && xR < ${r} && xCOffset >= 0 && xCOffset < ${a}) {\n                  vec4 previous = getX(batch, xR, xCOffset, d1);\n\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if(xCOffset + 1 >= ${a}) {\n                    previous.zw = vec2(0.);\n                  }\n\n                  xR${t}C${n} = vec4(previous.zw, xTexelR${t}C${n}.xy);\n                } else {\n                  xR${t}C${n} = vec4(0, 0, xTexelR${t}C${n}.xy);\n                }\n              `:`\n                if(xR >= 0 && xR < ${r} && xC >= 0 && xC < ${a}) {\n                  xTexelR${t}C${n} = getX(batch, xR, xC, d1);\n                } else {\n                  xTexelR${t}C${n} = vec4(0.);\n                }\n\n                xR${t}C${n} = xTexelR${t}C${n};\n              `,n+1<d)){const e=o%2==0?E(h):h;h%2==0&&o%2==1||h%2!=0&&o%2!=1?(m+=`\n                  xCOffset = xC + ${o%2} + ${e};\n\n                  if(xR >= 0 && xR < ${r} &&\n                    xCOffset >= 0 && xCOffset < ${a}) {\n                    xTexelR${t}C${n+2} = getX(batch, xR, xCOffset, d1);\n                  }\n                `,h>1&&(m+=`\n                    xCOffset -= 2;\n                    if(xR >= 0 && xR < ${r} &&\n                      xCOffset >= 0 && xCOffset < ${a}) {\n                      xTexelR${t}C${n} = getX(batch, xR, xCOffset, d1);\n                    } else {\n                      xTexelR${t}C${n} = vec4(0.);\n                    }\n                  `),m+=`\n                  xR${t}C${n+1} = vec4(\n                    xTexelR${t}C${n}.zw, xTexelR${t}C${n+2}.xy);\n                `):m+=`\n                  xCOffset = xC + ${e};\n\n                  if(xR >= 0 && xR < ${r} &&\n                    xCOffset >= 0 && xCOffset < ${a}) {\n                    xTexelR${t}C${n+2} = getX(batch, xR, xCOffset, d1);\n                  }\n\n                  xR${t}C${n+1} = xTexelR${t}C${n+2};\n                `}}else n<d&&(m+=`\n              if(xR >= 0 && xR < ${r}) {\n            `,o%2==1?(m+=`\n                xCOffset = xC + 1 - ${u};\n                if(xCOffset >= 0 && xCOffset < ${a}) {\n                  xTexelR${t}C${n} = getX(batch, xR, xCOffset, d1);\n                } else {\n                  xTexelR${t}C${n} = vec4(0.);\n                }\n\n                if(xC + 1 >= 0 && xC + 1 < ${a}) {\n                  xTexelR${t}C${n+2} = getX(batch, xR, xC + 1, d1);\n                } else {\n                  xTexelR${t}C${n+2} = vec4(0.);\n                }\n\n                xR${t}C${n} = vec4(\n                  xTexelR${t}C${n}.zw, xTexelR${t}C${n+2}.zw);\n              `,n+1<d&&(m+=`\n                  vec4 final = vec4(0.);\n                  xCOffset = xC + 1 + ${u};\n                  if(xCOffset >= 0 && xCOffset < ${a}) {\n                    final = getX(batch, xR, xCOffset, d1);\n                  }\n                  xR${t}C${n+1} = vec4(xTexelR${t}C${n+2}.xy, final.xy);\n                `)):(m+=`\n                if(xC >= 0 && xC < ${a}) {\n                  xTexelR${t}C${n} = getX(batch, xR, xC, d1);\n                } else {\n                  xTexelR${t}C${n} = vec4(0.);\n                }\n\n                xCOffset = xC + ${u};\n                if(xCOffset >= 0 && xCOffset < ${a}) {\n                  xTexelR${t}C${n+2} = getX(batch, xR, xCOffset, d1);\n                } else {\n                  xTexelR${t}C${n+2} = vec4(0.);\n                }\n\n                xR${t}C${n} = vec4(\n                  xTexelR${t}C${n}.xy, xTexelR${t}C${n+2}.xy);\n              `,n+1<d&&(m+=`\n                  xR${t}C${n+1} = vec4(\n                    xTexelR${t}C${n}.zw, xTexelR${t}C${n+2}.zw);\n                `)),m+="}");n<d&&(m+=`\n            vec4 wTexelR${t}C${n} = getW(${t}, ${n}, d1, q);\n            wR${t}C${n} = vec4(wTexelR${t}C${n}.xz, wTexelR${t}C${n}.xz);\n          `,n+1<d&&(m+=`\n              vec4 wTexelR${t}C${n+1} = getW(${t}, ${n+1}, d1, q);\n              wR${t}C${n+1} =\n                vec4(wTexelR${t}C${n+1}.xz, wTexelR${t}C${n+1}.xz);`))}for(let t=0;t<p;t++)for(let e=0;e<d;e++)m+=`dotProd += xR${t}C${e} * wR${t}C${e};`;let g="",y="";n&&(g=s?`vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }`:`vec4 activation(vec4 x) {\n          ${n}\n        }`,y="result = activation(result);");const b=e?"result += getBiasAtOutCoords();":"";e&&this.variableNames.push("bias"),s&&this.variableNames.push("preluActivationWeights"),this.userCode=`\n      ${g}\n\n      const ivec2 strides = ivec2(${l}, ${u});\n      const ivec2 pads = ivec2(${i}, ${o});\n\n      void main() {\n\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2;\n        int q = 0;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        vec4 dotProd = vec4(0.);\n\n        ${m}\n\n        vec4 result = dotProd;\n        ${b}\n        ${y}\n        setOutput(result);\n      }\n    `}}class II{constructor(t,e,n,s,r){this.variableNames=["Image","Boxes","BoxInd"],this.outputShape=[];const[a,i,o,l]=t,[u]=e,[c,h]=n;this.outputShape=[u,c,h,l];const p="bilinear"===s?1:0,[d,f]=[i-1+".0",o-1+".0"],[m,g,y]=c>1?[""+(i-1)/(c-1),"(y2-y1) * height_ratio",`y1*${d} + float(y)*(height_scale)`]:["0.0","0.0","0.5 * (y1+y2) * "+d],[b,x,w]=h>1?[""+(o-1)/(h-1),"(x2-x1) * width_ratio",`x1*${f} + float(x)*(width_scale)`]:["0.0","0.0","0.5 * (x1+x2) * "+f];this.userCode=`\n      const float height_ratio = float(${m});\n      const float width_ratio = float(${b});\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int y = coords[1];\n        int x = coords[2];\n        int d = coords[3];\n\n        // get box vals\n        float y1 = getBoxes(b,0);\n        float x1 = getBoxes(b,1);\n        float y2 = getBoxes(b,2);\n        float x2 = getBoxes(b,3);\n\n        // get image in batch index\n        int bInd = round(getBoxInd(b));\n        if(bInd < 0 || bInd >= ${a}) {\n          return;\n        }\n\n        float height_scale = ${g};\n        float width_scale = ${x};\n\n        float in_y = ${y};\n        if( in_y < 0.0 || in_y > ${d} ) {\n          setOutput(float(${r}));\n          return;\n        }\n        float in_x = ${w};\n        if( in_x < 0.0 || in_x > ${f} ) {\n          setOutput(float(${r}));\n          return;\n        }\n\n        vec2 sourceFracIndexCR = vec2(in_x,in_y);\n        if(${p} == 1) {\n          // Compute the four integer indices.\n          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);\n          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));\n\n          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);\n          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);\n          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);\n          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);\n\n          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);\n\n          float top = topLeft + (topRight - topLeft) * fracCR.x;\n          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\n          float newValue = top + (bottom - top) * fracCR.y;\n          setOutput(newValue);\n        } else {\n          // Compute the coordinators of nearest neighbor point.\n          ivec2 sourceNearestCR = ivec2(floor(\n            sourceFracIndexCR + vec2(0.5,0.5)));\n          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);\n          setOutput(newValue);\n        }\n      }\n    `}}class CI{constructor(t,e,n){this.variableNames=["x"],this.outputShape=t;const s=t.length,r=e?"0.0":`getX(${SI(s,"coords")})`,a=t[t.length-1];let i="",o="";e?(i=n?"end != "+(a-1):"end != 0",o=n?"end + 1":"end - 1"):(i=n?"end + pow2 < "+a:"end >= pow2",o=n?"end + pow2":"end - pow2"),this.userCode=`\n      uniform float index;\n      void main() {\n        ${eI(s)} coords = getOutputCoords();\n        int end = ${TI(s,"coords")};\n        float val = ${r};\n        int pow2 = int(pow(2.0, index));\n        if (${i}) {\n          int idx = ${o};\n          ${TI(s,"coords")} = idx;\n          val += getX(${SI(s,"coords")});\n        }\n        setOutput(val);\n      }\n    `}getCustomSetupFunc(t){return(e,n)=>{null==this.index&&(this.index=e.getUniformLocation(n,"index")),e.gl.uniform1f(this.index,t)}}}function SI(t,e){if(1===t)return""+e;if(2===t)return`${e}.x, ${e}.y`;if(3===t)return`${e}.x, ${e}.y, ${e}.z`;if(4===t)return`${e}.x, ${e}.y, ${e}.z, ${e}.w`;throw Error(`Cumulative sum for rank ${t} is not yet supported`)}function TI(t,e){if(1===t)return""+e;if(2===t)return e+".y";if(3===t)return e+".z";if(4===t)return e+".w";throw Error(`Cumulative sum for rank ${t} is not yet supported`)}class $I{constructor(t){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0,this.outPackingScheme=jk.DENSE;const e=Yk(t),n=WN();this.outputShape=t,this.userCode=`\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ${VN(["r","c","d"],t)}\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n          vec2(${e[0]}, ${e[1]}));\n        int index = 4 * (resTexRC.x * ${e[1]} + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getA(rc.x, rc.y, rc.z);\n        }\n\n        ${n.output} = result;\n      }\n    `}}class EI{constructor(t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outPackingScheme=jk.DENSE;const e=Yk(t),n=WN();this.outputShape=t,this.userCode=`\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ${VN(["r","c","d"],t)}\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n          vec2(${e[0]}, ${e[1]}));\n        int index = 4 * (resTexRC.x * ${e[1]} + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));\n        }\n\n        ${n.output} = result;\n      }\n    `}}class AI{constructor(t,e,n){this.variableNames=["x"],this.outputShape=[],this.outputShape=t,this.blockSize=e,this.dataFormat=n,this.userCode=`\n    void main() {\n      ivec4 coords = getOutputCoords();\n      int b = coords[0];\n      int h = ${this.getHeightCoordString()};\n      int w = ${this.getWidthCoordString()};\n      int d = ${this.getDepthCoordString()};\n\n      int in_h = h / ${e};\n      int offset_h = imod(h, ${e});\n      int in_w = w / ${e};\n      int offset_w = imod(w, ${e});\n      int offset_d = (offset_h * ${e} + offset_w) *\n        ${this.getOutputDepthSize()};\n      int in_d = d + offset_d;\n\n      float result = ${this.getInputSamplingString()};\n      setOutput(result);\n    }\n  `}getHeightCoordString(){return"NHWC"===this.dataFormat?"coords[1]":"coords[2]"}getWidthCoordString(){return"NHWC"===this.dataFormat?"coords[2]":"coords[3]"}getDepthCoordString(){return"NHWC"===this.dataFormat?"coords[3]":"coords[1]"}getOutputDepthSize(){return"NHWC"===this.dataFormat?this.outputShape[3]:this.outputShape[1]}getInputSamplingString(){return"NHWC"===this.dataFormat?"getX(b, in_h, in_w, in_d)":"getX(b, in_d, in_h, in_w)"}}class RI{constructor(t){this.variableNames=["X"],this.outputShape=[t,t],this.userCode="\n      void main() {\n          ivec2 coords = getOutputCoords();\n          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;\n          setOutput(val);\n      }\n    "}}class DI{constructor(t){this.variableNames=["A"],this.outTexUsage=qk.DOWNLOAD;const e=WN();this.outputShape=t,this.userCode=`\n      ${GN}\n\n      void main() {\n        float x = getAAtOutCoords();\n        ${e.output} = encode_float(x);\n      }\n    `}}class FI{constructor(t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!1,this.outTexUsage=qk.DOWNLOAD;const e=WN();this.outputShape=t,this.userCode=`\n      ${GN}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));\n        ${e.output} = encode_float(x);\n      }\n    `}}class _I{constructor(t,e,n=!1){this.variableNames=["A"];const s=WN(),[r,a]=e;this.outputShape=t;let i="result";n&&(i="floor(result * 255. + 0.5)"),this.userCode=`\n      ${UN(t)}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n\n        int flatIndex = getFlatIndex(coords);\n        int offset = imod(flatIndex, 4);\n\n        flatIndex = idiv(flatIndex, 4, 1.);\n\n        int r = flatIndex / ${a};\n        int c = imod(flatIndex, ${a});\n        vec2 uv = (vec2(c, r) + halfCR) / vec2(${a}.0, ${r}.0);\n        vec4 values = ${s.texture2D}(A, uv);\n\n        float result;\n\n        if(offset == 0) {\n          result = values[0];\n        } else if(offset == 1) {\n          result = values[1];\n        } else if(offset == 2) {\n          result = values[2];\n        } else {\n          result = values[3];\n        }\n\n        ${s.output} = vec4(${i}, 0., 0., 0.);\n      }\n    `}}class OI{constructor(t,e,n=!1){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0;const s=WN(),[r,a]=e;this.outputShape=t;let i="",o="result";n&&(o="floor(result * 255. + 0.5)");for(let e=0;e<=1;e++)for(let n=0;n<=1;n++){const o=2*e+n;i+=`\n          localCoords = coords;\n          if(localCoords[2] + ${n} < ${t[2]}) {\n            localCoords[2] += ${n};\n            if(localCoords[1] + ${e} < ${t[1]}) {\n              localCoords[1] += ${e};\n\n              flatIndex = getFlatIndex(localCoords);\n              offset = imod(flatIndex, 4);\n\n              flatIndex = idiv(flatIndex, 4, 1.);\n\n              r = flatIndex / ${a};\n              c = imod(flatIndex, ${a});\n              uv = (vec2(c, r) + halfCR) / vec2(${a}.0, ${r}.0);\n              values = ${s.texture2D}(A, uv);\n\n              if(offset == 0) {\n                result[${o}] = values[0];\n              } else if(offset == 1) {\n                result[${o}] = values[1];\n              } else if(offset == 2) {\n                result[${o}] = values[2];\n              } else {\n                result[${o}] = values[3];\n              }\n            }\n          }\n        `}this.userCode=`\n      ${UN(t)}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n\n        vec4 result = vec4(0.);\n        int flatIndex, r, c, offset;\n        ivec3 localCoords;\n        vec2 uv;\n        vec4 values;\n\n        ${i}\n\n        ${s.output} = ${o};\n      }\n    `}}class MI{constructor(t,e){this.outputShape=[],this.variableNames=["x"],this.outputShape=t,this.userCode="\n      uniform float value;\n      void main() {\n        // Input can be obtained from uniform value.\n        setOutput(value);\n      }\n    "}getCustomSetupFunc(t){return(e,n)=>{null==this.valueLoc&&(this.valueLoc=e.getUniformLocationNoThrow(n,"value")),e.gl.uniform1f(this.valueLoc,t)}}}class LI{constructor(t,e,n){this.variableNames=["A","indices"];const s=t.slice();s[n]=e,this.outputShape=s,this.rank=s.length;const r=eI(this.rank),a=function(t,e){const n=t.length;if(n>4)throw Error(`Gather for rank ${n} is not yet supported`);if(1===n)return"int(getIndices(resRC))";const s=["resRC.x","resRC.y","resRC.z","resRC.w"],r=[];for(let n=0;n<t.length;n++)n===e?r.push(`int(getIndices(${s[n]}))`):r.push(""+s[n]);return r.join()}(t,n);this.userCode=`\n      void main() {\n        ${r} resRC = getOutputCoords();\n        setOutput(getA(${a}));\n      }\n    `}}class zI{constructor(t,e,n){this.sliceDim=t,this.strides=e,this.variableNames=["x","indices"],this.outputShape=n;const s=eI(e.length),r=eI(n.length),a=this.sliceDim>1?"strides[j]":"strides";this.userCode=`\n        ${s} strides = ${s}(${this.strides});\n         void main() {\n          ${r} coords = getOutputCoords();\n          int flattenIndex = 0;\n          for (int j = 0; j < ${this.sliceDim}; j++) {\n            int index = round(getIndices(coords[0], j));\n            flattenIndex += index * ${a};\n          }\n          setOutput(getX(flattenIndex, coords[1]));\n        }\n      `}}function BI(t,e,n,s,r,a){!function(t,e){const n=ct().getNumber("WEBGL_MAX_TEXTURE_SIZE");if(t<=0||e<=0)throw new Error(`Requested texture size [${t}x${e}] is invalid.`);if(t>n||e>n)throw new Error(`Requested texture size [${t}x${e}] greater than WebGL maximum on this browser / GPU [${n}x${n}].`)}(e,n);const i=function(t){return uN(t,(()=>t.createTexture()),"Unable to create WebGLTexture.")}(t),o=t.TEXTURE_2D;return Qk(t,(()=>t.bindTexture(o,i))),Qk(t,(()=>t.texParameteri(o,t.TEXTURE_WRAP_S,t.CLAMP_TO_EDGE))),Qk(t,(()=>t.texParameteri(o,t.TEXTURE_WRAP_T,t.CLAMP_TO_EDGE))),Qk(t,(()=>t.texParameteri(o,t.TEXTURE_MIN_FILTER,t.NEAREST))),Qk(t,(()=>t.texParameteri(o,t.TEXTURE_MAG_FILTER,t.NEAREST))),Qk(t,(()=>t.texImage2D(o,0,s,e,n,0,r,a,null))),Qk(t,(()=>t.bindTexture(t.TEXTURE_2D,null))),i}function PI(t){return t.internalFormatFloat}function WI(t){return t.internalFormatHalfFloat}function VI(t){return t.downloadTextureFormat}function UI(t){return t.internalFormatPackedFloat}function GI(t){return t.internalFormatPackedHalfFloat}class HI{constructor(t){this.outputTexture=null,this.program=null,this.disposed=!1,this.vertexAttrsAreBound=!1,this.itemsToPoll=[];const e=ct().getNumber("WEBGL_VERSION");null!=t?(this.gl=t,function(t,e){Uk[t]=e}(e,t)):this.gl=Hk(e);let n="WEBGL_color_buffer_float";const s="EXT_color_buffer_half_float";if(1===ct().getNumber("WEBGL_VERSION")){const t="OES_texture_float",e="OES_texture_half_float";if(this.textureFloatExtension=eN(this.gl,t),yN(this.gl,e))this.textureHalfFloatExtension=eN(this.gl,e);else if(ct().get("WEBGL_FORCE_F16_TEXTURES"))throw new Error("GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");if(this.colorBufferFloatExtension=this.gl.getExtension(n),yN(this.gl,s))this.colorBufferHalfFloatExtension=eN(this.gl,s);else if(ct().get("WEBGL_FORCE_F16_TEXTURES"))throw new Error("GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.")}else if(n="EXT_color_buffer_float",yN(this.gl,n))this.colorBufferFloatExtension=this.gl.getExtension(n);else{if(!yN(this.gl,s))throw new Error("GL context does not support color renderable floats");this.colorBufferHalfFloatExtension=this.gl.getExtension(s)}this.vertexBuffer=function(t){return function(t,e){const n=uN(t,(()=>t.createBuffer()),"Unable to create WebGLBuffer");return Qk(t,(()=>t.bindBuffer(t.ARRAY_BUFFER,n))),Qk(t,(()=>t.bufferData(t.ARRAY_BUFFER,e,t.STATIC_DRAW))),n}(t,new Float32Array([-1,1,0,0,1,-1,-1,0,0,0,1,1,0,1,1,1,-1,0,1,0]))}(this.gl),this.indexBuffer=function(t){return function(t,e){const n=uN(t,(()=>t.createBuffer()),"Unable to create WebGLBuffer");return Qk(t,(()=>t.bindBuffer(t.ELEMENT_ARRAY_BUFFER,n))),Qk(t,(()=>t.bufferData(t.ELEMENT_ARRAY_BUFFER,e,t.STATIC_DRAW))),n}(t,new Uint16Array([0,1,2,2,1,3]))}(this.gl),this.framebuffer=function(t){return uN(t,(()=>t.createFramebuffer()),"Unable to create WebGLFramebuffer.")}(this.gl),this.textureConfig=Zk(this.gl,this.textureHalfFloatExtension)}get debug(){return ct().getBool("DEBUG")}dispose(){if(this.disposed)return;null!=this.program&&console.warn("Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing."),null!=this.outputTexture&&console.warn("Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.");const t=this.gl;Qk(t,(()=>t.finish())),Qk(t,(()=>t.bindFramebuffer(t.FRAMEBUFFER,null))),Qk(t,(()=>t.deleteFramebuffer(this.framebuffer))),Qk(t,(()=>t.bindBuffer(t.ARRAY_BUFFER,null))),Qk(t,(()=>t.bindBuffer(t.ELEMENT_ARRAY_BUFFER,null))),Qk(t,(()=>t.deleteBuffer(this.indexBuffer))),this.disposed=!0}createFloat32MatrixTexture(t,e){return this.throwIfDisposed(),function(t,e,n,s){const[r,a]=Xk(e,n);return BI(t,r,a,PI(s),s.textureFormatFloat,t.FLOAT)}(this.gl,t,e,this.textureConfig)}createFloat16MatrixTexture(t,e){return this.throwIfDisposed(),function(t,e,n,s){const[r,a]=Xk(e,n);return BI(t,r,a,WI(s),s.textureFormatFloat,s.textureTypeHalfFloat)}(this.gl,t,e,this.textureConfig)}createUnsignedBytesMatrixTexture(t,e){return this.throwIfDisposed(),function(t,e,n,s){const[r,a]=Xk(e,n);return BI(t,r,a,VI(s),t.RGBA,t.UNSIGNED_BYTE)}(this.gl,t,e,this.textureConfig)}uploadPixelDataToTexture(t,e){this.throwIfDisposed(),function(t,e,n){Qk(t,(()=>t.bindTexture(t.TEXTURE_2D,e))),n.data instanceof Uint8Array?Qk(t,(()=>t.texImage2D(t.TEXTURE_2D,0,t.RGBA,n.width,n.height,0,t.RGBA,t.UNSIGNED_BYTE,n.data))):Qk(t,(()=>t.texImage2D(t.TEXTURE_2D,0,t.RGBA,t.RGBA,t.UNSIGNED_BYTE,n))),Qk(t,(()=>t.bindTexture(t.TEXTURE_2D,null)))}(this.gl,t,e)}uploadDenseMatrixToTexture(t,e,n,s){this.throwIfDisposed(),function(t,e,n,s,r,a){let i,o,l;Qk(t,(()=>t.bindTexture(t.TEXTURE_2D,e))),r instanceof Uint8Array?(i=new Uint8Array(n*s*4),o=t.UNSIGNED_BYTE,l=t.RGBA):(i=new Float32Array(n*s*4),o=t.FLOAT,l=a.internalFormatPackedFloat),i.set(r),Qk(t,(()=>t.texImage2D(t.TEXTURE_2D,0,l,n,s,0,t.RGBA,o,i))),Qk(t,(()=>t.bindTexture(t.TEXTURE_2D,null)))}(this.gl,t,e,n,s,this.textureConfig)}createFloat16PackedMatrixTexture(t,e){return this.throwIfDisposed(),function(t,e,n,s){const[r,a]=Jk(e,n);return BI(t,r,a,GI(s),t.RGBA,s.textureTypeHalfFloat)}(this.gl,t,e,this.textureConfig)}createPackedMatrixTexture(t,e){return this.throwIfDisposed(),function(t,e,n,s){const[r,a]=Jk(e,n);return BI(t,r,a,UI(s),t.RGBA,t.FLOAT)}(this.gl,t,e,this.textureConfig)}deleteMatrixTexture(t){this.throwIfDisposed(),this.outputTexture===t&&(oN(this.gl,this.framebuffer),this.outputTexture=null),Qk(this.gl,(()=>this.gl.deleteTexture(t)))}downloadByteEncodedFloatMatrixFromOutputTexture(t,e,n){return this.downloadMatrixDriver(t,(()=>function(t,e,n,s){const[r,a]=Xk(e,n),i=new Uint8Array(e*n*4);return Qk(t,(()=>t.readPixels(0,0,r,a,s.downloadTextureFormat,t.UNSIGNED_BYTE,i))),new Float32Array(i.buffer)}(this.gl,e,n,this.textureConfig)))}downloadPackedMatrixFromBuffer(t,e,n,s,r,a){return function(t,e,n,s,r,a,i,o){const l=t,u=new Float32Array(function(t,e){const[n,s]=Jk(t,e);return n*s*4}(a,i));return l.bindBuffer(l.PIXEL_PACK_BUFFER,e),l.getBufferSubData(l.PIXEL_PACK_BUFFER,0,u),l.bindBuffer(l.PIXEL_PACK_BUFFER,null),u}(this.gl,t,0,0,0,r,a,this.textureConfig)}downloadFloat32MatrixFromBuffer(t,e){return function(t,e,n){const s=t,r=new Float32Array(n);return s.bindBuffer(s.PIXEL_PACK_BUFFER,e),s.getBufferSubData(s.PIXEL_PACK_BUFFER,0,r),s.bindBuffer(s.PIXEL_PACK_BUFFER,null),r}(this.gl,t,e)}createBufferFromTexture(t,e,n){this.bindTextureToFrameBuffer(t);const s=function(t,e,n,s){const r=t.createBuffer();Qk(t,(()=>t.bindBuffer(t.PIXEL_PACK_BUFFER,r)));const a=16*e*n;return Qk(t,(()=>t.bufferData(t.PIXEL_PACK_BUFFER,a,t.STREAM_READ))),Qk(t,(()=>t.readPixels(0,0,n,e,t.RGBA,t.FLOAT,0))),Qk(t,(()=>t.bindBuffer(t.PIXEL_PACK_BUFFER,null))),r}(this.gl,e,n,this.textureConfig);return this.unbindTextureToFrameBuffer(),s}createAndWaitForFence(){const t=this.createFence(this.gl);return this.pollFence(t)}createFence(t){let e,n;if(ct().getBool("WEBGL_FENCE_API_ENABLED")){const s=t,r=s.fenceSync(s.SYNC_GPU_COMMANDS_COMPLETE,0);t.flush(),n=()=>{const t=s.clientWaitSync(r,0,0);return t===s.ALREADY_SIGNALED||t===s.CONDITION_SATISFIED},e=r}else ct().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")>0?(e=this.beginQuery(),this.endQuery(),n=()=>this.isQueryAvailable(e,ct().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))):n=()=>!0;return{query:e,isFencePassed:n}}downloadMatrixFromPackedTexture(t,e,n){return this.downloadMatrixDriver(t,(()=>function(t,e,n){const s=new Float32Array(e*n*4);return Qk(t,(()=>t.readPixels(0,0,n,e,t.RGBA,t.FLOAT,s))),s}(this.gl,e,n)))}createProgram(t){this.throwIfDisposed();const e=this.gl,n=function(t,e){const n=uN(t,(()=>t.createShader(t.FRAGMENT_SHADER)),"Unable to create fragment WebGLShader.");if(Qk(t,(()=>t.shaderSource(n,e))),Qk(t,(()=>t.compileShader(n))),!1===t.getShaderParameter(n,t.COMPILE_STATUS))throw function(t,e){const n=nN.exec(e);if(null==n)return console.log("Couldn't parse line number in error: "+e),void console.log(t);const s=+n[1],r=t.split("\n"),a=r.length.toString().length+2,i=r.map(((t,e)=>z((e+1).toString(),a)+t));let o=0;for(let t=0;t<i.length;t++)o=Math.max(i[t].length,o);const l=i.slice(0,s-1),u=i.slice(s-1,s),c=i.slice(s);console.log(l.join("\n")),console.log(e.split("\n")[0]),console.log("%c "+z(u[0],o),"border:1px solid red; background-color:#e3d2d2; color:#a61717"),console.log(c.join("\n"))}(e,t.getShaderInfoLog(n)),new Error("Failed to compile fragment shader.");return n}(e,t),s=function(t){const e=WN();return function(t,e){const n=uN(t,(()=>t.createShader(t.VERTEX_SHADER)),"Unable to create vertex WebGLShader.");if(Qk(t,(()=>t.shaderSource(n,e))),Qk(t,(()=>t.compileShader(n))),!1===t.getShaderParameter(n,t.COMPILE_STATUS))throw console.log(t.getShaderInfoLog(n)),new Error("Failed to compile vertex shader.");return n}(t,`${e.version}\n    precision highp float;\n    ${e.attribute} vec3 clipSpacePos;\n    ${e.attribute} vec2 uv;\n    ${e.varyingVs} vec2 resultUV;\n\n    void main() {\n      gl_Position = vec4(clipSpacePos, 1);\n      resultUV = uv;\n    }`)}(e),r=function(t){return uN(t,(()=>t.createProgram()),"Unable to create WebGLProgram.")}(e);return Qk(e,(()=>e.attachShader(r,s))),Qk(e,(()=>e.attachShader(r,n))),function(t,e){if(Qk(t,(()=>t.linkProgram(e))),!1===t.getProgramParameter(e,t.LINK_STATUS))throw console.log(t.getProgramInfoLog(e)),new Error("Failed to link vertex and fragment shaders.")}(e,r),this.debug&&sN(e,r),this.vertexAttrsAreBound||(this.setProgram(r),this.vertexAttrsAreBound=function(t,e,n){return Qk(t,(()=>t.bindBuffer(t.ARRAY_BUFFER,n))),rN(t,e,"clipSpacePos",n,3,20,0)&&rN(t,e,"uv",n,2,20,12)}(e,this.program,this.vertexBuffer)),r}deleteProgram(t){this.throwIfDisposed(),t===this.program&&(this.program=null),null!=t&&Qk(this.gl,(()=>this.gl.deleteProgram(t)))}setProgram(t){this.throwIfDisposed(),this.program=t,null!=this.program&&this.debug&&sN(this.gl,this.program),Qk(this.gl,(()=>this.gl.useProgram(t)))}getUniformLocation(t,e,n=!0){return this.throwIfDisposed(),n?function(t,e,n){return uN(t,(()=>t.getUniformLocation(e,n)),'uniform "'+n+'" not present in program.')}(this.gl,t,e):function(t,e,n){return t.getUniformLocation(e,n)}(this.gl,t,e)}getAttributeLocation(t,e){return this.throwIfDisposed(),Qk(this.gl,(()=>this.gl.getAttribLocation(t,e)))}getUniformLocationNoThrow(t,e){return this.throwIfDisposed(),this.gl.getUniformLocation(t,e)}setInputMatrixTexture(t,e,n){this.throwIfDisposed(),this.throwIfNoProgram(),aN(this.gl,t,e,n)}setOutputMatrixTexture(t,e,n){this.setOutputMatrixTextureDriver(t,n,e)}setOutputPackedMatrixTexture(t,e,n){this.throwIfDisposed();const[s,r]=Jk(e,n);this.setOutputMatrixTextureDriver(t,s,r)}setOutputMatrixWriteRegion(t,e,n,s){this.setOutputMatrixWriteRegionDriver(n,t,s,e)}setOutputPackedMatrixWriteRegion(t,e,n,s){throw new Error("setOutputPackedMatrixWriteRegion not implemented.")}debugValidate(){null!=this.program&&sN(this.gl,this.program),lN(this.gl)}executeProgram(){this.throwIfDisposed(),this.throwIfNoProgram();const t=this.gl;this.debug&&this.debugValidate(),Qk(t,(()=>t.drawElements(t.TRIANGLES,6,t.UNSIGNED_SHORT,0)))}blockUntilAllProgramsCompleted(){this.throwIfDisposed(),Qk(this.gl,(()=>this.gl.finish()))}getQueryTimerExtension(){return null==this.disjointQueryTimerExtension&&(this.disjointQueryTimerExtension=eN(this.gl,2===ct().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")?"EXT_disjoint_timer_query_webgl2":"EXT_disjoint_timer_query")),this.disjointQueryTimerExtension}getQueryTimerExtensionWebGL2(){return this.getQueryTimerExtension()}getQueryTimerExtensionWebGL1(){return this.getQueryTimerExtension()}beginQuery(){if(2===ct().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")){const t=this.gl,e=this.getQueryTimerExtensionWebGL2(),n=t.createQuery();return t.beginQuery(e.TIME_ELAPSED_EXT,n),n}const t=this.getQueryTimerExtensionWebGL1(),e=t.createQueryEXT();return t.beginQueryEXT(t.TIME_ELAPSED_EXT,e),e}endQuery(){if(2===ct().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")){const t=this.gl,e=this.getQueryTimerExtensionWebGL2();return void t.endQuery(e.TIME_ELAPSED_EXT)}const t=this.getQueryTimerExtensionWebGL1();t.endQueryEXT(t.TIME_ELAPSED_EXT)}async waitForQueryAndGetTime(t){return await B((()=>this.disposed||this.isQueryAvailable(t,ct().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")))),this.getQueryTime(t,ct().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))}getQueryTime(t,e){if(0===e)return null;if(2===e){const e=this.gl;return e.getQueryParameter(t,e.QUERY_RESULT)/1e6}{const e=this.getQueryTimerExtensionWebGL1();return e.getQueryObjectEXT(t,e.QUERY_RESULT_EXT)/1e6}}isQueryAvailable(t,e){if(0===e)return!0;if(2===e){const e=this.gl,n=this.getQueryTimerExtensionWebGL2(),s=e.getQueryParameter(t,e.QUERY_RESULT_AVAILABLE);return null==this.disjoint&&(this.disjoint=this.gl.getParameter(n.GPU_DISJOINT_EXT)),s&&!this.disjoint}{const e=this.getQueryTimerExtensionWebGL1(),n=e.getQueryObjectEXT(t,e.QUERY_RESULT_AVAILABLE_EXT);return null==this.disjoint&&(this.disjoint=this.gl.getParameter(e.GPU_DISJOINT_EXT)),n&&!this.disjoint}}pollFence(t){return new Promise((e=>{this.addItemToPoll((()=>t.isFencePassed()),(()=>e()))}))}pollItems(){const t=function(t){let e=0;for(;e<t.length&&t[e]();++e);return e-1}(this.itemsToPoll.map((t=>t.isDoneFn)));for(let e=0;e<=t;++e){const{resolveFn:t}=this.itemsToPoll[e];t()}this.itemsToPoll=this.itemsToPoll.slice(t+1)}addItemToPoll(t,e){this.itemsToPoll.push({isDoneFn:t,resolveFn:e}),this.itemsToPoll.length>1||B((()=>(this.pollItems(),0===this.itemsToPoll.length)))}bindTextureToFrameBuffer(t){this.throwIfDisposed(),iN(this.gl,t,this.framebuffer),this.debug&&lN(this.gl)}unbindTextureToFrameBuffer(){null!=this.outputTexture?(iN(this.gl,this.outputTexture,this.framebuffer),this.debug&&lN(this.gl)):oN(this.gl,this.framebuffer)}downloadMatrixDriver(t,e){this.bindTextureToFrameBuffer(t);const n=e();return this.unbindTextureToFrameBuffer(),n}setOutputMatrixTextureDriver(t,e,n){this.throwIfDisposed();const s=this.gl;iN(s,t,this.framebuffer),this.debug&&lN(s),this.outputTexture=t,Qk(s,(()=>s.viewport(0,0,e,n))),Qk(s,(()=>s.scissor(0,0,e,n)))}setOutputMatrixWriteRegionDriver(t,e,n,s){this.throwIfDisposed(),Qk(this.gl,(()=>this.gl.scissor(t,e,n,s)))}throwIfDisposed(){if(this.disposed)throw new Error("Attempted to use disposed GPGPUContext.")}throwIfNoProgram(){if(null==this.program)throw new Error("No GPU program is currently set.")}}function jI(t,e){if(t.length!==e.length)throw Error(`Binary was compiled with ${t.length} inputs, but was executed with ${e.length} inputs`);t.forEach(((t,n)=>{const s=t.logicalShape,r=e[n],a=r.shape;if(!O(s,a))throw Error(`Binary was compiled with different shapes than the current args. Shapes ${s} and ${a} must match`);if(t.isUniform&&r.isUniform)return;const i=t.texShape,o=r.isUniform?null:r.texData.texShape;if(!O(i,o))throw Error(`Binary was compiled with different texture shapes than the current args. Shape ${i} and ${o} must match`)}))}class qI{constructor(t,e,n){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=t;const{filterWidth:s,inChannels:r,strideWidth:a,strideHeight:i,padInfo:o,outWidth:l,dilationWidth:u,dilationHeight:c,dataFormat:h}=n,{left:p,top:d}=o,f=r*s,m=WN(),g="channelsLast"===h,y=g?0:1,b=g?1:2;let x="";for(let n=0;n<=1;n++)for(let s=0;s<=1;s++)x+=`\n          blockIndex = rc.y + ${s};\n          pos = rc.x + ${n};\n\n          if(blockIndex < ${t[1]} && pos < ${t[0]}) {\n            offsetY = int(blockIndex / (${l})) * ${i} - ${d};\n            d0 = offsetY + ${c} * (pos / ${f});\n\n            if(d0 < ${e[y]} && d0 >= 0) {\n\n              offsetX = int(mod(float(blockIndex), ${l}.) * ${a}. - ${p}.);\n              d1 = offsetX + ${u} * (int(mod(float(pos), ${f}.) / ${r}.));\n\n              if(d1 < ${e[b]} && d1 >= 0) {\n\n                ch = int(mod(float(pos), ${r}.));\n\n                if (${g}) {\n                  innerDims = vec2(d1, ch);\n                  result[${2*n+s}] = getChannel(\n                    getA(d0, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                } else {\n                  innerDims = vec2(d0, d1);\n                  result[${2*n+s}] = getChannel(\n                    getA(ch, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                }\n              }\n            }\n          }\n        `;this.userCode=`\n      void main() {\n        ivec2 rc = getOutputCoords();\n\n        vec4 result = vec4(0);\n\n        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;\n        vec2 innerDims;\n\n        ${x}\n\n        ${m.output} = result;\n      }\n    `}}class KI{constructor(t,e,n,s,r){this.variableNames=["x"],this.outputShape=[];const a=e,i=t[3]-1;let o;this.outputShape=t;const l=`float(${n}) + float(${s}) * sum`;o=.5===r?`inversesqrt(${l})`:1===r?`1.0/(${l})`:`exp(log(${l}) * float(-${r}));`,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n        int d = coords[3];\n        float x = getX(b, r, c, d);\n        float sum = 0.0;\n        for (int j = -${a}; j <= ${a}; j++) {\n          int idx = d + j;\n          if (idx >= 0 && idx <=  ${i}) {\n            float z = getX(b, r, c, idx);\n            sum += z * z;\n          }\n        }\n        float val = x * ${o};\n        setOutput(val);\n      }\n    `}}class XI{constructor(t,e,n,s,r){this.variableNames=["inputImage","outputImage","dy"],this.outputShape=[],this.outputShape=t,this.depth=t[3],this.depthRadius=e,this.bias=n,this.alpha=s,this.beta=r,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n\n        float result = 0.0;\n        for (int d = 0; d < ${this.depth}; ++d) {\n          int depthBegin = int(max(0.0, float(d - ${e})));\n          int depthEnd = int(min(float(${this.depth}),\n              float(d + ${e} + 1)));\n\n          const int MIN_DEPTH_BEGIN = 0;\n          const int MAX_DEPTH_END = ${this.depth};\n\n          float norm = 0.0;\n          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd) {\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\n            }\n            else {\n              break;\n            }\n          }\n\n          norm = float(${s}) * norm + float(${n});\n\n          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd){\n              float dyi = -2.0 * float(${s})\n                * float(${r})\n                * getInputImage(b ,r ,c, k) * getOutputImage(b, r, c, d)\n                / norm;\n              if (k == d) {\n                dyi += pow(norm, -1.0 * ${r});\n              }\n              if (k == coords[3]) {\n                dyi *= getDy(b, r, c, d);\n                result += dyi;\n              }\n            }\n            else {\n              break;\n            }\n          }\n      }\n      setOutput(result);\n      }\n    `}}class YI{constructor(t,e,n,s,r){this.variableNames=["x"],this.outputShape=[],this.packedInputs=!0,this.packedOutput=!0;const a=e,i=t[3]-1;let o;this.outputShape=t;const l=`float(${n}) + float(${s}) * sum`;o=.5===r?`inversesqrt(${l})`:1===r?`1.0/(${l})`:`exp(log(${l}) * float(-${r}));`,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords.x;\n        int r = coords.y;\n        int c = coords.z;\n        int d = coords.w;\n\n        bool hasNextCol = d < ${this.outputShape[3]};\n        bool hasNextRow = c < ${this.outputShape[2]};\n\n        vec4 sum = vec4(0.);\n        vec4 xFragAtOutputCoords = getX(b, r, c, d);\n\n        vec4 xAtOutputCoords = vec4(\n          getChannel(xFragAtOutputCoords, vec2(c, d)),\n          hasNextCol ?\n            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,\n          hasNextRow ?\n            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0\n        );\n\n        int firstChannel = d - ${a};\n        vec2 cache = vec2(0.);\n        if(firstChannel >= 0){\n          vec4 firstChannelFrag = getX(b, r, c, firstChannel);\n          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));\n            if(hasNextRow){\n              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));\n            }\n        }\n\n        ivec2 depth = ivec2(d, d + 1);\n        for (int j = - ${a}; j <= ${a}; j++) {\n          ivec2 idx = depth + j;\n          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));\n          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(${i}));\n\n          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;\n          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;\n\n          if(depthInRange || depthPlusOneInRange){\n            vec4 z = vec4(0.);\n            vec4 xFragAtCurrentDepth;\n            z.xz = cache.xy;\n            if(depthPlusOneInRange && hasNextCol){\n              xFragAtCurrentDepth = idx.y != d ?\n                getX(b, r, c, idx.y) : xFragAtOutputCoords;\n              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));\n              if(hasNextRow){\n                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));\n              }\n            }\n            cache.xy = z.yw;\n            sum += z * z;\n          }\n        }\n        vec4 result = xAtOutputCoords * ${o};\n        setOutput(result);\n      }\n    `}}class JI{constructor(t){this.variableNames=["dy","maxPos"],this.outputShape=t.inShape;const e=t.strideHeight,n=t.strideWidth,s=t.dilationHeight,r=t.effectiveFilterHeight,a=t.effectiveFilterWidth,i=r-1-t.padInfo.top,o=a-1-t.padInfo.left,l=r*a-1;this.userCode=`\n      const ivec2 pads = ivec2(${i}, ${o});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${r};\n          wR += ${s}) {\n          float dyR = float(dyRCorner + wR) / ${e}.0;\n\n          if (dyR < 0.0 || dyR >= ${t.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ${a}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${n}.0;\n\n            if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n            int maxPosValue = ${l} - int(getMaxPos(b, idyR, idyC, d));\n\n            // Get the current value, check it against the value from the\n            // position matrix.\n            int curPosValue = wR * ${a} + wC;\n            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n            dotProd += dyValue * mask;\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class ZI{constructor(t){this.variableNames=["dy","maxPos"],this.outputShape=t.inShape;const e=t.strideDepth,n=t.strideHeight,s=t.strideWidth,r=t.dilationDepth,a=t.dilationHeight,i=t.dilationWidth,o=t.effectiveFilterDepth,l=t.effectiveFilterHeight,u=t.effectiveFilterWidth,c=o-1-t.padInfo.front,h=l-1-t.padInfo.top,p=u-1-t.padInfo.left,d=o*l*u-1;this.userCode=`\n      const ivec3 pads = ivec3(${c}, ${h}, ${p});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ${o};\n           wD += ${r}) {\n          float dyD = float(dyDCorner + wD) / ${e}.0;\n\n          if (dyD < 0.0 || dyD >= ${t.outDepth}.0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ${l};\n              wR += ${a}) {\n            float dyR = float(dyRCorner + wR) / ${n}.0;\n\n            if (dyR < 0.0 || dyR >= ${t.outHeight}.0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ${u};\n                wC += ${i}) {\n              float dyC = float(dyCCorner + wC) / ${s}.0;\n\n              if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n              int maxPosValue = ${d} -\n                  int(getMaxPos(batch, idyD, idyR, idyC, ch));\n\n              // Get the current value, check it against the value from the\n              // position matrix.\n              int curPosValue =\n                  wD * ${l} * ${u} +\n                  wR * ${u} + wC;\n              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n              dotProd += dyValue * mask;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class QI{constructor(t,e,n,s=!1,r=!1,a=!1,i=null,o=!1){this.variableNames=["matrixA","matrixB"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=n;const l=s?t[1]:t[2],u=Math.ceil(l/2),c=s?"i * 2, rc.y":"rc.y, i * 2",h=r?"rc.z, i * 2":"i * 2, rc.z",p=s?["a.xxyy","a.zzww"]:["a.xxzz","a.yyww"],d=r?["b.xzxz","b.ywyw"]:["b.xyxy","b.zwzw"];let f="",m="";i&&(f=o?`vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${i}\n        }`:`vec4 activation(vec4 x) {\n          ${i}\n        }`,m="result = activation(result);");const g=a?"result += getBiasAtOutCoords();":"";a&&this.variableNames.push("bias"),o&&this.variableNames.push("preluActivationWeights");let y="rc.x",b="rc.x";t[0]<e[0]?y=`int(min(float(rc.x), ${t[0]-1}.))`:e[0]<t[0]&&(b=`int(min(float(rc.x), ${e[0]-1}.))`),this.userCode=`\n      ${f}\n\n      const float sharedDimension = ${u}.0;\n\n      vec4 dot2x2ARowBCol(ivec3 rc) {\n        vec4 result = vec4(0);\n        for (int i = 0; i < ${u}; i++) {\n          int batchA = ${y};\n          int batchB = ${b};\n          vec4 a = getMatrixA(batchA, ${c});\n          vec4 b = getMatrixB(batchB, ${h});\n\n          // These swizzled products need to be separately added.\n          // See: https://github.com/tensorflow/tfjs/issues/1735\n          result += (${p[0]} * ${d[0]});\n          result += (${p[1]} * ${d[1]});\n        }\n        return result;\n      }\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n        vec4 result = dot2x2ARowBCol(rc);\n\n        ${g}\n\n        ${m}\n\n        setOutput(result);\n      }\n    `}}class tC{constructor(t,e,n){this.variableNames=["probs"],this.outputShape=[t,n],this.userCode=`\n      uniform float seed;\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n\n        float r = random(seed);\n        float cdf = 0.0;\n\n        for (int i = 0; i < ${e-1}; i++) {\n          cdf += getProbs(batch, i);\n\n          if (r < cdf) {\n            setOutput(float(i));\n            return;\n          }\n        }\n\n        // If no other event happened, last event happened.\n        setOutput(float(${e-1}));\n      }\n    `}getCustomSetupFunc(t){return(e,n)=>{null==this.seedLoc&&(this.seedLoc=e.getUniformLocation(n,"seed")),e.gl.uniform1f(this.seedLoc,t)}}}class eC{constructor(t,e,n,s){this.variableNames=["indices"],this.outputShape=[t,e],this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int index = round(getIndices(coords.x));\n        setOutput(mix(float(${s}), float(${n}),\n                      float(index == coords.y)));\n      }\n    `}}class nC{constructor(t){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0,this.outputShape=t;const e=t.length;if(0===e)this.userCode="\n        void main() {\n          setOutput(vec4(getA(), 0., 0., 0.));\n        }\n      ";else{const n=PN("rc",e),s=eI(e),r=function(t,e,n){if(1===t)return"rc > "+e[0];let s="";for(let r=t-2;r<t;r++)s+=`${n[r]} >= ${e[r]}`,r<t-1&&(s+="||");return s}(e,t,n),a=function(t,e,n,s){if(1===t)return"";const r=s.slice(-2);return`\n    int r = ${r[0]};\n    int c = ${r[1]};\n    int rp1 = r + 1;\n    int cp1 = c + 1;\n\n    bool cEdge = cp1 >= ${e};\n    bool rEdge = rp1 >= ${n};\n  `}(e,t[t.length-1],t[t.length-2],n),i=function(t,e){const n=t.length,s=function(t,e){const n=[];for(let s=0;s<=1;s++)for(let r=0;r<=1;r++){let a=`${0===s?"r":"rp1"}, ${0===r?"c":"cp1"}`;for(let n=2;n<t;n++)a=e[e.length-1-n]+","+a;n.push(a)}return n}(n,e);return 1===n?`getA(rc),\n            rc + 1 >= ${t[0]} ? 0. : getA(rc + 1),\n            0, 0`:`getA(${s[0]}),\n          cEdge ? 0. : getA(${s[1]}),\n          rEdge ? 0. : getA(${s[2]}),\n          rEdge || cEdge ? 0. : getA(${s[3]})`}(t,n);this.userCode=`\n        void main() {\n          ${s} rc = getOutputCoords();\n\n          if(${r}) {\n            setOutput(vec4(0));\n          } else {\n            ${a}\n\n            setOutput(vec4(${i}));\n          }\n        }\n      `}}}class sC{constructor(t,e,n){this.variableNames=["x"],this.outputShape=e.map(((e,n)=>e[0]+t[n]+e[1]));const s=t.length,r=eI(s),a=e.map((t=>t[0])).join(","),i=e.map(((e,n)=>e[0]+t[n])).join(","),o=["coords[0]","coords[1]","coords[2]","coords[3]"].slice(0,s);this.userCode=1!==s?`\n      ${r} start = ${r}(${a});\n      ${r} end = ${r}(${i});\n\n      void main() {\n        ${r} outC = getOutputCoords();\n        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {\n          setOutput(float(${n}));\n        } else {\n          ${r} coords = outC - start;\n          setOutput(getX(${o}));\n        }\n      }\n    `:`\n        int start = ${a};\n        int end = ${i};\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start || outC >= end) {\n            setOutput(float(${n}));\n          } else {\n            setOutput(getX(outC - start));\n          }\n        }\n      `}}class rC{constructor(t,e,n){this.variableNames=["x"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e.map(((e,n)=>e[0]+t[n]+e[1]));const s=t.length,r=eI(s),a=e.map((t=>t[0])).join(","),i=e.map(((e,n)=>e[0]+t[n])).join(","),o=PN("rc",s),l=PN("source",s),u=`${o[s-1]} < ${this.outputShape[s-1]}`,c=1===s?"source":`vec2(${l.slice(-2).join()})`,h=[r+" rc = outputLoc;",`${o[s-1]} += 1;\n       if(${u}) {\n      `,1===s?"":`}\n       rc = outputLoc;\n       ${o[s-2]} += 1;\n       if(${o[s-2]} < ${this.outputShape[s-2]}) {`,1===s?"":`  ${o[s-1]} += 1;\n         if(${u}) {`],p=1===s?"rc < start || rc >= end":"any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))";let d="";for(let t=0,e=1===s?2:4;t<e;t++)d+=`\n        ${h[t]}\n        if (${p}) {\n          result[${t}] = float(${n});\n        } else {\n          ${r} source = rc - start;\n          result[${t}] = getChannel(getX(${l.join()}), ${c});\n        }\n      `;d+=1===s?"} ":"}}",this.userCode=`\n      const ${r} start = ${r}(${a});\n      const ${r} end = ${r}(${i});\n\n      void main() {\n        ${r} outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ${d}\n        setOutput(result);\n      }\n    `}}class aC{constructor(t,e,n,s=!1,r=!1){if(this.variableNames=["x"],"avg"===e&&n)throw new Error("Cannot compute positions for average pool.");const a=t.filterWidth,i=t.strideHeight,o=t.strideWidth,l=t.dilationHeight,u=t.dilationWidth,c=t.effectiveFilterHeight,h=t.effectiveFilterWidth,p=t.padInfo.top,d=t.padInfo.left;this.outputShape=t.outShape;const f="avg"===e,m=`((batch  * ${t.inHeight} + xR) * ${t.inWidth} + xC) * ${t.inChannels} + d`,g=`(xR * ${t.inWidth} + xC) * ${t.inChannels} + d`;let y="0.0";if(f||(y="-1.0 / 1e-20"),n){const e=">=";return void(this.userCode=`\n        const ivec2 strides = ivec2(${i}, ${o});\n        const ivec2 pads = ivec2(${p}, ${d});\n\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int batch = coords[0];\n          int d = coords[3];\n\n          ivec2 xRCCorner = coords.yz * strides - pads;\n          int xRCorner = xRCCorner.x;\n          int xCCorner = xRCCorner.y;\n\n          // max/min x(?, ?, d) to get y(yR, yC, d).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n          float avgValue = 0.0;\n\n          for (int wR = 0; wR < ${c};\n              wR += ${l}) {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ${t.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${h};\n                wC += ${u}) {\n              int xC = xCCorner + wC;\n\n              if (xC < 0 || xC >= ${t.inWidth}) {\n                continue;\n              }\n\n              float value = getX(batch, xR, xC, d);\n\n              // If a min / max value has already been found, use it. If not,\n              // use the current value.\n              float currMinMaxValue = mix(\n                  value, minMaxValue, minMaxValueFound);\n              if (value ${e} currMinMaxValue) {\n                minMaxValue = value;\n                minMaxValueFound = 1.0;\n                minMaxPosition = ${s?r?m:g:`wR * ${h} + wC`};\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      `)}let b=`${e}(${e}(${e}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"avg"===e&&(b="avgValue / count");const x=4*Math.floor(a/4),w=a%4,v=`\n      if (${f}) {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    `;this.userCode=`\n      const ivec2 strides = ivec2(${i}, ${o});\n      const ivec2 pads = ivec2(${p}, ${d});\n      const float initializationValue = ${y};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xR, int xC, int d) {\n        if (xC < 0 || xC >= ${t.inWidth}) {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xR, xC, d);\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d = coords[3];\n\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // max/min x(?, ?, d) to get y(yR, yC, d).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(${y});\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wR = 0; wR < ${c};\n            wR += ${l}) {\n          int xR = xRCorner + wR;\n\n          if (xR < 0 || xR >= ${t.inHeight}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${x}; wC += 4) {\n            int xC = xCCorner + wC * ${u};\n\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${u}, d),\n              getValue(batch, xR, xC + 2 * ${u}, d),\n              getValue(batch, xR, xC + 3 * ${u}, d)\n            );\n\n            ${v}\n          }\n\n          int xC = xCCorner + ${x};\n          if (${1===w}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              initializationValue,\n              initializationValue,\n              initializationValue\n            );\n\n            ${v}\n          } else if (${2===w}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${u}, d),\n              initializationValue,\n              initializationValue\n            );\n\n            ${v}\n          } else if (${3===w}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${u}, d),\n              getValue(batch, xR, xC + 2 * ${u}, d),\n              initializationValue\n            );\n\n            ${v}\n          }\n        }\n        setOutput(${b});\n      }\n    `}}class iC{constructor(t,e,n,s=!1,r=!1){if(this.variableNames=["x"],"avg"===e&&n)throw new Error("Cannot compute positions for average pool.");const a=t.filterWidth,i=t.strideDepth,o=t.strideHeight,l=t.strideWidth,u=t.dilationDepth,c=t.dilationHeight,h=t.dilationWidth,p=t.effectiveFilterDepth,d=t.effectiveFilterHeight,f=t.effectiveFilterWidth,m=t.padInfo.front,g=t.padInfo.top,y=t.padInfo.left;this.outputShape=t.outShape;const b="avg"===e;let x="0.0";if(b||(x="-1.0 / 1e-20"),n){const e=">=";return void(this.userCode=`\n        const ivec3 strides =\n            ivec3(${i}, ${o}, ${l});\n        const ivec3 pads = ivec3(${m}, ${g}, ${y});\n\n        void main() {\n          ivec5 coords = getOutputCoords();\n          int batch = coords.x;\n          int ch = coords.u;\n\n          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n          int xDCorner = xCorner.x;\n          int xRCorner = xCorner.y;\n          int xCCorner = xCorner.z;\n\n          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n\n          for (int wD = 0; wD < ${p};\n              wD += ${u}) {\n            int xD = xDCorner + wD;\n\n            if (xD < 0 || xD >= ${t.inDepth}) {\n              continue;\n            }\n\n            for (int wR = 0; wR < ${d};\n                wR += ${c}) {\n              int xR = xRCorner + wR;\n\n              if (xR < 0 || xR >= ${t.inHeight}) {\n                continue;\n              }\n\n              for (int wC = 0; wC < ${f};\n                  wC += ${h}) {\n                int xC = xCCorner + wC;\n\n                if (xC < 0 || xC >= ${t.inWidth}) {\n                  continue;\n                }\n\n                float value = getX(batch, xD, xR, xC, ch);\n\n                // If a min / max value has already been found, use it. If not,\n                // use the current value.\n                float currMinMaxValue = mix(\n                    value, minMaxValue, minMaxValueFound);\n                if (value ${e} currMinMaxValue) {\n                  minMaxValue = value;\n                  minMaxValueFound = 1.0;\n                  minMaxPosition = ${s?r?`(((batch * ${t.inDepth} + xD) * ${t.inHeight} + xR) * ${t.inWidth} + xC) * ${t.inChannels} + ch`:`((xD * ${t.inHeight} + xR) * ${t.inWidth} + xC) * ${t.inChannels} + ch`:`wD * ${d} * ${f} +\n                      wR * ${f} + wC`};\n                }\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      `)}let w=`${e}(${e}(${e}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"avg"===e&&(w="avgValue / count");const v=4*Math.floor(a/4),k=a%4,N=`\n      if (${b}) {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    `;this.userCode=`\n      const ivec3 strides =\n        ivec3(${i}, ${o}, ${l});\n      const ivec3 pads = ivec3(${m}, ${g}, ${y});\n      const float initializationValue = ${x};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xD, int xR, int xC, int ch) {\n        if (xC < 0 || xC >= ${t.inWidth}) {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xD, xR, xC, ch);\n      }\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xDCorner = xCorner.x;\n        int xRCorner = xCorner.y;\n        int xCCorner = xCorner.z;\n\n        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(${x});\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wD = 0; wD < ${p};\n            wD += ${u}) {\n          int xD = xDCorner + wD;\n\n          if (xD < 0 || xD >= ${t.inDepth}) {\n            continue;\n          }\n\n          for (int wR = 0; wR < ${d};\n            wR += ${c}) {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ${t.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${v}; wC += 4) {\n              int xC = xCCorner + wC * ${h};\n\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${h}, ch),\n                getValue(batch, xD, xR, xC + 2 * ${h}, ch),\n                getValue(batch, xD, xR, xC + 3 * ${h}, ch)\n              );\n\n              ${N}\n            }\n\n            int xC = xCCorner + ${v};\n            if (${1===k}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                initializationValue,\n                initializationValue,\n                initializationValue\n              );\n\n              ${N}\n            } else if (${2===k}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${h}, ch),\n                initializationValue,\n                initializationValue\n              );\n\n              ${N}\n            } else if (${3===k}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${h}, ch),\n                getValue(batch, xD, xR, xC + 2 * ${h}, ch),\n                initializationValue\n              );\n\n              ${N}\n            }\n          }\n          setOutput(${w});\n        }\n      }\n    `}}class oC{constructor(t,e){this.variableNames=["x"];const{windowSize:n,batchSize:s,inSize:r,outSize:a}=t;this.outputShape=[s,a];let i="0.0",o="";"prod"===e?i="1.0":"min"===e?(i="1.0 / 1e-20",o="min"):"max"===e&&(i="-1.0 / 1e-20",o="max");let l=`${e}(${e}(${e}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"sum"===e?l="sumValue":"prod"===e?l="prodValue":"all"===e?l="allValue":"any"===e&&(l="anyValue");const u=4*Math.floor(n/4),c=n%4;let h=`\n      if (${"sum"===e}) {\n        sumValue += dot(values, ones);\n      } else if (${"prod"===e}) {\n        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);\n        prodValue *= tmp[0] * tmp[1];\n      } else {\n        minMaxValue = ${o}(values, minMaxValue);\n      }\n    `,p="vec4";"all"===e?(i="1.0",h="\n        bool reducedAllValue = all(values);\n        float floatedReducedAllValue = float(reducedAllValue);\n        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);\n      ",p="bvec4"):"any"===e&&(i="0.0",h="\n        bool reducedAnyValue = any(values);\n        float floatedReducedAnyValue = float(reducedAnyValue);\n        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);\n      ",p="bvec4");let d="";r%n>0&&(d=`\n        if (inIdx < 0 || inIdx >= ${r}) {\n          return initializationValue;\n        }\n      `),this.userCode=`\n      const float initializationValue = ${i};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ${d}\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${n};\n\n        vec4 minMaxValue = vec4(${i});\n        float prodValue = 1.0;\n        float sumValue = 0.0;\n        float allValue = 1.0;\n        float anyValue = 0.0;\n\n        for (int i = 0; i < ${u}; i += 4) {\n          int inIdx = inOffset + i;\n          ${p} values = ${p}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ${h}\n        }\n\n        int inIdx = inOffset + ${u};\n        if (${1===c}) {\n          ${p} values = ${p}(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          ${h}\n        } else if (${2===c}) {\n          ${p} values = ${p}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          ${h}\n        } else if (${3===c}) {\n          ${p} values = ${p}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          ${h}\n        }\n        setOutput(${l});\n      }\n    `}}class lC{constructor(t,e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=t;let n="";for(let t=0;t<4;t++){let e="thisRC = rc;";t%2==1&&(e+="thisRC.z += 1;"),t>1&&(e+="thisRC.y += 1;"),n+=`\n        ${e}\n        ${t>0?"if(thisRC.y < rows && thisRC.z < cols){":""}\n          int flatIndex = getFlatIndex(thisRC);\n\n          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);\n          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));\n\n          result[${t}] =\n            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);\n        ${t>0?"}":""}\n      `}var s;this.userCode=`\n      ${s=e,`\n    ivec3 inputCoordsFromReshapedOutCoords(int index) {\n      ${VN(["r","c","d"],s)}\n      return ivec3(r, c, d);\n    }\n  `}\n      ${UN(t)}\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n\n        vec4 result = vec4(0.);\n\n        ivec3 thisRC;\n        int rows = ${t[1]};\n        int cols = ${t[2]};\n\n        ${n}\n\n        setOutput(result);\n      }\n    `}}class uC{constructor(t,e,n){this.variableNames=["dy"],this.outputShape=[],this.outputShape=e.shape;const[,s,r]=e.shape,[,a,i]=t.shape,o=[n&&a>1?s-1:s,n&&i>1?r-1:r],l=[n&&a>1?a-1:a,n&&i>1?i-1:i],u=o[0]/l[0],c=o[1]/l[1],h=1/u,p=1/c,d=2*Math.ceil(h)+2,f=2*Math.ceil(p)+2;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(${u});\n        const float widthScale = float(${c});\n\n        const float invHeightScale = float(${h});\n        const float invWidthScale = float(${p});\n\n        const int winHeight = int(${d});\n        const int winWidth = int(${f});\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(startRLerp - float(winHeight / 2));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(startCLerp - float(winWidth / 2));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ${a}) {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ${i}) {\n              continue;\n            }\n\n            float dxR = float(dyR) * heightScale;\n            int topDxRIndex = int(floor(dxR));\n            int bottomDxRIndex = int(min(ceil(dxR), ${s-1}.0));\n            float dxRLerp = dxR - float(topDxRIndex);\n            float inverseDxRLerp = 1.0 - dxRLerp;\n\n            float dxC = float(dyC) * widthScale;\n            int leftDxCIndex = int(floor(dxC));\n            int rightDxCIndex = int(min(ceil(dxC), ${r-1}.0));\n            float dxCLerp = dxC - float(leftDxCIndex);\n            float inverseDxCLerp = 1.0 - dxCLerp;\n\n            if (r == topDxRIndex && c == leftDxCIndex) {\n              // topLeft\n              accumulator +=\n                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\n            }\n\n            if (r == topDxRIndex && c == rightDxCIndex) {\n              // topRight\n              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == leftDxCIndex) {\n              // bottomLeft\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == rightDxCIndex) {\n              // bottomRight\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    `}}class cC{constructor(t,e,n,s){this.variableNames=["A"],this.outputShape=[];const[r,a,i,o]=t;this.outputShape=[r,e,n,o];const l=[s&&e>1?a-1:a,s&&n>1?i-1:i],u=[s&&e>1?e-1:e,s&&n>1?n-1:n];this.userCode=`\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ${l[0]/u[0]},\n          ${l[1]/u[1]});\n      const vec2 inputShapeRC = vec2(${a}.0, ${i}.0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = vec2(yRC) * effectiveInputOverOutputRatioRC;\n\n        // Compute the four integer indices.\n        ivec2 sourceFloorRC = ivec2(sourceFracIndexRC);\n        ivec2 sourceCeilRC = ivec2(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);\n        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);\n        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);\n        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);\n\n        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);\n\n        float top = topLeft + (topRight - topLeft) * fracRC.y;\n        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\n        float newValue = top + (bottom - top) * fracRC.x;\n\n        setOutput(newValue);\n      }\n    `}}class hC{constructor(t,e,n,s){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=[];const[r,a,i,o]=t;this.outputShape=[r,e,n,o];const l=[s&&e>1?a-1:a,s&&n>1?i-1:i],u=[s&&e>1?e-1:e,s&&n>1?n-1:n];this.userCode=`\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ${l[0]/u[0]},\n          ${l[1]/u[1]},\n          ${l[1]/u[1]});\n      const vec3 inputShapeRC = vec3(${a}.0, ${i}.0,\n                                     ${i}.0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = vec3(yRC) * effectiveInputOverOutputRatioRC;\n\n        // Compute the four integer indices.\n        ivec3 sourceFloorRC = ivec3(sourceFracIndexRC);\n        ivec3 sourceCeilRC = ivec3(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ${o-1};\n        bool hasNextRow = coords.z < ${n-1};\n\n        // In parallel, construct four corners for all four components in\n        // packed 2x2 cell.\n        vec4 topLeft = vec4(\n          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 bottomLeft = vec4(\n          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 topRight = vec4(\n          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec4 bottomRight = vec4(\n          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);\n\n        vec4 top = mix(topLeft, topRight, fracRC.yyzz);\n        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);\n        vec4 newValue = mix(top, bottom, fracRC.x);\n\n        setOutput(newValue);\n      }\n    `}}class pC{constructor(t,e,n){this.variableNames=["dy"],this.outputShape=[],this.outputShape=e.shape;const[,s,r]=e.shape,[,a,i]=t.shape,o=[n&&a>1?s-1:s,n&&i>1?r-1:r],l=[n&&a>1?a-1:a,n&&i>1?i-1:i],u=o[0]/l[0],c=o[1]/l[1],h=1/u,p=1/c,d=2*Math.ceil(h)+2,f=2*Math.ceil(p)+2;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(${u});\n        const float widthScale = float(${c});\n\n        const float invHeightScale = float(${h});\n        const float invWidthScale = float(${p});\n\n        const int winHeight = int(${d});\n        const int winWidth = int(${f});\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(floor(startRLerp - float(winHeight / 2)));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(floor(startCLerp - float(winWidth / 2)));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ${a}) {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ${i}) {\n              continue;\n            }\n\n            float sourceFracRow =\n              float(${o[0]}) *\n                (float(dyR) / float(${l[0]}));\n\n            float sourceFracCol =\n                float(${o[1]}) *\n                  (float(dyC) / float(${l[1]}));\n\n            int sourceNearestRow = int(min(\n                float(int(${s}) - 1),\n                ${n} ? float(round(sourceFracRow)) :\n                                  float(floor(sourceFracRow))));\n\n            int sourceNearestCol = int(min(\n                float(int(${r}) - 1),\n                ${n} ? float(round(sourceFracCol)) :\n                                  float(floor(sourceFracCol))));\n\n            if (r == sourceNearestRow && c == sourceNearestCol) {\n              accumulator += getDy(b, dyR, dyC, d);\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    `}}class dC{constructor(t,e,n,s){this.variableNames=["A"],this.outputShape=[];const[r,a,i,o]=t;this.outputShape=[r,e,n,o];const l=[s&&e>1?a-1:a,s&&n>1?i-1:i],u=[s&&e>1?e-1:e,s&&n>1?n-1:n],c=s?"0.5":"0.0";this.userCode=`\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ${l[0]/u[0]},\n          ${l[1]/u[1]});\n      const vec2 inputShapeRC = vec2(${a}.0, ${i}.0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = vec2(yRC) * effectiveInputOverOutputRatioRC;\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec2 sourceNearestRC = ivec2(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${c})));\n\n        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);\n\n        setOutput(newValue);\n      }\n    `}}class fC{constructor(t,e){this.variableNames=["x"];const n=t.length;if(n>4)throw new Error(`WebGL backend: Reverse of rank-${n} tensor is not yet supported`);if(this.outputShape=t,1===n)return void(this.userCode=`\n        void main() {\n          int coord = getOutputCoords();\n          setOutput(getX(${t[0]} - coord - 1));\n        }\n      `);const s=t.map(((n,s)=>(n=>-1!==e.indexOf(n)&&1!==t[n]?`${t[n]} - coords[${n}] - 1`:`coords[${n}]`)(s))).join(","),r=eI(n);this.userCode=`\n      void main() {\n        ${r} coords = getOutputCoords();\n        setOutput(getX(${s}));\n      }\n    `}}class mC{constructor(t,e){this.variableNames=["x"],this.packedInputs=!0,this.packedOutput=!0;const n=t.length;if(n>4)throw new Error(`WebGL backend: Reverse of rank-${n} tensor is not yet supported`);this.outputShape=t;const s=PN("rc",n),r=`${s[n-1]} + 1 < ${this.outputShape[n-1]}`,a=`${s[n-2]} + 1 < ${this.outputShape[n-2]}`,i=eI(n);function o(n){const s=t.map(((s,r)=>function(n,s){return-1!==e.indexOf(n)&&1!==t[n]?`${t[n]} - ${s[n]} - 1`:""+s[n]}(r,n)));return`getChannel(getX(${s.join(",")}), vec2(${s.slice(-2).join(",")}))`}this.userCode=1===n?`\n        void main(){\n          int rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = getChannel(getX(${t[0]} - rc - 1),\n            ${t[0]} - rc - 1);\n          if(${r}){\n              result.g = getChannel(getX(${t[0]} - (rc  + 1) - 1),\n                ${t[0]} - (rc  + 1) - 1);\n          }\n          setOutput(result);\n        }\n      `:`\n        void main() {\n          ${i} rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = ${function(t){return o(t)}(s.slice())};\n          if(${r}){\n            result.g = ${function(t){return t[n-1]="("+t[n-1]+" + 1)",o(t)}(s.slice())};\n          }\n          if(${a}) {\n            result.b = ${function(t){return t[n-2]="("+t[n-2]+" + 1)",o(t)}(s.slice())};\n            if(${r}) {\n              result.a = ${function(t){return t[n-1]="("+t[n-1]+" + 1)",t[n-2]="("+t[n-2]+" + 1)",o(t)}(s.slice())};\n            }\n          }\n          setOutput(result);\n        }\n    `}}class gC{constructor(t,e,n,s,r,a,i=!0){this.variableNames=["updates","indices","defaultValue"],this.outputShape=a;const o=eI(r.length),l=eI(a.length);let u="";1===n?u="i":2===n&&(u="i, j");const c=`getIndices(${u})`;let h="";1===s?h="i":2===s&&(h="i, coords[1]");const p=`getUpdates(${h})`,d=e>1?"strides[j]":"strides";this.userCode=`\n        ${o} strides = ${o}(${r});\n\n        void main() {\n          ${l} coords = getOutputCoords();\n          float sum = 0.0;\n          bool found = false;\n          for (int i = 0; i < ${t}; i++) {\n            int flattenedIndex = 0;\n            for (int j = 0; j < ${e}; j++) {\n              int index = round(${c});\n              flattenedIndex += index * ${d};\n            }\n            if (flattenedIndex == coords[0]) {\n              sum += ${p};\n              found = true;\n            }\n          }\n          setOutput(mix(getDefaultValue(), sum, float(found)));\n        }\n      `}}class yC{constructor(t,e){this.variableNames=["x","segmentIds"];const n=t.windowSize,s=t.batchSize,r=t.inSize,a=t.numSegments,i=a*Math.ceil(r/n);this.outputShape=[s,i];const o=4*Math.floor(n/4),l=n%4,u="\n        sumValue += dot(values, segFilter);\n    ";let c="";r%n>0&&(c=`\n        if (inIdx < 0 || inIdx >= ${r}) {\n          return initializationValue;\n        }\n      `);let h="";r%n>0&&(h=`\n        if (inIdx < 0 || inIdx >= ${r}) {\n          return -1.0;\n        }\n      `),this.userCode=`\n      const float initializationValue = 0.0;\n\n      float getValue(int batch, int inIdx) {\n        ${c}\n        return getX(batch, inIdx);\n      }\n\n      float getSegmentIdAtIndex(int inIdx) {\n        ${h}\n        return getSegmentIds(inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = int(floor(float(outIdx) / float(\n          ${a})) * float(${n}));\n        int currentSeg = int(mod(float(outIdx), float(${a})));\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ${o}; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0\n          );\n\n          ${u}\n        }\n\n        int inIdx = inOffset + ${o};\n        if (${1===l}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            0,\n            0,\n            0\n          );\n\n          ${u}\n        } else if (${2===l}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n              0,\n              0\n          );\n\n          ${u}\n        } else if (${3===l}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            0\n          );\n\n          ${u}\n        }\n        setOutput(sumValue);\n      }\n    `}}class bC{constructor(t,e,n){let s,r;if(this.variableNames=["c","a","b"],this.outputShape=e,n>4)throw Error(`Where for rank ${n} is not yet supported`);if(1===n)r="resRC",s="resRC";else{const n=["resRC.x","resRC.y","resRC.z","resRC.w"],a=[],i=[];for(let s=0;s<e.length;s++)i.push(""+n[s]),s<t&&a.push(""+n[s]);s=a.join(),r=i.join()}const a=eI(n);this.userCode=`\n      void main() {\n        ${a} resRC = getOutputCoords();\n        float cVal = getC(${s});\n        if (cVal >= 1.0) {\n          setOutput(getA(${r}));\n        } else {\n          setOutput(getB(${r}));\n        }\n      }\n    `}}class xC{constructor(t){this.variableNames=["source"],this.outputShape=t,this.rank=t.length;const e=eI(this.rank),n=`uniform int start[${this.rank}];`,s=function(t){if(1===t)return"sourceLoc";if(t<=6)return wC.slice(0,t).map((t=>"sourceLoc."+t)).join(",");throw Error(`Slicing for rank ${t} is not yet supported`)}(this.rank);let r;r=`\n        ${e} sourceLoc;\n        ${e} coords = getOutputCoords();\n        ${t.map(((t,e)=>`sourceLoc.${wC[e]} = start[${e}] + coords.${wC[e]};`)).join("\n")}\n      `,this.userCode=`\n      ${n}\n      void main() {\n        ${r}\n        setOutput(getSource(${s}));\n      }\n    `}getCustomSetupFunc(t){if(t.length!==this.rank)throw Error(`The rank (${this.rank}) of the program must match the length of start (${t.length})`);return(e,n)=>{null==this.startLoc&&(this.startLoc=e.getUniformLocationNoThrow(n,"start"),null==this.startLoc)||e.gl.uniform1iv(this.startLoc,t)}}}const wC=["x","y","z","w","u","v"];class vC{constructor(t){this.variableNames=["source"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=t,this.rank=t.length;const e=eI(this.rank),n=PN("coords",this.rank),s=PN("sourceLoc",this.rank),r=1===this.rank?"sourceLoc":`vec2(${s.slice(-2).join()})`,a=`getChannel(getSource(${s.join()}), ${r})`,i=`\n      result.x = ${a};\n      if (++${n[this.rank-1]} < ${t[this.rank-1]}) {\n        ++${s[this.rank-1]};\n        result.y = ${a};\n        --${s[this.rank-1]};\n      }\n    `,o=1===this.rank?"":`\n      --${n[this.rank-1]};\n      if (++${n[this.rank-2]} < ${t[this.rank-2]}) {\n        ++${s[this.rank-2]};\n        result.z = ${a};\n        if (++${n[this.rank-1]} < ${t[this.rank-1]}) {\n          ++${s[this.rank-1]};\n          result.w = ${a};\n        }\n      }\n    `,l=this.rank<=4?`sourceLoc = coords +\n            ${e}(${t.map(((t,e)=>`start[${e}]`)).join()});`:t.map(((t,e)=>`${s[e]} = ${n[e]} + start[${e}];`)).join("\n");this.userCode=`\n      uniform int start[${this.rank}];\n      void main() {\n        ${e} coords = getOutputCoords();\n        ${e} sourceLoc;\n        ${l}\n        vec4 result = vec4(0.);\n        ${i}\n        ${o}\n        setOutput(result);\n      }\n    `}getCustomSetupFunc(t){if(t.length!==this.rank)throw Error(`The rank (${this.rank}) of the program must match the length of start (${t.length})`);return(e,n)=>{null==this.startLoc&&(this.startLoc=e.getUniformLocationNoThrow(n,"start"),null==this.startLoc)||e.gl.uniform1iv(this.startLoc,t)}}}class kC{constructor(t,e,n){this.variableNames=["x"],this.outputShape=n;const s=n.length,r=eI(n.length),a=eI(n.length);let i="";if(1===s)i="coords * strides + begin";else{let t=0;i=n.map(((e,s)=>(t++,1===n.length?`coords * strides[${s}] + begin[${s}]`:`coords[${t-1}] * strides[${s}] + begin[${s}]`))).join(",")}this.userCode=`\n      ${r} begin = ${r}(${t});\n      ${r} strides = ${r}(${e});\n\n      void main() {\n        ${a} coords = getOutputCoords();\n        setOutput(getX(${i}));\n      }\n    `}}class NC{constructor(t){this.gpgpu=t,this.numUsedTextures=0,this.numFreeTextures=0,this._numBytesAllocated=0,this._numBytesFree=0,this.freeTextures={},this.logEnabled=!1,this.usedTextures={}}acquireTexture(t,e,n){const s=CC(e,n),r=SC(t,s,n);r in this.freeTextures||(this.freeTextures[r]=[]),r in this.usedTextures||(this.usedTextures[r]=[]);const a=IC(t,s,this.gpgpu.gl,this.gpgpu.textureConfig,n);if(this.freeTextures[r].length>0){this.numFreeTextures--,this.numUsedTextures++,this._numBytesFree-=a,this.log();const t=this.freeTextures[r].shift();return this.usedTextures[r].push(t),t}let i;return s===Kk.PACKED_2X2_FLOAT32?i=this.gpgpu.createPackedMatrixTexture(t[0],t[1]):s===Kk.PACKED_2X2_FLOAT16?i=this.gpgpu.createFloat16PackedMatrixTexture(t[0],t[1]):s===Kk.UNPACKED_FLOAT32?i=this.gpgpu.createFloat32MatrixTexture(t[0],t[1]):s===Kk.UNPACKED_FLOAT16?i=this.gpgpu.createFloat16MatrixTexture(t[0],t[1]):s===Kk.PACKED_4X1_UNSIGNED_BYTE&&(i=this.gpgpu.createUnsignedBytesMatrixTexture(t[0],t[1])),this.usedTextures[r].push(i),this.numUsedTextures++,this._numBytesAllocated+=a,this.log(),i}releaseTexture(t,e,n,s){if(null==this.freeTextures)return;const r=CC(n,s),a=SC(e,r,s);a in this.freeTextures||(this.freeTextures[a]=[]);const i=IC(e,r,this.gpgpu.gl,this.gpgpu.textureConfig,s),o=ct().get("WEBGL_DELETE_TEXTURE_THRESHOLD");-1!==o&&this._numBytesAllocated>o?(this.gpgpu.deleteMatrixTexture(t),this._numBytesAllocated-=i):(this.freeTextures[a].push(t),this.numFreeTextures++,this._numBytesFree+=i),this.numUsedTextures--;const l=this.usedTextures[a],u=l.indexOf(t);if(u<0)throw new Error("Cannot release a texture that was never provided by this texture manager");l.splice(u,1),this.log()}log(){if(!this.logEnabled)return;const t=this.numFreeTextures+this.numUsedTextures;console.log("Free/Used",`${this.numFreeTextures} / ${this.numUsedTextures}`,`(${t})`);const e=this._numBytesFree/this._numBytesAllocated;console.log("Bytes allocated: "+this._numBytesAllocated),console.log(`Bytes unused: ${this._numBytesFree} (${Math.round(100*e)}%)`)}get numBytesAllocated(){return this._numBytesAllocated}get numBytesFree(){return this._numBytesFree}getNumUsedTextures(){return this.numUsedTextures}getNumFreeTextures(){return this.numFreeTextures}dispose(){if(null!=this.freeTextures){for(const t in this.freeTextures)this.freeTextures[t].forEach((t=>{this.gpgpu.deleteMatrixTexture(t)}));for(const t in this.usedTextures)this.usedTextures[t].forEach((t=>{this.gpgpu.deleteMatrixTexture(t)}));this.freeTextures=null,this.usedTextures=null,this.numUsedTextures=0,this.numFreeTextures=0,this._numBytesAllocated=0,this._numBytesFree=0}}}function IC(t,e,n,s,r){const a=function(t,e){switch(t){case Kk.PACKED_2X2_FLOAT32:return UI(e);case Kk.PACKED_2X2_FLOAT16:return GI(e);case Kk.UNPACKED_FLOAT32:return PI(e);case Kk.UNPACKED_FLOAT16:return WI(e);case Kk.PACKED_4X1_UNSIGNED_BYTE:return VI(e);default:throw new Error("Unknown physical texture type "+t)}}(e,s);let i;if(r){const[e,n]=Jk(t[0],t[1]);i=e*n}else{const[e,n]=Xk(t[0],t[1]);i=e*n}return i*function(t,e){const n=t;if(e===n.R32F)return 4;if(e===n.R16F)return 2;if(e===n.RGBA32F)return 16;if(e===t.RGBA)return 16;if(e===n.RGBA16F)return 8;throw new Error("Unknown internal format "+e)}(n,a)}function CC(t,e){if(t===qk.UPLOAD)return Kk.PACKED_2X2_FLOAT32;if(t===qk.RENDER||null==t)return function(t){return ct().getBool("WEBGL_RENDER_FLOAT32_ENABLED")?t?Kk.PACKED_2X2_FLOAT32:Kk.UNPACKED_FLOAT32:t?Kk.PACKED_2X2_FLOAT16:Kk.UNPACKED_FLOAT16}(e);if(t===qk.DOWNLOAD||t===qk.PIXELS)return Kk.PACKED_4X1_UNSIGNED_BYTE;throw new Error("Unknown logical texture type "+t)}function SC(t,e,n){return`${t[0]}_${t[1]}_${e}_${n}`}class TC{constructor(t,e){this.variableNames=["A"];const n=new Array(t.length);for(let s=0;s<n.length;s++)n[s]=t[s]*e[s];this.outputShape=n,this.rank=n.length;const s=eI(this.rank),r=function(t){const e=t.length;if(e>5)throw Error(`Tile for rank ${e} is not yet supported`);if(1===e)return`imod(resRC, ${t[0]})`;const n=["resRC.x","resRC.y","resRC.z","resRC.w","resRC.u"],s=[];for(let e=0;e<t.length;e++)s.push(`imod(${n[e]}, ${t[e]})`);return s.join()}(t);this.userCode=`\n      void main() {\n        ${s} resRC = getOutputCoords();\n        setOutput(getA(${r}));\n      }\n    `}}class $C{constructor(t,e){this.variableNames=["A"],this.outputShape=t,this.userCode=`\n      float unaryOperation(float x) {\n        ${e}\n      }\n\n      void main() {\n        float x = getAAtOutCoords();\n        float y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    `}}const EC="return abs(x);",AC="if (isnan(x)) return x;\n  return (x < 0.0) ? 0.0 : x;\n",RC="if (isnan(x)) return x;\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n",DC="return (x >= 0.0) ? x : (exp(x) - 1.0);",FC=`\n  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n  // see: https://arxiv.org/abs/1706.02515\n  float scaleAlpha = ${Ll};\n  float scale = ${zl};\n  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);\n`,_C="return -x;",OC="return ceil(x);",MC="return floor(x);",LC="return exp(x);",zC="return exp(x) - 1.0;",BC=`\n  // Error function is calculated approximately with elementary function.\n  // See "Handbook of Mathematical Functions with Formulas,\n  // Graphs, and Mathematical Tables", Abramowitz and Stegun.\n  float p = ${Bl};\n  float a1 = ${Pl};\n  float a2 = ${Wl};\n  float a3 = ${Vl};\n  float a4 = ${Ul};\n  float a5 = ${Gl};\n\n  float sign = sign(x);\n  x = abs(x);\n  float t = 1.0 / (1.0 + p * x);\n  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));\n`,PC="return x;",WC="\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",VC="\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",UC="\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n";class GC{constructor(t,e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=t,this.userCode=`\n      vec4 unaryOperation(vec4 x) {\n        ${e}\n      }\n\n      void main() {\n        vec4 x = getAAtOutCoords();\n        vec4 y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    `}}class HC{constructor(t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!1,this.outputShape=t;const e=t.length,n=PN("rc",e),s=eI(e),r=function(t,e){if(1===t)return"rc";let n="";for(let s=0;s<t;s++)n+=e[s],s<t-1&&(n+=",");return n}(e,n),a=n.slice(-2),i=e<=1?"rc":`vec2(${a.join(",")})`;this.userCode=`\n      void main() {\n        ${s} rc = getOutputCoords();\n        vec4 packedInput = getA(${r});\n\n        setOutput(getChannel(packedInput, ${i}));\n      }\n    `}}const{segment_util:jC}=s,qC=ru,KC=au,XC=iu,YC=ou,JC={};function ZC(t,e=!1){if("linear"===t)return"return x;";if("relu"===t)return e?WC:AC;if("elu"===t)return e?UC:DC;if("relu6"===t)return e?VC:RC;if("prelu"===t)return e?uI:oI;throw new Error(`Activation ${t} has not been implemented for the WebGL backend.`)}class QC extends C{constructor(t){if(super(),this.pendingRead=new WeakMap,this.pendingDisposal=new WeakSet,this.dataRefCount=new WeakMap,this.numBytesInGPU=0,this.uploadWaitMs=0,this.downloadWaitMs=0,this.warnedAboutMemory=!1,this.warnedAboutCPUBackend=!1,this.pendingDeletes=0,this.disposed=!1,!ct().getBool("HAS_WEBGL"))throw new Error("WebGL is not supported on this device");if(null==t){const t=Hk(ct().getNumber("WEBGL_VERSION"));this.binaryCache=((e=ct().getNumber("WEBGL_VERSION"))in JC||(JC[e]={}),JC[e]),this.gpgpu=new HI(t),this.canvas=t.canvas,this.gpgpuCreatedLocally=!0}else this.gpgpu=t,this.binaryCache={},this.gpgpuCreatedLocally=!1,this.canvas=t.gl.canvas;var e;this.textureManager=new NC(this.gpgpu),this.numMBBeforeWarning=null==ct().global.screen?1024:ct().global.screen.height*ct().global.screen.width*window.devicePixelRatio*600/1024/1024,this.texData=new I(this,Br())}numDataIds(){return this.texData.numDataIds()+(this.cpuBackend?this.cpuBackend.numDataIds():0)-this.pendingDeletes}write(t,e,n){if((ct().getBool("WEBGL_CHECK_NUMERICAL_PROBLEMS")||ct().getBool("DEBUG"))&&this.checkNumericalProblems(t),"complex64"===n&&null!=t)throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");const s={};return this.texData.set(s,{shape:e,dtype:n,values:t,usage:qk.UPLOAD,refCount:1,complexParentRefCount:0}),s}incRef(t){this.texData.get(t).refCount++}decRef(t){this.texData.has(t)&&this.texData.get(t).refCount--}move(t,e,n,s){if(ct().getBool("DEBUG")&&this.checkNumericalProblems(e),"complex64"===s)throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");this.texData.set(t,{shape:n,dtype:s,values:e,usage:qk.UPLOAD,refCount:1,complexParentRefCount:0})}disposeIntermediateTensorInfo(t){const e=t.dataId;if(this.texData.has(e)){const t=this.texData.get(e);t.refCount--,t.refCount<1&&this.disposeData(e)}}readSync(t){const e=this.texData.get(t),{values:n,dtype:s,complexTensorInfos:r,slice:a,shape:i,isPacked:o}=e;if(null!=a){let e;e=o?new GC(i,PC):new $C(i,PC);const n=this.runWebGLProgram(e,[{dataId:t,shape:i,dtype:s}],s),r=this.readSync(n.dataId);return this.disposeIntermediateTensorInfo(n),r}if(null!=n)return this.convertAndCacheOnCPU(t);if("string"===s)return n;const l=null!=this.activeTimers;let u,c;return l&&(u=Gn()),c="complex64"===s?ql(this.readSync(r.real.dataId),this.readSync(r.imag.dataId)):this.getValuesFromTexture(t),l&&(this.downloadWaitMs+=Gn()-u),this.convertAndCacheOnCPU(t,c)}async read(t){if(this.pendingRead.has(t)){const e=this.pendingRead.get(t);return new Promise((t=>e.push(t)))}const e=this.texData.get(t),{values:n,shape:s,slice:r,dtype:a,complexTensorInfos:i,isPacked:o}=e;if(null!=r){let e;e=o?new GC(s,PC):new $C(s,PC);const n=this.runWebGLProgram(e,[{dataId:t,shape:s,dtype:a}],a),r=this.read(n.dataId);return this.disposeIntermediateTensorInfo(n),r}if(null!=n)return this.convertAndCacheOnCPU(t);if(!ct().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")&&2===ct().getNumber("WEBGL_VERSION"))throw new Error("tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.");let l,u,c=null;if("complex64"!==a&&ct().get("WEBGL_BUFFER_SUPPORTED")){l=this.decode(t);const e=this.texData.get(l.dataId);c=this.gpgpu.createBufferFromTexture(e.texture,...Yk(s))}if(this.pendingRead.set(t,[]),"complex64"!==a&&await this.gpgpu.createAndWaitForFence(),"complex64"===a){const t=await Promise.all([this.read(i.real.dataId),this.read(i.imag.dataId)]);u=ql(t[0],t[1])}else if(null==c)u=this.getValuesFromTexture(t);else{const t=_(s);u=this.gpgpu.downloadFloat32MatrixFromBuffer(c,t)}null!=l&&this.disposeIntermediateTensorInfo(l);const h=this.convertAndCacheOnCPU(t,u),p=this.pendingRead.get(t);return this.pendingRead.delete(t),p.forEach((t=>t(h))),this.pendingDisposal.has(t)&&(this.pendingDisposal.delete(t),this.disposeData(t),this.pendingDeletes--),h}checkNumericalProblems(t){if(null!=t)for(let e=0;e<t.length;e++){const n=t[e];if(!tN(n)){if(ct().getBool("WEBGL_RENDER_FLOAT32_CAPABLE"))throw Error(`The value ${n} cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'`);throw Error(`The value ${n} cannot be represented on this device.`)}}}getValuesFromTexture(t){const{shape:e,dtype:n,isPacked:s}=this.texData.get(t),r=_(e);if(ct().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")){const n=this.decode(t),s=this.texData.get(n.dataId),a=this.gpgpu.downloadMatrixFromPackedTexture(s.texture,...Yk(e)).subarray(0,r);return this.disposeIntermediateTensorInfo(n),a}const a=ct().getBool("WEBGL_PACK")&&!0===s,i=a?pN(e):e,o=a?new FI(i):new DI(i),l=this.runWebGLProgram(o,[{shape:i,dtype:n,dataId:t}],"float32"),u=this.texData.get(l.dataId),c=this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(u.texture,u.texShape[0],u.texShape[1]).subarray(0,r);return this.disposeIntermediateTensorInfo(l),c}async time(t){const e=this.activeTimers,n=[];let s=!1;null==this.programTimersStack?(this.programTimersStack=n,s=!0):this.activeTimers.push(n),this.activeTimers=n,t();const r=F(this.activeTimers.map((t=>t.query))).filter((t=>null!=t)),a=F(this.activeTimers.map((t=>t.name))).filter((t=>null!=t));this.activeTimers=e,s&&(this.programTimersStack=null);const i={uploadWaitMs:this.uploadWaitMs,downloadWaitMs:this.downloadWaitMs,kernelMs:null,wallMs:null};if(ct().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0){const t=await Promise.all(r);i.kernelMs=function(t){let e=0;for(let n=0;n<t.length;n++)e+=t[n];return e}(t),i.getExtraProfileInfo=()=>t.map(((t,e)=>({name:a[e],ms:t}))).map((t=>`${t.name}: ${t.ms}`)).join(", ")}else i.kernelMs={error:"WebGL query timers are not supported in this environment."};return this.uploadWaitMs=0,this.downloadWaitMs=0,i}memory(){return{unreliable:!1,numBytesInGPU:this.numBytesInGPU,numBytesInGPUAllocated:this.textureManager.numBytesAllocated,numBytesInGPUFree:this.textureManager.numBytesFree}}startTimer(){return ct().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0?this.gpgpu.beginQuery():{startMs:Gn(),endMs:null}}endTimer(t){return ct().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0?(this.gpgpu.endQuery(),t):(t.endMs=Gn(),t)}async getQueryTime(t){if(ct().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0)return this.gpgpu.waitForQueryAndGetTime(t);const e=t;return e.endMs-e.startMs}disposeData(t){if(this.pendingDisposal.has(t))return;if(this.pendingRead.has(t))return this.pendingDisposal.add(t),void this.pendingDeletes++;if(!this.texData.has(t))return;if(this.texData.get(t).complexParentRefCount>0)return void this.texData.get(t).refCount--;this.releaseGPUData(t);const{complexTensorInfos:e}=this.texData.get(t);null!=e&&(this.texData.get(e.real.dataId).complexParentRefCount--,this.disposeIntermediateTensorInfo(e.real),this.texData.get(e.imag.dataId).complexParentRefCount--,this.disposeIntermediateTensorInfo(e.imag)),this.texData.delete(t)}releaseGPUData(t){const{texture:e,dtype:n,texShape:s,usage:r,isPacked:a,slice:i}=this.texData.get(t),o=i&&i.origDataId||t,l=this.dataRefCount.get(o);l>1?this.dataRefCount.set(o,l-1):(this.dataRefCount.delete(o),null!=e&&(this.numBytesInGPU-=this.computeBytes(s,n),this.textureManager.releaseTexture(e,s,r,a)));const u=this.texData.get(t);u.texture=null,u.texShape=null,u.isPacked=!1,u.slice=null}getTexture(t){return this.uploadToGPU(t),this.texData.get(t).texture}getDataInfo(t){return this.texData.get(t)}getCPUBackend(){return ct().getBool("WEBGL_CPU_FORWARD")?(null==this.cpuBackend&&(this.cpuBackend=Br().findBackend("cpu")),this.cpuBackend):null}shouldExecuteOnCPU(t,e=128){const n=this.getCPUBackend();return this.warnedAboutCPUBackend||null!=n||(console.warn("Your application contains ops that are small enough to be executed on the CPU backend, however the CPU backend cannot be found. Consider importing the CPU backend (@tensorflow/tfjs-backend-cpu) for better performance."),this.warnedAboutCPUBackend=!0),null!=n&&t.every((t=>null==this.texData.get(t.dataId).texture&&_(t.shape)<e))}getGPGPUContext(){return this.gpgpu}slice(t,e,n){if(this.shouldExecuteOnCPU([t])){const s=DN(this.texData.get(t.dataId).values,e,n,t.shape,t.dtype);return this.makeOutput(n,t.dtype,s)}if(0===_(n))return Ss([],n,t.dtype);const{isPacked:s}=this.texData.get(t.dataId),r=Dr(t.shape,e,n);if(s||!r){const s=ct().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new vC(n):new xC(n),r=s.getCustomSetupFunc(e);return this.compileAndRun(s,[t],null,r)}return this.uploadToGPU(t.dataId),this.shallowSlice(t,e,n)}shallowSlice(t,e,n){const s=this.texData.get(t.dataId),r=this.makeOutput(n,t.dtype),a=this.texData.get(r.dataId);Object.assign(a,s),a.shape=n,a.dtype=t.dtype;let i=Fr(e,t.strides);s.slice&&(i+=s.slice.flatOffset),a.slice={flatOffset:i,origDataId:s.slice&&s.slice.origDataId||t.dataId};const o=this.dataRefCount.get(a.slice.origDataId)||1;return this.dataRefCount.set(a.slice.origDataId,o+1),r}stridedSlice(t,e,n,s){const r=this.tryRunOnCpuOrThrow([t],(()=>this.cpuBackend.stridedSlice(t,e,n,s)));if(r)return r;const a=kr(e,n,s);if(a.some((t=>0===t)))return Ss([],a);const i=new kC(e,s,a);return this.compileAndRun(i,[t])}reverse(t,e){const n=ct().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new mC(t.shape,e):new fC(t.shape,e);return this.compileAndRun(n,[t])}neg(t){const e=this.tryRunOnCpuOrThrow([t],(()=>this.cpuBackend.neg(t)));if(e)return e;if(ct().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(t,_C,t.dtype);const n=new $C(t.shape,_C);return this.compileAndRun(n,[t])}batchMatMul(t,e,n,s){const r=n?t.shape[2]:t.shape[1],a=s?e.shape[1]:e.shape[2],i=n?t.shape[1]:t.shape[2],o=Math.max(t.shape[0],e.shape[0]);if((1===r||1===a)&&i>1e3){n&&(t=ia(t,[0,2,1])),s&&(e=ia(e,[0,2,1]));const r=1===a?t:t.as3D(o,i,1),l=1===a?2:1,u=1===a?e.as3D(o,1,i):e;return pi(r,u).sum(l,!0)}const l=as(t.dtype,e.dtype),u=new QI(t.shape,e.shape,[o,r,a],n,s);return this.compileAndRun(u,[t,e],l)}fusedBatchMatMul({a:t,b:e,transposeA:n,transposeB:s,bias:r,activation:a,preluActivationWeights:i}){const o=n?t.shape[2]:t.shape[1],l=s?e.shape[1]:e.shape[2],u=Math.max(t.shape[0],e.shape[0]),c=as(t.dtype,e.dtype),h=null!=r,p=null!=i,d=a?ZC(a,!0):null,f=new QI(t.shape,e.shape,[u,o,l],n,s,h,d,p),m=[t,e];return r&&m.push(r),i&&m.push(i),this.compileAndRun(f,m,c)}localResponseNormalization4D(t,e,n,s,r){const a=ct().getBool("WEBGL_PACK_NORMALIZATION")?new YI(t.shape,e,n,s,r):new KI(t.shape,e,n,s,r);return this.compileAndRun(a,[t])}LRNGrad(t,e,n,s,r,a,i){const o=new XI(e.shape,s,r,a,i);return this.compileAndRun(o,[e,n,t])}tile(t,e){if("string"===t.dtype){const n=this.readSync(t.dataId).map((t=>jn(t))),s=ir(t.shape,t.dtype,n);return KC(s,e)}const n=new TC(t.shape,e);return this.compileAndRun(n,[t])}pad(t,e,n){const s=ct().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new rC(t.shape,e,n):new sC(t.shape,e,n);return this.compileAndRun(s,[t])}gather(t,e,n){const s=this.tryRunOnCpuOrThrow([t,e],(()=>this.cpuBackend.gather(t,e,n)));if(s)return s;const r=new LI(t.shape,e.size,n);return this.compileAndRun(r,[t,e])}batchToSpaceND(t,e,n){A(t.rank<=4,(()=>"batchToSpaceND for rank > 4 with a WebGL backend not implemented yet"));const s=e.reduce(((t,e)=>t*e)),r=$l(t.shape,e,s),a=El(r.length,e.length),i=Al(t.shape,e,s),o=Rl(n,e.length),l=Dl(i,n,e.length);return ia(t.reshape(r),a).reshape(i).slice(o,l)}spaceToBatchND(t,e,n){A(t.rank<=4,(()=>"spaceToBatchND for rank > 4 with a WebGL backend not implemented yet"));const s=e.reduce(((t,e)=>t*e)),r=[[0,0]];r.push(...n);for(let n=1+e.length;n<t.shape.length;++n)r.push([0,0]);const a=t.pad(r),i=$l(a.shape,e,s,!1),o=El(i.length,e.length,!1),l=Al(a.shape,e,s,!1),u=ia(a.reshape(i),o);return aa(u,l)}reduce(t,e,n){const s=t.shape[0],r=t.shape[1],a=ri(r),i=Math.ceil(r/a),o=new oC({windowSize:a,inSize:r,batchSize:s,outSize:i},e),l=this.compileAndRun(o,[t],n);return 1===l.shape[1]?l:this.reduce(l,e,n)}argReduce(t,e,n=null){let s=t.shape[0],r=t.shape[1];null!=n&&(s=n.shape[0],r=n.shape[1]);const a=ri(r),i={windowSize:a,inSize:r,batchSize:s,outSize:Math.ceil(r/a)},o=new zN(i,e,null==n),l=[t];null!=n&&l.push(n);const u=this.compileAndRun(o,l,"int32");return 1===u.shape[1]?u:this.argReduce(t,e,u)}argReducePacked(t,e,n=null){const s=null!=n?n.shape:t.shape,r=ri(s[s.length-1]),a=new rI(s,r,e,null==n),i=null==n?[t]:[t,n],o=this.compileAndRun(a,i,"int32");return o.rank===t.rank?this.argReducePacked(t,e,o):o}sum(t,e){ea("sum",e,t.rank);const[n,s]=Qr(t.shape,e),r=_(s),a=t.as2D(-1,r),i=is(t.dtype);return this.reduce(a,"sum",i).reshape(n)}prod(t,e){const n=this.tryRunOnCpuOrThrow([t],(()=>this.cpuBackend.prod(t,e)));if(n)return n;const[s,r]=Qr(t.shape,e),a=_(r),i=t.as2D(-1,a),o=is(t.dtype);return this.reduce(i,"prod",o).reshape(s)}unsortedSegmentSum(t,e,n){let s=0;const r=na([s],t.rank);let a=t;null!=r&&(a=ia(t,r),s=ra(1,t.rank)[0]);const i=jC.computeOutShape(a.shape,s,n),o=_([a.shape[s]]),l=a.as2D(-1,o),u=is(t.dtype);let c=this.segOpCompute(l,"unsortedSegmentSum",e,u,n).reshape(i);return null!=r&&(c=ia(c,sa(r))),c}segOpCompute(t,e,n,s,r){const a=t.shape[0],i=t.shape[1],o=jC.segOpComputeOptimalWindowSize(i,r),l=new yC({windowSize:o,inSize:i,batchSize:a,numSegments:r},e),u=this.compileAndRun(l,[t,n],s);return u.shape[1]===r?u:(n=Gi(0,r).tile([i/o]),this.segOpCompute(u,e,n,s,r))}argMinMaxReduce(t,e,n){const s=[e];if(ea("arg"+n.charAt(0).toUpperCase()+n.slice(1),s,t.rank),!ct().getBool("WEBGL_PACK_REDUCE")||t.rank<=2){const[e,r]=Qr(t.shape,s),a=_(r),i=t.as2D(-1,a);return this.argReduce(i,n).reshape(e)}return this.argReducePacked(t,n)}argMin(t,e){return this.argMinMaxReduce(t,e,"min")}argMax(t,e){return this.argMinMaxReduce(t,e,"max")}cumsum(t,e,n,s){if(e!==t.rank-1)throw new Error(`WebGL cumsum shader expects an inner-most axis=${t.rank-1} but got axis=`+e);const r=t.shape[e];let a=t;for(let e=0;e<=Math.ceil(Math.log2(r))-1;e++){const n=new CI(t.shape,!1,s),r=n.getCustomSetupFunc(e),i=a;a=this.compileAndRun(n,[a],a.dtype,r),i.dispose()}if(n){const e=new CI(t.shape,n,s),r=a;a=this.compileAndRun(e,[a]),r.dispose()}return a}equal(t,e){if(ct().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,"\n  return vec4(equal(a, b));\n","bool");const n=new lI("return float(a == b);",t.shape,e.shape);return this.compileAndRun(n,[t,e],"bool")}less(t,e){const n=this.tryRunOnCpuOrThrow([t,e],(()=>this.cpuBackend.less(t,e)));if(n)return n;if(ct().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,"\n  return vec4(lessThan(a, b));\n","bool");const s=new lI("return float(a < b);",t.shape,e.shape);return this.compileAndRun(s,[t,e],"bool")}lessEqual(t,e){if(ct().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,"\n  return vec4(lessThanEqual(a, b));\n","bool");const n=new lI("return float(a <= b);",t.shape,e.shape);return this.compileAndRun(n,[t,e],"bool")}greater(t,e){const n=this.tryRunOnCpuOrThrow([t,e],(()=>this.cpuBackend.greater(t,e)));if(n)return n;if(ct().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,"\n  return vec4(greaterThan(a, b));\n","bool");const s=new lI("return float(a > b);",t.shape,e.shape);return this.compileAndRun(s,[t,e],"bool")}greaterEqual(t,e){if(ct().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,"\n  return vec4(greaterThanEqual(a, b));\n","bool");const n=new lI("return float(a >= b);",t.shape,e.shape);return this.compileAndRun(n,[t,e],"bool")}logicalNot(t){const e=new $C(t.shape,"return float(!(x >= 1.0));");return this.compileAndRun(e,[t])}logicalAnd(t,e){if(ct().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,"\n  return vec4(\n    vec4(greaterThanEqual(a, vec4(1.0))) *\n    vec4(greaterThanEqual(b, vec4(1.0))));\n","bool");const n=new lI("return float(a >= 1.0 && b >= 1.0);",t.shape,e.shape);return this.compileAndRun(n,[t,e],"bool")}logicalOr(t,e){if(ct().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,"\n  return min(\n    vec4(greaterThanEqual(a, vec4(1.0))) +\n    vec4(greaterThanEqual(b, vec4(1.0))),\n    vec4(1.0));\n","bool");const n=new lI("return float(a >= 1.0 || b >= 1.0);",t.shape,e.shape);return this.compileAndRun(n,[t,e],"bool")}select(t,e,n){const s=new bC(t.rank,e.shape,e.rank);return this.compileAndRun(s,[t,e,n],as(e.dtype,n.dtype))}where(t){Hl("tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead");const e=t.dataSync();return YC(t.shape,e)}topk(t,e,n){const s=t.dataSync();return XC(s,t.shape,t.dtype,e,n)}min(t,e){ea("min",e,t.rank);const[n,s]=Qr(t.shape,e),r=_(s),a=t.as2D(-1,r);return this.reduce(a,"min",a.dtype).reshape(n)}minimum(t,e){const n=this.tryRunOnCpuOrThrow([t,e],(()=>this.cpuBackend.minimum(t,e)));if(n)return n;const s=ct().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new cI("\n  vec4 result = vec4(min(a, b));\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  \n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n\n  return result;\n",t.shape,e.shape):new lI("\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n\n  return min(a, b);\n",t.shape,e.shape);return this.compileAndRun(s,[t,e])}mod(t,e){const n=ct().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new cI("\n  vec4 result = mod(a, b);\n  vec4 isNaN = vec4(equal(b, vec4(0.0)));\n  \n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n\n  return result;\n",t.shape,e.shape):new lI("if (b == 0.0) return NAN;\n  return mod(a, b);",t.shape,e.shape);return this.compileAndRun(n,[t,e])}maximum(t,e){const n=this.tryRunOnCpuOrThrow([t,e],(()=>this.cpuBackend.maximum(t,e)));if(n)return n;const s=ct().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new cI("\n  vec4 result = vec4(max(a, b));\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  \n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n\n  return result;\n",t.shape,e.shape):new lI("\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n\n  return max(a, b);\n",t.shape,e.shape);return this.compileAndRun(s,[t,e])}all(t,e){ea("all",e,t.rank);const[n,s]=Qr(t.shape,e),r=_(s),a=t.as2D(-1,r);return this.reduce(a,"all",a.dtype).reshape(n)}any(t,e){ea("any",e,t.rank);const[n,s]=Qr(t.shape,e),r=_(s),a=t.as2D(-1,r);return this.reduce(a,"any",a.dtype).reshape(n)}floorDiv(t,e){const n="int32";if(ct().getBool("WEBGL_PACK_BINARY_OPERATIONS"))return this.packedBinaryOp(t,e,"\n  ivec4 ia = round(a);\n  ivec4 ib = round(b);\n  bvec4 cond = notEqual(ib, ivec4(0));\n  ivec4 result = ivec4(0);\n  vec4 s = sign(a) * sign(b);\n\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n  if (cond[0]) {\n    result[0] = idiv(ia[0], ib[0], s[0]);\n  }\n  if (cond[1]) {\n    result[1] = idiv(ia[1], ib[1], s[1]);\n  }\n  if (cond[2]) {\n    result[2] = idiv(ia[2], ib[2], s[2]);\n  }\n  if (cond[3]) {\n    result[3] = idiv(ia[3], ib[3], s[3]);\n  }\n  return vec4(result);\n",n);const s=new lI("\n  float s = sign(a) * sign(b);\n  int ia = round(a);\n  int ib = round(b);\n  if (ib != 0) {\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n    return float(idiv(ia, ib, s));\n  } else {\n    return NAN;\n  }\n",t.shape,e.shape);return this.compileAndRun(s,[t,e],n)}packedUnaryOp(t,e,n){const s=new GC(t.shape,e);return this.compileAndRun(s,[t],n)}packedBinaryOp(t,e,n,s,r=!1){const a=new cI(n,t.shape,e.shape,r);return this.compileAndRun(a,[t,e],s)}makeComplexComponentTensorInfo(t,e){return{dataId:e.dataId,dtype:e.dtype,shape:t.shape}}addN(t){if(1===t.length)return t[0];if(t.length>ct().get("WEBGL_MAX_TEXTURES_IN_SHADER")){const e=Math.floor(t.length/2),n=this.addN(t.slice(0,e)),s=this.addN(t.slice(e));return this.addN([n,s])}const e=t.map((t=>t.dtype)).reduce(((t,e)=>as(t,e))),n=t.map((t=>t.shape)),s=ct().getBool("WEBGL_PACK")?new LN(t[0].shape,n):new MN(t[0].shape,n);return this.compileAndRun(s,t,e)}pow(t,e){const n=ct().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new cI("\n  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.\n  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));\n  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);\n  vec4 result = multiplier * pow(abs(a), b);\n\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\n  bvec4 isExpZero = equal(b, vec4(0.0));\n  result.r = isExpZero.r ? 1.0 : result.r;\n  result.g = isExpZero.g ? 1.0 : result.g;\n  result.b = isExpZero.b ? 1.0 : result.b;\n  result.a = isExpZero.a ? 1.0 : result.a;\n\n  vec4 isNaN = vec4(lessThan(a, vec4(0.0))) * vec4(lessThan(floor(b), b));\n  \n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n\n  return result;\n",t.shape,e.shape):new lI("\nif(a < 0.0 && floor(b) < b){\n  return NAN;\n}\nif (b == 0.0) {\n  return 1.0;\n}\nreturn (round(mod(b, 2.0)) != 1) ?\n    pow(abs(a), b) : sign(a) * pow(abs(a), b);\n",t.shape,e.shape),s=as(t.dtype,e.dtype);return this.compileAndRun(n,[t,e],s)}ceil(t){if(this.shouldExecuteOnCPU([t])){const e=IN(this.texData.get(t.dataId).values,t.dtype);return this.makeOutput(t.shape,t.dtype,e)}if(ct().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(t,OC,t.dtype);const e=new $C(t.shape,OC);return this.compileAndRun(e,[t])}floor(t){if(this.shouldExecuteOnCPU([t])){const e=TN(this.texData.get(t.dataId).values,t.dtype);return this.makeOutput(t.shape,t.dtype,e)}if(ct().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(t,MC,t.dtype);const e=new $C(t.shape,MC);return this.compileAndRun(e,[t])}sign(t){const e=new $C(t.shape,"\n  if (isnan(x)) { return 0.0; }\n  return sign(x);\n");return this.compileAndRun(e,[t])}isNaN(t){const e=new $C(t.shape,"return float(isnan(x));");return this.compileAndRun(e,[t],"bool")}isInf(t){const e=new $C(t.shape,"return float(isinf(x));");return this.compileAndRun(e,[t],"bool")}isFinite(t){const e=new $C(t.shape,"return float(!isnan(x) && !isinf(x));");return this.compileAndRun(e,[t],"bool")}round(t){const e=new $C(t.shape,"\n  // OpenGL ES does not support round function.\n  // The algorithm is based on banker's rounding.\n  float base = floor(x);\n  if ((x - base) < 0.5) {\n    return floor(x);\n  } else if ((x - base) > 0.5) {\n    return ceil(x);\n  } else {\n    if (mod(base, 2.0) == 0.0) {\n      return base;\n    } else {\n      return base + 1.0;\n    }\n  }\n");return this.compileAndRun(e,[t])}exp(t){if(this.shouldExecuteOnCPU([t])){const e=CN(this.texData.get(t.dataId).values,t.dtype);return this.makeOutput(t.shape,t.dtype,e)}if(ct().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(t,LC,t.dtype);const e=new $C(t.shape,LC);return this.compileAndRun(e,[t])}expm1(t){if(this.shouldExecuteOnCPU([t])){const e=SN(this.texData.get(t.dataId).values,t.dtype);return this.makeOutput(t.shape,t.dtype,e)}if(ct().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(t,zC,t.dtype);const e=new $C(t.shape,zC);return this.compileAndRun(e,[t])}softmax(t,e){const n=W([e],t.shape),s=mi(t,n),r=ta(s.shape,n),a=gi(t,s.reshape(r)),i=this.exp(a),o=this.sum(i,n).reshape(r);return Ha(i,o)}log(t){if(this.shouldExecuteOnCPU([t])){const e=$N(this.texData.get(t.dataId).values,t.dtype);return this.makeOutput(t.shape,t.dtype,e)}if(ct().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(t,"\n  vec4 result = log(x);\n  vec4 isNaN = vec4(lessThan(x, vec4(0.0)));\n  result.r = isNaN.r == 1.0 ? NAN : result.r;\n  result.g = isNaN.g == 1.0 ? NAN : result.g;\n  result.b = isNaN.b == 1.0 ? NAN : result.b;\n  result.a = isNaN.a == 1.0 ? NAN : result.a;\n\n  return result;\n",t.dtype);const e=new $C(t.shape,"if (x < 0.0) return NAN;\n  return log(x);");return this.compileAndRun(e,[t])}log1p(t){const e=new $C(t.shape,"return log(1.0 + x);");return this.compileAndRun(e,[t])}sqrt(t){const e=new $C(t.shape,"return sqrt(x);");return this.compileAndRun(e,[t])}rsqrt(t){if(this.shouldExecuteOnCPU([t])){const e=RN(this.texData.get(t.dataId).values,t.dtype);return this.makeOutput(t.shape,t.dtype,e)}const e=new $C(t.shape,"return inversesqrt(x);");return this.compileAndRun(e,[t])}reciprocal(t){const e=new $C(t.shape,"return 1.0 / x;");return this.compileAndRun(e,[t])}relu(t){let e;return e=ct().getBool("WEBGL_PACK")?new GC(t.shape,WC):new $C(t.shape,AC),this.compileAndRun(e,[t])}relu6(t){let e;return e=ct().getBool("WEBGL_PACK")?new GC(t.shape,VC):new $C(t.shape,RC),this.compileAndRun(e,[t])}prelu(t,e){const n=ct().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new cI(uI,t.shape,e.shape):new lI(oI,t.shape,e.shape);return this.compileAndRun(n,[t,e])}elu(t){if(ct().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(t,UC,t.dtype);const e=new $C(t.shape,DC);return this.compileAndRun(e,[t])}eluDer(t,e){const n=ct().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new cI("\n  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));\n  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));\n",t.shape,e.shape):new lI("return (b >= 1.0) ? a : a * (b + 1.0);",t.shape,e.shape);return this.compileAndRun(n,[t,e])}selu(t){const e=new $C(t.shape,FC);return this.compileAndRun(e,[t])}clip(t,e,n){let s;s=ct().getBool("WEBGL_PACK_CLIP")?new pI(t.shape):new hI(t.shape);const r=s.getCustomSetupFunc(e,n);return this.compileAndRun(s,[t],null,r)}abs(t){if(this.shouldExecuteOnCPU([t])&&"complex64"!==t.dtype){const e=kN(this.texData.get(t.dataId).values);return this.makeOutput(t.shape,t.dtype,e)}if(ct().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(t,EC,t.dtype);const e=new $C(t.shape,EC);return this.compileAndRun(e,[t])}complexAbs(t){const e=this.texData.get(t.dataId),n=new dI(t.shape),s=[this.makeComplexComponentTensorInfo(t,e.complexTensorInfos.real),this.makeComplexComponentTensorInfo(t,e.complexTensorInfos.imag)];return this.compileAndRun(n,s)}sigmoid(t){const e=new $C(t.shape,"return 1.0 / (1.0 + exp(-1.0 * x));");return this.compileAndRun(e,[t])}softplus(t){const e=new $C(t.shape,"\n  float epsilon = 1.1920928955078125e-7;\n  float threshold = log(epsilon) + 2.0;\n\n  bool too_large = x > -threshold;\n  bool too_small = x < threshold;\n\n  float result;\n  float exp_x = exp(x);\n\n  if (too_large){\n    result = x;\n  }\n  else if (too_small){\n    result = exp_x;\n  }\n  else{\n    result = log(exp_x + 1.0);\n  }\n  return result;\n");return this.compileAndRun(e,[t])}asin(t){const e=new $C(t.shape,"if (isnan(x)) return x;\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return asin(x);\n");return this.compileAndRun(e,[t])}acos(t){const e=new $C(t.shape,"if (isnan(x)) return x;\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return acos(x);\n");return this.compileAndRun(e,[t])}atan(t){const e=new $C(t.shape,"if (isnan(x)) return x;\n  return atan(x);\n");return this.compileAndRun(e,[t])}sinh(t){const e=new $C(t.shape,"\n  float e2x = exp(x);\n  return (e2x - 1.0 / e2x) / 2.0;\n");return this.compileAndRun(e,[t])}cosh(t){const e=new $C(t.shape,"\n  float e2x = exp(-x);\n  return (e2x + 1.0 / e2x) / 2.0;\n");return this.compileAndRun(e,[t])}tanh(t){const e=new $C(t.shape,"\n  float e2x = exp(-2.0 * abs(x));\n  return sign(x) * (1.0 - e2x) / (1.0 + e2x);\n");return this.compileAndRun(e,[t])}asinh(t){const e=new $C(t.shape,"if (isnan(x)) return x;return log(x + sqrt(x * x + 1.0));");return this.compileAndRun(e,[t])}acosh(t){const e=new $C(t.shape,"if (isnan(x)) return x;\n  if (x < 1.0) return NAN;\n  return log(x + sqrt(x * x - 1.0));");return this.compileAndRun(e,[t])}atanh(t){const e=new $C(t.shape,"if (isnan(x)) return x;\n  if ((x < -1.0) || (x > 1.0)) return NAN;\n  return (log(1.0 + x) - log(1.0 - x)) / 2.0;");return this.compileAndRun(e,[t])}erf(t){const e=new $C(t.shape,BC);return this.compileAndRun(e,[t])}step(t,e){const n=new $C(t.shape,function(t=0){return`if (isnan(x)) return x;\n    return x > 0.0 ? 1.0 : float(${t});\n  `}(e));return this.compileAndRun(n,[t])}conv2dByMatMul(t,e,n,s,r,a){const i=t.shape,o=this.texData.get(t.dataId),l=n.inChannels,u=i[0]*i[1]*i[2],c=n.outChannels,h="channelsLast"===n.dataFormat,p=(1===u||1===c)&&l>1e3,d=i[2]%2!=0&&!!o.isPacked;if(p||!ct().getBool("WEBGL_LAZILY_UNPACK")||!ct().getBool("WEBGL_PACK_BINARY_OPERATIONS")||!d){const o=h?i[0]*i[1]*i[2]:i[0]*i[2]*i[3],l=aa(t,[1,o,n.inChannels]),u=aa(e,[1,n.inChannels,n.outChannels]),c=this.fusedBatchMatMul({a:l,b:u,transposeA:!1,transposeB:!1,bias:s,activation:r,preluActivationWeights:a});return aa(c,n.outShape)}const f=h?i[0]*i[1]*(i[2]+1):i[0]*i[2]*(i[3]+1),m={dataId:t.dataId,shape:[1,f,n.inChannels],dtype:t.dtype},g=o.shape;o.shape=o.shape.slice(),o.shape[o.shape.length-2]++,A(fN(o.shape,m.shape),(()=>`packed reshape ${o.shape} to ${m.shape} isn't free`));const y=aa(e,[1,n.inChannels,n.outChannels]),b=this.fusedBatchMatMul({a:m,b:y,transposeA:!1,transposeB:!1,bias:s,activation:r,preluActivationWeights:a}),x=this.texData.get(b.dataId);return A(x.isPacked,(()=>"batchMatMul result is expected to be packed")),o.shape=g,x.shape=n.outShape,Br().makeTensorFromDataId(b.dataId,n.outShape,b.dtype)}conv2dWithIm2Row(t,e,n,s,r,a){const{filterWidth:i,filterHeight:o,inChannels:l,outWidth:u,outHeight:c,dataFormat:h}=n,p="channelsLast"===h,d=i*o*l,f=c*u,m=[d,f],g=t.squeeze([0]),y=e.reshape([1,d,-1]),b=new qI(m,g.shape,n),x=this.compileAndRun(b,[g]).reshape([1,m[0],m[1]]),w=null!=s,v=null!=a,k=r?ZC(r,!0):null,N=new QI(x.shape,y.shape,[1,f,n.outChannels],!0,!1,w,k,v),I=[x,y];s&&I.push(s),v&&I.push(a);const C=this.compileAndRun(N,I);return p?C.reshape([1,c,u,n.outChannels]):C.reshape([1,n.outChannels,c,u])}fusedConv2d({input:t,filter:e,convInfo:n,bias:s,activation:r,preluActivationWeights:a}){if(1===n.filterHeight&&1===n.filterWidth&&1===n.dilationHeight&&1===n.dilationWidth&&1===n.strideHeight&&1===n.strideWidth&&("SAME"===n.padInfo.type||"VALID"===n.padInfo.type))return this.conv2dByMatMul(t,e,n,s,r,a);if(ct().getBool("WEBGL_CONV_IM2COL")&&1===t.shape[0])return this.conv2dWithIm2Row(t,e,n,s,r,a);const i=null!=s,o=null!=a,l=r?ZC(r,!1):null,u=new wI(n,i,l,o),c=[t,e];return s&&c.push(s),a&&c.push(a),this.compileAndRun(u,c)}conv2d(t,e,n){if(1===n.filterHeight&&1===n.filterWidth&&1===n.dilationHeight&&1===n.dilationWidth&&1===n.strideHeight&&1===n.strideWidth&&("SAME"===n.padInfo.type||"VALID"===n.padInfo.type))return this.conv2dByMatMul(t,e,n);if(ct().getBool("WEBGL_CONV_IM2COL")&&1===t.shape[0])return this.conv2dWithIm2Row(t,e,n);const s=new wI(n);return this.compileAndRun(s,[t,e])}conv2dDerInput(t,e,n){const s=new mI(n);return this.compileAndRun(s,[t,e])}conv2dDerFilter(t,e,n){const s=new fI(n);return this.compileAndRun(s,[t,e])}fusedDepthwiseConv2D({input:t,filter:e,convInfo:n,bias:s,activation:r,preluActivationWeights:a}){const i=ct().getBool("WEBGL_PACK_DEPTHWISECONV")&&n.strideWidth<=2&&n.outChannels/n.inChannels==1,o=r?ZC(r,i):null,l=[t,e],u=null!=s,c=null!=a;let h;return u&&l.push(s),c&&l.push(a),i?(h=new NI(n,u,o,c),this.compileAndRun(h,l)):(h=new kI(n,u,o,c),this.compileAndRun(h,l))}depthwiseConv2D(t,e,n){let s;return ct().getBool("WEBGL_PACK_DEPTHWISECONV")&&n.strideWidth<=2&&n.outChannels/n.inChannels==1?(s=new NI(n),this.compileAndRun(s,[t,e])):(s=new kI(n),this.compileAndRun(s,[t,e]))}depthwiseConv2DDerInput(t,e,n){const s=new xI(n);return this.compileAndRun(s,[t,e])}depthwiseConv2DDerFilter(t,e,n){const s=new bI(n);return this.compileAndRun(s,[t,e])}conv3d(t,e,n){const s=new vI(n);return this.compileAndRun(s,[t,e])}conv3dDerInput(t,e,n){const s=new yI(n);return this.compileAndRun(s,[t,e])}conv3dDerFilter(t,e,n){const s=new gI(n);return this.compileAndRun(s,[t,e])}unstack(t,e){const n=t.shape[e],s=new Array(t.rank-1);let r=0;for(let n=0;n<t.rank;n++)n!==e&&(s[r++]=t.shape[n]);const a=new Array(t.rank).fill(0),i=t.shape.slice();i[e]=1;const o=new Array(n);for(let n=0;n<o.length;n++)a[e]=n,o[n]=this.slice(t,a,i).reshape(s);return o}avgPool3d(t,e){const n=new iC(e,"avg",!1);return this.compileAndRun(n,[t],"float32")}avgPool3dBackprop(t,e,n){const s=new iI(n);return this.compileAndRun(s,[t],e.dtype)}maxPool3d(t,e){const n=new iC(e,"max",!1);return this.compileAndRun(n,[t],"float32")}maxPool3dBackprop(t,e,n,s){const r=new iC(s,"max",!0),a=this.compileAndRun(r,[e]),i=new ZI(s),o=this.compileAndRun(i,[t,a],e.dtype);return a.dispose(),o}resizeBilinear(t,e,n,s){const r=ct().getBool("WEBGL_PACK_IMAGE_OPERATIONS")?new hC(t.shape,e,n,s):new cC(t.shape,e,n,s);return this.compileAndRun(r,[t],"float32")}resizeBilinearBackprop(t,e,n){const s=new uC(t,e,n);return this.compileAndRun(s,[t])}resizeNearestNeighbor(t,e,n,s){const r=new dC(t.shape,e,n,s);return this.compileAndRun(r,[t])}resizeNearestNeighborBackprop(t,e,n){const s=new pC(t,e,n);return this.compileAndRun(s,[t])}multinomial(t,e,n,s){const r=e?t:eo(t),a=r.shape[0],i=r.shape[1],o=new tC(a,i,n),l=o.getCustomSetupFunc(s);return this.compileAndRun(o,[r],"int32",l)}oneHot(t,e,n,s){const r=new eC(t.size,e,n,s);return this.compileAndRun(r,[t])}diag(t){const e=new RI(t.size);return this.compileAndRun(e,[t])}cropAndResize(t,e,n,s,r,a){const i=new II(t.shape,e.shape,s,r,a);return this.compileAndRun(i,[t,e,n],"float32")}depthToSpace(t,e,n){A(e>1,(()=>"blockSize should be > 1 for depthToSpace, but was: "+e));const s=t.shape[0],r="NHWC"===n?t.shape[1]:t.shape[2],a="NHWC"===n?t.shape[2]:t.shape[3],i="NHWC"===n?t.shape[3]:t.shape[1],o=r*e,l=a*e,u=i/(e*e),c=new AI("NHWC"===n?[s,o,l,u]:[s,u,o,l],e,n);return this.compileAndRun(c,[t])}split(t,e,n){return qC(t,e,n)}scatterND(t,e,n){const{sliceRank:s,numUpdates:r,sliceSize:a,strides:i,outputSize:o}=Ml(0,t,n),l=[o/a,a],u=t.reshape([r,s]),c=e.reshape([r,a]);if(0===o)return nu(Ss([]),n);const h=qr(0),p=new gC(r,s,u.rank,c.rank,i,l);return this.compileAndRun(p,[c,u,h]).reshape(n)}sparseToDense(t,e,n,s){const{sliceRank:r,numUpdates:a,strides:i,outputSize:o}=Ml(0,t,n),l=new gC(a,r,t.rank,e.rank,i,[o,1],!1);return this.compileAndRun(l,[e,t,s]).reshape(n)}gatherND(t,e){const n=e.shape,s=n[n.length-1],[r,a,i,o]=Fl(t,e),l=e.reshape([a,s]),u=t.reshape([t.size/i,i]),c=new zI(s,o,[a,i]);return this.compileAndRun(c,[u,l]).reshape(r)}fill(t,e,n){if("string"===(n=n||Y(e))){const s=G(n,_(t));return s.fill(e),Br().makeTensor(s,t,n,this)}{const s=new MI(t,e),r=s.getCustomSetupFunc(e);return this.compileAndRun(s,[],n,r)}}onesLike(t){if("string"===t.dtype)throw new Error("onesLike is not supported under string dtype");return this.fill(t.shape,1,t.dtype)}zerosLike(t){return this.fill(t.shape,"string"===t.dtype?"":0,t.dtype)}linspace(t,e,n){return su(t,e,n)}makeTensorInfo(t,e,n){const s=this.write(n,t,e);return this.texData.get(s).usage=null,{dataId:s,shape:t,dtype:e}}makeOutput(t,e,n){const{dataId:s}=this.makeTensorInfo(t,e,n);return Br().makeTensorFromDataId(s,t,e,this)}unpackTensor(t){const e=new HC(t.shape);return this.runWebGLProgram(e,[t],t.dtype)}packTensor(t){const e=new nC(t.shape);return this.runWebGLProgram(e,[t],t.dtype,null,!0)}packedReshape(t,e){const n=[cN(t.shape),...hN(t.shape)],s={dtype:t.dtype,shape:n,dataId:t.dataId},r=[cN(e),...hN(e)],a=new lC(r,n),i=this.runWebGLProgram(a,[s],t.dtype,null,!0);return{dataId:i.dataId,shape:e,dtype:i.dtype}}decode(t){const e=this.texData.get(t),{isPacked:n,shape:s,dtype:r}=e,a=pN(s);let i;return i=n?new EI(a):new $I(a),{dtype:r,shape:s,dataId:this.runWebGLProgram(i,[{shape:a,dtype:r,dataId:t}],r,null,!0).dataId}}runWebGLProgram(t,e,n,s,r=!1){const a=this.makeTensorInfo(t.outputShape,n),i=this.texData.get(a.dataId);if(t.packedOutput&&(i.isPacked=!0),t.outPackingScheme===jk.DENSE){const e=Yk(t.outputShape);i.texShape=e.map((t=>2*t))}if(null!=t.outTexUsage&&(i.usage=t.outTexUsage),0===_(a.shape))return i.values=U(a.dtype,0),a;const o=[],l=e.map((e=>{if("complex64"===e.dtype)throw new Error("GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.");let n=this.texData.get(e.dataId);if(null==n.texture){if(!t.packedInputs&&_(e.shape)<=ct().getNumber("WEBGL_SIZE_UPLOAD_UNIFORM"))return{shape:e.shape,texData:null,isUniform:!0,uniformValues:n.values};t.packedInputs&&(n.isPacked=!0,n.shape=e.shape)}else if(!!n.isPacked!=!!t.packedInputs)e=n.isPacked?this.unpackTensor(e):this.packTensor(e),o.push(e),n=this.texData.get(e.dataId);else if(n.isPacked&&!fN(n.shape,e.shape)){const t=e,s=e.shape;e.shape=n.shape,e=this.packedReshape(e,s),o.push(e),n=this.texData.get(e.dataId),t.shape=s}return this.uploadToGPU(e.dataId),{shape:e.shape,texData:n,isUniform:!1}}));this.uploadToGPU(a.dataId);const u={shape:a.shape,texData:i,isUniform:!1},c=function(t,e,n){let s="";e.concat(n).forEach((t=>{const e=null!=t.texData&&null!=t.texData.slice&&t.texData.slice.flatOffset>0,n=t.isUniform?"uniform":t.texData.texShape;s+=`${t.shape}_${n}_${e}`}));const r=t.userCode;let a=t.constructor.name;return a+="_"+s+"_"+r,a}(t,l,u),h=this.getAndSaveBinary(c,(()=>function(t,e,n,s){const r=e.userCode,a=n.map(((t,n)=>{const s={logicalShape:t.shape,texShape:t.isUniform?null:t.texData.texShape,isUniform:t.isUniform,isPacked:!t.isUniform&&t.texData.isPacked,flatOffset:null};return null!=t.texData&&null!=t.texData.slice&&t.texData.slice.flatOffset>0&&(s.flatOffset=t.texData.slice.flatOffset),{name:e.variableNames[n],shapeInfo:s}})),i=a.map((t=>t.shapeInfo)),o={logicalShape:s.shape,texShape:s.texData.texShape,isUniform:!1,isPacked:s.texData.isPacked,flatOffset:null},l=jN(a,o,r,e.packedInputs),u=t.createProgram(l);let c=null;const h=t.getUniformLocation(u,"NAN",!1);1===ct().getNumber("WEBGL_VERSION")&&(c=t.getUniformLocation(u,"INFINITY",!1));const p={};for(let n=0;n<e.variableNames.length;n++){const s=e.variableNames[n],r=!1;p[s]=t.getUniformLocation(u,s,r),p["offset"+s]=t.getUniformLocation(u,"offset"+s,r)}return{program:e,source:l,webGLProgram:u,uniformLocations:p,inShapeInfos:i,outShapeInfo:o,infLoc:c,nanLoc:h}}(this.gpgpu,t,l,u))),p=null!=this.activeTimers;let d;if(p&&(d=this.startTimer()),function(t,e,n,s,r){jI(e.inShapeInfos,n),jI([e.outShapeInfo],[s]);const a=s.texData.texture,i=s.texData.texShape;s.texData.isPacked?t.setOutputPackedMatrixTexture(a,i[0],i[1]):t.setOutputMatrixTexture(a,i[0],i[1]),t.setProgram(e.webGLProgram),1===ct().getNumber("WEBGL_VERSION")&&null!==e.infLoc&&t.gl.uniform1f(e.infLoc,1/0),null!==e.nanLoc&&t.gl.uniform1f(e.nanLoc,NaN),n.forEach(((n,s)=>{const r=e.program.variableNames[s],a=e.uniformLocations[r],i=e.uniformLocations["offset"+r];if(null!=a)if(n.isUniform)if(_(n.shape)<2)t.gl.uniform1f(a,n.uniformValues[0]);else{let e=n.uniformValues;e instanceof Float32Array||(e=new Float32Array(e)),t.gl.uniform1fv(a,e)}else null!=n.texData.slice&&null!=i&&t.gl.uniform1i(i,n.texData.slice.flatOffset),t.setInputMatrixTexture(n.texData.texture,a,s)})),null!=r&&r(t,e.webGLProgram),t.executeProgram()}(this.gpgpu,h,l,u,s),o.forEach((t=>this.disposeIntermediateTensorInfo(t))),p&&(d=this.endTimer(d),this.activeTimers.push({name:t.constructor.name,query:this.getQueryTime(d)})),!ct().getBool("WEBGL_LAZILY_UNPACK")&&i.isPacked&&!1===r){const t=this.unpackTensor(a);return this.disposeIntermediateTensorInfo(a),t}return a}compileAndRun(t,e,n,s,r=!1){n=n||e[0].dtype;const a=this.runWebGLProgram(t,e,n,s,r);return Br().makeTensorFromDataId(a.dataId,a.shape,a.dtype)}getAndSaveBinary(t,e){return t in this.binaryCache||(this.binaryCache[t]=e()),this.binaryCache[t]}getTextureManager(){return this.textureManager}dispose(){this.disposed||(ct().getBool("IS_TEST")||Object.keys(this.binaryCache).forEach((t=>{this.gpgpu.deleteProgram(this.binaryCache[t].webGLProgram),delete this.binaryCache[t]})),this.textureManager.dispose(),null!=this.canvas&&"undefined"!=typeof HTMLCanvasElement&&this.canvas instanceof HTMLCanvasElement?this.canvas.remove():this.canvas=null,this.gpgpuCreatedLocally&&(this.gpgpu.program=null,this.gpgpu.dispose()),this.disposed=!0)}floatPrecision(){return null==this.floatPrecisionValue&&(this.floatPrecisionValue=Wr((()=>{if(!ct().get("WEBGL_RENDER_FLOAT32_ENABLED")){const t=ct().getBool("DEBUG");ct().set("DEBUG",!1);const e=this.abs(qr(1e-8)).dataSync()[0];if(ct().set("DEBUG",t),e>0)return 32}return 16}))),this.floatPrecisionValue}epsilon(){return 32===this.floatPrecision()?1e-7:1e-4}uploadToGPU(t){const e=this.texData.get(t),{shape:n,dtype:s,values:r,texture:a,usage:i,isPacked:o}=e;if(null!=a)return;const l=null!=this.activeTimers;let u;l&&(u=Gn());let c=e.texShape;if(null==c&&(c=function(t,e=!1){let n=ct().getNumber("WEBGL_MAX_TEXTURE_SIZE");if(e&&(n*=2,1===(t=t.map(((e,n)=>n>=t.length-2?E(t[n]):t[n]))).length&&(t=[2,t[0]])),2!==t.length){const e=V(t);t=e.newShape}let s=_(t);if(t.length<=1&&s<=n)return[1,s];if(2===t.length&&t[0]<=n&&t[1]<=n)return t;if(3===t.length&&t[0]*t[1]<=n&&t[2]<=n)return[t[0]*t[1],t[2]];if(3===t.length&&t[0]<=n&&t[1]*t[2]<=n)return[t[0],t[1]*t[2]];if(4===t.length&&t[0]*t[1]*t[2]<=n&&t[3]<=n)return[t[0]*t[1]*t[2],t[3]];if(4===t.length&&t[0]<=n&&t[1]*t[2]*t[3]<=n)return[t[0],t[1]*t[2]*t[3]];if(e){const e=cN(t);let n=2,r=2;return t.length&&([n,r]=hN(t)),s=e*(n/2)*(r/2),L(s).map((t=>2*t))}return L(s)}(n,o),e.texShape=c),null!=r){const t=pN(n);let a,i=c[1],h=c[0];const p=r instanceof Uint8Array;o?([i,h]=Jk(c[0],c[1]),a=new OI(t,[h,i],p)):a=new _I(t,[h,i],p);const d=this.makeTensorInfo([h,i],s);this.texData.get(d.dataId).usage=p?qk.PIXELS:qk.UPLOAD,this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(d.dataId),i,h,r);const f=!0,m=this.runWebGLProgram(a,[d],s,null,f),g=this.texData.get(m.dataId);e.texture=g.texture,e.texShape=g.texShape,e.isPacked=g.isPacked,e.usage=g.usage,this.disposeIntermediateTensorInfo(d),this.texData.delete(m.dataId),e.values=null,l&&(this.uploadWaitMs+=Gn()-u)}else{const t=this.acquireTexture(c,i,s,o);e.texture=t}}convertAndCacheOnCPU(t,e){const n=this.texData.get(t),{dtype:s}=n;return this.releaseGPUData(t),null!=e&&(n.values=function(t,e){if("float32"===e||"complex64"===e)return t;if("int32"===e||"bool"===e){const n="int32"===e?new Int32Array(t.length):new Uint8Array(t.length);for(let e=0;e<n.length;++e)n[e]=Math.round(t[e]);return n}throw new Error("Unknown dtype "+e)}(e,s)),n.values}acquireTexture(t,e,n,s){if(this.numBytesInGPU+=this.computeBytes(t,n),!this.warnedAboutMemory&&this.numBytesInGPU>1024*this.numMBBeforeWarning*1024){const t=(this.numBytesInGPU/1024/1024).toFixed(2);this.warnedAboutMemory=!0,console.warn(`High memory usage in GPU: ${t} MB, most likely due to a memory leak`)}return this.textureManager.acquireTexture(t,e,s)}computeBytes(t,e){return t[0]*t[1]*q(e)}tryRunOnCpuOrThrow(t,e){if(this.shouldExecuteOnCPU(t))try{return e()}catch(t){if(ct().getBool("IS_TEST"))throw new Error("CPU forwarding failed")}return null}}function tS(t){const{inputs:e,backend:n}=t,{x:s}=e;return n.incRef(s.dataId),{dataId:s.dataId,shape:s.shape,dtype:s.dtype}}gs()&&Hr("webgl",(()=>new QC),2);const eS={kernelName:pe,backendName:"webgl",kernelFunc:tS};function nS(t){const{inputs:e,backend:n}=t,{real:s,imag:r}=e,a=n.makeTensorInfo(s.shape,"complex64"),i=n.texData.get(a.dataId),o=tS({inputs:{x:s},backend:n});n.texData.get(o.dataId).complexParentRefCount++;const l=tS({inputs:{x:r},backend:n});return n.texData.get(l.dataId).complexParentRefCount++,i.complexTensorInfos={real:o,imag:l},a}const sS={kernelName:Mt,backendName:"webgl",kernelFunc:nS};function rS(t){return({inputs:e,backend:n})=>{const{x:s}=e,r=n,a=new $C(s.shape,t);return r.runWebGLProgram(a,[s],s.dtype)}}function aS({opSnippet:t,packedOpSnippet:e,checkOutOfBounds:n=!1,supportsComplex:s=!1,cpuKernelImpl:r,dtype:a}){return({inputs:i,backend:o})=>{const{a:l,b:u}=i,c=o;if(s&&"complex64"===l.dtype){const e=c.texData.get(l.dataId),n=c.texData.get(u.dataId),[s,r]=[[e.complexTensorInfos.real,n.complexTensorInfos.real],[e.complexTensorInfos.imag,n.complexTensorInfos.imag]].map((e=>{const[n,s]=e,r={dataId:n.dataId,dtype:n.dtype,shape:l.shape},a={dataId:s.dataId,dtype:s.dtype,shape:u.shape},i=new lI(t,l.shape,u.shape);return c.runWebGLProgram(i,[r,a],as(n.dtype,s.dtype))})),a=nS({inputs:{real:s,imag:r},backend:c});return c.disposeIntermediateTensorInfo(s),c.disposeIntermediateTensorInfo(r),a}const h=a||as(l.dtype,u.dtype);if(c.shouldExecuteOnCPU([l,u])&&null!=r){const t=c.texData.get(l.dataId),e=c.texData.get(u.dataId),[n,s]=r(l.shape,u.shape,t.values,e.values,h),a=c.makeTensorInfo(s,h);return c.texData.get(a.dataId).values=n,a}let p;return p=ct().getBool("WEBGL_PACK_BINARY_OPERATIONS")&&null!=e?new cI(e,l.shape,u.shape,n):new lI(t,l.shape,u.shape),c.runWebGLProgram(p,[l,u],h)}}const iS="return a + b;",oS=aS({opSnippet:iS,packedOpSnippet:iS,supportsComplex:!0,cpuKernelImpl:NN}),lS={kernelName:bt,backendName:"webgl",kernelFunc:oS},uS=aS({opSnippet:"\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n\n  return atan(a, b);\n",packedOpSnippet:"\n  vec4 result = atan(a, b);\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  \n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n\n  return result;\n"}),cS={kernelName:St,backendName:"webgl",kernelFunc:uS},hS={kernelName:Tt,backendName:"webgl",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e;wN(r,"avgPool");const{filterSize:a,strides:i,pad:o,dimRoundingMode:l}=s;A(va(i,1),(()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`));const u=ha(r.shape,a,i,1,o,l);if(1===u.filterWidth&&1===u.filterHeight&&O(u.inShape,u.outShape))return tS({inputs:{x:r},backend:n});const c=new aC(u,"avg",!1);return n.runWebGLProgram(c,[r],"float32")}},pS={kernelName:$t,backendName:"webgl",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{dy:r,input:a}=e,i=a;wN([r,a],"avgPoolBackprop");const{filterSize:o,strides:l,pad:u}=s,c=ha(i.shape,o,l,1,u),h=new aI(c);return n.runWebGLProgram(h,[r],i.dtype)}};class dS{constructor(t,e,n,s,r,a){this.outputShape=[],this.variableNames=["x","mean","variance"],Xa(t,e),Xa(t,n);let i="0.0";null!=s&&(Xa(t,s),this.variableNames.push("offset"),i="getOffsetAtOutCoords()");let o="1.0";null!=r&&(Xa(t,r),this.variableNames.push("scale"),o="getScaleAtOutCoords()"),this.outputShape=t,this.userCode=`\n      void main() {\n        float x = getXAtOutCoords();\n        float mean = getMeanAtOutCoords();\n        float variance = getVarianceAtOutCoords();\n        float offset = ${i};\n        float scale = ${o};\n        float inv = scale * inversesqrt(variance + float(${a}));\n        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));\n      }\n    `}}class fS{constructor(t,e,n,s,r,a){this.packedInputs=!0,this.packedOutput=!0,this.variableNames=["x","mean","variance"],Xa(t,e),Xa(t,n);let i="vec4(0.0)";null!=s&&(Xa(t,s),this.variableNames.push("offset"),i="getOffsetAtOutCoords()");let o="vec4(1.0)";null!=r&&(Xa(t,r),this.variableNames.push("scale"),o="getScaleAtOutCoords()"),this.outputShape=t,this.userCode=`\n      void main() {\n        vec4 offset = ${i};\n        vec4 scale = ${o};\n\n        vec4 x = getXAtOutCoords();\n        vec4 mean = getMeanAtOutCoords();\n        vec4 variance = getVarianceAtOutCoords();\n\n        vec4 inv = scale * inversesqrt(variance + vec4(${a}));\n\n        setOutput((x - mean) * inv + offset);\n      }\n    `}}const mS={kernelName:ue,backendName:"webgl",kernelFunc:({inputs:t,backend:e,attrs:n})=>{const{x:s,mean:r,variance:a,offset:i,scale:o}=t;A(r.shape.length===a.shape.length,(()=>"Batch normalization gradient requires mean and variance to have equal ranks.")),A(null==i||r.shape.length===i.shape.length,(()=>"Batch normalization gradient requires mean and offset to have equal ranks.")),A(null==o||r.shape.length===o.shape.length,(()=>"Batch normalization gradient requires mean and scale to have equal ranks."));let{varianceEpsilon:l}=n;null==l&&(l=.001);const u=[s,r,a];let c=null;null!=i&&(c=i.shape,u.push(i));let h=null;null!=o&&(h=o.shape,u.push(o));const p=ct().getBool("WEBGL_PACK_NORMALIZATION")?new fS(s.shape,r.shape,a.shape,c,h,l):new dS(s.shape,r.shape,a.shape,c,h,l);return e.runWebGLProgram(p,u,u[0].dtype)}},gS=aS({opSnippet:"return float(a != b);",dtype:"bool"}),yS={kernelName:Fe,backendName:"webgl",kernelFunc:gS};function bS(t){const{inputs:e,backend:n}=t,{input:s}=e;return tS({inputs:{x:n.texData.get(s.dataId).complexTensorInfos.real},backend:n})}const xS={kernelName:We,backendName:"webgl",kernelFunc:bS},wS={kernelName:Ft,backendName:"webgl",kernelFunc:function t(e){const{inputs:n,backend:s,attrs:r}=e,{x:a}=n,{dtype:i}=r;if("complex64"===i){if("complex64"===a.dtype)return tS({inputs:{x:a},backend:s});const e=ki(a.shape),n=t({inputs:{x:a},backend:s,attrs:{dtype:"float32"}}),r=nS({inputs:{real:n,imag:e},backend:s});return e.dispose(),s.disposeIntermediateTensorInfo(n),r}if("complex64"===a.dtype){const e=bS({inputs:{input:a},backend:s}),n=t({inputs:{x:e},backend:s,attrs:{dtype:i}});return s.disposeIntermediateTensorInfo(e),n}if(!H(a.dtype,i)){const t=tS({inputs:{x:a},backend:s});return{dataId:t.dataId,shape:t.shape,dtype:i}}if("int32"===i)return function(t,e){const n=new $C(t.shape,"return float(int(x));"),s=e.runWebGLProgram(n,[t],"int32");return{dataId:s.dataId,shape:s.shape,dtype:s.dtype}}(a,s);if("bool"===i){const t=s.makeTensorInfo([],"bool",U("bool",1)),e=gS({inputs:{a,b:t},backend:s});return s.disposeIntermediateTensorInfo(t),e}throw new Error(`Error in Cast: failed to cast ${a.dtype} to ${i}`)}};class vS{constructor(t){this.outputShape=[],this.outputShape=Da(t,1),this.variableNames=t.map(((t,e)=>"T"+e));const e=new Array(t.length-1);e[0]=t[0][1];for(let n=1;n<e.length;n++)e[n]=e[n-1]+t[n][1];const n=[`if (yC < ${e[0]}) setOutput(getT0(yR, yC));`];for(let t=1;t<e.length;t++){const s=e[t-1];n.push(`else if (yC < ${e[t]}) setOutput(getT${t}(yR, yC-${s}));`)}const s=e.length,r=e[e.length-1];n.push(`else setOutput(getT${s}(yR, yC-${r}));`),this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int yR = coords.x;\n        int yC = coords.y;\n\n        ${n.join("\n        ")}\n      }\n    `}}class kS{constructor(t,e){this.packedInputs=!0,this.packedOutput=!0,this.outputShape=[],this.outputShape=Da(t,e);const n=this.outputShape,s=n.length,r=eI(s),a=PN("coords",s),i=["x","y","z","w","u","v"].slice(0,s);this.variableNames=t.map(((t,e)=>"T"+e));const o=new Array(t.length-1);o[0]=t[0][e];for(let n=1;n<o.length;n++)o[n]=o[n-1]+t[n][e];const l=i[e],u=i.slice(-2),c=i.join();let h=`if (${l} < ${o[0]}) {\n        return getChannel(\n            getT0(${c}), vec2(${u.join()}));\n        }`;for(let t=1;t<o.length;t++){const e=o[t-1];h+=`\n        if (${l} < ${o[t]}  && ${l} >= ${o[t-1]}) {\n          return getChannel(\n            getT${t}(${NS(i,l,e)}),\n            vec2(${NS(u,l,e)}));\n        }`}const p=o.length,d=o[o.length-1];h+=`\n        return getChannel(\n          getT${p}(${NS(i,l,d)}),\n          vec2(${NS(u,l,d)}));`,this.userCode=`\n      float getValue(${i.map((t=>"int "+t))}) {\n        ${h}\n      }\n\n      void main() {\n        ${r} coords = getOutputCoords();\n        vec4 result = vec4(getValue(${a}), 0., 0., 0.);\n\n        ${a[s-1]} = ${a[s-1]} + 1;\n        if (${a[s-1]} < ${n[s-1]}) {\n          result.g = getValue(${a});\n        }\n\n        ${a[s-2]} = ${a[s-2]} + 1;\n        if (${a[s-2]} < ${n[s-2]}) {\n          result.a = getValue(${a});\n        }\n\n        ${a[s-1]} = ${a[s-1]} - 1;\n        if (${a[s-2]} < ${n[s-2]} &&\n            ${a[s-1]} < ${n[s-1]}) {\n          result.b = getValue(${a});\n        }\n        setOutput(result);\n      }\n    `}}function NS(t,e,n){const s=t.indexOf(e);return t.map(((t,e)=>e===s?`${t} - ${n}`:t)).join()}function IS(t){const{inputs:e,backend:n}=t,{input:s}=e;return tS({inputs:{x:n.texData.get(s.dataId).complexTensorInfos.imag},backend:n})}const CS={kernelName:fe,backendName:"webgl",kernelFunc:IS};function SS(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{shape:a}=s,i=n,o=_(r.shape),l=P(a,o),u=_(l);A(o===u,(()=>`The new shape (${l}) has ${u} elements and the old shape (${r.shape}) has ${o} elements. The new shape and old shape must have the same number of elements.`));const c=i.texData.get(r.dataId);return!c.isPacked||fN(r.shape,l)||null!==c.texture&&fN(c.shape,l)?(i.incRef(r.dataId),{dataId:r.dataId,shape:l,dtype:r.dtype}):function(t,e,n){const s=[cN(t.shape),...hN(t.shape)],r={dtype:t.dtype,shape:s,dataId:t.dataId},a=[cN(e),...hN(e)],i=new lC(a,s),o=n.runWebGLProgram(i,[r],t.dtype,null,!0);return{dataId:o.dataId,shape:e,dtype:o.dtype}}(r,l,i)}const TS={kernelName:Ge,backendName:"webgl",kernelFunc:SS};function $S(t,e,n){const s=t[0].dtype;if("complex64"===s){const s=t.map((t=>bS({inputs:{input:t},backend:n}))),r=t.map((t=>IS({inputs:{input:t},backend:n}))),a=$S(s,e,n),i=$S(r,e,n),o=nS({inputs:{real:a,imag:i},backend:n});return s.forEach((t=>n.disposeIntermediateTensorInfo(t))),r.forEach((t=>n.disposeIntermediateTensorInfo(t))),n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(i),o}if(t.length>ct().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER")){const s=Math.floor(t.length/2),r=$S(t.slice(0,s),e,n),a=$S(t.slice(s),e,n),i=$S([r,a],e,n);return n.disposeIntermediateTensorInfo(r),n.disposeIntermediateTensorInfo(a),i}if(ct().getBool("WEBGL_PACK_ARRAY_OPERATIONS")&&t[0].shape.length>1){const r=new kS(t.map((t=>t.shape)),e);return n.runWebGLProgram(r,t,s)}const r=Da(t.map((t=>t.shape)),e),a=t.map((t=>SS({inputs:{x:t},attrs:{shape:[-1,_(t.shape.slice(e))]},backend:n}))),i=new vS(a.map((t=>t.shape))),o=n.runWebGLProgram(i,a,s);a.forEach((t=>n.disposeIntermediateTensorInfo(t)));const l=SS({inputs:{x:o},attrs:{shape:r},backend:n});return n.disposeIntermediateTensorInfo(o),l}const ES={kernelName:Lt,backendName:"webgl",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{axis:r}=s,a=W(r,e[0].shape)[0],i=Da(e.map((t=>t.shape)),a);if(0===_(i))return n.makeTensorInfo(i,e[0].dtype,[]);const o=e.filter((t=>_(t.shape)>0));return 1===o.length?o[0]:(Ra(o.map((t=>t.shape)),a),$S(o,a,n))}},AS=rS("if (isnan(x)) return x;\n  return cos(x);\n"),RS={kernelName:Gt,backendName:"webgl",kernelFunc:AS},DS=aS({opSnippet:"\nif (a == b) {\n  return 1.0;\n};\nreturn a / b;",packedOpSnippet:"\n  // vec4 one = vec4(equal(a, b));\n  // return one + (vec4(1.0) - one) * a / b;\n  vec4 result = a / b;\n  if(a.x == b.x) {\n    result.x = 1.;\n  }\n  if(a.y == b.y) {\n    result.y = 1.;\n  }\n  if(a.z == b.z) {\n    result.z = 1.;\n  }\n  if(a.w == b.w) {\n    result.w = 1.;\n  }\n\n  return result;\n",checkOutOfBounds:!0}),FS={kernelName:Qt,backendName:"webgl",kernelFunc:DS};class _S{constructor(t,e,n){this.variableNames=["real","imag"];const s=e[1];this.outputShape=e;const r=n?"2.0 * "+Math.PI:"-2.0 * "+Math.PI,a=n?s+".0":"1.0";let i;if("real"===t)i="return real * expR - imag * expI;";else{if("imag"!==t)throw new Error(`FFT component must be either "real" or "imag", got ${t}.`);i="return real * expI + imag * expR;"}this.userCode=`\n      const float exponentMultiplier = ${r};\n\n      float unaryOpComplex(float real, float expR, float imag, float expI) {\n        ${i}\n      }\n\n      float mulMatDFT(int batch, int index) {\n        float indexRatio = float(index) / float(${s});\n        float exponentMultiplierTimesIndexRatio =\n            exponentMultiplier * indexRatio;\n\n        float result = 0.0;\n\n        for (int i = 0; i < ${s}; i++) {\n          // x = (-2|2 * PI / N) * index * i;\n          float x = exponentMultiplierTimesIndexRatio * float(i);\n          float expR = cos(x);\n          float expI = sin(x);\n          float real = getReal(batch, i);\n          float imag = getImag(batch, i);\n\n          result +=\n              unaryOpComplex(real, expR, imag, expI) / ${a};\n        }\n\n        return result;\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        setOutput(mulMatDFT(coords[0], coords[1]));\n      }\n    `}}function OS(t,e,n){const s=n.texData.get(t.dataId),r=_(t.shape),a=t.shape[t.shape.length-1],i=SS({inputs:{x:t},backend:n,attrs:{shape:[r/a,a]}}).shape,o=new _S("real",i,e),l=new _S("imag",i,e),u=[{dataId:s.complexTensorInfos.real.dataId,dtype:s.complexTensorInfos.real.dtype,shape:i},{dataId:s.complexTensorInfos.imag.dataId,dtype:s.complexTensorInfos.imag.dtype,shape:i}],c=n.runWebGLProgram(o,u,"float32"),h=n.runWebGLProgram(l,u,"float32"),p=nS({inputs:{real:c,imag:h},backend:n});n.disposeIntermediateTensorInfo(c),n.disposeIntermediateTensorInfo(h);const d=SS({inputs:{x:p},backend:n,attrs:{shape:t.shape}});return n.disposeIntermediateTensorInfo(d),d}const MS={kernelName:re,backendName:"webgl",kernelFunc:function(t){const{inputs:e,backend:n}=t,{input:s}=e;return OS(s,!1,n)}};class LS{constructor(t){this.variableNames=["Image"],this.outputShape=[];const e=t[2];this.outputShape=t,this.userCode=`\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n\n          int coordX = ${e} - x;\n          float outputValue;\n          if(coordX >= 0 && coordX < ${e}) {\n            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);\n          } else {\n            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    `}}const zS={kernelName:ie,backendName:"webgl",kernelFunc:({inputs:t,backend:e})=>{const{image:n}=t,s=e,r=new LS(n.shape);return s.runWebGLProgram(r,[n],n.dtype)}};class BS{constructor(t){this.variableNames=["A"];const e=WN(),[n,s]=t;this.outputShape=t,this.userCode=`\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${s}.0, ${n}.0);\n\n        vec4 values = ${e.texture2D}(A, uv);\n        float value;\n        if (depth == 0) {\n          value = values.r;\n        } else if (depth == 1) {\n          value = values.g;\n        } else if (depth == 2) {\n          value = values.b;\n        } else if (depth == 3) {\n          value = values.a;\n        }\n\n        setOutput(floor(value * 255.0 + 0.5));\n      }\n    `}}class PS{constructor(t){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0;const e=WN(),[n,s]=t;this.outputShape=t,this.userCode=`\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n\n        vec4 result = vec4(0.);\n\n        for(int row=0; row<=1; row++) {\n          for(int col=0; col<=1; col++) {\n            texC = coords[1] + row;\n            depth = coords[2] + col;\n\n            vec2 uv = (vec2(texC, texR) + halfCR) /\n                       vec2(${s}.0, ${n}.0);\n            vec4 values = ${e.texture2D}(A, uv);\n            float value;\n            if (depth == 0) {\n              value = values.r;\n            } else if (depth == 1) {\n              value = values.g;\n            } else if (depth == 2) {\n              value = values.b;\n            } else if (depth == 3) {\n              value = values.a;\n            }\n\n            result[row * 2 + col] = floor(value * 255.0 + 0.5);\n          }\n        }\n\n        ${e.output} = result;\n      }\n    `}}const WS={kernelName:kn,backendName:"webgl",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t;let{pixels:r}=e;const{numChannels:a}=s,i="undefined"!=typeof HTMLVideoElement&&r instanceof HTMLVideoElement,o="undefined"!=typeof HTMLImageElement&&r instanceof HTMLImageElement,[l,u]=i?[r.videoWidth,r.videoHeight]:[r.width,r.height],c=[u,l],h=[u,l,a];(o||i)&&(null==VS&&(VS=document.createElement("canvas").getContext("2d")),VS.canvas.width=l,VS.canvas.height=u,VS.drawImage(r,0,0,l,u),r=VS.canvas);const p=n.makeTensorInfo(c,"int32");n.texData.get(p.dataId).usage=qk.PIXELS,n.gpgpu.uploadPixelDataToTexture(n.getTexture(p.dataId),r);const d=ct().getBool("WEBGL_PACK")?new PS(h):new BS(h),f=n.runWebGLProgram(d,[p],"int32");return n.disposeData(p.dataId),f}};let VS;const US={kernelName:de,backendName:"webgl",kernelFunc:function(t){const{inputs:e,backend:n}=t,{input:s}=e;return OS(s,!0,n)}};class GS{constructor(t,e){this.variableNames=["x"];const{windowSize:n,batchSize:s,inSize:r,outSize:a}=t;this.outputShape=[s,a];const i=4*Math.floor(n/4),o=n%4;let l="sumValue += dot(values, ones);";if(null!=e){const t=1/e;l=`sumValue += dot(values * ${M(t)?t.toPrecision(2):t}, ones);`}let u="";r%n>0&&(u=`\n        if (inIdx < 0 || inIdx >= ${r}) {\n          return 0.0;\n        }\n      `),this.userCode=`\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ${u}\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${n};\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ${i}; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ${l}\n        }\n\n        int inIdx = inOffset + ${i};\n        if (${1===o}) {\n          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);\n\n          ${l}\n        } else if (${2===o}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1), 0.0, 0.0);\n\n          ${l}\n        } else if (${3===o}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2), 0.0);\n\n          ${l}\n        }\n        setOutput(sumValue);\n      }\n    `}}function HS(t,e,n,s){const r=function(t){const e=[];for(;0===e.length||1!==e[e.length-1].outSize;){const n=e.length?e[e.length-1].outSize:t[1],s=ri(n);e.push({inSize:n,windowSize:s,outSize:Math.ceil(n/s)})}return e}(t.shape);let a=t;for(let i=0;i<r.length;i++){const{inSize:o,windowSize:l,outSize:u}=r[i];let c,h;c="mean"===n?0===i?new GS({windowSize:l,inSize:o,batchSize:t.shape[0],outSize:u},o):new GS({windowSize:l,inSize:o,batchSize:t.shape[0],outSize:u}):new oC({windowSize:l,inSize:o,batchSize:t.shape[0],outSize:u},n),h=a,a=s.runWebGLProgram(c,[a],e),h.dataId!==t.dataId&&s.disposeIntermediateTensorInfo(h)}return a}class jS{constructor(t,e){this.variableNames=["A"];const n=new Array(t.length);for(let s=0;s<n.length;s++)n[s]=t[e[s]];this.outputShape=n,this.rank=n.length;const s=eI(this.rank),r=function(t){const e=t.length;if(e>6)throw Error(`Transpose for rank ${e} is not yet supported`);const n=["resRC.x","resRC.y","resRC.z","resRC.w","resRC.u","resRC.v"],s=new Array(e);for(let e=0;e<t.length;e++)s[t[e]]=n[e];return s.join()}(e);this.userCode=`\n    void main() {\n      ${s} resRC = getOutputCoords();\n      setOutput(getA(${r}));\n    }\n    `}}class qS{constructor(t,e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0;const n=new Array(t.length);for(let s=0;s<n.length;s++)n[s]=t[e[s]];if(this.outputShape=n,this.rank=n.length,this.rank>6)throw Error(`Packed transpose for rank ${this.rank} is not yet supported.`);const s=eI(this.rank),r=BN("rc",this.rank),a=new Array(this.rank);for(let t=0;t<e.length;t++)a[e[t]]=r[t];const i=`vec2(${a.slice(-2).join()})`,o=`++${r[this.rank-1]} < ${n[this.rank-1]}`,l=`getChannel(getA(${a.join()}), ${i})`;this.userCode=`\n    void main() {\n      ${s} rc = getOutputCoords();\n      vec4 result = vec4(0.);\n      result[0] = ${l};\n      if(${o}) {\n        result[1] = ${l};\n      }\n      --${r[this.rank-1]};\n      if(++${r[this.rank-2]} < ${n[this.rank-2]}) {\n        result[2] = ${l};\n        if(${o}) {\n          result[3] = ${l};\n        }\n      }\n      setOutput(result);\n    }\n    `}}function KS(t,e,n){const s=ct().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new qS(t.shape,e):new jS(t.shape,e);return n.runWebGLProgram(s,[t],t.dtype)}const XS={kernelName:ke,backendName:"webgl",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{x:s}=t,{reductionIndices:r,keepDims:a}=e,i=n,o=s.shape.length,l=W(r,s.shape);let u=l;const c=na(u,o),h=null!=c,p=i.shouldExecuteOnCPU([s]);let d=s;if(h){if(p){const t=i.texData.get(d.dataId).values,e=new Array(o);for(let t=0;t<e.length;t++)e[t]=s.shape[c[t]];const n=_N(t,s.shape,s.dtype,c,e);d=i.makeTensorInfo(e,s.dtype),i.texData.get(d.dataId).values=n}else d=KS(s,c,i);u=ra(u.length,o)}ea("max",u,o);const[f,m]=Qr(d.shape,u);let g,y=f;if(a&&(y=ta(f,l)),p){const t=i.texData.get(d.dataId).values,e=EN(t,_(m),y,s.dtype);g=i.makeTensorInfo(y,s.dtype),i.texData.get(g.dataId).values=e}else g=function(t,e,n,s){const r=_(e),a=SS({inputs:{x:t},attrs:{shape:[_(t.shape)/r,r]},backend:s}),i=HS(a,t.dtype,"max",s),o=SS({inputs:{x:i},attrs:{shape:n},backend:s});return s.disposeIntermediateTensorInfo(a),s.disposeIntermediateTensorInfo(i),o}(d,m,y,i);return h&&i.disposeIntermediateTensorInfo(d),g}},YS={kernelName:Ie,backendName:"webgl",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e;wN(r,"maxPool");const{filterSize:a,strides:i,pad:o,dimRoundingMode:l}=s;A(va(i,1),(()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`));const u=ha(r.shape,a,i,1,o,l);if(1===u.filterWidth&&1===u.filterHeight&&O(u.inShape,u.outShape))return tS({inputs:{x:r},backend:n});const c=new aC(u,"max",!1);return n.runWebGLProgram(c,[r],r.dtype)}},JS={kernelName:Ce,backendName:"webgl",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{dy:r,input:a,output:i}=e,o=a;wN([a,i],"maxPoolBackprop");const{filterSize:l,strides:u,pad:c,dimRoundingMode:h}=s,p=ha(o.shape,l,u,1,c,h),d=new aC(p,"max",!0),f=n.runWebGLProgram(d,[o],o.dtype),m=new JI(p),g=n.runWebGLProgram(m,[r,f],o.dtype);return n.disposeIntermediateTensorInfo(f),g}},ZS={kernelName:Te,backendName:"webgl",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{x:s}=t,{filterSize:r,strides:a,pad:i,includeBatchInIndex:o}=e,l=n;A(4===s.shape.length,(()=>`Error in maxPool: input must be rank 4 but got rank ${s.shape.length}.`));const u=[1,1];A(va(a,u),(()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${a} and dilations '${u}'`));const c=ha(s.shape,r,a,u,i),[h,p]=function(t,e,n,s){let r=new aC(n,"max",!1);const a=s.runWebGLProgram(r,[t],"float32");return r=new aC(n,"max",!0,!0,e),[a,s.runWebGLProgram(r,[t],"float32")]}(s,o,c,l);return[h,p]}},QS={kernelName:$e,backendName:"webgl",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{x:s}=t,{keepDims:r,axis:a}=e,i=n,o=s.shape.length,l=W(a,s.shape);let u=l;const c=na(u,o),h=null!=c,p=i.shouldExecuteOnCPU([s]),d=[];let f=s;if(h){if(p){const t=i.texData.get(f.dataId).values,e=new Array(o);for(let t=0;t<e.length;t++)e[t]=s.shape[c[t]];const n=_N(t,s.shape,s.dtype,c,e);f=i.makeTensorInfo(e,s.dtype),i.texData.get(f.dataId).values=n}else f=KS(s,c,i);d.push(f),u=ra(u.length,o)}ea("sum",u,o);const[m,g]=Qr(f.shape,u);let y=m;r&&(y=ta(m,l));const b=function(t,e,n,s){const r=_(e),a=SS({inputs:{x:t},attrs:{shape:[_(t.shape)/r,r]},backend:s}),i=HS(a,"float32","mean",s),o=SS({inputs:{x:i},attrs:{shape:n},backend:s});return s.disposeIntermediateTensorInfo(a),s.disposeIntermediateTensorInfo(i),o}(f,g,y,i);for(const t of d)i.disposeIntermediateTensorInfo(t);return b}};class tT{constructor(t,e,n){this.variableNames=["x"],this.outputShape=e.map(((e,n)=>e[0]+t[n]+e[1]));const s=t.length,r=eI(s),a=e.map((t=>t[0])).join(","),i=e.map(((e,n)=>e[0]+t[n])).join(","),o=["coords[0]","coords[1]","coords[2]","coords[3]"].slice(0,s),l="reflect"===n?0:1;this.userCode=1!==s?`\n      ${r} start = ${r}(${a});\n      ${r} end = ${r}(${i});\n\n      void main() {\n        ${r} outC = getOutputCoords();\n        for (int i = 0; i < ${s}; i++) {\n          if (outC[i] < start[i]) {\n            outC[i] = start[i] * 2 - outC[i] - ${l};\n          } else if(outC[i] >= end[i]) {\n            outC[i] = (end[i] - 1) * 2 - outC[i] + ${l};\n          }\n        }\n        ${r} coords = outC - start;\n        setOutput(getX(${o}));\n      }\n    `:`\n        int start = ${a};\n        int end = ${i};\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start) {\n            outC = start * 2 - outC - ${l};\n          } else if(outC >= end) {\n            outC = (end - 1) * 2 - outC + ${l};\n          }\n          setOutput(getX(outC - start));\n        }\n      `}}class eT{constructor(t,e,n){this.variableNames=["x"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e.map(((e,n)=>e[0]+t[n]+e[1]));const s=t.length,r=eI(s),a=e.map((t=>t[0])).join(","),i=e.map(((e,n)=>e[0]+t[n])).join(","),o=PN("rc",s),l=PN("source",s),u=`${o[s-1]} < ${this.outputShape[s-1]}`,c=1===s?"source":`vec2(${l.slice(-2).join()})`,h="reflect"===n?0:1;let p="";if(1===s){const t=`\n        ${r} source = rc;\n        if (source < start) {\n          source = start * 2 - source - ${h};\n        } else if (source >= end) {\n          source = (end - 1) * 2 - source + ${h};\n        }\n        source -= start;\n      `;p=`\n        ${r} rc = outputLoc;\n        ${t}\n        result[0] = getChannel(getX(${l.join()}), ${c});\n        ${o[s-1]} += 1;\n        if(${u}) {\n          ${t}\n          result[1] = getChannel(getX(${l.join()}), ${c});\n        }\n      `}else{const t=`\n        ${r} source = rc;\n        ${r} lt = ${r}(lessThan(source, start));\n        ${r} gte = ${r}(greaterThanEqual(source, end));\n        ${r} orig = 1 - (lt + gte);\n        source = orig * source +\n                lt * (start * 2 - source - ${h}) +\n                gte * ((end - 1) * 2 - source + ${h});\n        source -= start;\n      `;p=`\n        ${r} rc = outputLoc;\n        ${t}\n        result[0] = getChannel(getX(${l.join()}), ${c});\n        ${o[s-1]} += 1;\n        if(${u}) {\n          ${t}\n          result[1] = getChannel(getX(${l.join()}), ${c});\n        }\n        rc = outputLoc;\n        ${o[s-2]} += 1;\n        if(${o[s-2]} < ${this.outputShape[s-2]}) {\n          ${t}\n          result[2] = getChannel(getX(${l.join()}), ${c});\n          ${o[s-1]} += 1;\n          if(${u}) {\n            ${t}\n            result[3] = getChannel(getX(${l.join()}), ${c});\n          }\n        }\n      `}this.userCode=`\n      const ${r} start = ${r}(${a});\n      const ${r} end = ${r}(${i});\n\n      void main() {\n        ${r} outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ${p}\n        setOutput(result);\n      }\n    `}}const nT={kernelName:Ae,backendName:"webgl",kernelFunc:({inputs:t,backend:e,attrs:n})=>{const{x:s}=t,{paddings:r,mode:a}=n,i=ct().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new eT(s.shape,r,a):new tT(s.shape,r,a);return e.runWebGLProgram(i,[s],s.dtype)}};class sT{constructor(t,e,n){this.variableNames=["AReal","AImag","BReal","BImag"],this.outputShape=Xa(e,n),this.userCode=`\n      float binaryOpComplex(\n          float areal, float aimag, float breal, float bimag) {\n        ${t}\n      }\n\n      void main() {\n        float areal = getARealAtOutCoords();\n        float aimag = getAImagAtOutCoords();\n        float breal = getBRealAtOutCoords();\n        float bimag = getBImagAtOutCoords();\n        setOutput(binaryOpComplex(areal, aimag, breal, bimag));\n      }\n    `}}const rT="return a * b;",aT={kernelName:Re,backendName:"webgl",kernelFunc:function(t){const{inputs:e,backend:n}=t,{a:s,b:r}=e,a=as(s.dtype,r.dtype);if("complex64"===s.dtype){const t=n.texData.get(s.dataId),e=n.texData.get(r.dataId),a=new sT("return areal * breal - aimag * bimag;",s.shape,r.shape),i=new sT("return areal * bimag + aimag * breal;",s.shape,r.shape),o=[{dataId:t.complexTensorInfos.real.dataId,dtype:t.complexTensorInfos.real.dtype,shape:s.shape},{dataId:t.complexTensorInfos.imag.dataId,dtype:t.complexTensorInfos.imag.dtype,shape:s.shape},{dataId:e.complexTensorInfos.real.dataId,dtype:e.complexTensorInfos.real.dtype,shape:r.shape},{dataId:e.complexTensorInfos.imag.dataId,dtype:e.complexTensorInfos.imag.dtype,shape:r.shape}],l=n.runWebGLProgram(a,o,"float32"),u=n.runWebGLProgram(i,o,"float32"),c=nS({inputs:{real:l,imag:u},backend:n});return n.disposeIntermediateTensorInfo(l),n.disposeIntermediateTensorInfo(u),c}if(n.shouldExecuteOnCPU([s,r])){const t=n.texData.get(s.dataId),e=n.texData.get(r.dataId),[i,o]=AN(s.shape,r.shape,t.values,e.values,a),l=n.makeTensorInfo(o,a);return n.texData.get(l.dataId).values=i,l}let i;return i=ct().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new cI(rT,s.shape,r.shape):new lI(rT,s.shape,r.shape),n.runWebGLProgram(i,[s,r],a)}},iT={kernelName:_e,backendName:"webgl",kernelFunc:({inputs:t,backend:e,attrs:n})=>{Hl("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{boxes:s,scores:r}=t,{maxOutputSize:a,iouThreshold:i,scoreThreshold:o}=n,l=e;return Go(l.readSync(s.dataId),l.readSync(r.dataId),a,i,o)}},oT=Ho,lT={kernelName:Oe,backendName:"webgl",kernelFunc:({inputs:t,backend:e,attrs:n})=>{Hl("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{boxes:s,scores:r}=t,{maxOutputSize:a,iouThreshold:i,scoreThreshold:o,padToMaxOutputSize:l}=n,u=e,c=u.readSync(s.dataId),h=u.readSync(r.dataId),{selectedIndices:p,validOutputs:d}=oT(c,h,a,i,o,l);return[p,d]}},uT=jo,cT={kernelName:Me,backendName:"webgl",kernelFunc:({inputs:t,backend:e,attrs:n})=>{Hl("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{boxes:s,scores:r}=t,{maxOutputSize:a,iouThreshold:i,scoreThreshold:o,softNmsSigma:l}=n,u=e,c=u.readSync(s.dataId),h=u.readSync(r.dataId),p=a,d=i,f=o,m=l,{selectedIndices:g,selectedScores:y}=uT(c,h,p,d,f,m);return[g,y]}};class hT{constructor(t,e,n,s){this.variableNames=["Image"],this.outputShape=[];const r=t[1],a=t[2],i=Math.sin(e).toFixed(3),o=Math.cos(e).toFixed(3);this.outputShape=t;const[l,u]=Tl(s,r,a),c=l.toFixed(3),h=u.toFixed(3);let p="";p="number"==typeof n?`float outputValue = ${n.toFixed(2)};`:`\n        vec3 fill = vec3(${n.join(",")});\n        float outputValue = fill[coords[3]];`,this.userCode=`\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n          int y = coords[1];\n          float coordXFloat = (float(x) - ${c}) * ${o} - (float(y) - ${h}) * ${i};\n          float coordYFloat = (float(x) - ${c}) * ${i} + (float(y) - ${h}) * ${o};\n          int coordX = int(round(coordXFloat + ${c}));\n          int coordY = int(round(coordYFloat + ${h}));\n          ${p}\n          if(coordX >= 0 && coordX < ${a} && coordY >= 0 && coordY < ${r}) {\n            outputValue = getImage(coords[0], coordY, coordX, coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    `}}const pT={kernelName:Nn,backendName:"webgl",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{image:s}=t,{radians:r,fillValue:a,center:i}=e,o=n,l=new hT(s.shape,r,a,i);return o.runWebGLProgram(l,[s],s.dtype)}},dT=rS("if (isnan(x)) return x;\n  return sin(x);\n"),fT={kernelName:tn,backendName:"webgl",kernelFunc:dT},mT={kernelName:hn,backendName:"webgl",kernelFunc:rS("return x * x;")},gT="return (a - b) * (a - b);",yT=aS({opSnippet:gT,packedOpSnippet:gT}),bT={kernelName:cn,backendName:"webgl",kernelFunc:yT},xT="return a - b;",wT=aS({opSnippet:xT,packedOpSnippet:xT,supportsComplex:!0,cpuKernelImpl:FN}),vT={kernelName:pn,backendName:"webgl",kernelFunc:wT},kT=rS("return tan(x);"),NT=[lS,cS,hS,pS,mS,wS,sS,ES,RS,FS,MS,zS,WS,eS,US,CS,XS,YS,JS,ZS,QS,nT,aT,iT,lT,cT,yS,xS,TS,pT,fT,mT,vT,bT,{kernelName:dn,backendName:"webgl",kernelFunc:kT},{kernelName:gn,backendName:"webgl",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{x:s}=t,{perm:r}=e,a=n,i=s.shape.length,o=new Array(i);for(let t=0;t<o.length;t++)o[t]=s.shape[r[t]];let l;if(a.shouldExecuteOnCPU([s])){const t=a.texData.get(s.dataId).values,e=_N(t,s.shape,s.dtype,r,o);l=a.makeTensorInfo(o,s.dtype),a.texData.get(l.dataId).values=e}else l=KS(s,r,a);return l}},{kernelName:yn,backendName:"webgl",kernelFunc:function(t){const{inputs:e,attrs:n,backend:s}=t,{axis:r}=n,{x:a}=e;wN(a,"unique"),console.warn("WARNING: ","UI might be locked temporarily as data is being downloaded");const i=s.readSync(a.dataId),{outputValues:o,outputShape:l,indices:u}=ON(i,r,a.shape,a.dtype);return[s.makeTensorInfo(l,a.dtype,o),s.makeTensorInfo([u.length],"int32",u)]}}];for(const t of NT)Dn(t);async function IT(){if(!N.video)return;const t=await N.model.estimateFaces(N.video,!1);if(t.length>0){N.ctx.clearRect(0,0,N.canvas.width,N.canvas.height);for(let e=0;e<t.length;e++){const n=t[e].topLeft,s=t[e].bottomRight,r=[s[0]-n[0],s[1]-n[1]];N.ctx.strokeStyle="white",N.ctx.strokeRect(n[0],n[1],r[0],r[1]);{const n=t[e].landmarks;N.ctx.fillStyle="white";for(let t=0;t<n.length;t++){const e=n[t][0],s=n[t][1];N.ctx.fillRect(e,s,5,5)}}}}requestAnimationFrame(IT)}!async function(){await k.wasm.setWasmPath("https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-wasm/dist/tfjs-backend-wasm.wasm"),await Gr("wasm"),N.model=await async function({maxFaces:t=10,inputWidth:e=128,inputHeight:n=128,iouThreshold:s=.3,scoreThreshold:r=.75}={}){const a=await async function(t,e={}){if(null==t)throw new Error("modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");null==e&&(e={}),e.fromTFHub&&null==t.load&&(t.endsWith("/")||(t+="/"),t+="model.json?tfjs-format=file");const n=new dd(t,e);return await n.load(),n}("https://tfhub.dev/tensorflow/tfjs-model/blazeface/1/default/1",{fromTFHub:!0});return new bd(a,e,n,t,s,r)}(),console.log("Finished loading model")}(),window.addEventListener("click",(function t(e){console.log("Detected a click");let n=e.target;if("A"===n.nodeName){let s=n.getAttribute("href");if(s.includes("youtube")){e.preventDefault(),console.log("Stopped redirection to Youtube"),window.removeEventListener("click",t);let n=document.createElement("div");n.id="studyModeLocker",n.addEventListener("click",(t=>{t.stopPropagation(),console.log("Overlay clicked")})),document.getElementsByTagName("BODY")[0].appendChild(n),function(t){let e=document.getElementById("studyModeLocker"),n=document.createElement("DIV"),s=document.createElement("BUTTON"),r=document.createElement("I"),a=document.createElement("BUTTON"),i=document.createElement("I");r.setAttribute("class","fas fa-times-circle icon-left-padding"),s.setAttribute("class","button exit-button"),s.innerText="Leave",s.addEventListener("click",(e=>function(t,e){t.stopPropagation();let n=document.getElementById("studyModeLocker");n&&(n.remove(),N.stream.getTracks().forEach((function(t){t.stop()})),N.video=null,window.addEventListener("click",e))}(e,t))),i.setAttribute("class","fas fa-question icon-left-padding"),a.setAttribute("class","button question-button"),a.innerText="Question",a.addEventListener("click",(t=>async function(t){t.stopPropagation(),console.debug("Question ButtonPressed at "+N.player.getCurrentTime())}(t))),s.appendChild(r),a.appendChild(i),n.setAttribute("class","button-container"),n.appendChild(s),n.appendChild(a),e.appendChild(n)}(t),function(t){let e=document.getElementById("studyModeLocker"),n=t.split("youtube.com/watch?v="),s="hXDiv7f73H0";s=2==n.length?n[1]:n[0];let r=document.createElement("div"),a=document.createElement("iframe");r.id="videoWrapper",a.id="videoIFrame",a.origin="youtube.com",a.setAttribute("width","100%"),a.setAttribute("height","100%"),a.setAttribute("class","youtubeIFrame"),a.src=`https://www.youtube-nocookie.com/embed/${s}?enablejsapi=1&controls=0`,r.appendChild(a),e.appendChild(r),N.player=new YT.Player("videoIFrame",{events:{onReady:t=>{console.debug("Embedded Youtube Player is ready"),window.localStorage.setItem("youtube_video_id",s),window.localStorage.setItem("youtube_video_duration",t.target.getDuration()),window.localStorage.setItem("youtube_video_title",t.target.getVideoData().title)},onStateChange:t=>{console.debug("Embedded Youtube Player has a new change"),t.data,YT.PlayerState.ENDED}}})}(s),async function(){!function(){let t=document.createElement("VIDEO");t.id="overlayVideoCam",t.setAttribute("autoplay","");let e=document.createElement("CANVAS");e.id="overlayVideoCanvas",e.width=640,e.height=480;let n=document.getElementById("studyModeLocker");n.appendChild(t),n.appendChild(e)}(),await async function(){return N.video=document.getElementById("overlayVideoCam"),N.stream=await navigator.mediaDevices.getUserMedia({audio:!1,video:{facingMode:"user"}}),N.video.srcObject=N.stream,new Promise((t=>{N.video.onloadedmetadata=()=>{t(N.video)}}))}(),N.canvas=document.getElementById("overlayVideoCanvas"),N.ctx=N.canvas.getContext("2d"),N.ctx.fillStyle="rgba(255, 0, 0, 0.5)",IT()}()}}})),console.log("Google Classroom Overlay registered")})()})();